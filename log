{'time': '2021-10-29 11:54:22.268268', 'sst-2_dev_eval_loss': 0.3773651123046875, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 0.3900911808013916, 'sst-2_test_eval_acc': 0.8142201834862385, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-10-13-roberta-large-26228', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_11-48-14_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-13-roberta-large-26228', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 12:01:02.669542', 'sst-2_dev_eval_loss': 0.18813666701316833, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.28726810216903687, 'sst-2_test_eval_acc': 0.8761467889908257, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-10-21-roberta-large-21377', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_11-54-33_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-21-roberta-large-21377', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 12:08:04.428164', 'sst-2_dev_eval_loss': 0.33715569972991943, 'sst-2_dev_eval_acc': 0.875, 'sst-2_test_eval_loss': 0.2926813066005707, 'sst-2_test_eval_acc': 0.8944954128440367, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-10-42-roberta-large-20299', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_12-01-14_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-42-roberta-large-20299', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 12:15:08.468418', 'sst-2_dev_eval_loss': 0.17740792036056519, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.30741554498672485, 'sst-2_test_eval_acc': 0.8772935779816514, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-10-87-roberta-large-24105', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_12-08-12_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-87-roberta-large-24105', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 12:24:03.656975', 'sst-2_dev_eval_loss': 0.22081083059310913, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.3369605243206024, 'sst-2_test_eval_acc': 0.8658256880733946, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-10-100-roberta-large-12317', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_12-17-03_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-100-roberta-large-12317', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 12:33:00.986475', 'sst-2_dev_eval_loss': 0.7424033284187317, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 0.5526729226112366, 'sst-2_test_eval_acc': 0.926605504587156, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-13-roberta-large-11682', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_12-24-16_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-13-roberta-large-11682', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 12:41:43.122257', 'sst-2_dev_eval_loss': 1.1097863912582397, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 0.6484587788581848, 'sst-2_test_eval_acc': 0.9220183486238532, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-13-roberta-large-2560', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_12-33-13_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-13-roberta-large-2560', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 12:49:22.665839', 'sst-2_dev_eval_loss': 0.6657127141952515, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.5242862105369568, 'sst-2_test_eval_acc': 0.9254587155963303, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-13-roberta-large-10047', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_12-41-55_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-13-roberta-large-10047', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 12:57:15.565674', 'sst-2_dev_eval_loss': 0.41329890489578247, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.3759898543357849, 'sst-2_test_eval_acc': 0.9174311926605505, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-13-roberta-large-25450', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_12-49-32_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-13-roberta-large-25450', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 13:05:12.243656', 'sst-2_dev_eval_loss': 0.5078533887863159, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 1.2572200298309326, 'sst-2_test_eval_acc': 0.8830275229357798, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-21-roberta-large-30764', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_12-57-26_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-21-roberta-large-30764', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 13:13:20.090918', 'sst-2_dev_eval_loss': 0.34311601519584656, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.76073157787323, 'sst-2_test_eval_acc': 0.9254587155963303, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-21-roberta-large-21121', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_13-05-25_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-21-roberta-large-21121', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 13:22:02.279837', 'sst-2_dev_eval_loss': 0.5539488792419434, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.6224682927131653, 'sst-2_test_eval_acc': 0.9197247706422018, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-21-roberta-large-15567', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_13-13-33_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-21-roberta-large-15567', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 13:30:40.099933', 'sst-2_dev_eval_loss': 0.3674478530883789, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.41801732778549194, 'sst-2_test_eval_acc': 0.9174311926605505, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-21-roberta-large-30597', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_13-22-13_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-21-roberta-large-30597', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 13:38:51.280204', 'sst-2_dev_eval_loss': 0.6283280849456787, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.6945906281471252, 'sst-2_test_eval_acc': 0.9128440366972477, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-42-roberta-large-9539', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_13-30-50_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-42-roberta-large-9539', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 13:47:08.704522', 'sst-2_dev_eval_loss': 0.9563190340995789, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 1.1318169832229614, 'sst-2_test_eval_acc': 0.8910550458715596, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-42-roberta-large-20104', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_13-39-01_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-42-roberta-large-20104', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 13:55:24.870306', 'sst-2_dev_eval_loss': 0.21768273413181305, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.4547143876552582, 'sst-2_test_eval_acc': 0.930045871559633, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-42-roberta-large-8104', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_13-47-19_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-42-roberta-large-8104', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 14:03:52.482803', 'sst-2_dev_eval_loss': 0.14950791001319885, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.34884417057037354, 'sst-2_test_eval_acc': 0.9254587155963303, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-42-roberta-large-19169', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_13-55-35_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-42-roberta-large-19169', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 14:12:42.973650', 'sst-2_dev_eval_loss': 1.0197670459747314, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 1.2855314016342163, 'sst-2_test_eval_acc': 0.893348623853211, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-87-roberta-large-6974', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_14-04-06_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-87-roberta-large-6974', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 14:21:20.156013', 'sst-2_dev_eval_loss': 0.4089920222759247, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.8925469517707825, 'sst-2_test_eval_acc': 0.8922018348623854, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-87-roberta-large-6799', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_14-12-54_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-87-roberta-large-6799', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 14:29:38.763345', 'sst-2_dev_eval_loss': 0.3766760230064392, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.547814130783081, 'sst-2_test_eval_acc': 0.9277522935779816, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-87-roberta-large-3230', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_14-21-32_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-87-roberta-large-3230', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 14:38:18.420408', 'sst-2_dev_eval_loss': 0.24594980478286743, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.3723231256008148, 'sst-2_test_eval_acc': 0.9220183486238532, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-87-roberta-large-22268', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_14-29-48_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-87-roberta-large-22268', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 14:47:26.659320', 'sst-2_dev_eval_loss': 1.6606785720796324e-05, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.777485728263855, 'sst-2_test_eval_acc': 0.9105504587155964, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-100-roberta-large-17392', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_14-38-35_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-100-roberta-large-17392', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 14:59:28.626086', 'sst-2_dev_eval_loss': 0.10141957551240921, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.5742713212966919, 'sst-2_test_eval_acc': 0.9185779816513762, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-100-roberta-large-15135', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_14-47-42_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-100-roberta-large-15135', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 15:10:28.560409', 'sst-2_dev_eval_loss': 0.008355976082384586, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.5165627002716064, 'sst-2_test_eval_acc': 0.9174311926605505, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-100-roberta-large-11531', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_14-59-42_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-100-roberta-large-11531', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 15:21:16.784413', 'sst-2_dev_eval_loss': 0.015503697097301483, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.3844255208969116, 'sst-2_test_eval_acc': 0.9059633027522935, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-100-roberta-large-2170', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_15-10-43_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-100-roberta-large-2170', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 15:30:08.277368', 'sst-2_dev_eval_loss': 1.2616087198257446, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 1.1362134218215942, 'sst-2_test_eval_acc': 0.8761467889908257, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-10-13-roberta-large-11533', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_15-21-34_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-13-roberta-large-11533', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 15:38:24.959990', 'sst-2_dev_eval_loss': 0.7867663502693176, 'sst-2_dev_eval_acc': 0.875, 'sst-2_test_eval_loss': 0.45290079712867737, 'sst-2_test_eval_acc': 0.9288990825688074, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-10-13-roberta-large-3019', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_15-30-21_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-13-roberta-large-3019', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 15:44:53.303020', 'sst-2_dev_eval_loss': 0.5054996609687805, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 0.3638515770435333, 'sst-2_test_eval_acc': 0.9174311926605505, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-10-13-roberta-large-6252', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_15-38-34_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-13-roberta-large-6252', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 15:51:23.504887', 'sst-2_dev_eval_loss': 0.2566402554512024, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.24299964308738708, 'sst-2_test_eval_acc': 0.9059633027522935, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-10-13-roberta-large-15292', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_15-45-04_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-13-roberta-large-15292', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 15:57:58.389164', 'sst-2_dev_eval_loss': 0.6169351935386658, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.7594805955886841, 'sst-2_test_eval_acc': 0.9185779816513762, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-10-21-roberta-large-29405', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_15-51-33_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-21-roberta-large-29405', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 16:04:57.067046', 'sst-2_dev_eval_loss': 0.32115769386291504, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.5180642604827881, 'sst-2_test_eval_acc': 0.9323394495412844, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-10-21-roberta-large-32062', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_15-58-08_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-21-roberta-large-32062', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 16:16:05.471494', 'sst-2_dev_eval_loss': 0.3158698081970215, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.4945354759693146, 'sst-2_test_eval_acc': 0.9243119266055045, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-10-21-roberta-large-23439', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_16-05-10_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-21-roberta-large-23439', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 16:28:13.750384', 'sst-2_dev_eval_loss': 0.25595492124557495, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.28313973546028137, 'sst-2_test_eval_acc': 0.9105504587155964, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-10-21-roberta-large-20298', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_16-16-27_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-21-roberta-large-20298', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 16:37:47.674849', 'sst-2_dev_eval_loss': 0.19053836166858673, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.5182707905769348, 'sst-2_test_eval_acc': 0.9311926605504587, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-10-42-roberta-large-2064', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_16-28-30_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-42-roberta-large-2064', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 16:47:33.660551', 'sst-2_dev_eval_loss': 0.2348829060792923, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.4607057571411133, 'sst-2_test_eval_acc': 0.9277522935779816, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-10-42-roberta-large-17236', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_16-38-05_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-42-roberta-large-17236', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 16:57:22.455264', 'sst-2_dev_eval_loss': 0.15261398255825043, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.3462110757827759, 'sst-2_test_eval_acc': 0.9277522935779816, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-10-42-roberta-large-16302', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_16-47-51_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-42-roberta-large-16302', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 17:07:08.328042', 'sst-2_dev_eval_loss': 0.11581618338823318, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.32536929845809937, 'sst-2_test_eval_acc': 0.9231651376146789, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-10-42-roberta-large-7148', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_16-57-36_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-42-roberta-large-7148', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 17:17:11.826905', 'sst-2_dev_eval_loss': 1.0008443593978882, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 1.1047545671463013, 'sst-2_test_eval_acc': 0.875, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-10-87-roberta-large-4093', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_17-07-30_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-87-roberta-large-4093', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 17:26:35.246190', 'sst-2_dev_eval_loss': 0.31557396054267883, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.4479246139526367, 'sst-2_test_eval_acc': 0.9323394495412844, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-10-87-roberta-large-17862', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_17-17-26_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-87-roberta-large-17862', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 17:36:15.075062', 'sst-2_dev_eval_loss': 0.2141798436641693, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.3916633725166321, 'sst-2_test_eval_acc': 0.9254587155963303, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-10-87-roberta-large-19380', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_17-26-47_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-87-roberta-large-19380', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 17:45:54.458365', 'sst-2_dev_eval_loss': 0.12192230671644211, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.2533302903175354, 'sst-2_test_eval_acc': 0.911697247706422, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-10-87-roberta-large-10283', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_17-36-29_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-87-roberta-large-10283', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 17:56:14.943301', 'sst-2_dev_eval_loss': 0.02303377538919449, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.8961069583892822, 'sst-2_test_eval_acc': 0.9048165137614679, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-10-100-roberta-large-20117', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_17-46-11_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-100-roberta-large-20117', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 18:05:59.534379', 'sst-2_dev_eval_loss': 0.0012726164422929287, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.5896416306495667, 'sst-2_test_eval_acc': 0.911697247706422, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-10-100-roberta-large-30702', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_17-56-31_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-100-roberta-large-30702', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 18:16:19.321551', 'sst-2_dev_eval_loss': 0.012543374672532082, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.4135039448738098, 'sst-2_test_eval_acc': 0.9059633027522935, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-10-100-roberta-large-11007', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_18-06-21_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-100-roberta-large-11007', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 18:26:48.851513', 'sst-2_dev_eval_loss': 0.02834344655275345, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.3104039430618286, 'sst-2_test_eval_acc': 0.908256880733945, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-10-100-roberta-large-19134', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_18-16-40_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-100-roberta-large-19134', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 18:42:56.960991', 'sst-2_dev_eval_loss': 0.7954939603805542, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 1.0002315044403076, 'sst-2_test_eval_acc': 0.9174311926605505, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-13-roberta-large-1150', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_18-29-19_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-13-roberta-large-1150', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 18:56:32.859557', 'sst-2_dev_eval_loss': 0.9855624437332153, 'sst-2_dev_eval_acc': 0.875, 'sst-2_test_eval_loss': 0.6249107122421265, 'sst-2_test_eval_acc': 0.9094036697247706, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-13-roberta-large-2923', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_18-43-20_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-13-roberta-large-2923', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 19:09:29.671418', 'sst-2_dev_eval_loss': 0.7064046859741211, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.5363993048667908, 'sst-2_test_eval_acc': 0.9231651376146789, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-13-roberta-large-8567', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_18-56-56_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-13-roberta-large-8567', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 19:22:12.185660', 'sst-2_dev_eval_loss': 0.5060297250747681, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.435854434967041, 'sst-2_test_eval_acc': 0.9197247706422018, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-13-roberta-large-20132', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_19-09-47_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-13-roberta-large-20132', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 19:35:19.279860', 'sst-2_dev_eval_loss': 0.8922183513641357, 'sst-2_dev_eval_acc': 0.84375, 'sst-2_test_eval_loss': 0.8815075159072876, 'sst-2_test_eval_acc': 0.8853211009174312, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-21-roberta-large-26641', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_19-22-58_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-21-roberta-large-26641', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 19:47:49.746262', 'sst-2_dev_eval_loss': 0.26630303263664246, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.8483836054801941, 'sst-2_test_eval_acc': 0.9197247706422018, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-21-roberta-large-24666', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_19-35-35_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-21-roberta-large-24666', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 20:00:02.906871', 'sst-2_dev_eval_loss': 0.4902361035346985, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.642687201499939, 'sst-2_test_eval_acc': 0.9288990825688074, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-21-roberta-large-24557', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_19-48-04_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-21-roberta-large-24557', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 20:12:36.083494', 'sst-2_dev_eval_loss': 0.35328659415245056, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.5401480197906494, 'sst-2_test_eval_acc': 0.9231651376146789, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-21-roberta-large-23942', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_20-00-19_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-21-roberta-large-23942', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 20:24:55.616668', 'sst-2_dev_eval_loss': 0.9307690858840942, 'sst-2_dev_eval_acc': 0.875, 'sst-2_test_eval_loss': 0.7793615460395813, 'sst-2_test_eval_acc': 0.8864678899082569, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-42-roberta-large-14657', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_20-12-52_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-42-roberta-large-14657', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 20:37:42.643973', 'sst-2_dev_eval_loss': 0.7045062780380249, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.8863751888275146, 'sst-2_test_eval_acc': 0.9185779816513762, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-42-roberta-large-21322', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_20-25-14_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-42-roberta-large-21322', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 20:50:00.061605', 'sst-2_dev_eval_loss': 0.24862633645534515, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.5039166212081909, 'sst-2_test_eval_acc': 0.930045871559633, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-42-roberta-large-21941', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_20-38-04_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-42-roberta-large-21941', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 21:02:15.255720', 'sst-2_dev_eval_loss': 0.15465539693832397, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.39812758564949036, 'sst-2_test_eval_acc': 0.9220183486238532, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-42-roberta-large-12352', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_20-50-19_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-42-roberta-large-12352', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 21:14:35.217128', 'sst-2_dev_eval_loss': 0.653649091720581, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 2.815058708190918, 'sst-2_test_eval_acc': 0.8027522935779816, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-87-roberta-large-3092', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_21-02-32_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-87-roberta-large-3092', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 21:26:44.126057', 'sst-2_dev_eval_loss': 0.9428974390029907, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.7415691018104553, 'sst-2_test_eval_acc': 0.9197247706422018, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-87-roberta-large-8949', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_21-14-51_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-87-roberta-large-8949', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 21:38:26.492976', 'sst-2_dev_eval_loss': 0.38931429386138916, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.5799045562744141, 'sst-2_test_eval_acc': 0.9277522935779816, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-87-roberta-large-5022', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_21-27-00_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-87-roberta-large-5022', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 21:50:18.075362', 'sst-2_dev_eval_loss': 0.30603981018066406, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.41937771439552307, 'sst-2_test_eval_acc': 0.9208715596330275, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-87-roberta-large-6362', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_21-38-42_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-87-roberta-large-6362', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 22:02:05.857694', 'sst-2_dev_eval_loss': 0.07098357379436493, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.5963809490203857, 'sst-2_test_eval_acc': 0.9128440366972477, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-100-roberta-large-18674', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_21-50-31_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-100-roberta-large-18674', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 22:02:28.179419', 'sst-2_dev_eval_loss': 1.127719759941101, 'sst-2_dev_eval_acc': 0.5, 'sst-2_test_eval_loss': 1.1660906076431274, 'sst-2_test_eval_acc': 0.5091743119266054, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--13-roberta-large-31582', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_22-01-48_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-31582', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'all', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 22:04:30.129453', 'sst-2_dev_eval_loss': 1.127719759941101, 'sst-2_dev_eval_acc': 0.5, 'sst-2_test_eval_loss': 1.1660906076431274, 'sst-2_test_eval_acc': 0.5091743119266054, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--13-roberta-large-4953', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_22-03-52_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-4953', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'all', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 22:14:02.370188', 'sst-2_dev_eval_loss': 0.11730846762657166, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.881989061832428, 'sst-2_test_eval_acc': 0.9220183486238532, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-100-roberta-large-1296', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_22-02-22_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-100-roberta-large-1296', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 22:17:38.501525', 'sst-2_dev_eval_loss': 1.127719759941101, 'sst-2_dev_eval_acc': 0.5, 'sst-2_test_eval_loss': 1.1660906076431274, 'sst-2_test_eval_acc': 0.5091743119266054, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--13-roberta-large-16232', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_22-17-03_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-16232', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'all', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 22:22:28.122844', 'sst-2_dev_eval_loss': 1.127719759941101, 'sst-2_dev_eval_acc': 0.5, 'sst-2_test_eval_loss': 1.1660906076431274, 'sst-2_test_eval_acc': 0.5091743119266054, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--13-roberta-large-1077', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_22-21-52_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-1077', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'all', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 22:25:34.146949', 'sst-2_dev_eval_loss': 0.003820872399955988, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.7167471647262573, 'sst-2_test_eval_acc': 0.9025229357798165, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-100-roberta-large-21111', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_22-14-16_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-100-roberta-large-21111', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 22:31:31.152416', 'sst-2_dev_eval_loss': 0.4468078911304474, 'sst-2_dev_eval_acc': 0.84375, 'sst-2_test_eval_loss': 0.5030831694602966, 'sst-2_test_eval_acc': 0.7557339449541285, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-20046', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_22-23-10_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-20046', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 22:37:29.436382', 'sst-2_dev_eval_loss': 0.012965627014636993, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.4383637011051178, 'sst-2_test_eval_acc': 0.911697247706422, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-100-roberta-large-2621', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_22-25-49_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-100-roberta-large-2621', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 22:40:17.666812', 'sst-2_dev_eval_loss': 0.4085879325866699, 'sst-2_dev_eval_acc': 0.875, 'sst-2_test_eval_loss': 0.6553938388824463, 'sst-2_test_eval_acc': 0.6926605504587156, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-31448', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_22-31-45_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-31448', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 22:48:26.899674', 'sst-2_dev_eval_loss': 0.5919574499130249, 'sst-2_dev_eval_acc': 0.75, 'sst-2_test_eval_loss': 0.5911914706230164, 'sst-2_test_eval_acc': 0.680045871559633, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-19077', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_22-40-31_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-19077', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 22:56:40.879095', 'sst-2_dev_eval_loss': 1.275490403175354, 'sst-2_dev_eval_acc': 0.65625, 'sst-2_test_eval_loss': 1.0853945016860962, 'sst-2_test_eval_acc': 0.6571100917431193, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-21-roberta-large-17847', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_22-48-39_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-21-roberta-large-17847', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 23:05:09.885888', 'sst-2_dev_eval_loss': 0.5926591753959656, 'sst-2_dev_eval_acc': 0.71875, 'sst-2_test_eval_loss': 0.5466280579566956, 'sst-2_test_eval_acc': 0.7236238532110092, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-21-roberta-large-20247', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_22-56-56_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-21-roberta-large-20247', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 23:13:21.251707', 'sst-2_dev_eval_loss': 0.654649019241333, 'sst-2_dev_eval_acc': 0.75, 'sst-2_test_eval_loss': 0.6034670472145081, 'sst-2_test_eval_acc': 0.7511467889908257, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-21-roberta-large-2996', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_23-05-25_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-21-roberta-large-2996', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 23:21:55.779386', 'sst-2_dev_eval_loss': 0.5153437256813049, 'sst-2_dev_eval_acc': 0.78125, 'sst-2_test_eval_loss': 0.5536253452301025, 'sst-2_test_eval_acc': 0.7557339449541285, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-18866', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_23-13-36_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-18866', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 23:30:10.784714', 'sst-2_dev_eval_loss': 0.6081357002258301, 'sst-2_dev_eval_acc': 0.75, 'sst-2_test_eval_loss': 0.6155980825424194, 'sst-2_test_eval_acc': 0.6788990825688074, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-15582', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_23-22-11_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-15582', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 23:38:02.566433', 'sst-2_dev_eval_loss': 0.4902292490005493, 'sst-2_dev_eval_acc': 0.8125, 'sst-2_test_eval_loss': 0.5939550399780273, 'sst-2_test_eval_acc': 0.7075688073394495, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-744', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_23-30-24_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-744', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 23:46:09.795106', 'sst-2_dev_eval_loss': 0.5514919757843018, 'sst-2_dev_eval_acc': 0.75, 'sst-2_test_eval_loss': 0.6415923237800598, 'sst-2_test_eval_acc': 0.6502293577981652, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-87-roberta-large-26456', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_23-38-17_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-87-roberta-large-26456', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 23:54:25.423340', 'sst-2_dev_eval_loss': 1.2147037982940674, 'sst-2_dev_eval_acc': 0.75, 'sst-2_test_eval_loss': 1.4415353536605835, 'sst-2_test_eval_acc': 0.6444954128440367, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-87-roberta-large-14693', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_23-46-24_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-87-roberta-large-14693', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 00:02:57.780292', 'sst-2_dev_eval_loss': 0.3752322196960449, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 0.4415360987186432, 'sst-2_test_eval_acc': 0.8073394495412844, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-87-roberta-large-6276', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_23-54-40_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-87-roberta-large-6276', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 00:11:42.769493', 'sst-2_dev_eval_loss': 0.6974568367004395, 'sst-2_dev_eval_acc': 0.8125, 'sst-2_test_eval_loss': 0.9709756374359131, 'sst-2_test_eval_acc': 0.6857798165137615, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-16059', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_00-03-12_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-16059', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 00:20:07.629619', 'sst-2_dev_eval_loss': 0.6588075757026672, 'sst-2_dev_eval_acc': 0.65625, 'sst-2_test_eval_loss': 0.5662373304367065, 'sst-2_test_eval_acc': 0.713302752293578, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-8541', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_00-11-57_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-8541', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 00:28:35.244101', 'sst-2_dev_eval_loss': 0.36251938343048096, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.5780166983604431, 'sst-2_test_eval_acc': 0.7454128440366973, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-27577', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_00-20-20_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-27577', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 00:37:34.048272', 'sst-2_dev_eval_loss': 0.8265790939331055, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 0.5527151823043823, 'sst-2_test_eval_acc': 0.9231651376146789, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--13-roberta-large-10489', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_00-28-50_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-10489', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 00:46:12.594589', 'sst-2_dev_eval_loss': 0.43118852376937866, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 0.5031181573867798, 'sst-2_test_eval_acc': 0.9334862385321101, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--13-roberta-large-31089', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_00-37-47_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-31089', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 00:54:47.522416', 'sst-2_dev_eval_loss': 0.8265790939331055, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 0.5527151823043823, 'sst-2_test_eval_acc': 0.9231651376146789, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--13-roberta-large-32181', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_00-46-24_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-32181', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 01:03:42.146266', 'sst-2_dev_eval_loss': 0.0011031104950234294, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.6747609972953796, 'sst-2_test_eval_acc': 0.9208715596330275, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--21-roberta-large-1467', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_00-55-00_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--21-roberta-large-1467', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 01:12:24.211734', 'sst-2_dev_eval_loss': 0.4730323851108551, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.46992042660713196, 'sst-2_test_eval_acc': 0.9346330275229358, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--21-roberta-large-23662', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_01-03-55_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--21-roberta-large-23662', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 01:21:21.369777', 'sst-2_dev_eval_loss': 0.0011031104950234294, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.6747609972953796, 'sst-2_test_eval_acc': 0.9208715596330275, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--21-roberta-large-9547', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_01-12-38_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--21-roberta-large-9547', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 01:30:33.913532', 'sst-2_dev_eval_loss': 0.007846829481422901, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.5578012466430664, 'sst-2_test_eval_acc': 0.9277522935779816, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--42-roberta-large-32310', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_01-21-36_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--42-roberta-large-32310', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 01:39:53.193372', 'sst-2_dev_eval_loss': 0.19351467490196228, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.46751248836517334, 'sst-2_test_eval_acc': 0.9254587155963303, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--42-roberta-large-30010', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_01-30-49_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--42-roberta-large-30010', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 01:49:02.018077', 'sst-2_dev_eval_loss': 0.007846829481422901, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.5578012466430664, 'sst-2_test_eval_acc': 0.9277522935779816, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--42-roberta-large-22218', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_01-40-07_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--42-roberta-large-22218', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 01:57:40.483654', 'sst-2_dev_eval_loss': 0.4396226108074188, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.7748415470123291, 'sst-2_test_eval_acc': 0.908256880733945, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--87-roberta-large-23971', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_01-49-14_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--87-roberta-large-23971', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 02:06:14.692638', 'sst-2_dev_eval_loss': 0.7094954252243042, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.8178085088729858, 'sst-2_test_eval_acc': 0.9174311926605505, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--87-roberta-large-2214', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_01-57-53_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--87-roberta-large-2214', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 02:14:52.122188', 'sst-2_dev_eval_loss': 0.4396226108074188, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.7748415470123291, 'sst-2_test_eval_acc': 0.908256880733945, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--87-roberta-large-21036', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_02-06-28_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--87-roberta-large-21036', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 02:23:45.447713', 'sst-2_dev_eval_loss': 7.242929132189602e-05, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.7634484767913818, 'sst-2_test_eval_acc': 0.9197247706422018, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--100-roberta-large-5714', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_02-15-07_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--100-roberta-large-5714', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 02:32:36.961529', 'sst-2_dev_eval_loss': 0.0025537547189742327, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.5683792233467102, 'sst-2_test_eval_acc': 0.930045871559633, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--100-roberta-large-4434', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_02-24-01_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--100-roberta-large-4434', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 02:41:20.456022', 'sst-2_dev_eval_loss': 7.242929132189602e-05, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.7634484767913818, 'sst-2_test_eval_acc': 0.9197247706422018, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--100-roberta-large-15582', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_02-32-51_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--100-roberta-large-15582', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 02:52:20.947241', 'sst-2_dev_eval_loss': 0.7183629870414734, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.6350259780883789, 'sst-2_test_eval_acc': 0.930045871559633, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--13-roberta-large-15914', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_02-41-36_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-15914', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 03:03:18.312883', 'sst-2_dev_eval_loss': 2.3264987468719482, 'sst-2_dev_eval_acc': 0.875, 'sst-2_test_eval_loss': 1.746672511100769, 'sst-2_test_eval_acc': 0.8864678899082569, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--13-roberta-large-6345', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_02-52-34_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-6345', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 03:14:24.030360', 'sst-2_dev_eval_loss': 0.13114327192306519, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.2201562523841858, 'sst-2_test_eval_acc': 0.9231651376146789, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--13-roberta-large-17741', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_03-03-35_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-17741', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 03:25:38.786155', 'sst-2_dev_eval_loss': 0.31572309136390686, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.8957540392875671, 'sst-2_test_eval_acc': 0.9254587155963303, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--21-roberta-large-4884', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_03-14-39_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--21-roberta-large-4884', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 03:36:50.551465', 'sst-2_dev_eval_loss': 1.086646556854248, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 1.2302329540252686, 'sst-2_test_eval_acc': 0.8738532110091743, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--21-roberta-large-5358', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_03-25-58_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--21-roberta-large-5358', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 03:47:54.254470', 'sst-2_dev_eval_loss': 0.3031473159790039, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.5362391471862793, 'sst-2_test_eval_acc': 0.9323394495412844, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--21-roberta-large-29758', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_03-37-05_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--21-roberta-large-29758', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 03:59:35.481008', 'sst-2_dev_eval_loss': 1.0769832134246826, 'sst-2_dev_eval_acc': 0.84375, 'sst-2_test_eval_loss': 0.7405440211296082, 'sst-2_test_eval_acc': 0.908256880733945, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--42-roberta-large-16343', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_03-48-09_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--42-roberta-large-16343', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 04:10:36.935871', 'sst-2_dev_eval_loss': 0.2725488245487213, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.7944315075874329, 'sst-2_test_eval_acc': 0.9059633027522935, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--42-roberta-large-28588', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_03-59-50_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--42-roberta-large-28588', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 04:21:39.435424', 'sst-2_dev_eval_loss': 0.1806878000497818, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.38460949063301086, 'sst-2_test_eval_acc': 0.9277522935779816, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--42-roberta-large-16681', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_04-10-54_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--42-roberta-large-16681', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 04:32:21.908436', 'sst-2_dev_eval_loss': 0.6884267330169678, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.810525119304657, 'sst-2_test_eval_acc': 0.9231651376146789, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--87-roberta-large-1239', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_04-21-55_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--87-roberta-large-1239', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 04:43:28.889859', 'sst-2_dev_eval_loss': 2.9085257053375244, 'sst-2_dev_eval_acc': 0.875, 'sst-2_test_eval_loss': 2.3110780715942383, 'sst-2_test_eval_acc': 0.8772935779816514, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--87-roberta-large-29623', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_04-32-37_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--87-roberta-large-29623', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 04:54:11.296025', 'sst-2_dev_eval_loss': 0.28896772861480713, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.31733468174934387, 'sst-2_test_eval_acc': 0.9208715596330275, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--87-roberta-large-23411', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_04-43-43_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--87-roberta-large-23411', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 05:05:28.485763', 'sst-2_dev_eval_loss': 0.013900868594646454, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.9667631387710571, 'sst-2_test_eval_acc': 0.9036697247706422, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--100-roberta-large-12586', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_04-54-27_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--100-roberta-large-12586', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 05:16:47.078243', 'sst-2_dev_eval_loss': 0.027139605954289436, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.9223499894142151, 'sst-2_test_eval_acc': 0.9002293577981652, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--100-roberta-large-11639', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_05-05-42_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--100-roberta-large-11639', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 05:27:52.069263', 'sst-2_dev_eval_loss': 0.013530482538044453, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.45456045866012573, 'sst-2_test_eval_acc': 0.9197247706422018, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--100-roberta-large-1985', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_05-17-03_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--100-roberta-large-1985', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 05:38:43.673990', 'sst-2_dev_eval_loss': 1.1528773307800293, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 0.9694678783416748, 'sst-2_test_eval_acc': 0.9094036697247706, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-21321', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_05-28-05_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-21321', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 05:49:43.282135', 'sst-2_dev_eval_loss': 0.7507412433624268, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 1.0094738006591797, 'sst-2_test_eval_acc': 0.8738532110091743, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-27281', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_05-38-59_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-27281', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 06:00:44.841064', 'sst-2_dev_eval_loss': 0.2990998923778534, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.45840317010879517, 'sst-2_test_eval_acc': 0.9231651376146789, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-16477', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_05-49-55_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-16477', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 06:12:03.133787', 'sst-2_dev_eval_loss': 0.4092846214771271, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.9426609873771667, 'sst-2_test_eval_acc': 0.9139908256880734, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-21-roberta-large-9560', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_06-01-00_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-21-roberta-large-9560', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 06:23:10.278464', 'sst-2_dev_eval_loss': 0.2025197148323059, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.7025768756866455, 'sst-2_test_eval_acc': 0.9208715596330275, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-21-roberta-large-29338', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_06-12-19_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-21-roberta-large-29338', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 06:34:27.455057', 'sst-2_dev_eval_loss': 0.34203916788101196, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.40176329016685486, 'sst-2_test_eval_acc': 0.9277522935779816, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-21-roberta-large-2854', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_06-23-26_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-21-roberta-large-2854', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 06:45:51.820815', 'sst-2_dev_eval_loss': 0.009613839909434319, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.7138524055480957, 'sst-2_test_eval_acc': 0.9197247706422018, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-30048', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_06-34-43_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-30048', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 06:57:03.125965', 'sst-2_dev_eval_loss': 0.0044067371636629105, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.9280872344970703, 'sst-2_test_eval_acc': 0.9174311926605505, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-31573', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_06-46-05_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-31573', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 07:08:23.942864', 'sst-2_dev_eval_loss': 0.08033523708581924, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.5662437677383423, 'sst-2_test_eval_acc': 0.9139908256880734, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-7198', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_06-57-19_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-7198', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 07:19:38.801667', 'sst-2_dev_eval_loss': 0.983453631401062, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 1.3442968130111694, 'sst-2_test_eval_acc': 0.8956422018348624, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-87-roberta-large-11984', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_07-08-39_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-87-roberta-large-11984', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 07:30:45.937069', 'sst-2_dev_eval_loss': 0.399929404258728, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 0.4245765507221222, 'sst-2_test_eval_acc': 0.875, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-87-roberta-large-29522', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_07-19-53_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-87-roberta-large-29522', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 07:42:03.034367', 'sst-2_dev_eval_loss': 0.2985263466835022, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.35862645506858826, 'sst-2_test_eval_acc': 0.9094036697247706, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-87-roberta-large-4110', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_07-31-03_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-87-roberta-large-4110', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 07:52:58.134031', 'sst-2_dev_eval_loss': 0.00012573467392940074, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.9413406848907471, 'sst-2_test_eval_acc': 0.9174311926605505, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-23813', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_07-42-15_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-23813', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 08:04:05.811126', 'sst-2_dev_eval_loss': 0.4725898802280426, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.8497094511985779, 'sst-2_test_eval_acc': 0.875, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-371', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_07-53-13_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-371', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 08:15:22.100708', 'sst-2_dev_eval_loss': 0.12514086067676544, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.5276971459388733, 'sst-2_test_eval_acc': 0.9174311926605505, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-21755', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_08-04-19_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-21755', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 08:24:26.396649', 'sst-2_dev_eval_loss': 0.7439283728599548, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.9388284683227539, 'sst-2_test_eval_acc': 0.8990825688073395, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-1181', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_08-15-39_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-1181', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 08:33:11.317111', 'sst-2_dev_eval_loss': 0.8709073066711426, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 0.6270284652709961, 'sst-2_test_eval_acc': 0.9220183486238532, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-1872', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_08-24-42_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-1872', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 08:41:56.479506', 'sst-2_dev_eval_loss': 0.19818782806396484, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.25675100088119507, 'sst-2_test_eval_acc': 0.9174311926605505, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-26024', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_08-33-24_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-26024', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 08:51:00.734841', 'sst-2_dev_eval_loss': 0.6872036457061768, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.6293572783470154, 'sst-2_test_eval_acc': 0.9357798165137615, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-21-roberta-large-16734', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_08-42-11_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-21-roberta-large-16734', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 08:59:58.459344', 'sst-2_dev_eval_loss': 0.7818633317947388, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.7700827121734619, 'sst-2_test_eval_acc': 0.9231651376146789, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-21-roberta-large-4664', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_08-51-14_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-21-roberta-large-4664', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 09:08:55.835596', 'sst-2_dev_eval_loss': 0.32967039942741394, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 0.26289260387420654, 'sst-2_test_eval_acc': 0.9231651376146789, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-21-roberta-large-13849', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_09-00-12_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-21-roberta-large-13849', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 09:17:52.382758', 'sst-2_dev_eval_loss': 0.16915880143642426, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.8015191555023193, 'sst-2_test_eval_acc': 0.9036697247706422, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-190', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_09-09-08_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-190', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 09:27:12.453995', 'sst-2_dev_eval_loss': 0.06180200353264809, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.7488133311271667, 'sst-2_test_eval_acc': 0.908256880733945, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-25399', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_09-18-07_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-25399', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 09:36:02.125340', 'sst-2_dev_eval_loss': 0.1042618677020073, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.435287743806839, 'sst-2_test_eval_acc': 0.9048165137614679, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-18038', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_09-27-27_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-18038', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 09:45:02.768320', 'sst-2_dev_eval_loss': 0.907878041267395, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.898109495639801, 'sst-2_test_eval_acc': 0.9185779816513762, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-87-roberta-large-665', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_09-36-16_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-87-roberta-large-665', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 09:53:59.334485', 'sst-2_dev_eval_loss': 0.7435100674629211, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.9659531116485596, 'sst-2_test_eval_acc': 0.8990825688073395, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-87-roberta-large-20579', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_09-45-16_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-87-roberta-large-20579', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 10:02:52.471884', 'sst-2_dev_eval_loss': 0.30291998386383057, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 0.3704282343387604, 'sst-2_test_eval_acc': 0.8704128440366973, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-87-roberta-large-16763', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_09-54-14_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-87-roberta-large-16763', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 10:11:24.331114', 'sst-2_dev_eval_loss': 0.12557341158390045, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.6518628001213074, 'sst-2_test_eval_acc': 0.9071100917431193, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-8029', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_10-03-05_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-8029', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 10:20:12.563029', 'sst-2_dev_eval_loss': 0.002617131220176816, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.7005869746208191, 'sst-2_test_eval_acc': 0.911697247706422, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-15689', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_10-11-38_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-15689', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 10:29:07.158895', 'sst-2_dev_eval_loss': 0.09182731807231903, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.28957846760749817, 'sst-2_test_eval_acc': 0.9139908256880734, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-28505', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_10-20-25_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-28505', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 10:40:31.919225', 'sst-2_dev_eval_loss': 0.5346472859382629, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 0.6400929093360901, 'sst-2_test_eval_acc': 0.9197247706422018, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--13-roberta-large-10756', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_10-29-21_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-10756', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 10:52:11.819301', 'sst-2_dev_eval_loss': 0.7045474648475647, 'sst-2_dev_eval_acc': 0.5, 'sst-2_test_eval_loss': 0.707400381565094, 'sst-2_test_eval_acc': 0.4908256880733945, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--13-roberta-large-3178', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_10-40-45_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-3178', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 11:04:01.724460', 'sst-2_dev_eval_loss': 0.19934120774269104, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.28581660985946655, 'sst-2_test_eval_acc': 0.926605504587156, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--13-roberta-large-20209', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_10-52-27_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-20209', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 11:15:34.291998', 'sst-2_dev_eval_loss': 0.25644955039024353, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.4706142544746399, 'sst-2_test_eval_acc': 0.9346330275229358, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--21-roberta-large-1390', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_11-04-19_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--21-roberta-large-1390', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 11:27:18.575859', 'sst-2_dev_eval_loss': 0.7395016551017761, 'sst-2_dev_eval_acc': 0.5, 'sst-2_test_eval_loss': 0.7452185153961182, 'sst-2_test_eval_acc': 0.4908256880733945, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--21-roberta-large-16991', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_11-15-51_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--21-roberta-large-16991', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 11:39:05.369547', 'sst-2_dev_eval_loss': 0.2821928858757019, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.5478283166885376, 'sst-2_test_eval_acc': 0.9357798165137615, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--21-roberta-large-8451', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_11-27-35_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--21-roberta-large-8451', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 11:50:09.260594', 'sst-2_dev_eval_loss': 0.44164061546325684, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.8501307368278503, 'sst-2_test_eval_acc': 0.9208715596330275, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--42-roberta-large-28768', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_11-39-19_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--42-roberta-large-28768', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 12:01:03.230622', 'sst-2_dev_eval_loss': 1.6768324375152588, 'sst-2_dev_eval_acc': 0.875, 'sst-2_test_eval_loss': 1.25934636592865, 'sst-2_test_eval_acc': 0.8727064220183486, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--42-roberta-large-4809', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_11-50-23_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--42-roberta-large-4809', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 12:11:49.431977', 'sst-2_dev_eval_loss': 0.17868618667125702, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.39066824316978455, 'sst-2_test_eval_acc': 0.9288990825688074, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--42-roberta-large-21726', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_12-01-18_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--42-roberta-large-21726', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 12:22:03.508107', 'sst-2_dev_eval_loss': 1.2510591745376587, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 1.1897550821304321, 'sst-2_test_eval_acc': 0.8922018348623854, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--87-roberta-large-27764', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_12-12-01_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--87-roberta-large-27764', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 12:33:15.811432', 'sst-2_dev_eval_loss': 0.887117326259613, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 1.2042804956436157, 'sst-2_test_eval_acc': 0.8084862385321101, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--87-roberta-large-20609', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_12-22-16_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--87-roberta-large-20609', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 12:43:45.609277', 'sst-2_dev_eval_loss': 0.4039379060268402, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.5168851613998413, 'sst-2_test_eval_acc': 0.9231651376146789, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--87-roberta-large-4910', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_12-33-30_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--87-roberta-large-4910', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 12:54:04.839719', 'sst-2_dev_eval_loss': 7.502219523303211e-05, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.9987448453903198, 'sst-2_test_eval_acc': 0.911697247706422, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--100-roberta-large-5623', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_12-44-01_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--100-roberta-large-5623', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 13:04:46.341134', 'sst-2_dev_eval_loss': 0.6001089215278625, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 1.6007647514343262, 'sst-2_test_eval_acc': 0.8864678899082569, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--100-roberta-large-18553', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_12-54-20_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--100-roberta-large-18553', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 13:15:37.783572', 'sst-2_dev_eval_loss': 0.06603702157735825, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.3362184464931488, 'sst-2_test_eval_acc': 0.9197247706422018, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--100-roberta-large-13512', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_13-04-59_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--100-roberta-large-13512', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 13:26:06.719681', 'sst-2_dev_eval_loss': 1.0443706512451172, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 0.8652612566947937, 'sst-2_test_eval_acc': 0.9094036697247706, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-13271', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_13-15-54_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-13271', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 13:36:45.539326', 'sst-2_dev_eval_loss': 0.6986694931983948, 'sst-2_dev_eval_acc': 0.5, 'sst-2_test_eval_loss': 0.7005983591079712, 'sst-2_test_eval_acc': 0.4908256880733945, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-25265', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_13-26-21_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-25265', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 13:47:44.848565', 'sst-2_dev_eval_loss': 0.19890554249286652, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.36201703548431396, 'sst-2_test_eval_acc': 0.9197247706422018, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-15518', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_13-36-57_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-15518', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 13:58:39.401854', 'sst-2_dev_eval_loss': 1.1121753454208374, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 0.9819356799125671, 'sst-2_test_eval_acc': 0.908256880733945, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-21-roberta-large-10673', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_13-47-57_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-21-roberta-large-10673', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 14:09:46.161645', 'sst-2_dev_eval_loss': 0.831653892993927, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 1.2713574171066284, 'sst-2_test_eval_acc': 0.8784403669724771, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-21-roberta-large-16772', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_13-58-52_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-21-roberta-large-16772', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 14:20:23.483080', 'sst-2_dev_eval_loss': 0.4292961061000824, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.43985551595687866, 'sst-2_test_eval_acc': 0.9277522935779816, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-21-roberta-large-30036', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_14-10-00_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-21-roberta-large-30036', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 14:31:46.899104', 'sst-2_dev_eval_loss': 0.8304372429847717, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 0.5689888596534729, 'sst-2_test_eval_acc': 0.9197247706422018, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-5991', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_14-20-39_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-5991', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 14:42:46.285703', 'sst-2_dev_eval_loss': 0.7646454572677612, 'sst-2_dev_eval_acc': 0.5, 'sst-2_test_eval_loss': 0.7576253414154053, 'sst-2_test_eval_acc': 0.5091743119266054, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-28592', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_14-32-02_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-28592', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 14:52:35.503285', 'sst-2_dev_eval_loss': 0.3668482005596161, 'sst-2_dev_eval_acc': 0.8125, 'sst-2_test_eval_loss': 0.3679763078689575, 'sst-2_test_eval_acc': 0.8360091743119266, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--13-roberta-large-29481', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_14-52-05_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-29481', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'all', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 14:53:28.771526', 'sst-2_dev_eval_loss': 0.10043936967849731, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.5484496355056763, 'sst-2_test_eval_acc': 0.9128440366972477, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-30880', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_14-42-58_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-30880', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 15:01:40.030492', 'cola_dev_eval_loss': 0.9494186043739319, 'cola_dev_eval_mcc': 0.1889822365046136, 'cola_test_eval_loss': 0.7721861004829407, 'cola_test_eval_mcc': 0.022067101449159066, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--13-roberta-large-25101', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_15-01-08_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-25101', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'all', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 15:03:51.970239', 'sst-2_dev_eval_loss': 1.0713622570037842, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 1.5896962881088257, 'sst-2_test_eval_acc': 0.8761467889908257, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-87-roberta-large-11978', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_14-53-42_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-87-roberta-large-11978', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 15:10:26.403122', 'cola_dev_eval_loss': 2.15047550201416, 'cola_dev_eval_mcc': 0.18786728732554486, 'cola_test_eval_loss': 2.723461389541626, 'cola_test_eval_mcc': 0.002327667096204007, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-6427', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_15-02-23_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-6427', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 15:14:50.288203', 'sst-2_dev_eval_loss': 1.2264364957809448, 'sst-2_dev_eval_acc': 0.875, 'sst-2_test_eval_loss': 1.3166863918304443, 'sst-2_test_eval_acc': 0.8589449541284404, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-87-roberta-large-8410', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_15-04-03_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-87-roberta-large-8410', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 15:17:38.980040', 'cola_dev_eval_loss': 0.8225656747817993, 'cola_dev_eval_mcc': 0.20851441405707474, 'cola_test_eval_loss': 0.8481382131576538, 'cola_test_eval_mcc': -0.004821487463052175, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-28128', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_15-10-40_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-28128', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 15:25:04.965440', 'sst-2_dev_eval_loss': 0.45304155349731445, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.5131089687347412, 'sst-2_test_eval_acc': 0.9174311926605505, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-87-roberta-large-3976', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_15-15-01_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-87-roberta-large-3976', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 15:25:29.774782', 'cola_dev_eval_loss': 0.687289834022522, 'cola_dev_eval_mcc': 0.5163977794943222, 'cola_test_eval_loss': 0.8773282766342163, 'cola_test_eval_mcc': 0.0059212002386345415, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-28826', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_15-17-53_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-28826', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 15:33:46.283440', 'cola_dev_eval_loss': 0.753375768661499, 'cola_dev_eval_mcc': 0.40451991747794525, 'cola_test_eval_loss': 1.0804458856582642, 'cola_test_eval_mcc': -0.06710117044559215, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-21-roberta-large-24737', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_15-25-44_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-21-roberta-large-24737', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 15:36:23.699161', 'sst-2_dev_eval_loss': 0.09321676939725876, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 1.047671914100647, 'sst-2_test_eval_acc': 0.9208715596330275, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-18244', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_15-25-18_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-18244', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 15:41:27.302094', 'cola_dev_eval_loss': 0.6846048831939697, 'cola_dev_eval_mcc': 0.48038446141526137, 'cola_test_eval_loss': 0.7214452624320984, 'cola_test_eval_mcc': -0.01353995115492936, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-21-roberta-large-4536', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_15-33-59_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-21-roberta-large-4536', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 15:46:54.324126', 'sst-2_dev_eval_loss': 0.00026411228463985026, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.7397996187210083, 'sst-2_test_eval_acc': 0.9208715596330275, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-27244', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_15-36-37_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-27244', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 15:49:19.808362', 'cola_dev_eval_loss': 1.065861463546753, 'cola_dev_eval_mcc': 0.25819888974716115, 'cola_test_eval_loss': 1.3759485483169556, 'cola_test_eval_mcc': -0.06029853283595914, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-21-roberta-large-5214', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_15-41-38_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-21-roberta-large-5214', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 15:57:05.470442', 'cola_dev_eval_loss': 0.703203022480011, 'cola_dev_eval_mcc': 0.31814238148788887, 'cola_test_eval_loss': 0.8137380480766296, 'cola_test_eval_mcc': 0.02081929121300342, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-8020', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_15-49-33_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-8020', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 15:58:16.122163', 'sst-2_dev_eval_loss': 0.14964839816093445, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.5701166987419128, 'sst-2_test_eval_acc': 0.9185779816513762, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-1859', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_15-47-08_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-1859', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 16:04:29.041291', 'cola_dev_eval_loss': 0.8291659951210022, 'cola_dev_eval_mcc': -0.06262242910851495, 'cola_test_eval_loss': 0.8912036418914795, 'cola_test_eval_mcc': 0.015164886608486137, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-12406', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_15-57-21_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-12406', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 16:11:43.596502', 'cola_dev_eval_loss': 0.8902494311332703, 'cola_dev_eval_mcc': 0.07559289460184544, 'cola_test_eval_loss': 1.0167704820632935, 'cola_test_eval_mcc': 0.06880556417853113, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-5728', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_16-04-39_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-5728', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 16:19:15.541537', 'cola_dev_eval_loss': 0.808090329170227, 'cola_dev_eval_mcc': 0.22677868380553634, 'cola_test_eval_loss': 0.7052857279777527, 'cola_test_eval_mcc': -0.02156188721031119, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-87-roberta-large-27996', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_16-11-56_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-87-roberta-large-27996', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 16:26:45.348783', 'cola_dev_eval_loss': 1.8579163551330566, 'cola_dev_eval_mcc': 0.22677868380553634, 'cola_test_eval_loss': 2.072610855102539, 'cola_test_eval_mcc': -0.014316991321430212, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-87-roberta-large-5490', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_16-19-29_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-87-roberta-large-5490', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 16:34:06.881318', 'cola_dev_eval_loss': 0.9453266859054565, 'cola_dev_eval_mcc': -0.1259881576697424, 'cola_test_eval_loss': 0.9130507707595825, 'cola_test_eval_mcc': -0.04017046538576979, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-87-roberta-large-22059', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_16-26-57_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-87-roberta-large-22059', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 16:41:20.761801', 'cola_dev_eval_loss': 1.0318745374679565, 'cola_dev_eval_mcc': 0.3216337604513384, 'cola_test_eval_loss': 0.8564050793647766, 'cola_test_eval_mcc': -0.037379655264689206, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-23531', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_16-34-20_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-23531', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 16:49:16.886981', 'cola_dev_eval_loss': 0.6374201774597168, 'cola_dev_eval_mcc': 0.31311214554257477, 'cola_test_eval_loss': 0.7807929515838623, 'cola_test_eval_mcc': 0.026411418801770368, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-28913', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_16-41-34_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-28913', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 17:00:35.523542', 'cola_dev_eval_loss': 0.7497915625572205, 'cola_dev_eval_mcc': 0.37796447300922725, 'cola_test_eval_loss': 0.9818110466003418, 'cola_test_eval_mcc': 0.016385611650580112, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-29752', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_16-49-40_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-29752', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 17:12:11.876186', 'cola_dev_eval_loss': 2.9811105728149414, 'cola_dev_eval_mcc': 0.19738550848793068, 'cola_test_eval_loss': 5.307530403137207, 'cola_test_eval_mcc': -0.04017046538576979, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--13-roberta-large-5520', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_17-00-54_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-5520', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 17:23:57.742260', 'cola_dev_eval_loss': 3.897552013397217, 'cola_dev_eval_mcc': 0.14433756729740646, 'cola_test_eval_loss': 3.5735697746276855, 'cola_test_eval_mcc': 0.013478520925728866, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--13-roberta-large-30218', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_17-12-34_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-30218', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 17:35:49.251443', 'cola_dev_eval_loss': 2.9811105728149414, 'cola_dev_eval_mcc': 0.19738550848793068, 'cola_test_eval_loss': 5.307530403137207, 'cola_test_eval_mcc': -0.04017046538576979, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--13-roberta-large-27014', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_17-24-18_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-27014', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 17:47:14.991370', 'cola_dev_eval_loss': 3.7920637130737305, 'cola_dev_eval_mcc': 0.06262242910851495, 'cola_test_eval_loss': 3.629507064819336, 'cola_test_eval_mcc': 0.04213206366664149, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--21-roberta-large-24611', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_17-36-08_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--21-roberta-large-24611', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 17:58:36.396969', 'cola_dev_eval_loss': 3.689846992492676, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 3.0839357376098633, 'cola_test_eval_mcc': 0.041391483016143815, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--21-roberta-large-299', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_17-47-35_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--21-roberta-large-299', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 18:09:28.487279', 'cola_dev_eval_loss': 3.7920637130737305, 'cola_dev_eval_mcc': 0.06262242910851495, 'cola_test_eval_loss': 3.629507064819336, 'cola_test_eval_mcc': 0.04213206366664149, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--21-roberta-large-434', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_17-58-55_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--21-roberta-large-434', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 18:20:02.801484', 'cola_dev_eval_loss': 2.937812566757202, 'cola_dev_eval_mcc': 0.31814238148788887, 'cola_test_eval_loss': 3.6747891902923584, 'cola_test_eval_mcc': 0.03761181881231492, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--42-roberta-large-14774', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_18-09-43_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-14774', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 18:31:37.906902', 'cola_dev_eval_loss': 2.4458513259887695, 'cola_dev_eval_mcc': 0.31814238148788887, 'cola_test_eval_loss': 2.8854877948760986, 'cola_test_eval_mcc': 0.003992939933304405, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--42-roberta-large-1768', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_18-20-21_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-1768', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 18:43:16.067150', 'cola_dev_eval_loss': 2.937812566757202, 'cola_dev_eval_mcc': 0.31814238148788887, 'cola_test_eval_loss': 3.6747891902923584, 'cola_test_eval_mcc': 0.03761181881231492, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--42-roberta-large-7969', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_18-32-00_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-7969', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-30 18:54:46.112565', 'cola_dev_eval_loss': 5.610970973968506, 'cola_dev_eval_mcc': -0.06362847629757777, 'cola_test_eval_loss': 5.102104663848877, 'cola_test_eval_mcc': 0.08662645235966238, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--87-roberta-large-19221', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct30_18-43-33_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--87-roberta-large-19221', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 01:09:14.242121', 'cola_dev_eval_loss': 5.007694244384766, 'cola_dev_eval_mcc': 0.125, 'cola_test_eval_loss': 7.784728527069092, 'cola_test_eval_mcc': -0.03208714935088473, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--13-roberta-large-27791', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_01-00-26_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-27791', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 01:16:49.176953', 'cola_dev_eval_loss': 5.488154411315918, 'cola_dev_eval_mcc': 0.14433756729740646, 'cola_test_eval_loss': 7.380643844604492, 'cola_test_eval_mcc': 0.10740841489063019, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--13-roberta-large-11763', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_01-09-26_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-11763', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 01:38:09.889301', 'cola_dev_eval_loss': 2.2657103538513184, 'cola_dev_eval_mcc': -0.0657951694959769, 'cola_test_eval_loss': 2.5461270809173584, 'cola_test_eval_mcc': 0.027368247672189008, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--13-roberta-large-382', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_01-17-01_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-382', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 02:01:00.658016', 'cola_dev_eval_loss': 4.038242816925049, 'cola_dev_eval_mcc': -0.13483997249264842, 'cola_test_eval_loss': 2.301572322845459, 'cola_test_eval_mcc': 0.06806120640169684, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--21-roberta-large-4083', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_01-38-41_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--21-roberta-large-4083', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 02:26:09.370493', 'cola_dev_eval_loss': 7.501317501068115, 'cola_dev_eval_mcc': 0.12909944487358055, 'cola_test_eval_loss': 5.882197380065918, 'cola_test_eval_mcc': 0.12008388000067936, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--21-roberta-large-26798', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_02-01-34_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--21-roberta-large-26798', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 02:48:36.989713', 'cola_dev_eval_loss': 2.5840542316436768, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 2.0470528602600098, 'cola_test_eval_mcc': 0.05464392981324288, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--21-roberta-large-31977', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_02-26-43_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--21-roberta-large-31977', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 03:13:26.254517', 'cola_dev_eval_loss': 2.405468225479126, 'cola_dev_eval_mcc': 0.629940788348712, 'cola_test_eval_loss': 3.1367361545562744, 'cola_test_eval_mcc': 0.13920453077193884, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--42-roberta-large-10305', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_02-49-13_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-10305', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 03:37:26.378110', 'cola_dev_eval_loss': 4.079829216003418, 'cola_dev_eval_mcc': 0.31311214554257477, 'cola_test_eval_loss': 4.69291353225708, 'cola_test_eval_mcc': 0.07860013951896609, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--42-roberta-large-5185', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_03-14-02_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-5185', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 04:00:15.490023', 'cola_dev_eval_loss': 1.8110935688018799, 'cola_dev_eval_mcc': 0.3779644730092272, 'cola_test_eval_loss': 2.48710036277771, 'cola_test_eval_mcc': 0.024404843297653255, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--42-roberta-large-18840', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_03-38-01_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-18840', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 04:21:46.428946', 'cola_dev_eval_loss': 4.87306547164917, 'cola_dev_eval_mcc': 0.16012815380508713, 'cola_test_eval_loss': 4.0667643547058105, 'cola_test_eval_mcc': 0.07886467602714639, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--87-roberta-large-29530', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_04-00-48_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--87-roberta-large-29530', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 04:46:02.839628', 'cola_dev_eval_loss': 9.586450576782227, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 8.441275596618652, 'cola_test_eval_mcc': 0.17117779951912074, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--87-roberta-large-6639', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_04-22-19_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--87-roberta-large-6639', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 05:08:42.063314', 'cola_dev_eval_loss': 2.639753818511963, 'cola_dev_eval_mcc': 0.12909944487358055, 'cola_test_eval_loss': 2.7910938262939453, 'cola_test_eval_mcc': 0.06812999983459382, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--87-roberta-large-20759', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_04-46-36_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--87-roberta-large-20759', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 05:31:40.533178', 'cola_dev_eval_loss': 2.648798704147339, 'cola_dev_eval_mcc': 0.31814238148788887, 'cola_test_eval_loss': 3.911705493927002, 'cola_test_eval_mcc': 0.13909234522830197, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--100-roberta-large-27266', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_05-09-17_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-27266', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 05:53:56.063748', 'cola_dev_eval_loss': 3.1490888595581055, 'cola_dev_eval_mcc': 0.19738550848793068, 'cola_test_eval_loss': 2.3430192470550537, 'cola_test_eval_mcc': 0.2514273674713439, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--100-roberta-large-26355', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_05-32-10_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-26355', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 06:14:31.966084', 'cola_dev_eval_loss': 0.8124458193778992, 'cola_dev_eval_mcc': 0.592156525463792, 'cola_test_eval_loss': 1.2079871892929077, 'cola_test_eval_mcc': 0.07229259996801789, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--100-roberta-large-32610', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_05-54-23_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-32610', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 06:35:34.741174', 'cola_dev_eval_loss': 3.390559434890747, 'cola_dev_eval_mcc': 0.16012815380508713, 'cola_test_eval_loss': 2.8196487426757812, 'cola_test_eval_mcc': -0.0025813664570153694, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-15805', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_06-15-04_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-15805', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 06:58:23.116872', 'cola_dev_eval_loss': 2.9966249465942383, 'cola_dev_eval_mcc': 0.125, 'cola_test_eval_loss': 4.306641101837158, 'cola_test_eval_mcc': 0.08786294524989008, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-3201', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_06-36-06_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-3201', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 07:20:46.590085', 'cola_dev_eval_loss': 3.633681535720825, 'cola_dev_eval_mcc': 0.16012815380508713, 'cola_test_eval_loss': 2.811039447784424, 'cola_test_eval_mcc': 0.0013725843745189608, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-7716', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_06-58-55_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-7716', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 07:42:35.233984', 'cola_dev_eval_loss': 5.905216693878174, 'cola_dev_eval_mcc': 0.2886751345948129, 'cola_test_eval_loss': 6.302436828613281, 'cola_test_eval_mcc': 0.05654021706947046, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-21-roberta-large-19222', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_07-21-16_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-21-roberta-large-19222', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 08:04:09.023155', 'cola_dev_eval_loss': 0.7243688702583313, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.8202895522117615, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-21-roberta-large-30650', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_07-43-08_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-21-roberta-large-30650', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 08:27:02.442338', 'cola_dev_eval_loss': 1.8752169609069824, 'cola_dev_eval_mcc': 0.2519763153394848, 'cola_test_eval_loss': 1.631614327430725, 'cola_test_eval_mcc': 0.10722608142055544, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-21-roberta-large-18767', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_08-04-41_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-21-roberta-large-18767', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 08:49:22.756102', 'cola_dev_eval_loss': 4.271081447601318, 'cola_dev_eval_mcc': 0.32025630761017426, 'cola_test_eval_loss': 6.9608988761901855, 'cola_test_eval_mcc': 0.06790303560227395, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-5766', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_08-27-34_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-5766', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 09:19:53.597733', 'cola_dev_eval_loss': 2.9811105728149414, 'cola_dev_eval_mcc': 0.19738550848793068, 'cola_test_eval_loss': 5.307530403137207, 'cola_test_eval_mcc': -0.04017046538576979, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--13-roberta-large-5701', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_09-02-19_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-5701', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 09:36:26.358820', 'cola_dev_eval_loss': 3.897552013397217, 'cola_dev_eval_mcc': 0.14433756729740646, 'cola_test_eval_loss': 3.5735697746276855, 'cola_test_eval_mcc': 0.013478520925728866, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--13-roberta-large-29042', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_09-20-21_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-29042', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 09:53:09.611641', 'cola_dev_eval_loss': 2.9648683071136475, 'cola_dev_eval_mcc': 0.06950480468569159, 'cola_test_eval_loss': 2.9121899604797363, 'cola_test_eval_mcc': 0.009135772469106344, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--13-roberta-large-11495', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_09-36-56_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-11495', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 10:10:56.014692', 'cola_dev_eval_loss': 3.7920637130737305, 'cola_dev_eval_mcc': 0.06262242910851495, 'cola_test_eval_loss': 3.629507064819336, 'cola_test_eval_mcc': 0.04213206366664149, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--21-roberta-large-23068', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_09-53-39_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--21-roberta-large-23068', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 10:27:51.758344', 'cola_dev_eval_loss': 3.689846992492676, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 3.0839357376098633, 'cola_test_eval_mcc': 0.041391483016143815, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--21-roberta-large-24751', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_10-11-24_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--21-roberta-large-24751', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 10:45:16.775113', 'cola_dev_eval_loss': 1.0217869281768799, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.9375280737876892, 'cola_test_eval_mcc': 0.01284891837826528, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--21-roberta-large-11012', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_10-28-23_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--21-roberta-large-11012', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 11:02:00.288099', 'cola_dev_eval_loss': 2.937812566757202, 'cola_dev_eval_mcc': 0.31814238148788887, 'cola_test_eval_loss': 3.6747891902923584, 'cola_test_eval_mcc': 0.03761181881231492, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--42-roberta-large-18692', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_10-45-45_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-18692', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 11:19:19.400576', 'cola_dev_eval_loss': 2.4458513259887695, 'cola_dev_eval_mcc': 0.31814238148788887, 'cola_test_eval_loss': 2.8854877948760986, 'cola_test_eval_mcc': 0.003992939933304405, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--42-roberta-large-16549', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_11-02-29_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-16549', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 11:36:25.842303', 'cola_dev_eval_loss': 1.2448512315750122, 'cola_dev_eval_mcc': 0.31311214554257477, 'cola_test_eval_loss': 1.5884716510772705, 'cola_test_eval_mcc': 0.01128995600364935, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--42-roberta-large-13427', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_11-19-48_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-13427', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 11:53:18.874653', 'cola_dev_eval_loss': 5.610970973968506, 'cola_dev_eval_mcc': -0.06362847629757777, 'cola_test_eval_loss': 5.102104663848877, 'cola_test_eval_mcc': 0.08662645235966238, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--87-roberta-large-29643', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_11-36-56_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--87-roberta-large-29643', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 12:09:21.660218', 'cola_dev_eval_loss': 2.5196852684020996, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 3.3184540271759033, 'cola_test_eval_mcc': 0.07269879903640734, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--87-roberta-large-5280', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_11-53-45_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--87-roberta-large-5280', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 12:26:23.365160', 'cola_dev_eval_loss': 1.9716994762420654, 'cola_dev_eval_mcc': -0.06262242910851495, 'cola_test_eval_loss': 2.2237095832824707, 'cola_test_eval_mcc': 0.02153410832696622, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--87-roberta-large-25849', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_12-09-50_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--87-roberta-large-25849', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 12:42:48.228301', 'cola_dev_eval_loss': 2.727900981903076, 'cola_dev_eval_mcc': 0.4383570037596047, 'cola_test_eval_loss': 3.8393590450286865, 'cola_test_eval_mcc': 0.08365596584613585, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--100-roberta-large-2737', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_12-26-52_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-2737', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 12:59:50.260471', 'cola_dev_eval_loss': 1.3527722358703613, 'cola_dev_eval_mcc': 0.31311214554257477, 'cola_test_eval_loss': 1.7246723175048828, 'cola_test_eval_mcc': 0.0350522008290228, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--100-roberta-large-15151', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_12-43-16_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-15151', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 13:14:59.868843', 'cola_dev_eval_loss': 0.6870499849319458, 'cola_dev_eval_mcc': 0.592156525463792, 'cola_test_eval_loss': 1.0338594913482666, 'cola_test_eval_mcc': 0.050421074811524996, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--100-roberta-large-8130', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_13-00-18_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-8130', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 13:37:22.542705', 'cola_dev_eval_loss': 4.9385552406311035, 'cola_dev_eval_mcc': 0.08606629658238704, 'cola_test_eval_loss': 3.9633588790893555, 'cola_test_eval_mcc': 0.016997960426542797, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--13-roberta-large-8248', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_13-15-30_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-8248', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 13:59:43.757160', 'cola_dev_eval_loss': 0.7142105102539062, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.7930415272712708, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--13-roberta-large-27760', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_13-42-54_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-27760', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 14:00:04.441095', 'cola_dev_eval_loss': 5.589451789855957, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 5.9419989585876465, 'cola_test_eval_mcc': 0.061939616110094145, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--13-roberta-large-30268', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_13-37-55_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-30268', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 14:16:18.968852', 'cola_dev_eval_loss': 3.999427080154419, 'cola_dev_eval_mcc': 0.19088542889273333, 'cola_test_eval_loss': 6.052587985992432, 'cola_test_eval_mcc': -0.02013428050343557, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--13-roberta-large-31901', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_14-00-13_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-31901', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 14:21:27.576789', 'cola_dev_eval_loss': 1.282652735710144, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 1.2105680704116821, 'cola_test_eval_mcc': 0.013221719361375632, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--13-roberta-large-9168', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_14-00-41_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-9168', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 14:33:15.479892', 'cola_dev_eval_loss': 1.043601393699646, 'cola_dev_eval_mcc': 0.19738550848793068, 'cola_test_eval_loss': 1.1265615224838257, 'cola_test_eval_mcc': 0.02719591010185443, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--13-roberta-large-10020', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_14-16-46_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-10020', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 14:42:59.652067', 'cola_dev_eval_loss': 4.756782531738281, 'cola_dev_eval_mcc': 0.06262242910851495, 'cola_test_eval_loss': 3.4809207916259766, 'cola_test_eval_mcc': 0.1153095175877232, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--21-roberta-large-28007', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_14-22-02_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--21-roberta-large-28007', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 14:51:21.677053', 'cola_dev_eval_loss': 0.7987695932388306, 'cola_dev_eval_mcc': 0.19088542889273333, 'cola_test_eval_loss': 0.9243009686470032, 'cola_test_eval_mcc': -0.003075585125491812, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--13-roberta-large-27926', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_14-33-45_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-27926', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 15:04:09.593011', 'cola_dev_eval_loss': 6.161351203918457, 'cola_dev_eval_mcc': 0.06262242910851495, 'cola_test_eval_loss': 4.73671293258667, 'cola_test_eval_mcc': 0.12830244968474244, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--21-roberta-large-7955', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_14-43-32_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--21-roberta-large-7955', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 15:07:46.645321', 'cola_dev_eval_loss': 0.7051123380661011, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.7645838260650635, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--21-roberta-large-18595', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_14-51-55_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--21-roberta-large-18595', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 15:23:35.974777', 'cola_dev_eval_loss': 6.060238361358643, 'cola_dev_eval_mcc': -0.0657951694959769, 'cola_test_eval_loss': 4.070684909820557, 'cola_test_eval_mcc': 0.02296626218821298, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--21-roberta-large-7387', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_15-08-15_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--21-roberta-large-7387', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 15:24:47.147027', 'cola_dev_eval_loss': 3.381784677505493, 'cola_dev_eval_mcc': 0.06262242910851495, 'cola_test_eval_loss': 2.648324728012085, 'cola_test_eval_mcc': 0.06285570361060565, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--21-roberta-large-18973', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_15-04-42_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--21-roberta-large-18973', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 15:41:33.923998', 'cola_dev_eval_loss': 0.8043450117111206, 'cola_dev_eval_mcc': 0.1259881576697424, 'cola_test_eval_loss': 0.8540807962417603, 'cola_test_eval_mcc': -0.014506283767817275, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--21-roberta-large-28064', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_15-24-05_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--21-roberta-large-28064', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 15:46:40.823483', 'cola_dev_eval_loss': 2.344430923461914, 'cola_dev_eval_mcc': 0.3779644730092272, 'cola_test_eval_loss': 3.148549795150757, 'cola_test_eval_mcc': 0.09472663093639469, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--42-roberta-large-16665', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_15-25-21_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-16665', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 15:59:01.300024', 'cola_dev_eval_loss': 0.774040162563324, 'cola_dev_eval_mcc': 0.19088542889273333, 'cola_test_eval_loss': 0.8338170647621155, 'cola_test_eval_mcc': -0.019037565541124325, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--21-roberta-large-23794', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_15-42-03_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--21-roberta-large-23794', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 16:09:28.405638', 'cola_dev_eval_loss': 2.799478054046631, 'cola_dev_eval_mcc': 0.3872983346207417, 'cola_test_eval_loss': 3.920445680618286, 'cola_test_eval_mcc': 0.14347606891532197, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--42-roberta-large-9961', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_15-47-12_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-9961', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 16:16:04.020411', 'cola_dev_eval_loss': 0.7623770236968994, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.9062744975090027, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--42-roberta-large-31213', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_15-59-33_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-31213', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 16:32:42.300217', 'cola_dev_eval_loss': 1.1772499084472656, 'cola_dev_eval_mcc': 0.31311214554257477, 'cola_test_eval_loss': 1.4629839658737183, 'cola_test_eval_mcc': 0.023290059906339155, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--42-roberta-large-26467', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_16-10-03_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-26467', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 16:33:25.490435', 'cola_dev_eval_loss': 3.671113967895508, 'cola_dev_eval_mcc': 0.2519763153394848, 'cola_test_eval_loss': 3.962229013442993, 'cola_test_eval_mcc': 0.12829974762194854, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--42-roberta-large-32151', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_16-16-35_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-32151', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 16:51:33.355214', 'cola_dev_eval_loss': 1.0647878646850586, 'cola_dev_eval_mcc': 0.18786728732554486, 'cola_test_eval_loss': 1.2498350143432617, 'cola_test_eval_mcc': 0.015503265447197241, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--42-roberta-large-21580', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_16-33-55_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-21580', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 16:55:15.384936', 'cola_dev_eval_loss': 3.5744776725769043, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 4.514816761016846, 'cola_test_eval_mcc': 0.011279083323635539, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--87-roberta-large-13534', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_16-33-13_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--87-roberta-large-13534', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 17:09:04.151628', 'cola_dev_eval_loss': 0.7882834672927856, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.8798031806945801, 'cola_test_eval_mcc': -0.044282311862980185, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--42-roberta-large-22797', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_16-52-02_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-22797', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 17:16:42.217324', 'cola_dev_eval_loss': 9.391464233398438, 'cola_dev_eval_mcc': 0.1889822365046136, 'cola_test_eval_loss': 5.718145370483398, 'cola_test_eval_mcc': 0.14745403829221004, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--87-roberta-large-16873', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_16-55-50_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--87-roberta-large-16873', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 17:26:02.534626', 'cola_dev_eval_loss': 0.7314908504486084, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.6249635815620422, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--87-roberta-large-11093', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_17-09-37_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--87-roberta-large-11093', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 17:38:04.726435', 'cola_dev_eval_loss': 2.4403133392333984, 'cola_dev_eval_mcc': 0.19738550848793068, 'cola_test_eval_loss': 2.4436662197113037, 'cola_test_eval_mcc': 0.06892233459426672, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--87-roberta-large-14147', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_17-17-13_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--87-roberta-large-14147', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 17:43:06.492807', 'cola_dev_eval_loss': 5.726707458496094, 'cola_dev_eval_mcc': -0.19088542889273333, 'cola_test_eval_loss': 3.7057504653930664, 'cola_test_eval_mcc': 0.02689325752685812, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--87-roberta-large-3090', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_17-26-33_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--87-roberta-large-3090', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 17:58:18.350583', 'cola_dev_eval_loss': 2.074016809463501, 'cola_dev_eval_mcc': 0.3779644730092272, 'cola_test_eval_loss': 2.69958758354187, 'cola_test_eval_mcc': 0.14983009943788278, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--100-roberta-large-11694', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_17-38-38_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-11694', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 18:00:04.473496', 'cola_dev_eval_loss': 1.3527092933654785, 'cola_dev_eval_mcc': -0.06262242910851495, 'cola_test_eval_loss': 1.4309426546096802, 'cola_test_eval_mcc': 0.004860299153684483, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--87-roberta-large-15659', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_17-43-33_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--87-roberta-large-15659', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 18:17:17.924350', 'cola_dev_eval_loss': 0.8868062496185303, 'cola_dev_eval_mcc': -0.25, 'cola_test_eval_loss': 0.8831107020378113, 'cola_test_eval_mcc': -0.029811879657757286, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--87-roberta-large-6844', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_18-00-37_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--87-roberta-large-6844', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 18:19:34.021389', 'cola_dev_eval_loss': 3.2267961502075195, 'cola_dev_eval_mcc': 0.2519763153394848, 'cola_test_eval_loss': 2.887993097305298, 'cola_test_eval_mcc': 0.12179121960611036, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--100-roberta-large-23102', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_17-58-48_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-23102', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 18:34:35.464725', 'cola_dev_eval_loss': 0.7036404609680176, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.7591602802276611, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--100-roberta-large-24479', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_18-17-47_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-24479', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 18:40:43.334709', 'cola_dev_eval_loss': 0.7220141887664795, 'cola_dev_eval_mcc': 0.5393598899705937, 'cola_test_eval_loss': 0.9961373805999756, 'cola_test_eval_mcc': 0.08674441403415814, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--100-roberta-large-2210', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_18-20-09_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-2210', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 18:50:50.909634', 'cola_dev_eval_loss': 3.2281439304351807, 'cola_dev_eval_mcc': 0.2581988897471611, 'cola_test_eval_loss': 4.352757453918457, 'cola_test_eval_mcc': 0.06438507609753406, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--100-roberta-large-12129', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_18-35-04_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-12129', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 19:02:13.748002', 'cola_dev_eval_loss': 2.7934494018554688, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 4.870992660522461, 'cola_test_eval_mcc': 0.012200847128768986, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-9379', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_18-41-17_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-9379', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 19:07:34.043613', 'cola_dev_eval_loss': 0.6437829732894897, 'cola_dev_eval_mcc': 0.6454972243679028, 'cola_test_eval_loss': 0.8975153565406799, 'cola_test_eval_mcc': 0.03124076858819477, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--100-roberta-large-14648', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_18-51-19_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-14648', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 19:23:12.756323', 'cola_dev_eval_loss': 3.410135269165039, 'cola_dev_eval_mcc': 0.19738550848793068, 'cola_test_eval_loss': 6.54339075088501, 'cola_test_eval_mcc': 0.06546898588791382, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-21797', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_19-02-48_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-21797', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 19:24:45.858802', 'cola_dev_eval_loss': 0.6331508159637451, 'cola_dev_eval_mcc': 0.6454972243679028, 'cola_test_eval_loss': 0.8732837438583374, 'cola_test_eval_mcc': 0.015250050854703214, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--100-roberta-large-2375', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_19-08-02_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-2375', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 19:45:33.583799', 'cola_dev_eval_loss': 2.150653123855591, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 1.9211914539337158, 'cola_test_eval_mcc': -0.0022288396942593304, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-16739', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_19-23-42_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-16739', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 20:09:36.442315', 'cola_dev_eval_loss': 0.6951679587364197, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.7194653153419495, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--13-roberta-large-15552', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_19-51-07_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-15552', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 20:09:52.487492', 'cola_dev_eval_loss': 4.761052131652832, 'cola_dev_eval_mcc': 0.2581988897471611, 'cola_test_eval_loss': 3.4537904262542725, 'cola_test_eval_mcc': 0.14473544389563828, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-21-roberta-large-3880', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_19-46-07_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-21-roberta-large-3880', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 20:31:10.419113', 'cola_dev_eval_loss': 5.181133270263672, 'cola_dev_eval_mcc': 0.06262242910851495, 'cola_test_eval_loss': 4.068702220916748, 'cola_test_eval_mcc': 0.06767056899674591, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-21-roberta-large-3467', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_20-10-26_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-21-roberta-large-3467', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 20:31:54.501368', 'cola_dev_eval_loss': 0.6946326494216919, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.7155183553695679, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--13-roberta-large-21439', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_20-10-10_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-21439', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 20:52:30.316228', 'cola_dev_eval_loss': 2.6029326915740967, 'cola_dev_eval_mcc': 0.2519763153394848, 'cola_test_eval_loss': 2.1081135272979736, 'cola_test_eval_mcc': 0.1266933317443712, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-21-roberta-large-4393', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_20-31-44_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-21-roberta-large-4393', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 20:53:18.951291', 'cola_dev_eval_loss': 4.65083122253418, 'cola_dev_eval_mcc': 0.08606629658238704, 'cola_test_eval_loss': 3.589735984802246, 'cola_test_eval_mcc': 0.020486952109793892, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--13-roberta-large-6858', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_20-32-30_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-6858', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 21:15:46.780027', 'cola_dev_eval_loss': 0.6935673356056213, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.6823409795761108, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--21-roberta-large-26866', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_20-53-51_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--21-roberta-large-26866', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 21:16:03.071912', 'cola_dev_eval_loss': 2.0075182914733887, 'cola_dev_eval_mcc': 0.5726562866782, 'cola_test_eval_loss': 2.7683029174804688, 'cola_test_eval_mcc': 0.08250633713033333, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-30968', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_20-53-09_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-30968', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 21:38:02.110982', 'cola_dev_eval_loss': 0.6951754093170166, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.6708582043647766, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--21-roberta-large-17842', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_21-16-20_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--21-roberta-large-17842', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 21:38:18.270714', 'cola_dev_eval_loss': 5.880026817321777, 'cola_dev_eval_mcc': 0.1796053020267749, 'cola_test_eval_loss': 3.6241681575775146, 'cola_test_eval_mcc': 0.14044820662671217, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-5155', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_21-16-36_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-5155', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 21:59:27.331997', 'cola_dev_eval_loss': 1.4962303638458252, 'cola_dev_eval_mcc': 0.31311214554257477, 'cola_test_eval_loss': 1.7196190357208252, 'cola_test_eval_mcc': 0.07657311135558306, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-30208', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_21-38-51_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-30208', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 22:00:03.255803', 'cola_dev_eval_loss': 4.047131061553955, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 2.995558261871338, 'cola_test_eval_mcc': 0.05651605612059193, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--21-roberta-large-13026', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_21-38-36_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--21-roberta-large-13026', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 22:20:56.565429', 'cola_dev_eval_loss': 0.7117478847503662, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.7858231067657471, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--42-roberta-large-25919', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_22-00-34_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-25919', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 22:22:15.721446', 'cola_dev_eval_loss': 5.613089561462402, 'cola_dev_eval_mcc': 0.14433756729740646, 'cola_test_eval_loss': 6.305272579193115, 'cola_test_eval_mcc': 0.05363786683064096, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-87-roberta-large-32622', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_22-00-00_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-87-roberta-large-32622', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 22:42:44.223577', 'cola_dev_eval_loss': 0.69855135679245, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.7383003830909729, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--42-roberta-large-29307', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_22-21-27_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-29307', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 22:43:53.026765', 'cola_dev_eval_loss': 0.7022057175636292, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.6506048440933228, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-87-roberta-large-28627', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_22-22-51_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-87-roberta-large-28627', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 23:05:00.132032', 'cola_dev_eval_loss': 3.760925531387329, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 3.1121346950531006, 'cola_test_eval_mcc': 0.055254872718697653, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-87-roberta-large-24429', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_22-44-27_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-87-roberta-large-24429', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 23:05:06.510669', 'cola_dev_eval_loss': 2.0511269569396973, 'cola_dev_eval_mcc': 0.31311214554257477, 'cola_test_eval_loss': 2.8441689014434814, 'cola_test_eval_mcc': 0.045550170209454295, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--42-roberta-large-32209', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_22-43-15_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-32209', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 23:26:06.426729', 'cola_dev_eval_loss': 0.693179190158844, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.6962409615516663, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--87-roberta-large-4193', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_23-05-46_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--87-roberta-large-4193', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 23:26:30.036624', 'cola_dev_eval_loss': 3.121990442276001, 'cola_dev_eval_mcc': 0.19738550848793068, 'cola_test_eval_loss': 3.530487298965454, 'cola_test_eval_mcc': 0.17520541995655226, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-17991', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_23-05-33_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-17991', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 23:47:07.934472', 'cola_dev_eval_loss': 5.512284278869629, 'cola_dev_eval_mcc': 0.2886751345948129, 'cola_test_eval_loss': 7.295788764953613, 'cola_test_eval_mcc': 0.13811032573996337, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-32527', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_23-27-03_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-32527', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-31 23:48:13.304889', 'cola_dev_eval_loss': 0.7039878368377686, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.760383665561676, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--87-roberta-large-21102', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_23-26-37_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--87-roberta-large-21102', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 00:08:29.796567', 'cola_dev_eval_loss': 5.239169120788574, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 4.741489887237549, 'cola_test_eval_mcc': 0.06310120951306152, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--87-roberta-large-31194', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_23-48-46_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--87-roberta-large-31194', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 00:08:57.838951', 'cola_dev_eval_loss': 0.7799239158630371, 'cola_dev_eval_mcc': 0.375, 'cola_test_eval_loss': 0.9334949851036072, 'cola_test_eval_mcc': 0.053092729198220515, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-29901', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct31_23-47-40_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-29901', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 00:26:31.693758', 'cola_dev_eval_loss': 2.784471273422241, 'cola_dev_eval_mcc': 0.16012815380508713, 'cola_test_eval_loss': 3.0923967361450195, 'cola_test_eval_mcc': 0.04166445924287233, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-15070', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_00-09-35_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-15070', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 00:29:55.873495', 'cola_dev_eval_loss': 0.7010707855224609, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.7492052912712097, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--100-roberta-large-7575', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_00-09-00_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-7575', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 00:42:28.934818', 'cola_dev_eval_loss': 2.166879653930664, 'cola_dev_eval_mcc': 0.2519763153394848, 'cola_test_eval_loss': 3.6890244483947754, 'cola_test_eval_mcc': 0.05847641771146506, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-22907', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_00-27-02_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-22907', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 00:48:09.974404', 'cola_dev_eval_loss': 0.6962528228759766, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.7266483902931213, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--100-roberta-large-17814', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_00-30-27_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-17814', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 00:56:11.524642', 'cola_dev_eval_loss': 1.414435625076294, 'cola_dev_eval_mcc': 0.06950480468569159, 'cola_test_eval_loss': 1.4360320568084717, 'cola_test_eval_mcc': 0.028487460941303652, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-12176', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_00-42-52_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-12176', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 01:04:19.197989', 'cola_dev_eval_loss': 1.6344481706619263, 'cola_dev_eval_mcc': 0.3779644730092272, 'cola_test_eval_loss': 2.320298910140991, 'cola_test_eval_mcc': 0.06192947565400458, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--100-roberta-large-13187', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_00-48-33_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-13187', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 01:09:35.728009', 'cola_dev_eval_loss': 3.898210287094116, 'cola_dev_eval_mcc': 0.19088542889273333, 'cola_test_eval_loss': 3.512728452682495, 'cola_test_eval_mcc': 0.03826578330139463, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-21-roberta-large-18749', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_00-56-33_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-21-roberta-large-18749', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 01:22:00.287037', 'cola_dev_eval_loss': 3.5368247032165527, 'cola_dev_eval_mcc': 0.2581988897471611, 'cola_test_eval_loss': 3.8457889556884766, 'cola_test_eval_mcc': 0.02108889476836773, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-21-roberta-large-31589', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_01-09-57_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-21-roberta-large-31589', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 01:33:36.735270', 'cola_dev_eval_loss': 0.7100868225097656, 'cola_dev_eval_mcc': 0.18786728732554486, 'cola_test_eval_loss': 0.8524028062820435, 'cola_test_eval_mcc': -0.012011668791665235, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-21-roberta-large-5474', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_01-22-22_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-21-roberta-large-5474', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 01:43:43.215777', 'cola_dev_eval_loss': 2.4304747581481934, 'cola_dev_eval_mcc': 0.2581988897471611, 'cola_test_eval_loss': 3.1871676445007324, 'cola_test_eval_mcc': 0.01029747168884776, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-201', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_01-33-57_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-201', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 01:52:46.205434', 'cola_dev_eval_loss': 2.469069719314575, 'cola_dev_eval_mcc': 0.31311214554257477, 'cola_test_eval_loss': 3.080420732498169, 'cola_test_eval_mcc': 0.02073254809770125, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-14472', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_01-43-59_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-14472', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 02:00:35.796561', 'cola_dev_eval_loss': 0.902134895324707, 'cola_dev_eval_mcc': 0.0657951694959769, 'cola_test_eval_loss': 0.9258516430854797, 'cola_test_eval_mcc': 0.03578227240558791, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-28119', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_01-53-00_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-28119', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 02:08:29.488694', 'cola_dev_eval_loss': 4.24666690826416, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 4.194563388824463, 'cola_test_eval_mcc': 0.014848629714250272, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-87-roberta-large-25160', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_02-00-49_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-87-roberta-large-25160', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 02:15:58.478550', 'cola_dev_eval_loss': 5.746255397796631, 'cola_dev_eval_mcc': 0.07559289460184544, 'cola_test_eval_loss': 6.217563152313232, 'cola_test_eval_mcc': 0.03011485814423695, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-87-roberta-large-53', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_02-08-43_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-87-roberta-large-53', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 02:23:05.465799', 'cola_dev_eval_loss': 1.701391339302063, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 1.5726735591888428, 'cola_test_eval_mcc': -0.01458620407508954, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-87-roberta-large-8201', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_02-16-11_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-87-roberta-large-8201', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 02:29:48.942986', 'cola_dev_eval_loss': 3.082878589630127, 'cola_dev_eval_mcc': 0.1259881576697424, 'cola_test_eval_loss': 3.3614389896392822, 'cola_test_eval_mcc': 0.05456141685553711, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-24358', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_02-23-19_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-24358', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 02:36:39.249184', 'cola_dev_eval_loss': 2.352787971496582, 'cola_dev_eval_mcc': 0.12909944487358055, 'cola_test_eval_loss': 2.74277400970459, 'cola_test_eval_mcc': 0.1184418077607741, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-24571', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_02-30-02_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-24571', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 02:43:16.283441', 'cola_dev_eval_loss': 0.7693402171134949, 'cola_dev_eval_mcc': 0.5726562866782, 'cola_test_eval_loss': 0.97257399559021, 'cola_test_eval_mcc': 0.03543537775471986, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-28106', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_02-36-51_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-28106', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 02:52:00.040837', 'cola_dev_eval_loss': 4.271081447601318, 'cola_dev_eval_mcc': 0.32025630761017426, 'cola_test_eval_loss': 6.9608988761901855, 'cola_test_eval_mcc': 0.06790303560227395, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-6189', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_02-43-31_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-6189', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 03:00:46.055300', 'cola_dev_eval_loss': 0.7144298553466797, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.7936180830001831, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-9892', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_02-52-13_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-9892', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 03:09:30.400847', 'cola_dev_eval_loss': 1.463849425315857, 'cola_dev_eval_mcc': 0.31311214554257477, 'cola_test_eval_loss': 1.8894213438034058, 'cola_test_eval_mcc': 0.05967951992863991, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-13272', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_03-00-58_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-13272', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 03:18:22.656123', 'cola_dev_eval_loss': 7.529117584228516, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 7.844552040100098, 'cola_test_eval_mcc': 0.09736520571667104, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-87-roberta-large-11738', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_03-09-43_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-87-roberta-large-11738', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 03:26:58.362951', 'cola_dev_eval_loss': 6.410223960876465, 'cola_dev_eval_mcc': -0.14433756729740646, 'cola_test_eval_loss': 6.53762149810791, 'cola_test_eval_mcc': 0.025755672585352832, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-87-roberta-large-8256', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_03-18-36_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-87-roberta-large-8256', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 03:35:52.577909', 'cola_dev_eval_loss': 2.6415493488311768, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 2.5114457607269287, 'cola_test_eval_mcc': 0.03131613525128643, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-87-roberta-large-8195', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_03-27-12_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-87-roberta-large-8195', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 03:45:12.862047', 'cola_dev_eval_loss': 1.7629565000534058, 'cola_dev_eval_mcc': 0.6999132392733555, 'cola_test_eval_loss': 2.236502170562744, 'cola_test_eval_mcc': 0.3164614552047354, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-10627', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_03-36-05_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-10627', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 03:53:45.047592', 'cola_dev_eval_loss': 0.7388781905174255, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.8553237318992615, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-3205', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_03-45-26_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-3205', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 04:02:21.042824', 'cola_dev_eval_loss': 0.8785101175308228, 'cola_dev_eval_mcc': 0.18786728732554486, 'cola_test_eval_loss': 1.0657461881637573, 'cola_test_eval_mcc': 0.023906912578341318, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-19828', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_03-53-58_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-19828', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 04:08:40.871504', 'cola_dev_eval_loss': 3.0985069274902344, 'cola_dev_eval_mcc': 0.2886751345948129, 'cola_test_eval_loss': 3.0633420944213867, 'cola_test_eval_mcc': 0.017053897067501995, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--13-roberta-large-10604', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_04-02-35_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-10604', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 04:15:00.252532', 'cola_dev_eval_loss': 1.1032071113586426, 'cola_dev_eval_mcc': 0.0657951694959769, 'cola_test_eval_loss': 1.544362187385559, 'cola_test_eval_mcc': 0.025105097850353104, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--13-roberta-large-25349', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_04-08-53_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-25349', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 04:21:15.244141', 'cola_dev_eval_loss': 0.6224433779716492, 'cola_dev_eval_mcc': 0.3779644730092272, 'cola_test_eval_loss': 0.7304348349571228, 'cola_test_eval_mcc': 0.031045687963647612, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--13-roberta-large-3403', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_04-15-11_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-3403', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 04:27:11.406947', 'cola_dev_eval_loss': 2.521181106567383, 'cola_dev_eval_mcc': 0.37796447300922725, 'cola_test_eval_loss': 2.2089521884918213, 'cola_test_eval_mcc': 0.17725871643406393, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--21-roberta-large-25265', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_04-21-26_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--21-roberta-large-25265', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 04:33:06.573800', 'cola_dev_eval_loss': 2.7345199584960938, 'cola_dev_eval_mcc': 0.40451991747794525, 'cola_test_eval_loss': 2.3607280254364014, 'cola_test_eval_mcc': 0.24006602064196175, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--21-roberta-large-18832', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_04-27-22_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--21-roberta-large-18832', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 04:39:11.962888', 'cola_dev_eval_loss': 1.7742246389389038, 'cola_dev_eval_mcc': 0.26967994498529685, 'cola_test_eval_loss': 1.5478792190551758, 'cola_test_eval_mcc': 0.1340995761496152, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--21-roberta-large-16878', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_04-33-17_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--21-roberta-large-16878', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 04:45:18.098491', 'cola_dev_eval_loss': 4.339003562927246, 'cola_dev_eval_mcc': 0.18786728732554486, 'cola_test_eval_loss': 4.060433864593506, 'cola_test_eval_mcc': 0.03915163091540927, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--42-roberta-large-19623', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_04-39-23_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-19623', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 04:51:11.587690', 'cola_dev_eval_loss': 1.5174323320388794, 'cola_dev_eval_mcc': 0.31311214554257477, 'cola_test_eval_loss': 1.9847087860107422, 'cola_test_eval_mcc': 0.06656211570576546, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--42-roberta-large-7296', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_04-45-29_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-7296', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 04:57:27.334089', 'cola_dev_eval_loss': 0.8419206142425537, 'cola_dev_eval_mcc': 0.2886751345948129, 'cola_test_eval_loss': 0.8407335877418518, 'cola_test_eval_mcc': 0.008696971007386667, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--42-roberta-large-7769', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_04-51-22_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-7769', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 05:03:23.387159', 'cola_dev_eval_loss': 6.746086120605469, 'cola_dev_eval_mcc': -0.125, 'cola_test_eval_loss': 5.2202959060668945, 'cola_test_eval_mcc': 0.05713735503189502, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--87-roberta-large-22621', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_04-57-39_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--87-roberta-large-22621', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 05:09:07.901787', 'cola_dev_eval_loss': 4.030379772186279, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 3.6148438453674316, 'cola_test_eval_mcc': 0.06829937683893118, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--87-roberta-large-25125', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_05-03-35_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--87-roberta-large-25125', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 05:14:53.667902', 'cola_dev_eval_loss': 1.6417763233184814, 'cola_dev_eval_mcc': -0.06262242910851495, 'cola_test_eval_loss': 1.468072772026062, 'cola_test_eval_mcc': 0.03097809753400038, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--87-roberta-large-22965', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_05-09-18_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--87-roberta-large-22965', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 05:20:40.351945', 'cola_dev_eval_loss': 0.7126659154891968, 'cola_dev_eval_mcc': 0.6888467201936644, 'cola_test_eval_loss': 1.5535186529159546, 'cola_test_eval_mcc': 0.35316529017155296, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--100-roberta-large-6073', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_05-15-04_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-6073', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 05:26:19.721580', 'cola_dev_eval_loss': 2.304274320602417, 'cola_dev_eval_mcc': 0.19738550848793068, 'cola_test_eval_loss': 2.4452667236328125, 'cola_test_eval_mcc': 0.15488036894219614, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--100-roberta-large-23862', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_05-20-51_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-23862', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 05:32:14.048369', 'cola_dev_eval_loss': 1.797541618347168, 'cola_dev_eval_mcc': 0.2581988897471611, 'cola_test_eval_loss': 1.7734854221343994, 'cola_test_eval_mcc': 0.11125651336121405, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--100-roberta-large-11020', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_05-26-30_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-11020', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 05:40:01.962530', 'cola_dev_eval_loss': 5.269240856170654, 'cola_dev_eval_mcc': 0.32025630761017426, 'cola_test_eval_loss': 4.774439334869385, 'cola_test_eval_mcc': 0.050158066308867176, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--13-roberta-large-23297', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_05-32-27_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-23297', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 05:47:33.656726', 'cola_dev_eval_loss': 4.937648296356201, 'cola_dev_eval_mcc': 0.25819888974716115, 'cola_test_eval_loss': 3.6079094409942627, 'cola_test_eval_mcc': 0.0012438732397634547, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--13-roberta-large-29347', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_05-40-15_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-29347', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 05:55:00.058585', 'cola_dev_eval_loss': 0.6304556131362915, 'cola_dev_eval_mcc': 0.31814238148788887, 'cola_test_eval_loss': 0.766645073890686, 'cola_test_eval_mcc': 0.029077875044971595, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--13-roberta-large-15044', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_05-47-46_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-15044', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 06:02:33.008258', 'cola_dev_eval_loss': 3.3612794876098633, 'cola_dev_eval_mcc': 0.3872983346207417, 'cola_test_eval_loss': 3.1169273853302, 'cola_test_eval_mcc': 0.3622959935975777, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--21-roberta-large-6130', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_05-55-12_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--21-roberta-large-6130', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 06:10:13.628940', 'cola_dev_eval_loss': 1.4670480489730835, 'cola_dev_eval_mcc': 0.2581988897471611, 'cola_test_eval_loss': 1.8109134435653687, 'cola_test_eval_mcc': 0.32182918054478277, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--21-roberta-large-73', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_06-02-44_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--21-roberta-large-73', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 06:17:50.383956', 'cola_dev_eval_loss': 2.7535905838012695, 'cola_dev_eval_mcc': 0.31814238148788887, 'cola_test_eval_loss': 2.8914589881896973, 'cola_test_eval_mcc': 0.1550910215048534, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--21-roberta-large-22370', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_06-10-25_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--21-roberta-large-22370', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 06:25:21.210961', 'cola_dev_eval_loss': 2.682555675506592, 'cola_dev_eval_mcc': 0.44539933408304444, 'cola_test_eval_loss': 3.0444746017456055, 'cola_test_eval_mcc': 0.13370366640599715, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--42-roberta-large-18644', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_06-18-02_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-18644', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 06:32:59.227103', 'cola_dev_eval_loss': 3.245565414428711, 'cola_dev_eval_mcc': 0.48038446141526137, 'cola_test_eval_loss': 3.0382039546966553, 'cola_test_eval_mcc': 0.11548355376965193, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--42-roberta-large-20082', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_06-25-34_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-20082', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 06:40:35.747120', 'cola_dev_eval_loss': 1.6389082670211792, 'cola_dev_eval_mcc': 0.31311214554257477, 'cola_test_eval_loss': 2.2667815685272217, 'cola_test_eval_mcc': 0.07574030325304984, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--42-roberta-large-21538', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_06-33-12_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-21538', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 06:48:06.630186', 'cola_dev_eval_loss': 7.53449010848999, 'cola_dev_eval_mcc': 0.07559289460184544, 'cola_test_eval_loss': 7.182959079742432, 'cola_test_eval_mcc': 0.11359727751359497, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--87-roberta-large-32421', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_06-40-49_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--87-roberta-large-32421', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 06:55:54.884675', 'cola_dev_eval_loss': 7.153527736663818, 'cola_dev_eval_mcc': 0.08606629658238704, 'cola_test_eval_loss': 10.030306816101074, 'cola_test_eval_mcc': 0.08906435545083306, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--87-roberta-large-21431', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_06-48-18_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--87-roberta-large-21431', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 07:03:35.576072', 'cola_dev_eval_loss': 3.2255845069885254, 'cola_dev_eval_mcc': 0.1259881576697424, 'cola_test_eval_loss': 3.5105435848236084, 'cola_test_eval_mcc': 0.08873915544944823, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--87-roberta-large-31273', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_06-56-07_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--87-roberta-large-31273', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 07:11:03.505459', 'cola_dev_eval_loss': 3.197654962539673, 'cola_dev_eval_mcc': 0.44539933408304444, 'cola_test_eval_loss': 2.882875680923462, 'cola_test_eval_mcc': 0.3207987002340054, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--100-roberta-large-21224', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_07-03-47_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-21224', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 07:18:43.319403', 'cola_dev_eval_loss': 0.6934071779251099, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.6846015453338623, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--100-roberta-large-17400', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_07-11-15_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-17400', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 07:26:24.876545', 'cola_dev_eval_loss': 2.4303860664367676, 'cola_dev_eval_mcc': 0.40451991747794525, 'cola_test_eval_loss': 2.1528191566467285, 'cola_test_eval_mcc': 0.1931570229003587, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--100-roberta-large-13418', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_07-18-56_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-13418', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 07:33:59.063175', 'cola_dev_eval_loss': 6.198760032653809, 'cola_dev_eval_mcc': 0.06950480468569159, 'cola_test_eval_loss': 5.36500883102417, 'cola_test_eval_mcc': 0.01966899444564274, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-14951', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_07-26-38_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-14951', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 07:41:28.982632', 'cola_dev_eval_loss': 0.6970849633216858, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.7309069037437439, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-17317', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_07-34-11_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-17317', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 07:49:01.146687', 'cola_dev_eval_loss': 2.7348577976226807, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 2.835160732269287, 'cola_test_eval_mcc': 0.021345273397007876, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-3929', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_07-41-41_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-3929', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 07:56:17.503995', 'cola_dev_eval_loss': 0.7064919471740723, 'cola_dev_eval_mcc': 0.1796053020267749, 'cola_test_eval_loss': 0.6188319325447083, 'cola_test_eval_mcc': 0.07738463889453959, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-21-roberta-large-28459', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_07-49-12_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-21-roberta-large-28459', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 08:03:40.410189', 'cola_dev_eval_loss': 3.5181641578674316, 'cola_dev_eval_mcc': 0.31311214554257477, 'cola_test_eval_loss': 3.554926633834839, 'cola_test_eval_mcc': 0.2527606464058462, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-21-roberta-large-13254', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_07-56-29_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-21-roberta-large-13254', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 08:11:27.351831', 'cola_dev_eval_loss': 1.7564899921417236, 'cola_dev_eval_mcc': 0.31311214554257477, 'cola_test_eval_loss': 1.9069910049438477, 'cola_test_eval_mcc': 0.08873800493332572, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-21-roberta-large-31403', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_08-03-53_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-21-roberta-large-31403', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 08:19:00.375181', 'cola_dev_eval_loss': 4.267282485961914, 'cola_dev_eval_mcc': 0.48038446141526137, 'cola_test_eval_loss': 2.5529227256774902, 'cola_test_eval_mcc': 0.25499375075452474, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-6559', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_08-11-39_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-6559', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 08:26:37.980324', 'cola_dev_eval_loss': 2.0390634536743164, 'cola_dev_eval_mcc': 0.44539933408304444, 'cola_test_eval_loss': 3.185514450073242, 'cola_test_eval_mcc': 0.0866649887367734, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-17828', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_08-19-12_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-17828', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 08:34:23.109634', 'cola_dev_eval_loss': 1.6787776947021484, 'cola_dev_eval_mcc': 0.5393598899705937, 'cola_test_eval_loss': 1.7443548440933228, 'cola_test_eval_mcc': 0.2027348095662474, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-25034', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_08-26-50_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-25034', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 08:42:01.713319', 'cola_dev_eval_loss': 7.790341377258301, 'cola_dev_eval_mcc': -0.19738550848793068, 'cola_test_eval_loss': 6.702672958374023, 'cola_test_eval_mcc': 0.06262776182574667, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-87-roberta-large-8126', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_08-34-35_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-87-roberta-large-8126', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 08:49:50.621690', 'cola_dev_eval_loss': 11.10374927520752, 'cola_dev_eval_mcc': -0.16012815380508713, 'cola_test_eval_loss': 5.5507073402404785, 'cola_test_eval_mcc': 0.09990234865271709, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-87-roberta-large-5394', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_08-42-14_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-87-roberta-large-5394', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 08:57:25.164572', 'cola_dev_eval_loss': 4.978724002838135, 'cola_dev_eval_mcc': -0.2519763153394848, 'cola_test_eval_loss': 3.6957526206970215, 'cola_test_eval_mcc': 0.02682725532845537, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-87-roberta-large-26532', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_08-50-03_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-87-roberta-large-26532', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 09:05:18.949466', 'cola_dev_eval_loss': 2.6590757369995117, 'cola_dev_eval_mcc': 0.5726562866782, 'cola_test_eval_loss': 2.6115102767944336, 'cola_test_eval_mcc': 0.3921440743742665, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-27891', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_08-57-37_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-27891', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 09:12:59.609834', 'cola_dev_eval_loss': 0.69437175989151, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.6753138303756714, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-21102', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_09-05-31_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-21102', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 09:20:35.454825', 'cola_dev_eval_loss': 0.6563711166381836, 'cola_dev_eval_mcc': 0.5039526306789696, 'cola_test_eval_loss': 0.7038768529891968, 'cola_test_eval_mcc': 0.0973591289916797, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-29036', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_09-13-10_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-29036', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 09:26:39.500792', 'cola_dev_eval_loss': 3.771742343902588, 'cola_dev_eval_mcc': 0.2886751345948129, 'cola_test_eval_loss': 4.022465705871582, 'cola_test_eval_mcc': -0.04869486281826412, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-9952', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_09-20-48_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-9952', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 09:32:44.351441', 'cola_dev_eval_loss': 3.664125442504883, 'cola_dev_eval_mcc': 0.20851441405707474, 'cola_test_eval_loss': 3.987114191055298, 'cola_test_eval_mcc': -0.01937264844212568, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-5373', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_09-26-50_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-5373', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 09:38:57.615714', 'cola_dev_eval_loss': 0.7526830434799194, 'cola_dev_eval_mcc': 0.2581988897471611, 'cola_test_eval_loss': 0.7393763661384583, 'cola_test_eval_mcc': 0.02884488423167299, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-29926', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_09-32-56_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-29926', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 09:44:56.966078', 'cola_dev_eval_loss': 2.686539649963379, 'cola_dev_eval_mcc': 0.3779644730092272, 'cola_test_eval_loss': 2.748013973236084, 'cola_test_eval_mcc': 0.19229465646730529, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-21-roberta-large-3764', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_09-39-09_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-21-roberta-large-3764', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 09:50:40.953413', 'cola_dev_eval_loss': 3.0947213172912598, 'cola_dev_eval_mcc': 0.125, 'cola_test_eval_loss': 2.6010935306549072, 'cola_test_eval_mcc': 0.09429785117832348, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-21-roberta-large-10120', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_09-45-07_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-21-roberta-large-10120', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 09:56:30.999718', 'cola_dev_eval_loss': 0.9519325494766235, 'cola_dev_eval_mcc': 0.06950480468569159, 'cola_test_eval_loss': 0.9449439644813538, 'cola_test_eval_mcc': 0.01753305072260879, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-21-roberta-large-22597', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_09-50-51_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-21-roberta-large-22597', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 10:02:18.254101', 'cola_dev_eval_loss': 1.7401349544525146, 'cola_dev_eval_mcc': 0.5163977794943222, 'cola_test_eval_loss': 1.8048661947250366, 'cola_test_eval_mcc': 0.15028537409567955, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-15128', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_09-56-41_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-15128', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 10:08:20.984822', 'cola_dev_eval_loss': 2.286674976348877, 'cola_dev_eval_mcc': 0.34752402342845795, 'cola_test_eval_loss': 3.012505292892456, 'cola_test_eval_mcc': 0.23840276772615265, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-23628', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_10-02-28_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-23628', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 10:14:19.709476', 'cola_dev_eval_loss': 0.9006932973861694, 'cola_dev_eval_mcc': 0.20851441405707474, 'cola_test_eval_loss': 0.6912131905555725, 'cola_test_eval_mcc': 0.08194229584238152, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-30545', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_10-08-33_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-30545', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 10:20:10.854748', 'cola_dev_eval_loss': 5.129271507263184, 'cola_dev_eval_mcc': -0.19088542889273333, 'cola_test_eval_loss': 3.859628438949585, 'cola_test_eval_mcc': 0.03569892980325369, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-87-roberta-large-14955', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_10-14-30_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-87-roberta-large-14955', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 10:25:57.043433', 'cola_dev_eval_loss': 4.954625606536865, 'cola_dev_eval_mcc': -0.1259881576697424, 'cola_test_eval_loss': 3.8705642223358154, 'cola_test_eval_mcc': 0.05523563707672053, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-87-roberta-large-28062', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_10-20-22_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-87-roberta-large-28062', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 10:31:42.561592', 'cola_dev_eval_loss': 0.8030167818069458, 'cola_dev_eval_mcc': -0.12909944487358055, 'cola_test_eval_loss': 0.7648754715919495, 'cola_test_eval_mcc': 0.014203977288626742, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-87-roberta-large-18212', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_10-26-07_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-87-roberta-large-18212', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 10:37:43.721509', 'cola_dev_eval_loss': 1.9749398231506348, 'cola_dev_eval_mcc': 0.3289758474798845, 'cola_test_eval_loss': 1.8997575044631958, 'cola_test_eval_mcc': 0.23463319651935413, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-165', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_10-31-54_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-165', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 10:43:18.331329', 'cola_dev_eval_loss': 1.4315345287322998, 'cola_dev_eval_mcc': 0.5726562866782, 'cola_test_eval_loss': 2.217402219772339, 'cola_test_eval_mcc': 0.22259844534795453, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-28236', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_10-37-54_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-28236', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 10:49:01.522785', 'cola_dev_eval_loss': 0.6457409858703613, 'cola_dev_eval_mcc': 0.26967994498529685, 'cola_test_eval_loss': 0.684521496295929, 'cola_test_eval_mcc': 0.029679560222568006, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-2732', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_10-43-29_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-2732', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 10:56:48.614992', 'cola_dev_eval_loss': 2.83762264251709, 'cola_dev_eval_mcc': 0.5039526306789696, 'cola_test_eval_loss': 3.58075213432312, 'cola_test_eval_mcc': 0.2092135271792309, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-4174', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_10-49-14_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-4174', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 11:04:46.373115', 'cola_dev_eval_loss': 0.698218822479248, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.7368981242179871, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-27608', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_10-57-00_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-27608', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 11:12:45.954713', 'cola_dev_eval_loss': 1.8012690544128418, 'cola_dev_eval_mcc': 0.4605661864718383, 'cola_test_eval_loss': 2.282724380493164, 'cola_test_eval_mcc': 0.19703712059830134, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-17855', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_11-04-59_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-17855', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 11:20:43.710468', 'cola_dev_eval_loss': 7.337557792663574, 'cola_dev_eval_mcc': -0.25, 'cola_test_eval_loss': 5.152074337005615, 'cola_test_eval_mcc': 0.05636302188300527, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-87-roberta-large-10849', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_11-12-58_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-87-roberta-large-10849', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 11:28:40.211337', 'cola_dev_eval_loss': 0.6985909938812256, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.6586900353431702, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-87-roberta-large-32643', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_11-20-57_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-87-roberta-large-32643', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 11:36:45.206689', 'cola_dev_eval_loss': 5.317324638366699, 'cola_dev_eval_mcc': -0.19088542889273333, 'cola_test_eval_loss': 3.937357187271118, 'cola_test_eval_mcc': 0.016841845839918407, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-87-roberta-large-414', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_11-28-52_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-87-roberta-large-414', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 11:44:55.204266', 'cola_dev_eval_loss': 2.18477725982666, 'cola_dev_eval_mcc': 0.3872983346207417, 'cola_test_eval_loss': 2.1574246883392334, 'cola_test_eval_mcc': 0.3894436200368164, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-133', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_11-36-58_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-133', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 11:52:51.762430', 'cola_dev_eval_loss': 0.7369446754455566, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.8508427143096924, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-28953', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_11-45-08_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-28953', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 12:00:44.107649', 'cola_dev_eval_loss': 0.6561625003814697, 'cola_dev_eval_mcc': 0.44539933408304444, 'cola_test_eval_loss': 0.6938154697418213, 'cola_test_eval_mcc': 0.10970954428504726, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-22842', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_11-53-03_node2', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-22842', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 12:27:36.790559', 'mnli_dev_eval_loss': 2.0271341800689697, 'mnli_dev_eval_mnli/acc': 0.5, 'mnli_test_eval_loss': 2.15118670463562, 'mnli_test_eval_mnli/acc': 0.5087111563932756, 'mnli-mm_test_eval_loss': 2.1030895709991455, 'mnli-mm_test_eval_mnli-mm/acc': 0.5171887713588283, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--13-roberta-large-12183', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_12-26-46_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--13-roberta-large-12183', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'all', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 12:40:11.617216', 'mnli_dev_eval_loss': 1.546237826347351, 'mnli_dev_eval_mnli/acc': 0.4583333333333333, 'mnli_test_eval_loss': 1.6800916194915771, 'mnli_test_eval_mnli/acc': 0.3390728476821192, 'mnli-mm_test_eval_loss': 1.670211672782898, 'mnli-mm_test_eval_mnli-mm/acc': 0.3407241659886086, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-3233', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_12-30-36_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-3233', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 12:52:03.767918', 'mnli_dev_eval_loss': 1.1572400331497192, 'mnli_dev_eval_mnli/acc': 0.5833333333333334, 'mnli_test_eval_loss': 1.2027665376663208, 'mnli_test_eval_mnli/acc': 0.5063678043810494, 'mnli-mm_test_eval_loss': 1.1736152172088623, 'mnli-mm_test_eval_mnli-mm/acc': 0.5098657445077298, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-16366', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_12-42-30_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-16366', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 13:04:08.894750', 'mnli_dev_eval_loss': 1.1535395383834839, 'mnli_dev_eval_mnli/acc': 0.5208333333333334, 'mnli_test_eval_loss': 1.1507248878479004, 'mnli_test_eval_mnli/acc': 0.5275598573611818, 'mnli-mm_test_eval_loss': 1.1207587718963623, 'mnli-mm_test_eval_mnli-mm/acc': 0.5398698128559805, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-25024', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_12-54-26_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-25024', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 13:16:17.022792', 'mnli_dev_eval_loss': 1.5813498497009277, 'mnli_dev_eval_mnli/acc': 0.4166666666666667, 'mnli_test_eval_loss': 1.6595110893249512, 'mnli_test_eval_mnli/acc': 0.32511462047885886, 'mnli-mm_test_eval_loss': 1.666223168373108, 'mnli-mm_test_eval_mnli-mm/acc': 0.33228234336859236, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-21-roberta-large-26440', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_13-06-34_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-21-roberta-large-26440', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-21', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 13:28:11.846150', 'mnli_dev_eval_loss': 1.8362118005752563, 'mnli_dev_eval_mnli/acc': 0.5833333333333334, 'mnli_test_eval_loss': 1.737846851348877, 'mnli_test_eval_mnli/acc': 0.5154355578196638, 'mnli-mm_test_eval_loss': 1.7030282020568848, 'mnli-mm_test_eval_mnli-mm/acc': 0.5252237591537836, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-21-roberta-large-29493', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_13-18-44_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-21-roberta-large-29493', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-21', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 13:40:46.303990', 'mnli_dev_eval_loss': 1.8904162645339966, 'mnli_dev_eval_mnli/acc': 0.6041666666666666, 'mnli_test_eval_loss': 1.830152153968811, 'mnli_test_eval_mnli/acc': 0.5152317880794702, 'mnli-mm_test_eval_loss': 1.8039520978927612, 'mnli-mm_test_eval_mnli-mm/acc': 0.528173311635476, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-21-roberta-large-23351', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_13-30-35_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-21-roberta-large-23351', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-21', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 13:52:42.370149', 'mnli_dev_eval_loss': 1.1229729652404785, 'mnli_dev_eval_mnli/acc': 0.4375, 'mnli_test_eval_loss': 1.2807843685150146, 'mnli_test_eval_mnli/acc': 0.3382577687213449, 'mnli-mm_test_eval_loss': 1.2727571725845337, 'mnli-mm_test_eval_mnli-mm/acc': 0.33563873067534583, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-15598', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_13-43-16_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-15598', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 14:04:43.520872', 'mnli_dev_eval_loss': 1.10242760181427, 'mnli_dev_eval_mnli/acc': 0.5625, 'mnli_test_eval_loss': 1.1012475490570068, 'mnli_test_eval_mnli/acc': 0.49271523178807947, 'mnli-mm_test_eval_loss': 1.1029844284057617, 'mnli-mm_test_eval_mnli-mm/acc': 0.4908462164361269, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-5412', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_13-55-09_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-5412', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 14:16:38.743358', 'mnli_dev_eval_loss': 1.0021284818649292, 'mnli_dev_eval_mnli/acc': 0.5625, 'mnli_test_eval_loss': 1.0772758722305298, 'mnli_test_eval_mnli/acc': 0.5174732552215996, 'mnli-mm_test_eval_loss': 1.0703272819519043, 'mnli-mm_test_eval_mnli-mm/acc': 0.5112896663954435, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-7099', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_14-07-08_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-7099', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 14:28:37.266639', 'mnli_dev_eval_loss': 1.302384376525879, 'mnli_dev_eval_mnli/acc': 0.5416666666666666, 'mnli_test_eval_loss': 1.0406248569488525, 'mnli_test_eval_mnli/acc': 0.5708609271523178, 'mnli-mm_test_eval_loss': 1.0101662874221802, 'mnli-mm_test_eval_mnli-mm/acc': 0.5806550040683482, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-87-roberta-large-27264', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_14-18-58_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-87-roberta-large-27264', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-87', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 14:40:41.433130', 'mnli_dev_eval_loss': 1.2070198059082031, 'mnli_dev_eval_mnli/acc': 0.5833333333333334, 'mnli_test_eval_loss': 1.0827445983886719, 'mnli_test_eval_mnli/acc': 0.5549668874172186, 'mnli-mm_test_eval_loss': 1.0687657594680786, 'mnli-mm_test_eval_mnli-mm/acc': 0.5533970707892596, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-87-roberta-large-12912', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_14-31-02_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-87-roberta-large-12912', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-87', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 14:52:39.401252', 'mnli_dev_eval_loss': 1.3013933897018433, 'mnli_dev_eval_mnli/acc': 0.5416666666666666, 'mnli_test_eval_loss': 1.1407153606414795, 'mnli_test_eval_mnli/acc': 0.5497707590422822, 'mnli-mm_test_eval_loss': 1.1109390258789062, 'mnli-mm_test_eval_mnli-mm/acc': 0.5478030919446705, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-87-roberta-large-12739', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_14-43-05_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-87-roberta-large-12739', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-87', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 15:04:37.996610', 'mnli_dev_eval_loss': 1.6651734113693237, 'mnli_dev_eval_mnli/acc': 0.4375, 'mnli_test_eval_loss': 1.7524631023406982, 'mnli_test_eval_mnli/acc': 0.33937850229240957, 'mnli-mm_test_eval_loss': 1.7601903676986694, 'mnli-mm_test_eval_mnli-mm/acc': 0.3328925956061839, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-18388', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_14-55-02_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-18388', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 15:16:30.754458', 'mnli_dev_eval_loss': 2.00122332572937, 'mnli_dev_eval_mnli/acc': 0.4166666666666667, 'mnli_test_eval_loss': 2.0327186584472656, 'mnli_test_eval_mnli/acc': 0.336729495669893, 'mnli-mm_test_eval_loss': 1.9929578304290771, 'mnli-mm_test_eval_mnli-mm/acc': 0.3381814483319772, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-14847', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_15-07-05_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-14847', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 15:28:27.226585', 'mnli_dev_eval_loss': 1.1600998640060425, 'mnli_dev_eval_mnli/acc': 0.5208333333333334, 'mnli_test_eval_loss': 1.0905770063400269, 'mnli_test_eval_mnli/acc': 0.5164544065206317, 'mnli-mm_test_eval_loss': 1.0731465816497803, 'mnli-mm_test_eval_mnli-mm/acc': 0.5148494711147275, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-15633', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_15-18-52_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-15633', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 15:40:10.603343', 'mnli_dev_eval_loss': 1.9496850967407227, 'mnli_dev_eval_mnli/acc': 0.8125, 'mnli_test_eval_loss': 2.419534683227539, 'mnli_test_eval_mnli/acc': 0.6510443199184921, 'mnli-mm_test_eval_loss': 2.383197784423828, 'mnli-mm_test_eval_mnli-mm/acc': 0.6644629780309195, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--13-roberta-large-29240', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_15-30-55_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--13-roberta-large-29240', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 15:52:14.859910', 'mnli_dev_eval_loss': 1.54820716381073, 'mnli_dev_eval_mnli/acc': 0.7916666666666666, 'mnli_test_eval_loss': 1.88966703414917, 'mnli_test_eval_mnli/acc': 0.6585838003056547, 'mnli-mm_test_eval_loss': 1.8280051946640015, 'mnli-mm_test_eval_mnli-mm/acc': 0.6772782750203418, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--13-roberta-large-31541', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_15-42-25_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--13-roberta-large-31541', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 16:03:35.269933', 'mnli_dev_eval_loss': 1.3019747734069824, 'mnli_dev_eval_mnli/acc': 0.8125, 'mnli_test_eval_loss': 1.5823664665222168, 'mnli_test_eval_mnli/acc': 0.6500254712175242, 'mnli-mm_test_eval_loss': 1.5426229238510132, 'mnli-mm_test_eval_mnli-mm/acc': 0.6687347436940602, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--13-roberta-large-3771', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_15-54-38_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--13-roberta-large-3771', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 16:13:47.755570', 'mnli_dev_eval_loss': 2.580939531326294, 'mnli_dev_eval_mnli/acc': 0.7291666666666666, 'mnli_test_eval_loss': 2.090165138244629, 'mnli_test_eval_mnli/acc': 0.7011716760061131, 'mnli-mm_test_eval_loss': 2.0634076595306396, 'mnli-mm_test_eval_mnli-mm/acc': 0.7078925956061839, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--21-roberta-large-23654', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_16-05-46_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--21-roberta-large-23654', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-21', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 16:24:21.610438', 'mnli_dev_eval_loss': 1.0685759782791138, 'mnli_dev_eval_mnli/acc': 0.6458333333333334, 'mnli_test_eval_loss': 1.111768126487732, 'mnli_test_eval_mnli/acc': 0.6657157412124299, 'mnli-mm_test_eval_loss': 1.152052879333496, 'mnli-mm_test_eval_mnli-mm/acc': 0.6671074043938161, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--21-roberta-large-29593', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_16-16-03_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--21-roberta-large-29593', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-21', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 16:34:38.306023', 'mnli_dev_eval_loss': 1.1479687690734863, 'mnli_dev_eval_mnli/acc': 0.625, 'mnli_test_eval_loss': 1.146765947341919, 'mnli_test_eval_mnli/acc': 0.6582781456953642, 'mnli-mm_test_eval_loss': 1.1848196983337402, 'mnli-mm_test_eval_mnli-mm/acc': 0.6600895036615134, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--21-roberta-large-20783', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_16-26-36_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--21-roberta-large-20783', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-21', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 16:45:23.622759', 'mnli_dev_eval_loss': 2.1504814624786377, 'mnli_dev_eval_mnli/acc': 0.6875, 'mnli_test_eval_loss': 2.0763115882873535, 'mnli_test_eval_mnli/acc': 0.6660213958227204, 'mnli-mm_test_eval_loss': 1.9552594423294067, 'mnli-mm_test_eval_mnli-mm/acc': 0.6799227013832384, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--42-roberta-large-22624', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_16-36-49_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--42-roberta-large-22624', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 16:55:36.474761', 'mnli_dev_eval_loss': 1.8245357275009155, 'mnli_dev_eval_mnli/acc': 0.6458333333333334, 'mnli_test_eval_loss': 1.7660424709320068, 'mnli_test_eval_mnli/acc': 0.6437086092715232, 'mnli-mm_test_eval_loss': 1.643498420715332, 'mnli-mm_test_eval_mnli-mm/acc': 0.6623270951993491, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--42-roberta-large-20750', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_16-47-39_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--42-roberta-large-20750', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 17:06:15.858676', 'mnli_dev_eval_loss': 1.2666014432907104, 'mnli_dev_eval_mnli/acc': 0.6458333333333334, 'mnli_test_eval_loss': 1.3068244457244873, 'mnli_test_eval_mnli/acc': 0.6271013754457463, 'mnli-mm_test_eval_loss': 1.2332830429077148, 'mnli-mm_test_eval_mnli-mm/acc': 0.641273393002441, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--42-roberta-large-14134', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_16-57-48_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--42-roberta-large-14134', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 17:16:24.362444', 'mnli_dev_eval_loss': 2.6081981658935547, 'mnli_dev_eval_mnli/acc': 0.6666666666666666, 'mnli_test_eval_loss': 2.0871872901916504, 'mnli_test_eval_mnli/acc': 0.7088130412633724, 'mnli-mm_test_eval_loss': 1.9562523365020752, 'mnli-mm_test_eval_mnli-mm/acc': 0.7238608624898292, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--87-roberta-large-16317', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_17-08-32_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--87-roberta-large-16317', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-87', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 17:26:46.178399', 'mnli_dev_eval_loss': 2.3276522159576416, 'mnli_dev_eval_mnli/acc': 0.625, 'mnli_test_eval_loss': 1.5948750972747803, 'mnli_test_eval_mnli/acc': 0.6754966887417219, 'mnli-mm_test_eval_loss': 1.4841537475585938, 'mnli-mm_test_eval_mnli-mm/acc': 0.6872457282343368, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--87-roberta-large-2905', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_17-18-36_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--87-roberta-large-2905', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-87', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 17:36:52.940166', 'mnli_dev_eval_loss': 1.2951664924621582, 'mnli_dev_eval_mnli/acc': 0.6041666666666666, 'mnli_test_eval_loss': 1.0574791431427002, 'mnli_test_eval_mnli/acc': 0.6026490066225165, 'mnli-mm_test_eval_loss': 1.0327328443527222, 'mnli-mm_test_eval_mnli-mm/acc': 0.6116761594792515, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--87-roberta-large-25563', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_17-29-01_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--87-roberta-large-25563', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-87', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 17:47:26.466027', 'mnli_dev_eval_loss': 2.183502435684204, 'mnli_dev_eval_mnli/acc': 0.7708333333333334, 'mnli_test_eval_loss': 2.406315565109253, 'mnli_test_eval_mnli/acc': 0.6814060112073357, 'mnli-mm_test_eval_loss': 2.1281895637512207, 'mnli-mm_test_eval_mnli-mm/acc': 0.7013832384052074, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--100-roberta-large-30184', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_17-39-15_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--100-roberta-large-30184', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 17:58:15.783963', 'mnli_dev_eval_loss': 1.495782732963562, 'mnli_dev_eval_mnli/acc': 0.6875, 'mnli_test_eval_loss': 1.524627685546875, 'mnli_test_eval_mnli/acc': 0.6546102903718798, 'mnli-mm_test_eval_loss': 1.5033433437347412, 'mnli-mm_test_eval_mnli-mm/acc': 0.660699755899105, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--100-roberta-large-21770', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_17-49-40_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--100-roberta-large-21770', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 18:08:44.020329', 'mnli_dev_eval_loss': 1.4255303144454956, 'mnli_dev_eval_mnli/acc': 0.6666666666666666, 'mnli_test_eval_loss': 1.4704663753509521, 'mnli_test_eval_mnli/acc': 0.6459500764136525, 'mnli-mm_test_eval_loss': 1.4683022499084473, 'mnli-mm_test_eval_mnli-mm/acc': 0.6472742066720911, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--100-roberta-large-15701', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_18-00-31_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--100-roberta-large-15701', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 18:21:38.250944', 'mnli_dev_eval_loss': 2.1564083099365234, 'mnli_dev_eval_mnli/acc': 0.75, 'mnli_test_eval_loss': 2.342495918273926, 'mnli_test_eval_mnli/acc': 0.6672440142638818, 'mnli-mm_test_eval_loss': 2.1733767986297607, 'mnli-mm_test_eval_mnli-mm/acc': 0.6908055329536208, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--13-roberta-large-15662', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_18-11-28_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--13-roberta-large-15662', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 18:34:46.691440', 'mnli_dev_eval_loss': 2.2281367778778076, 'mnli_dev_eval_mnli/acc': 0.7291666666666666, 'mnli_test_eval_loss': 2.2973392009735107, 'mnli_test_eval_mnli/acc': 0.6913907284768211, 'mnli-mm_test_eval_loss': 2.2243876457214355, 'mnli-mm_test_eval_mnli-mm/acc': 0.7074857607811229, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--13-roberta-large-12738', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_18-24-19_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--13-roberta-large-12738', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 18:48:27.354118', 'mnli_dev_eval_loss': 1.6513794660568237, 'mnli_dev_eval_mnli/acc': 0.75, 'mnli_test_eval_loss': 1.8444777727127075, 'mnli_test_eval_mnli/acc': 0.6507386653082017, 'mnli-mm_test_eval_loss': 1.733581781387329, 'mnli-mm_test_eval_mnli-mm/acc': 0.6728030919446705, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--13-roberta-large-13234', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_18-37-23_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--13-roberta-large-13234', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 19:01:37.594231', 'mnli_dev_eval_loss': 1.4926689863204956, 'mnli_dev_eval_mnli/acc': 0.7291666666666666, 'mnli_test_eval_loss': 1.6627272367477417, 'mnli_test_eval_mnli/acc': 0.6464595007641365, 'mnli-mm_test_eval_loss': 1.5769517421722412, 'mnli-mm_test_eval_mnli-mm/acc': 0.6667005695687551, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--13-roberta-large-11104', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_18-51-05_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--13-roberta-large-11104', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 19:15:11.526152', 'mnli_dev_eval_loss': 2.3496482372283936, 'mnli_dev_eval_mnli/acc': 0.6875, 'mnli_test_eval_loss': 2.1720974445343018, 'mnli_test_eval_mnli/acc': 0.6420784513499745, 'mnli-mm_test_eval_loss': 2.111705780029297, 'mnli-mm_test_eval_mnli-mm/acc': 0.653173311635476, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--21-roberta-large-18058', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_19-04-18_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--21-roberta-large-18058', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-21', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 19:29:02.505971', 'mnli_dev_eval_loss': 1.9214481115341187, 'mnli_dev_eval_mnli/acc': 0.6458333333333334, 'mnli_test_eval_loss': 1.5412415266036987, 'mnli_test_eval_mnli/acc': 0.6766174223127865, 'mnli-mm_test_eval_loss': 1.6446452140808105, 'mnli-mm_test_eval_mnli-mm/acc': 0.6752441008950366, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--21-roberta-large-9376', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_19-17-55_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--21-roberta-large-9376', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-21', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 19:42:38.632939', 'mnli_dev_eval_loss': 2.0105245113372803, 'mnli_dev_eval_mnli/acc': 0.6666666666666666, 'mnli_test_eval_loss': 1.7770847082138062, 'mnli_test_eval_mnli/acc': 0.6841569026999491, 'mnli-mm_test_eval_loss': 1.8224624395370483, 'mnli-mm_test_eval_mnli-mm/acc': 0.6898901545972336, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--21-roberta-large-14850', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_19-31-39_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--21-roberta-large-14850', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-21', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 19:55:23.487518', 'mnli_dev_eval_loss': 1.2472361326217651, 'mnli_dev_eval_mnli/acc': 0.625, 'mnli_test_eval_loss': 1.2563936710357666, 'mnli_test_eval_mnli/acc': 0.6464595007641365, 'mnli-mm_test_eval_loss': 1.2891175746917725, 'mnli-mm_test_eval_mnli-mm/acc': 0.6471724979658259, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--21-roberta-large-25363', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_19-45-16_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--21-roberta-large-25363', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-21', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 20:08:06.750754', 'mnli_dev_eval_loss': 2.9934988021850586, 'mnli_dev_eval_mnli/acc': 0.6875, 'mnli_test_eval_loss': 3.617164134979248, 'mnli_test_eval_mnli/acc': 0.667142129393785, 'mnli-mm_test_eval_loss': 3.266676664352417, 'mnli-mm_test_eval_mnli-mm/acc': 0.6943653376729048, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--42-roberta-large-3227', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_19-57-59_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--42-roberta-large-3227', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 20:21:14.665202', 'mnli_dev_eval_loss': 2.6180295944213867, 'mnli_dev_eval_mnli/acc': 0.6666666666666666, 'mnli_test_eval_loss': 2.644545078277588, 'mnli_test_eval_mnli/acc': 0.6467651553744269, 'mnli-mm_test_eval_loss': 2.43287992477417, 'mnli-mm_test_eval_mnli-mm/acc': 0.6709723352318958, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--42-roberta-large-3942', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_20-10-40_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--42-roberta-large-3942', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 20:35:10.527864', 'mnli_dev_eval_loss': 1.8224869966506958, 'mnli_dev_eval_mnli/acc': 0.6666666666666666, 'mnli_test_eval_loss': 1.896230697631836, 'mnli_test_eval_mnli/acc': 0.6453387671930718, 'mnli-mm_test_eval_loss': 1.7211731672286987, 'mnli-mm_test_eval_mnli-mm/acc': 0.6675142392188771, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--42-roberta-large-14504', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_20-23-56_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--42-roberta-large-14504', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 20:48:12.588207', 'mnli_dev_eval_loss': 1.6529227495193481, 'mnli_dev_eval_mnli/acc': 0.6458333333333334, 'mnli_test_eval_loss': 1.668798804283142, 'mnli_test_eval_mnli/acc': 0.6310748853795212, 'mnli-mm_test_eval_loss': 1.5477477312088013, 'mnli-mm_test_eval_mnli-mm/acc': 0.6465622457282343, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--42-roberta-large-19271', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_20-37-55_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--42-roberta-large-19271', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 21:01:56.706484', 'mnli_dev_eval_loss': 4.182003498077393, 'mnli_dev_eval_mnli/acc': 0.75, 'mnli_test_eval_loss': 4.1366801261901855, 'mnli_test_eval_mnli/acc': 0.7050433010697912, 'mnli-mm_test_eval_loss': 3.8443825244903564, 'mnli-mm_test_eval_mnli-mm/acc': 0.7312855980471928, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--87-roberta-large-27339', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_20-50-48_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--87-roberta-large-27339', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-87', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 21:14:23.873626', 'mnli_dev_eval_loss': 1.81574285030365, 'mnli_dev_eval_mnli/acc': 0.5, 'mnli_test_eval_loss': 1.929611086845398, 'mnli_test_eval_mnli/acc': 0.51777890983189, 'mnli-mm_test_eval_loss': 1.8968026638031006, 'mnli-mm_test_eval_mnli-mm/acc': 0.531326281529699, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-7573', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_21-05-13_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-7573', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 21:15:25.214027', 'mnli_dev_eval_loss': 2.9845521450042725, 'mnli_dev_eval_mnli/acc': 0.6875, 'mnli_test_eval_loss': 2.194445848464966, 'mnli_test_eval_mnli/acc': 0.6816097809475293, 'mnli-mm_test_eval_loss': 1.9810214042663574, 'mnli-mm_test_eval_mnli-mm/acc': 0.7012815296989422, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--87-roberta-large-21159', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_21-04-39_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--87-roberta-large-21159', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-87', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 21:26:50.130338', 'mnli_dev_eval_loss': 2.1649115085601807, 'mnli_dev_eval_mnli/acc': 0.5833333333333334, 'mnli_test_eval_loss': 2.0100467205047607, 'mnli_test_eval_mnli/acc': 0.5241976566479878, 'mnli-mm_test_eval_loss': 1.9733827114105225, 'mnli-mm_test_eval_mnli-mm/acc': 0.5353946297803092, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-21-roberta-large-1040', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_21-18-20_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-21-roberta-large-1040', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-21', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 21:29:44.558078', 'mnli_dev_eval_loss': 2.1957452297210693, 'mnli_dev_eval_mnli/acc': 0.625, 'mnli_test_eval_loss': 1.5496327877044678, 'mnli_test_eval_mnli/acc': 0.6667345899133978, 'mnli-mm_test_eval_loss': 1.4266343116760254, 'mnli-mm_test_eval_mnli-mm/acc': 0.6763628966639544, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--87-roberta-large-20248', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_21-18-27_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--87-roberta-large-20248', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-87', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 21:38:39.625055', 'mnli_dev_eval_loss': 1.8901554346084595, 'mnli_dev_eval_mnli/acc': 0.5416666666666666, 'mnli_test_eval_loss': 1.757975697517395, 'mnli_test_eval_mnli/acc': 0.5156393275598573, 'mnli-mm_test_eval_loss': 1.7090686559677124, 'mnli-mm_test_eval_mnli-mm/acc': 0.5266476810414972, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-10272', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_21-29-24_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-10272', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 21:44:31.759460', 'mnli_dev_eval_loss': 2.2123029232025146, 'mnli_dev_eval_mnli/acc': 0.6458333333333334, 'mnli_test_eval_loss': 1.600388526916504, 'mnli_test_eval_mnli/acc': 0.6620478858889455, 'mnli-mm_test_eval_loss': 1.5032480955123901, 'mnli-mm_test_eval_mnli-mm/acc': 0.6720911310008136, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--87-roberta-large-30075', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_21-32-45_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--87-roberta-large-30075', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-87', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 21:50:32.367774', 'mnli_dev_eval_loss': 2.2854840755462646, 'mnli_dev_eval_mnli/acc': 0.5208333333333334, 'mnli_test_eval_loss': 2.0217926502227783, 'mnli_test_eval_mnli/acc': 0.5268466632705043, 'mnli-mm_test_eval_loss': 1.982431411743164, 'mnli-mm_test_eval_mnli-mm/acc': 0.5370219690805533, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-87-roberta-large-1851', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_21-41-34_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-87-roberta-large-1851', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-87', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 21:58:12.716814', 'mnli_dev_eval_loss': 3.5220329761505127, 'mnli_dev_eval_mnli/acc': 0.7083333333333334, 'mnli_test_eval_loss': 4.818580150604248, 'mnli_test_eval_mnli/acc': 0.6370860927152318, 'mnli-mm_test_eval_loss': 4.195833683013916, 'mnli-mm_test_eval_mnli-mm/acc': 0.6688364524003255, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--100-roberta-large-22574', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_21-47-35_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--100-roberta-large-22574', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 22:02:07.544142', 'mnli_dev_eval_loss': 2.199578285217285, 'mnli_dev_eval_mnli/acc': 0.5, 'mnli_test_eval_loss': 2.0105550289154053, 'mnli_test_eval_mnli/acc': 0.5228731533367295, 'mnli-mm_test_eval_loss': 1.9701550006866455, 'mnli-mm_test_eval_mnli-mm/acc': 0.5352929210740439, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-9080', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_21-53-10_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-9080', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 22:12:49.479778', 'mnli_dev_eval_loss': 1.3555668592453003, 'mnli_dev_eval_mnli/acc': 0.7708333333333334, 'mnli_test_eval_loss': 1.7444219589233398, 'mnli_test_eval_mnli/acc': 0.678349465104432, 'mnli-mm_test_eval_loss': 1.6350374221801758, 'mnli-mm_test_eval_mnli-mm/acc': 0.6882628152969894, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--100-roberta-large-29013', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_22-01-35_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--100-roberta-large-29013', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 22:26:24.393917', 'mnli_dev_eval_loss': 1.3822373151779175, 'mnli_dev_eval_mnli/acc': 0.625, 'mnli_test_eval_loss': 1.4553678035736084, 'mnli_test_eval_mnli/acc': 0.6621497707590422, 'mnli-mm_test_eval_loss': 1.432812213897705, 'mnli-mm_test_eval_mnli-mm/acc': 0.6685313262815297, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--100-roberta-large-727', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_22-15-31_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--100-roberta-large-727', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 22:39:32.528877', 'mnli_dev_eval_loss': 1.2664791345596313, 'mnli_dev_eval_mnli/acc': 0.5833333333333334, 'mnli_test_eval_loss': 1.3682270050048828, 'mnli_test_eval_mnli/acc': 0.6363728986245543, 'mnli-mm_test_eval_loss': 1.415930151939392, 'mnli-mm_test_eval_mnli-mm/acc': 0.6354759967453214, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--100-roberta-large-22816', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_22-29-12_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--100-roberta-large-22816', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 22:53:22.655870', 'mnli_dev_eval_loss': 3.446559190750122, 'mnli_dev_eval_mnli/acc': 0.7708333333333334, 'mnli_test_eval_loss': 3.5776760578155518, 'mnli_test_eval_mnli/acc': 0.6708099847172695, 'mnli-mm_test_eval_loss': 3.4790115356445312, 'mnli-mm_test_eval_mnli-mm/acc': 0.6920260374288039, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-13936', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_22-42-11_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-13936', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 23:07:01.083871', 'mnli_dev_eval_loss': 1.569346308708191, 'mnli_dev_eval_mnli/acc': 0.75, 'mnli_test_eval_loss': 2.0415151119232178, 'mnli_test_eval_mnli/acc': 0.6657157412124299, 'mnli-mm_test_eval_loss': 2.0231258869171143, 'mnli-mm_test_eval_mnli-mm/acc': 0.6783970707892596, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-13179', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_22-56-06_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-13179', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 23:20:48.063823', 'mnli_dev_eval_loss': 1.9052411317825317, 'mnli_dev_eval_mnli/acc': 0.75, 'mnli_test_eval_loss': 2.259165048599243, 'mnli_test_eval_mnli/acc': 0.6607233825776873, 'mnli-mm_test_eval_loss': 2.187325954437256, 'mnli-mm_test_eval_mnli-mm/acc': 0.6750406834825061, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-24699', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_23-09-41_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-24699', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 23:33:40.724616', 'mnli_dev_eval_loss': 1.5713039636611938, 'mnli_dev_eval_mnli/acc': 0.7291666666666666, 'mnli_test_eval_loss': 1.6314263343811035, 'mnli_test_eval_mnli/acc': 0.6351502801833928, 'mnli-mm_test_eval_loss': 1.5775806903839111, 'mnli-mm_test_eval_mnli-mm/acc': 0.6525630593978845, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-320', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_23-23-26_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-320', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 23:46:31.864459', 'mnli_dev_eval_loss': 2.3825483322143555, 'mnli_dev_eval_mnli/acc': 0.7291666666666666, 'mnli_test_eval_loss': 2.2739357948303223, 'mnli_test_eval_mnli/acc': 0.6723382577687214, 'mnli-mm_test_eval_loss': 2.2202892303466797, 'mnli-mm_test_eval_mnli-mm/acc': 0.6871440195280716, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-21-roberta-large-26209', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_23-36-23_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-21-roberta-large-26209', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-21', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-01 23:59:06.816728', 'mnli_dev_eval_loss': 2.6382503509521484, 'mnli_dev_eval_mnli/acc': 0.625, 'mnli_test_eval_loss': 2.0173797607421875, 'mnli_test_eval_mnli/acc': 0.6713194090677534, 'mnli-mm_test_eval_loss': 2.0980987548828125, 'mnli-mm_test_eval_mnli-mm/acc': 0.6824654190398698, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-21-roberta-large-18957', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov01_23-49-07_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-21-roberta-large-18957', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-21', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 00:11:37.354899', 'mnli_dev_eval_loss': 2.5479180812835693, 'mnli_dev_eval_mnli/acc': 0.6666666666666666, 'mnli_test_eval_loss': 1.878807544708252, 'mnli_test_eval_mnli/acc': 0.6617422312786552, 'mnli-mm_test_eval_loss': 1.9811240434646606, 'mnli-mm_test_eval_mnli-mm/acc': 0.665480065093572, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-21-roberta-large-26948', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_00-01-44_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-21-roberta-large-26948', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-21', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 00:23:57.315081', 'mnli_dev_eval_loss': 1.0009732246398926, 'mnli_dev_eval_mnli/acc': 0.625, 'mnli_test_eval_loss': 1.035335898399353, 'mnli_test_eval_mnli/acc': 0.5908303616912889, 'mnli-mm_test_eval_loss': 1.0404428243637085, 'mnli-mm_test_eval_mnli-mm/acc': 0.5969283970707893, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-21-roberta-large-31551', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_00-14-09_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-21-roberta-large-31551', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-21', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 00:36:27.784838', 'mnli_dev_eval_loss': 3.21152663230896, 'mnli_dev_eval_mnli/acc': 0.6875, 'mnli_test_eval_loss': 3.0245742797851562, 'mnli_test_eval_mnli/acc': 0.6407539480387162, 'mnli-mm_test_eval_loss': 2.906446695327759, 'mnli-mm_test_eval_mnli-mm/acc': 0.6669039869812856, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-18892', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_00-26-29_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-18892', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 00:49:02.548105', 'mnli_dev_eval_loss': 2.480217695236206, 'mnli_dev_eval_mnli/acc': 0.625, 'mnli_test_eval_loss': 2.5462191104888916, 'mnli_test_eval_mnli/acc': 0.634029546612328, 'mnli-mm_test_eval_loss': 2.3182334899902344, 'mnli-mm_test_eval_mnli-mm/acc': 0.6602929210740439, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-15677', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_00-38-58_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-15677', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 01:01:30.131087', 'mnli_dev_eval_loss': 2.0769596099853516, 'mnli_dev_eval_mnli/acc': 0.6666666666666666, 'mnli_test_eval_loss': 2.2007603645324707, 'mnli_test_eval_mnli/acc': 0.6308711156393275, 'mnli-mm_test_eval_loss': 2.076361656188965, 'mnli-mm_test_eval_mnli-mm/acc': 0.6467656631407649, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-9775', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_00-51-33_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-9775', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 01:14:01.386863', 'mnli_dev_eval_loss': 1.8479312658309937, 'mnli_dev_eval_mnli/acc': 0.6458333333333334, 'mnli_test_eval_loss': 1.7325092554092407, 'mnli_test_eval_mnli/acc': 0.6231278655119715, 'mnli-mm_test_eval_loss': 1.63758385181427, 'mnli-mm_test_eval_mnli-mm/acc': 0.6363913751017087, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-20709', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_01-04-01_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-20709', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 01:26:34.680198', 'mnli_dev_eval_loss': 1.6955772638320923, 'mnli_dev_eval_mnli/acc': 0.3333333333333333, 'mnli_test_eval_loss': 1.6727514266967773, 'mnli_test_eval_mnli/acc': 0.3544574630667346, 'mnli-mm_test_eval_loss': 1.679348349571228, 'mnli-mm_test_eval_mnli-mm/acc': 0.3522172497965826, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-87-roberta-large-10390', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_01-16-30_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-87-roberta-large-10390', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-87', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 01:38:59.188553', 'mnli_dev_eval_loss': 2.8250606060028076, 'mnli_dev_eval_mnli/acc': 0.6666666666666666, 'mnli_test_eval_loss': 2.555079460144043, 'mnli_test_eval_mnli/acc': 0.6960774325012735, 'mnli-mm_test_eval_loss': 2.4589791297912598, 'mnli-mm_test_eval_mnli-mm/acc': 0.7111472742066721, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-87-roberta-large-7186', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_01-29-04_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-87-roberta-large-7186', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-87', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 01:54:28.762950', 'mnli_dev_eval_loss': 2.0856456756591797, 'mnli_dev_eval_mnli/acc': 0.6041666666666666, 'mnli_test_eval_loss': 1.5880231857299805, 'mnli_test_eval_mnli/acc': 0.6791645440652063, 'mnli-mm_test_eval_loss': 1.5534206628799438, 'mnli-mm_test_eval_mnli-mm/acc': 0.6834825061025224, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-87-roberta-large-21597', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_01-41-26_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-87-roberta-large-21597', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-87', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 02:18:26.166375', 'mnli_dev_eval_loss': 2.033597707748413, 'mnli_dev_eval_mnli/acc': 0.6041666666666666, 'mnli_test_eval_loss': 1.4708794355392456, 'mnli_test_eval_mnli/acc': 0.6530820173204279, 'mnli-mm_test_eval_loss': 1.4251277446746826, 'mnli-mm_test_eval_mnli-mm/acc': 0.6587672904800651, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-87-roberta-large-24500', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_01-58-34_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-87-roberta-large-24500', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-87', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 02:41:02.180470', 'mnli_dev_eval_loss': 1.8082504272460938, 'mnli_dev_eval_mnli/acc': 0.6875, 'mnli_test_eval_loss': 2.6867892742156982, 'mnli_test_eval_mnli/acc': 0.6870096790626592, 'mnli-mm_test_eval_loss': 2.6574392318725586, 'mnli-mm_test_eval_mnli-mm/acc': 0.6977217249796582, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-29747', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_02-22-32_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-29747', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 03:03:04.140177', 'mnli_dev_eval_loss': 1.801474928855896, 'mnli_dev_eval_mnli/acc': 0.6666666666666666, 'mnli_test_eval_loss': 1.958530306816101, 'mnli_test_eval_mnli/acc': 0.6837493632195619, 'mnli-mm_test_eval_loss': 1.892128586769104, 'mnli-mm_test_eval_mnli-mm/acc': 0.6970097640358015, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-25513', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_02-44-59_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-25513', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 03:24:07.012673', 'mnli_dev_eval_loss': 1.3108941316604614, 'mnli_dev_eval_mnli/acc': 0.7083333333333334, 'mnli_test_eval_loss': 1.2880167961120605, 'mnli_test_eval_mnli/acc': 0.6418746816097809, 'mnli-mm_test_eval_loss': 1.363845944404602, 'mnli-mm_test_eval_mnli-mm/acc': 0.6351708706265257, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-9935', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_03-06-37_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-9935', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 03:45:05.301092', 'mnli_dev_eval_loss': 1.6048334836959839, 'mnli_dev_eval_mnli/acc': 0.6458333333333334, 'mnli_test_eval_loss': 1.4261376857757568, 'mnli_test_eval_mnli/acc': 0.6679572083545593, 'mnli-mm_test_eval_loss': 1.4716206789016724, 'mnli-mm_test_eval_mnli-mm/acc': 0.674633848657445, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-22692', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_03-27-49_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-22692', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 04:02:17.086950', 'mnli_dev_eval_loss': 2.8858602046966553, 'mnli_dev_eval_mnli/acc': 0.7291666666666666, 'mnli_test_eval_loss': 3.4304234981536865, 'mnli_test_eval_mnli/acc': 0.6178298522669383, 'mnli-mm_test_eval_loss': 3.489166498184204, 'mnli-mm_test_eval_mnli-mm/acc': 0.6265256305939788, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-7942', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_03-48-42_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-7942', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 04:18:34.408995', 'mnli_dev_eval_loss': 1.6697474718093872, 'mnli_dev_eval_mnli/acc': 0.7291666666666666, 'mnli_test_eval_loss': 1.9835635423660278, 'mnli_test_eval_mnli/acc': 0.6551197147223637, 'mnli-mm_test_eval_loss': 1.9591292142868042, 'mnli-mm_test_eval_mnli-mm/acc': 0.6718877135882831, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-32200', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_04-05-14_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-32200', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 04:34:37.400157', 'mnli_dev_eval_loss': 0.9825887084007263, 'mnli_dev_eval_mnli/acc': 0.7083333333333334, 'mnli_test_eval_loss': 1.1417272090911865, 'mnli_test_eval_mnli/acc': 0.6123280692817117, 'mnli-mm_test_eval_loss': 1.1309502124786377, 'mnli-mm_test_eval_mnli-mm/acc': 0.6164564686737185, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-28425', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_04-21-25_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-28425', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 04:50:57.919414', 'mnli_dev_eval_loss': 0.969409167766571, 'mnli_dev_eval_mnli/acc': 0.7291666666666666, 'mnli_test_eval_loss': 1.0912717580795288, 'mnli_test_eval_mnli/acc': 0.6093734080489047, 'mnli-mm_test_eval_loss': 1.0774096250534058, 'mnli-mm_test_eval_mnli-mm/acc': 0.609947111472742, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-26350', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_04-37-27_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-26350', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 05:07:07.587320', 'mnli_dev_eval_loss': 2.3323214054107666, 'mnli_dev_eval_mnli/acc': 0.7083333333333334, 'mnli_test_eval_loss': 2.410872459411621, 'mnli_test_eval_mnli/acc': 0.6397350993377483, 'mnli-mm_test_eval_loss': 2.5041816234588623, 'mnli-mm_test_eval_mnli-mm/acc': 0.6472742066720911, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-21-roberta-large-19025', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_04-53-54_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-21-roberta-large-19025', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-21', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 05:24:27.416162', 'mnli_dev_eval_loss': 1.2169256210327148, 'mnli_dev_eval_mnli/acc': 0.6458333333333334, 'mnli_test_eval_loss': 1.121609091758728, 'mnli_test_eval_mnli/acc': 0.6447274579724911, 'mnli-mm_test_eval_loss': 1.1544075012207031, 'mnli-mm_test_eval_mnli-mm/acc': 0.6511391375101708, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-21-roberta-large-16622', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_05-09-46_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-21-roberta-large-16622', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-21', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 05:41:41.619958', 'mnli_dev_eval_loss': 1.1504316329956055, 'mnli_dev_eval_mnli/acc': 0.6666666666666666, 'mnli_test_eval_loss': 1.1022403240203857, 'mnli_test_eval_mnli/acc': 0.6356597045338768, 'mnli-mm_test_eval_loss': 1.1316066980361938, 'mnli-mm_test_eval_mnli-mm/acc': 0.6361879576891782, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-21-roberta-large-29314', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_05-27-35_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-21-roberta-large-29314', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-21', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 06:00:00.283829', 'mnli_dev_eval_loss': 1.043777585029602, 'mnli_dev_eval_mnli/acc': 0.6458333333333334, 'mnli_test_eval_loss': 1.050593614578247, 'mnli_test_eval_mnli/acc': 0.6231278655119715, 'mnli-mm_test_eval_loss': 1.0750102996826172, 'mnli-mm_test_eval_mnli-mm/acc': 0.6273393002441009, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-21-roberta-large-27613', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_05-44-40_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-21-roberta-large-27613', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-21', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 06:17:13.322047', 'mnli_dev_eval_loss': 2.121910333633423, 'mnli_dev_eval_mnli/acc': 0.7083333333333334, 'mnli_test_eval_loss': 2.1688172817230225, 'mnli_test_eval_mnli/acc': 0.6577687213448803, 'mnli-mm_test_eval_loss': 2.099844217300415, 'mnli-mm_test_eval_mnli-mm/acc': 0.6797192839707079, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-15386', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_06-03-11_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-15386', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 06:33:34.209682', 'mnli_dev_eval_loss': 1.7175445556640625, 'mnli_dev_eval_mnli/acc': 0.6666666666666666, 'mnli_test_eval_loss': 2.0110533237457275, 'mnli_test_eval_mnli/acc': 0.6168110035659704, 'mnli-mm_test_eval_loss': 1.9069615602493286, 'mnli-mm_test_eval_mnli-mm/acc': 0.6299837266069975, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-1054', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_06-20-00_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-1054', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 06:49:59.735435', 'mnli_dev_eval_loss': 1.0285309553146362, 'mnli_dev_eval_mnli/acc': 0.6458333333333334, 'mnli_test_eval_loss': 0.9854316711425781, 'mnli_test_eval_mnli/acc': 0.6107997962302598, 'mnli-mm_test_eval_loss': 0.957377016544342, 'mnli-mm_test_eval_mnli-mm/acc': 0.6113710333604556, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-22937', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_06-36-31_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-22937', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 07:06:41.222620', 'mnli_dev_eval_loss': 1.1431756019592285, 'mnli_dev_eval_mnli/acc': 0.6041666666666666, 'mnli_test_eval_loss': 1.0828750133514404, 'mnli_test_eval_mnli/acc': 0.6113092205807438, 'mnli-mm_test_eval_loss': 1.0561954975128174, 'mnli-mm_test_eval_mnli-mm/acc': 0.6104556550040684, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-32364', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_06-52-58_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-32364', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 07:23:12.212550', 'mnli_dev_eval_loss': 2.9857866764068604, 'mnli_dev_eval_mnli/acc': 0.6875, 'mnli_test_eval_loss': 2.254595994949341, 'mnli_test_eval_mnli/acc': 0.6993377483443709, 'mnli-mm_test_eval_loss': 2.2557668685913086, 'mnli-mm_test_eval_mnli-mm/acc': 0.7163344182262001, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-87-roberta-large-19678', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_07-09-40_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-87-roberta-large-19678', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-87', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 07:40:12.067834', 'mnli_dev_eval_loss': 2.013385057449341, 'mnli_dev_eval_mnli/acc': 0.6041666666666666, 'mnli_test_eval_loss': 1.5471636056900024, 'mnli_test_eval_mnli/acc': 0.6728476821192053, 'mnli-mm_test_eval_loss': 1.4826141595840454, 'mnli-mm_test_eval_mnli-mm/acc': 0.6869406021155411, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-87-roberta-large-18977', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_07-26-05_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-87-roberta-large-18977', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-87', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 07:56:34.911261', 'mnli_dev_eval_loss': 2.0356996059417725, 'mnli_dev_eval_mnli/acc': 0.6041666666666666, 'mnli_test_eval_loss': 1.4461452960968018, 'mnli_test_eval_mnli/acc': 0.6455425369332655, 'mnli-mm_test_eval_loss': 1.3875569105148315, 'mnli-mm_test_eval_mnli-mm/acc': 0.6565296989422295, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-87-roberta-large-7876', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_07-43-13_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-87-roberta-large-7876', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-87', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 08:13:03.341664', 'mnli_dev_eval_loss': 1.3922785520553589, 'mnli_dev_eval_mnli/acc': 0.6041666666666666, 'mnli_test_eval_loss': 1.1118059158325195, 'mnli_test_eval_mnli/acc': 0.6013245033112583, 'mnli-mm_test_eval_loss': 1.098993182182312, 'mnli-mm_test_eval_mnli-mm/acc': 0.6015052888527258, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-87-roberta-large-6888', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_07-59-31_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-87-roberta-large-6888', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-87', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 08:29:12.359680', 'mnli_dev_eval_loss': 1.6109672784805298, 'mnli_dev_eval_mnli/acc': 0.7083333333333334, 'mnli_test_eval_loss': 1.6798810958862305, 'mnli_test_eval_mnli/acc': 0.6568517575140091, 'mnli-mm_test_eval_loss': 1.6186540126800537, 'mnli-mm_test_eval_mnli-mm/acc': 0.6722945484133441, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-17089', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_08-15-56_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-17089', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 08:45:46.844577', 'mnli_dev_eval_loss': 1.1873692274093628, 'mnli_dev_eval_mnli/acc': 0.6666666666666666, 'mnli_test_eval_loss': 1.1308785676956177, 'mnli_test_eval_mnli/acc': 0.645236882322975, 'mnli-mm_test_eval_loss': 1.2003437280654907, 'mnli-mm_test_eval_mnli-mm/acc': 0.6468673718470301, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-21882', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_08-32-10_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-21882', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 09:02:38.706855', 'mnli_dev_eval_loss': 1.534279704093933, 'mnli_dev_eval_mnli/acc': 0.7083333333333334, 'mnli_test_eval_loss': 1.4570417404174805, 'mnli_test_eval_mnli/acc': 0.6745797249108507, 'mnli-mm_test_eval_loss': 1.5341969728469849, 'mnli-mm_test_eval_mnli-mm/acc': 0.6764646053702197, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-22831', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_08-48-50_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-22831', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 09:19:23.779426', 'mnli_dev_eval_loss': 1.0099924802780151, 'mnli_dev_eval_mnli/acc': 0.6458333333333334, 'mnli_test_eval_loss': 0.9923978447914124, 'mnli_test_eval_mnli/acc': 0.6239429444727458, 'mnli-mm_test_eval_loss': 1.0228710174560547, 'mnli-mm_test_eval_mnli-mm/acc': 0.6219487388120423, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-7920', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_09-05-38_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-7920', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 09:41:54.338387', 'mnli_dev_eval_loss': 2.1480143070220947, 'mnli_dev_eval_mnli/acc': 0.7291666666666666, 'mnli_test_eval_loss': 2.933046817779541, 'mnli_test_eval_mnli/acc': 0.6835455934793683, 'mnli-mm_test_eval_loss': 2.908653736114502, 'mnli-mm_test_eval_mnli-mm/acc': 0.6884662327095199, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--13-roberta-large-25098', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_09-22-23_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--13-roberta-large-25098', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 10:01:59.757856', 'mnli_dev_eval_loss': 2.4250471591949463, 'mnli_dev_eval_mnli/acc': 0.75, 'mnli_test_eval_loss': 2.609199047088623, 'mnli_test_eval_mnli/acc': 0.6725420275089149, 'mnli-mm_test_eval_loss': 2.480199098587036, 'mnli-mm_test_eval_mnli-mm/acc': 0.6957892595606184, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--13-roberta-large-20751', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_09-45-39_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--13-roberta-large-20751', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 10:22:09.099130', 'mnli_dev_eval_loss': 1.7211856842041016, 'mnli_dev_eval_mnli/acc': 0.75, 'mnli_test_eval_loss': 2.0953359603881836, 'mnli_test_eval_mnli/acc': 0.6592969943963322, 'mnli-mm_test_eval_loss': 2.0207412242889404, 'mnli-mm_test_eval_mnli-mm/acc': 0.6817534580960131, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--13-roberta-large-6820', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_10-05-19_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--13-roberta-large-6820', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 10:42:23.238389', 'mnli_dev_eval_loss': 1.5373846292495728, 'mnli_dev_eval_mnli/acc': 0.7708333333333334, 'mnli_test_eval_loss': 1.8025463819503784, 'mnli_test_eval_mnli/acc': 0.652572592969944, 'mnli-mm_test_eval_loss': 1.719752550125122, 'mnli-mm_test_eval_mnli-mm/acc': 0.6723962571196095, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--13-roberta-large-27082', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_10-25-19_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--13-roberta-large-27082', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 11:02:01.809974', 'mnli_dev_eval_loss': 3.3441359996795654, 'mnli_dev_eval_mnli/acc': 0.75, 'mnli_test_eval_loss': 3.297452449798584, 'mnli_test_eval_mnli/acc': 0.6999490575649516, 'mnli-mm_test_eval_loss': 3.07220721244812, 'mnli-mm_test_eval_mnli-mm/acc': 0.722233523189585, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--21-roberta-large-24226', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_10-45-42_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--21-roberta-large-24226', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-21', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 11:22:10.635045', 'mnli_dev_eval_loss': 2.5278170108795166, 'mnli_dev_eval_mnli/acc': 0.6666666666666666, 'mnli_test_eval_loss': 1.8304470777511597, 'mnli_test_eval_mnli/acc': 0.6923076923076923, 'mnli-mm_test_eval_loss': 1.8591783046722412, 'mnli-mm_test_eval_mnli-mm/acc': 0.7035191212367778, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--21-roberta-large-13066', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_11-05-30_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--21-roberta-large-13066', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-21', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 11:42:25.233943', 'mnli_dev_eval_loss': 2.2611007690429688, 'mnli_dev_eval_mnli/acc': 0.6875, 'mnli_test_eval_loss': 1.9724761247634888, 'mnli_test_eval_mnli/acc': 0.6762098828323994, 'mnli-mm_test_eval_loss': 2.0442423820495605, 'mnli-mm_test_eval_mnli-mm/acc': 0.6757526444263628, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--21-roberta-large-11272', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_11-25-49_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--21-roberta-large-11272', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-21', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 12:02:08.031474', 'mnli_dev_eval_loss': 0.8912009596824646, 'mnli_dev_eval_mnli/acc': 0.625, 'mnli_test_eval_loss': 1.0069297552108765, 'mnli_test_eval_mnli/acc': 0.5990830361691288, 'mnli-mm_test_eval_loss': 1.0167453289031982, 'mnli-mm_test_eval_mnli-mm/acc': 0.5982506102522376, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--21-roberta-large-3109', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_11-45-47_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--21-roberta-large-3109', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-21', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 12:20:37.478075', 'mnli_dev_eval_loss': 3.5499422550201416, 'mnli_dev_eval_mnli/acc': 0.625, 'mnli_test_eval_loss': 3.1176109313964844, 'mnli_test_eval_mnli/acc': 0.6375955170657157, 'mnli-mm_test_eval_loss': 2.8582680225372314, 'mnli-mm_test_eval_mnli-mm/acc': 0.6719894222945484, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--42-roberta-large-4713', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_12-05-26_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--42-roberta-large-4713', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 12:37:33.150776', 'mnli_dev_eval_loss': 2.635795831680298, 'mnli_dev_eval_mnli/acc': 0.6666666666666666, 'mnli_test_eval_loss': 2.595940589904785, 'mnli_test_eval_mnli/acc': 0.6478858889454916, 'mnli-mm_test_eval_loss': 2.343129873275757, 'mnli-mm_test_eval_mnli-mm/acc': 0.6749389747762409, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--42-roberta-large-9734', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_12-23-38_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--42-roberta-large-9734', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 12:55:47.824381', 'mnli_dev_eval_loss': 2.068105697631836, 'mnli_dev_eval_mnli/acc': 0.6666666666666666, 'mnli_test_eval_loss': 2.0188941955566406, 'mnli_test_eval_mnli/acc': 0.6464595007641365, 'mnli-mm_test_eval_loss': 1.8553966283798218, 'mnli-mm_test_eval_mnli-mm/acc': 0.6736167615947926, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--42-roberta-large-31149', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_12-40-29_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--42-roberta-large-31149', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 13:11:06.528511', 'mnli_dev_eval_loss': 1.7024577856063843, 'mnli_dev_eval_mnli/acc': 0.6458333333333334, 'mnli_test_eval_loss': 1.6955292224884033, 'mnli_test_eval_mnli/acc': 0.6343352012226184, 'mnli-mm_test_eval_loss': 1.571750521659851, 'mnli-mm_test_eval_mnli-mm/acc': 0.6482912937347437, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--42-roberta-large-21020', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_12-58-55_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--42-roberta-large-21020', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 13:24:51.282041', 'mnli_dev_eval_loss': 2.3968849182128906, 'mnli_dev_eval_mnli/acc': 0.7708333333333334, 'mnli_test_eval_loss': 3.83429217338562, 'mnli_test_eval_mnli/acc': 0.6552215995924605, 'mnli-mm_test_eval_loss': 3.7581565380096436, 'mnli-mm_test_eval_mnli-mm/acc': 0.6699552481692432, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--87-roberta-large-3034', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_13-13-45_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--87-roberta-large-3034', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-87', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 13:38:14.891302', 'mnli_dev_eval_loss': 3.046647787094116, 'mnli_dev_eval_mnli/acc': 0.7291666666666666, 'mnli_test_eval_loss': 2.5107169151306152, 'mnli_test_eval_mnli/acc': 0.7242995415180845, 'mnli-mm_test_eval_loss': 2.2061686515808105, 'mnli-mm_test_eval_mnli-mm/acc': 0.7476606997558991, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--87-roberta-large-10854', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_13-27-24_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--87-roberta-large-10854', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-87', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 13:53:37.313633', 'mnli_dev_eval_loss': 2.431753158569336, 'mnli_dev_eval_mnli/acc': 0.6666666666666666, 'mnli_test_eval_loss': 1.6870629787445068, 'mnli_test_eval_mnli/acc': 0.6751910341314314, 'mnli-mm_test_eval_loss': 1.567643642425537, 'mnli-mm_test_eval_mnli-mm/acc': 0.6865337672904801, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--87-roberta-large-29161', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_13-40-46_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--87-roberta-large-29161', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-87', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 14:08:33.057900', 'mnli_dev_eval_loss': 2.170851469039917, 'mnli_dev_eval_mnli/acc': 0.6458333333333334, 'mnli_test_eval_loss': 1.5595438480377197, 'mnli_test_eval_mnli/acc': 0.6577687213448803, 'mnli-mm_test_eval_loss': 1.4704753160476685, 'mnli-mm_test_eval_mnli-mm/acc': 0.6661920260374288, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--87-roberta-large-22139', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_13-56-18_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--87-roberta-large-22139', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-87', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 14:23:58.166741', 'mnli_dev_eval_loss': 4.356420516967773, 'mnli_dev_eval_mnli/acc': 0.6458333333333334, 'mnli_test_eval_loss': 3.9293248653411865, 'mnli_test_eval_mnli/acc': 0.6599083036169129, 'mnli-mm_test_eval_loss': 3.6591951847076416, 'mnli-mm_test_eval_mnli-mm/acc': 0.6890764849471115, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--100-roberta-large-12101', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_14-11-17_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--100-roberta-large-12101', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 14:37:56.881678', 'mnli_dev_eval_loss': 2.8723413944244385, 'mnli_dev_eval_mnli/acc': 0.6875, 'mnli_test_eval_loss': 2.455268383026123, 'mnli_test_eval_mnli/acc': 0.6989302088639837, 'mnli-mm_test_eval_loss': 2.2046267986297607, 'mnli-mm_test_eval_mnli-mm/acc': 0.7171480878763222, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--100-roberta-large-1965', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_14-26-41_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--100-roberta-large-1965', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 14:52:56.709339', 'mnli_dev_eval_loss': 1.2705897092819214, 'mnli_dev_eval_mnli/acc': 0.625, 'mnli_test_eval_loss': 1.4501655101776123, 'mnli_test_eval_mnli/acc': 0.6441161487519104, 'mnli-mm_test_eval_loss': 1.4780570268630981, 'mnli-mm_test_eval_mnli-mm/acc': 0.6497152156224573, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--100-roberta-large-30277', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_14-41-09_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--100-roberta-large-30277', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 15:08:35.160278', 'mnli_dev_eval_loss': 1.3941925764083862, 'mnli_dev_eval_mnli/acc': 0.6041666666666666, 'mnli_test_eval_loss': 1.502914547920227, 'mnli_test_eval_mnli/acc': 0.6354559347936831, 'mnli-mm_test_eval_loss': 1.5601255893707275, 'mnli-mm_test_eval_mnli-mm/acc': 0.6355777054515866, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--100-roberta-large-26325', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_14-56-10_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--100-roberta-large-26325', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 15:25:42.894855', 'mnli_dev_eval_loss': 3.8307511806488037, 'mnli_dev_eval_mnli/acc': 0.5416666666666666, 'mnli_test_eval_loss': 2.9254281520843506, 'mnli_test_eval_mnli/acc': 0.614569536423841, 'mnli-mm_test_eval_loss': 2.652080774307251, 'mnli-mm_test_eval_mnli-mm/acc': 0.6476810414971521, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-28030', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_15-12-00_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-28030', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 15:42:46.198637', 'mnli_dev_eval_loss': 2.5205113887786865, 'mnli_dev_eval_mnli/acc': 0.625, 'mnli_test_eval_loss': 2.6014530658721924, 'mnli_test_eval_mnli/acc': 0.6392256749872643, 'mnli-mm_test_eval_loss': 2.3103902339935303, 'mnli-mm_test_eval_mnli-mm/acc': 0.6655817737998373, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-19010', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_15-28-38_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-19010', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 16:01:53.321598', 'mnli_dev_eval_loss': 1.6829862594604492, 'mnli_dev_eval_mnli/acc': 0.6458333333333334, 'mnli_test_eval_loss': 1.758000373840332, 'mnli_test_eval_mnli/acc': 0.6251655629139072, 'mnli-mm_test_eval_loss': 1.6649603843688965, 'mnli-mm_test_eval_mnli-mm/acc': 0.6402563059397884, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-18741', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_15-46-13_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-18741', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 16:21:49.471867', 'mnli_dev_eval_loss': 2.072514772415161, 'mnli_dev_eval_mnli/acc': 0.6458333333333334, 'mnli_test_eval_loss': 2.0122146606445312, 'mnli_test_eval_mnli/acc': 0.6251655629139072, 'mnli-mm_test_eval_loss': 1.8888174295425415, 'mnli-mm_test_eval_mnli-mm/acc': 0.6390358014646054, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-21019', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_16-05-31_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-21019', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 16:42:09.187533', 'mnli_dev_eval_loss': 2.7731285095214844, 'mnli_dev_eval_mnli/acc': 0.7708333333333334, 'mnli_test_eval_loss': 3.2629528045654297, 'mnli_test_eval_mnli/acc': 0.7099337748344371, 'mnli-mm_test_eval_loss': 3.0452487468719482, 'mnli-mm_test_eval_mnli-mm/acc': 0.7290480065093572, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-87-roberta-large-29453', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_16-25-18_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-87-roberta-large-29453', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-87', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 17:02:15.997362', 'mnli_dev_eval_loss': 2.241649866104126, 'mnli_dev_eval_mnli/acc': 0.6875, 'mnli_test_eval_loss': 2.3493030071258545, 'mnli_test_eval_mnli/acc': 0.6529801324503312, 'mnli-mm_test_eval_loss': 2.312875747680664, 'mnli-mm_test_eval_mnli-mm/acc': 0.6659886086248983, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-87-roberta-large-22881', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_16-45-35_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-87-roberta-large-22881', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-87', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-11-02 17:22:08.451167', 'mnli_dev_eval_loss': 2.4733049869537354, 'mnli_dev_eval_mnli/acc': 0.625, 'mnli_test_eval_loss': 1.9597357511520386, 'mnli_test_eval_mnli/acc': 0.687111563932756, 'mnli-mm_test_eval_loss': 1.9061663150787354, 'mnli-mm_test_eval_mnli-mm/acc': 0.693653376729048, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-87-roberta-large-14963', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Nov02_17-05-50_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-87-roberta-large-14963', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt,bias,adapter', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-87', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
