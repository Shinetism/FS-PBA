{'time': '2021-10-29 11:54:22.268268', 'sst-2_dev_eval_loss': 0.3773651123046875, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 0.3900911808013916, 'sst-2_test_eval_acc': 0.8142201834862385, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-10-13-roberta-large-26228', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_11-48-14_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-13-roberta-large-26228', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 12:01:02.669542', 'sst-2_dev_eval_loss': 0.18813666701316833, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.28726810216903687, 'sst-2_test_eval_acc': 0.8761467889908257, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-10-21-roberta-large-21377', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_11-54-33_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-21-roberta-large-21377', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 12:08:04.428164', 'sst-2_dev_eval_loss': 0.33715569972991943, 'sst-2_dev_eval_acc': 0.875, 'sst-2_test_eval_loss': 0.2926813066005707, 'sst-2_test_eval_acc': 0.8944954128440367, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-10-42-roberta-large-20299', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_12-01-14_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-42-roberta-large-20299', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 12:15:08.468418', 'sst-2_dev_eval_loss': 0.17740792036056519, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.30741554498672485, 'sst-2_test_eval_acc': 0.8772935779816514, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-10-87-roberta-large-24105', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_12-08-12_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-87-roberta-large-24105', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 12:24:03.656975', 'sst-2_dev_eval_loss': 0.22081083059310913, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.3369605243206024, 'sst-2_test_eval_acc': 0.8658256880733946, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-10-100-roberta-large-12317', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_12-17-03_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-100-roberta-large-12317', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 12:33:00.986475', 'sst-2_dev_eval_loss': 0.7424033284187317, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 0.5526729226112366, 'sst-2_test_eval_acc': 0.926605504587156, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-13-roberta-large-11682', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_12-24-16_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-13-roberta-large-11682', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 12:41:43.122257', 'sst-2_dev_eval_loss': 1.1097863912582397, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 0.6484587788581848, 'sst-2_test_eval_acc': 0.9220183486238532, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-13-roberta-large-2560', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_12-33-13_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-13-roberta-large-2560', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 12:49:22.665839', 'sst-2_dev_eval_loss': 0.6657127141952515, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.5242862105369568, 'sst-2_test_eval_acc': 0.9254587155963303, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-13-roberta-large-10047', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_12-41-55_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-13-roberta-large-10047', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 12:57:15.565674', 'sst-2_dev_eval_loss': 0.41329890489578247, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.3759898543357849, 'sst-2_test_eval_acc': 0.9174311926605505, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-13-roberta-large-25450', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_12-49-32_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-13-roberta-large-25450', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 13:05:12.243656', 'sst-2_dev_eval_loss': 0.5078533887863159, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 1.2572200298309326, 'sst-2_test_eval_acc': 0.8830275229357798, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-21-roberta-large-30764', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_12-57-26_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-21-roberta-large-30764', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 13:13:20.090918', 'sst-2_dev_eval_loss': 0.34311601519584656, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.76073157787323, 'sst-2_test_eval_acc': 0.9254587155963303, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-21-roberta-large-21121', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_13-05-25_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-21-roberta-large-21121', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 13:22:02.279837', 'sst-2_dev_eval_loss': 0.5539488792419434, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.6224682927131653, 'sst-2_test_eval_acc': 0.9197247706422018, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-21-roberta-large-15567', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_13-13-33_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-21-roberta-large-15567', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 13:30:40.099933', 'sst-2_dev_eval_loss': 0.3674478530883789, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.41801732778549194, 'sst-2_test_eval_acc': 0.9174311926605505, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-21-roberta-large-30597', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_13-22-13_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-21-roberta-large-30597', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 13:38:51.280204', 'sst-2_dev_eval_loss': 0.6283280849456787, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.6945906281471252, 'sst-2_test_eval_acc': 0.9128440366972477, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-42-roberta-large-9539', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_13-30-50_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-42-roberta-large-9539', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 13:47:08.704522', 'sst-2_dev_eval_loss': 0.9563190340995789, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 1.1318169832229614, 'sst-2_test_eval_acc': 0.8910550458715596, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-42-roberta-large-20104', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_13-39-01_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-42-roberta-large-20104', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 13:55:24.870306', 'sst-2_dev_eval_loss': 0.21768273413181305, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.4547143876552582, 'sst-2_test_eval_acc': 0.930045871559633, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-42-roberta-large-8104', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_13-47-19_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-42-roberta-large-8104', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 14:03:52.482803', 'sst-2_dev_eval_loss': 0.14950791001319885, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.34884417057037354, 'sst-2_test_eval_acc': 0.9254587155963303, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-42-roberta-large-19169', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_13-55-35_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-42-roberta-large-19169', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 14:12:42.973650', 'sst-2_dev_eval_loss': 1.0197670459747314, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 1.2855314016342163, 'sst-2_test_eval_acc': 0.893348623853211, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-87-roberta-large-6974', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_14-04-06_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-87-roberta-large-6974', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 14:21:20.156013', 'sst-2_dev_eval_loss': 0.4089920222759247, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.8925469517707825, 'sst-2_test_eval_acc': 0.8922018348623854, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-87-roberta-large-6799', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_14-12-54_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-87-roberta-large-6799', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 14:29:38.763345', 'sst-2_dev_eval_loss': 0.3766760230064392, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.547814130783081, 'sst-2_test_eval_acc': 0.9277522935779816, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-87-roberta-large-3230', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_14-21-32_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-87-roberta-large-3230', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 14:38:18.420408', 'sst-2_dev_eval_loss': 0.24594980478286743, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.3723231256008148, 'sst-2_test_eval_acc': 0.9220183486238532, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-87-roberta-large-22268', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_14-29-48_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-87-roberta-large-22268', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 14:47:26.659320', 'sst-2_dev_eval_loss': 1.6606785720796324e-05, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.777485728263855, 'sst-2_test_eval_acc': 0.9105504587155964, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-100-roberta-large-17392', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_14-38-35_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-100-roberta-large-17392', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 14:59:28.626086', 'sst-2_dev_eval_loss': 0.10141957551240921, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.5742713212966919, 'sst-2_test_eval_acc': 0.9185779816513762, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-100-roberta-large-15135', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_14-47-42_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-100-roberta-large-15135', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 15:10:28.560409', 'sst-2_dev_eval_loss': 0.008355976082384586, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.5165627002716064, 'sst-2_test_eval_acc': 0.9174311926605505, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-100-roberta-large-11531', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_14-59-42_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-100-roberta-large-11531', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 15:21:16.784413', 'sst-2_dev_eval_loss': 0.015503697097301483, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.3844255208969116, 'sst-2_test_eval_acc': 0.9059633027522935, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-10-100-roberta-large-2170', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_15-10-43_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-100-roberta-large-2170', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'adapter,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 15:30:08.277368', 'sst-2_dev_eval_loss': 1.2616087198257446, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 1.1362134218215942, 'sst-2_test_eval_acc': 0.8761467889908257, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-10-13-roberta-large-11533', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_15-21-34_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-13-roberta-large-11533', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 15:38:24.959990', 'sst-2_dev_eval_loss': 0.7867663502693176, 'sst-2_dev_eval_acc': 0.875, 'sst-2_test_eval_loss': 0.45290079712867737, 'sst-2_test_eval_acc': 0.9288990825688074, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-10-13-roberta-large-3019', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_15-30-21_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-13-roberta-large-3019', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-10-29 15:44:53.303020', 'sst-2_dev_eval_loss': 0.5054996609687805, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 0.3638515770435333, 'sst-2_test_eval_acc': 0.9174311926605505, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-10-13-roberta-large-6252', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Oct29_15-38-34_node1', 'logging_first_step': False, 'logging_steps': 100, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-10-13-roberta-large-6252', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': 'bias,prompt', 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-pre', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
