{'sst-2_dev_eval_loss': 0.3668482005596161, 'sst-2_dev_eval_acc': 0.8125, 'sst-2_test_eval_loss': 0.3679763078689575, 'sst-2_test_eval_acc': 0.8360091743119266, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--13-roberta-large-3046', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_15-26-05_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-3046', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': None, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_eval_loss': 0.9497717022895813, 'cola_dev_eval_mcc': 0.1889822365046136, 'cola_test_eval_loss': 0.7720293998718262, 'cola_test_eval_mcc': 0.022067101449159066, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--13-roberta-large-17689', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_15-32-17_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-17689', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': None, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_eval_loss': 0.9717034101486206, 'mrpc_dev_eval_acc': 0.46875, 'mrpc_dev_eval_f1': 0.5405405405405405, 'mrpc_dev_eval_acc_and_f1': 0.5046452702702702, 'mrpc_test_eval_loss': 0.9839727282524109, 'mrpc_test_eval_acc': 0.5049019607843137, 'mrpc_test_eval_f1': 0.6188679245283017, 'mrpc_test_eval_acc_and_f1': 0.5618849426563077, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16--13-roberta-large-3605', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_15-40-16_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--13-roberta-large-3605', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': None, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt_eval_loss': 0.2957068085670471, 'sst-2_dev_prompt_eval_acc': 0.9375, 'sst-2_test_prompt_eval_loss': 0.28934016823768616, 'sst-2_test_prompt_eval_acc': 0.9139908256880734, 'sst-2_dev_eval_loss': 0.2957068085670471, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.28934016823768616, 'sst-2_test_eval_acc': 0.9139908256880734, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-17458', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_15-26-48_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-17458', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt_eval_loss': 0.6982873678207397, 'cola_dev_prompt_eval_mcc': 0.34752402342845795, 'cola_test_prompt_eval_loss': 0.7120416760444641, 'cola_test_prompt_eval_mcc': -0.03381150611380647, 'cola_dev_eval_loss': 0.6982873678207397, 'cola_dev_eval_mcc': 0.34752402342845795, 'cola_test_eval_loss': 0.7120416760444641, 'cola_test_eval_mcc': -0.03381150611380647, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-30316', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_15-33-09_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-30316', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt_eval_loss': 0.7684525847434998, 'mrpc_dev_prompt_eval_acc': 0.5625, 'mrpc_dev_prompt_eval_f1': 0.6666666666666667, 'mrpc_dev_prompt_eval_acc_and_f1': 0.6145833333333334, 'mrpc_test_prompt_eval_loss': 0.7776007056236267, 'mrpc_test_prompt_eval_acc': 0.6127450980392157, 'mrpc_test_prompt_eval_f1': 0.7459807073954984, 'mrpc_test_prompt_eval_acc_and_f1': 0.6793629027173571, 'mrpc_dev_eval_loss': 0.7684525847434998, 'mrpc_dev_eval_acc': 0.5625, 'mrpc_dev_eval_f1': 0.6666666666666667, 'mrpc_dev_eval_acc_and_f1': 0.6145833333333334, 'mrpc_test_eval_loss': 0.7776007056236267, 'mrpc_test_eval_acc': 0.6127450980392157, 'mrpc_test_eval_f1': 0.7459807073954984, 'mrpc_test_eval_acc_and_f1': 0.6793629027173571, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-13-roberta-large-28769', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_15-41-10_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-13-roberta-large-28769', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt_eval_loss': 0.6050107479095459, 'cola_dev_prompt_eval_mcc': 0.5039526306789696, 'cola_test_prompt_eval_loss': 0.9219910502433777, 'cola_test_prompt_eval_mcc': 0.014631046841036801, 'cola_dev_eval_loss': 0.6050107479095459, 'cola_dev_eval_mcc': 0.5039526306789696, 'cola_test_eval_loss': 0.9219910502433777, 'cola_test_eval_mcc': 0.014631046841036801, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-12346', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_16-00-11_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-12346', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt_eval_loss': 0.23539118468761444, 'sst-2_dev_prompt_eval_acc': 0.96875, 'sst-2_test_prompt_eval_loss': 0.7867220044136047, 'sst-2_test_prompt_eval_acc': 0.8348623853211009, 'sst-2_dev_eval_loss': 0.23539118468761444, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.7867220044136047, 'sst-2_test_eval_acc': 0.8348623853211009, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-29795', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_15-57-07_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-29795', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt_eval_loss': 0.8976137042045593, 'mrpc_dev_prompt_eval_acc': 0.625, 'mrpc_dev_prompt_eval_f1': 0.6842105263157896, 'mrpc_dev_prompt_eval_acc_and_f1': 0.6546052631578948, 'mrpc_test_prompt_eval_loss': 0.9818639755249023, 'mrpc_test_prompt_eval_acc': 0.5269607843137255, 'mrpc_test_prompt_eval_f1': 0.628131021194605, 'mrpc_test_prompt_eval_acc_and_f1': 0.5775459027541652, 'mrpc_dev_eval_loss': 0.8976137042045593, 'mrpc_dev_eval_acc': 0.625, 'mrpc_dev_eval_f1': 0.6842105263157896, 'mrpc_dev_eval_acc_and_f1': 0.6546052631578948, 'mrpc_test_eval_loss': 0.9818639755249023, 'mrpc_test_eval_acc': 0.5269607843137255, 'mrpc_test_eval_f1': 0.628131021194605, 'mrpc_test_eval_acc_and_f1': 0.5775459027541652, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-13-roberta-large-23838', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_16-07-39_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-13-roberta-large-23838', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt_eval_loss': 0.7197284698486328, 'cola_dev_prompt_eval_mcc': 0.44539933408304444, 'cola_test_prompt_eval_loss': 0.9575195908546448, 'cola_test_prompt_eval_mcc': 0.010048204204434964, 'cola_dev_eval_loss': 0.7197284698486328, 'cola_dev_eval_mcc': 0.44539933408304444, 'cola_test_eval_loss': 0.9575195908546448, 'cola_test_eval_mcc': 0.010048204204434964, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-27850', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_16-25-11_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-27850', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_eval_loss': 2.0271341800689697, 'mnli_dev_eval_mnli/acc': 0.5, 'mnli_test_eval_loss': 2.15118670463562, 'mnli_test_eval_mnli/acc': 0.5087111563932756, 'mnli-mm_test_eval_loss': 2.1030895709991455, 'mnli-mm_test_eval_mnli-mm/acc': 0.5171887713588283, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--13-roberta-large-31277', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_16-50-25_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--13-roberta-large-31277', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': None, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt_eval_loss': 0.3683854639530182, 'sst-2_dev_prompt_eval_acc': 0.90625, 'sst-2_test_prompt_eval_loss': 0.28693410754203796, 'sst-2_test_prompt_eval_acc': 0.8864678899082569, 'sst-2_dev_eval_loss': 0.3683854639530182, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 0.28693410754203796, 'sst-2_test_eval_acc': 0.8864678899082569, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-1541', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_16-26-37_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-1541', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt_eval_loss': 1.2347996234893799, 'mrpc_dev_prompt_eval_acc': 0.71875, 'mrpc_dev_prompt_eval_f1': 0.7567567567567567, 'mrpc_dev_prompt_eval_acc_and_f1': 0.7377533783783783, 'mrpc_test_prompt_eval_loss': 1.2122585773468018, 'mrpc_test_prompt_eval_acc': 0.6421568627450981, 'mrpc_test_prompt_eval_f1': 0.7355072463768115, 'mrpc_test_prompt_eval_acc_and_f1': 0.6888320545609548, 'mrpc_dev_eval_loss': 1.2347996234893799, 'mrpc_dev_eval_acc': 0.71875, 'mrpc_dev_eval_f1': 0.7567567567567567, 'mrpc_dev_eval_acc_and_f1': 0.7377533783783783, 'mrpc_test_eval_loss': 1.2122585773468018, 'mrpc_test_eval_acc': 0.6421568627450981, 'mrpc_test_eval_f1': 0.7355072463768115, 'mrpc_test_eval_acc_and_f1': 0.6888320545609548, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-13-roberta-large-5094', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_16-33-43_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-13-roberta-large-5094', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt_eval_loss': 0.6854237914085388, 'cola_dev_prompt_eval_mcc': 0.3872983346207417, 'cola_test_prompt_eval_loss': 0.8614621758460999, 'cola_test_prompt_eval_mcc': 0.012011668791665235, 'cola_dev_eval_loss': 0.6854237914085388, 'cola_dev_eval_mcc': 0.3872983346207417, 'cola_test_eval_loss': 0.8614621758460999, 'cola_test_eval_mcc': 0.012011668791665235, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-13727', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_16-53-04_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-13727', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt_eval_loss': 0.9579123258590698, 'mrpc_dev_prompt_eval_acc': 0.625, 'mrpc_dev_prompt_eval_f1': 0.7000000000000001, 'mrpc_dev_prompt_eval_acc_and_f1': 0.6625000000000001, 'mrpc_test_prompt_eval_loss': 1.0484260320663452, 'mrpc_test_prompt_eval_acc': 0.6176470588235294, 'mrpc_test_prompt_eval_f1': 0.7243816254416962, 'mrpc_test_prompt_eval_acc_and_f1': 0.6710143421326128, 'mrpc_dev_eval_loss': 0.9579123258590698, 'mrpc_dev_eval_acc': 0.625, 'mrpc_dev_eval_f1': 0.7000000000000001, 'mrpc_dev_eval_acc_and_f1': 0.6625000000000001, 'mrpc_test_eval_loss': 1.0484260320663452, 'mrpc_test_eval_acc': 0.6176470588235294, 'mrpc_test_eval_f1': 0.7243816254416962, 'mrpc_test_eval_acc_and_f1': 0.6710143421326128, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-13-roberta-large-30354', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_16-59-31_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-13-roberta-large-30354', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt_eval_loss': 0.3713318705558777, 'sst-2_dev_prompt_eval_acc': 0.90625, 'sst-2_test_prompt_eval_loss': 0.3811998963356018, 'sst-2_test_prompt_eval_acc': 0.8211009174311926, 'sst-2_dev_eval_loss': 0.3713318705558777, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 0.3811998963356018, 'sst-2_test_eval_acc': 0.8211009174311926, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-9607', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_16-57-06_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-9607', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt_eval_loss': 1.2602747678756714, 'mnli_dev_prompt_eval_mnli/acc': 0.6041666666666666, 'mnli_test_prompt_eval_loss': 1.433363676071167, 'mnli_test_prompt_eval_mnli/acc': 0.49210392256749874, 'mnli-mm_test_prompt_eval_loss': 1.4069005250930786, 'mnli-mm_test_prompt_eval_mnli-mm/acc': 0.5105777054515866, 'mnli_dev_eval_loss': 1.2602747678756714, 'mnli_dev_eval_mnli/acc': 0.6041666666666666, 'mnli-mm_test_eval_loss': 1.4069005250930786, 'mnli-mm_test_eval_mnli-mm/acc': 0.5105777054515866, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-6451', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_16-53-12_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-6451', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt_eval_loss': 0.7874295115470886, 'mrpc_dev_prompt_eval_acc': 0.65625, 'mrpc_dev_prompt_eval_f1': 0.7441860465116279, 'mrpc_dev_prompt_eval_acc_and_f1': 0.700218023255814, 'mrpc_test_prompt_eval_loss': 0.796533465385437, 'mrpc_test_prompt_eval_acc': 0.5465686274509803, 'mrpc_test_prompt_eval_f1': 0.6782608695652175, 'mrpc_test_prompt_eval_acc_and_f1': 0.6124147485080988, 'mrpc_dev_eval_loss': 0.7874295115470886, 'mrpc_dev_eval_acc': 0.65625, 'mrpc_dev_eval_f1': 0.7441860465116279, 'mrpc_dev_eval_acc_and_f1': 0.700218023255814, 'mrpc_test_eval_loss': 0.796533465385437, 'mrpc_test_eval_acc': 0.5465686274509803, 'mrpc_test_eval_f1': 0.6782608695652175, 'mrpc_test_eval_acc_and_f1': 0.6124147485080988, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-21-roberta-large-13491', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_17-25-26_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-21-roberta-large-13491', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt_eval_loss': 0.9232919812202454, 'mnli_dev_prompt_eval_mnli/acc': 0.625, 'mnli_test_prompt_eval_loss': 1.0573326349258423, 'mnli_test_prompt_eval_mnli/acc': 0.5573102394294447, 'mnli-mm_test_prompt_eval_loss': 1.0235227346420288, 'mnli-mm_test_prompt_eval_mnli-mm/acc': 0.5657038242473555, 'mnli_dev_eval_loss': 0.9232919812202454, 'mnli_dev_eval_mnli/acc': 0.625, 'mnli-mm_test_eval_loss': 1.0235227346420288, 'mnli-mm_test_eval_mnli-mm/acc': 0.5657038242473555, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-19760', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_17-29-08_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-19760', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias_eval_loss': 1.4646990299224854, 'sst-2_dev_bias_eval_acc': 0.84375, 'sst-2_test_bias_eval_loss': 1.8229014873504639, 'sst-2_test_bias_eval_acc': 0.7947247706422018, 'sst-2_dev_eval_loss': 1.4646990299224854, 'sst-2_dev_eval_acc': 0.84375, 'sst-2_test_eval_loss': 1.8229014873504639, 'sst-2_test_eval_acc': 0.7947247706422018, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--13-roberta-large-6323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_17-43-53_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-6323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias_eval_loss': 4.384610176086426, 'cola_dev_bias_eval_mcc': 0.31311214554257477, 'cola_test_bias_eval_loss': 6.830787658691406, 'cola_test_bias_eval_mcc': -0.026960620676519206, 'cola_dev_eval_loss': 4.384610176086426, 'cola_dev_eval_mcc': 0.31311214554257477, 'cola_test_eval_loss': 6.830787658691406, 'cola_test_eval_mcc': -0.026960620676519206, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--13-roberta-large-2354', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_17-49-33_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-2354', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias_eval_loss': 3.029086112976074, 'mrpc_dev_bias_eval_acc': 0.71875, 'mrpc_dev_bias_eval_f1': 0.742857142857143, 'mrpc_dev_bias_eval_acc_and_f1': 0.7308035714285714, 'mrpc_test_bias_eval_loss': 3.153043746948242, 'mrpc_test_bias_eval_acc': 0.6078431372549019, 'mrpc_test_bias_eval_f1': 0.6981132075471699, 'mrpc_test_bias_eval_acc_and_f1': 0.652978172401036, 'mrpc_dev_eval_loss': 3.029086112976074, 'mrpc_dev_eval_acc': 0.71875, 'mrpc_dev_eval_f1': 0.742857142857143, 'mrpc_dev_eval_acc_and_f1': 0.7308035714285714, 'mrpc_test_eval_loss': 3.153043746948242, 'mrpc_test_eval_acc': 0.6078431372549019, 'mrpc_test_eval_f1': 0.6981132075471699, 'mrpc_test_eval_acc_and_f1': 0.652978172401036, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16--13-roberta-large-19642', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_17-57-07_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--13-roberta-large-19642', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt_eval_loss': 1.0213717222213745, 'mnli_dev_prompt_eval_mnli/acc': 0.6458333333333334, 'mnli_test_prompt_eval_loss': 1.1350582838058472, 'mnli_test_prompt_eval_mnli/acc': 0.5273560876209883, 'mnli-mm_test_prompt_eval_loss': 1.1035739183425903, 'mnli-mm_test_prompt_eval_mnli-mm/acc': 0.5340724165988608, 'mnli_dev_eval_loss': 1.0213717222213745, 'mnli_dev_eval_mnli/acc': 0.6458333333333334, 'mnli-mm_test_eval_loss': 1.1035739183425903, 'mnli-mm_test_eval_mnli-mm/acc': 0.5340724165988608, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-7416', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_18-09-24_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-7416', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias_eval_loss': 0.9961835741996765, 'sst-2_dev_bias_eval_acc': 0.875, 'sst-2_test_bias_eval_loss': 0.6199982166290283, 'sst-2_test_bias_eval_acc': 0.9243119266055045, 'sst-2_dev_eval_loss': 0.9961835741996765, 'sst-2_dev_eval_acc': 0.875, 'sst-2_test_eval_loss': 0.6199982166290283, 'sst-2_test_eval_acc': 0.9243119266055045, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--13-roberta-large-19670', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_18-18-24_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-19670', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias_eval_loss': 6.264068126678467, 'cola_dev_bias_eval_mcc': -0.06362847629757777, 'cola_test_bias_eval_loss': 7.910280704498291, 'cola_test_bias_eval_mcc': -0.01726754801723407, 'cola_dev_eval_loss': 6.264068126678467, 'cola_dev_eval_mcc': -0.06362847629757777, 'cola_test_eval_loss': 7.910280704498291, 'cola_test_eval_mcc': -0.01726754801723407, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--13-roberta-large-19461', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_18-19-30_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-19461', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias_eval_loss': 1.7623456716537476, 'mrpc_dev_bias_eval_acc': 0.75, 'mrpc_dev_bias_eval_f1': 0.7777777777777777, 'mrpc_dev_bias_eval_acc_and_f1': 0.7638888888888888, 'mrpc_test_bias_eval_loss': 2.376688003540039, 'mrpc_test_bias_eval_acc': 0.5980392156862745, 'mrpc_test_bias_eval_f1': 0.6846153846153846, 'mrpc_test_bias_eval_acc_and_f1': 0.6413273001508295, 'mrpc_dev_eval_loss': 1.7623456716537476, 'mrpc_dev_eval_acc': 0.75, 'mrpc_dev_eval_f1': 0.7777777777777777, 'mrpc_dev_eval_acc_and_f1': 0.7638888888888888, 'mrpc_test_eval_loss': 2.376688003540039, 'mrpc_test_eval_acc': 0.5980392156862745, 'mrpc_test_eval_f1': 0.6846153846153846, 'mrpc_test_eval_acc_and_f1': 0.6413273001508295, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16--13-roberta-large-5559', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_18-27-02_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--13-roberta-large-5559', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt_eval_loss': 0.9982584118843079, 'mnli_dev_prompt_eval_mnli/acc': 0.6666666666666666, 'mnli_test_prompt_eval_loss': 1.015684723854065, 'mnli_test_prompt_eval_mnli/acc': 0.5656647987773815, 'mnli-mm_test_prompt_eval_loss': 0.9913723468780518, 'mnli-mm_test_prompt_eval_mnli-mm/acc': 0.560720097640358, 'mnli_dev_eval_loss': 0.9982584118843079, 'mnli_dev_eval_mnli/acc': 0.6666666666666666, 'mnli-mm_test_eval_loss': 0.9913723468780518, 'mnli-mm_test_eval_mnli-mm/acc': 0.560720097640358, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-12171', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_18-44-39_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-12171', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias_eval_loss': 0.6180641651153564, 'sst-2_dev_bias_eval_acc': 0.9375, 'sst-2_test_bias_eval_loss': 0.5082018971443176, 'sst-2_test_bias_eval_acc': 0.9220183486238532, 'sst-2_dev_eval_loss': 0.6180641651153564, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.5082018971443176, 'sst-2_test_eval_acc': 0.9220183486238532, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--13-roberta-large-10703', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_18-51-04_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-10703', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias_eval_loss': 1.7015173435211182, 'mrpc_dev_bias_eval_acc': 0.78125, 'mrpc_dev_bias_eval_f1': 0.7999999999999999, 'mrpc_dev_bias_eval_acc_and_f1': 0.7906249999999999, 'mrpc_test_bias_eval_loss': 1.9576449394226074, 'mrpc_test_bias_eval_acc': 0.6715686274509803, 'mrpc_test_bias_eval_f1': 0.7640845070422534, 'mrpc_test_bias_eval_acc_and_f1': 0.7178265672466169, 'mrpc_dev_eval_loss': 1.7015173435211182, 'mrpc_dev_eval_acc': 0.78125, 'mrpc_dev_eval_f1': 0.7999999999999999, 'mrpc_dev_eval_acc_and_f1': 0.7906249999999999, 'mrpc_test_eval_loss': 1.9576449394226074, 'mrpc_test_eval_acc': 0.6715686274509803, 'mrpc_test_eval_f1': 0.7640845070422534, 'mrpc_test_eval_acc_and_f1': 0.7178265672466169, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16--13-roberta-large-26889', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_18-57-09_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--13-roberta-large-26889', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias_eval_loss': 4.193913459777832, 'cola_dev_bias_eval_mcc': 0.08606629658238704, 'cola_test_bias_eval_loss': 3.760326385498047, 'cola_test_bias_eval_mcc': -0.008342907804743322, 'cola_dev_eval_loss': 4.193913459777832, 'cola_dev_eval_mcc': 0.08606629658238704, 'cola_test_eval_loss': 3.760326385498047, 'cola_test_eval_mcc': -0.008342907804743322, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--13-roberta-large-19087', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_18-54-18_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-19087', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias_eval_loss': 3.0463664531707764, 'cola_dev_bias_eval_mcc': 0.07559289460184544, 'cola_test_bias_eval_loss': 3.3269147872924805, 'cola_test_bias_eval_mcc': 0.02085228147100117, 'cola_dev_eval_loss': 3.0463664531707764, 'cola_dev_eval_mcc': 0.07559289460184544, 'cola_test_eval_loss': 3.3269147872924805, 'cola_test_eval_mcc': 0.02085228147100117, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--13-roberta-large-693', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_19-27-17_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-693', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias_eval_loss': 0.5030081272125244, 'sst-2_dev_bias_eval_acc': 0.9375, 'sst-2_test_bias_eval_loss': 0.32552000880241394, 'sst-2_test_bias_eval_acc': 0.9277522935779816, 'sst-2_dev_eval_loss': 0.5030081272125244, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.32552000880241394, 'sst-2_test_eval_acc': 0.9277522935779816, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--13-roberta-large-6263', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_19-24-03_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-6263', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias_eval_loss': 2.5843982696533203, 'mnli_dev_bias_eval_mnli/acc': 0.7083333333333334, 'mnli_test_bias_eval_loss': 3.607689619064331, 'mnli_test_bias_eval_mnli/acc': 0.5588385124808966, 'mnli-mm_test_bias_eval_loss': 3.611374616622925, 'mnli-mm_test_bias_eval_mnli-mm/acc': 0.5689585028478438, 'mnli_dev_eval_loss': 2.5843982696533203, 'mnli_dev_eval_mnli/acc': 0.7083333333333334, 'mnli-mm_test_eval_loss': 3.611374616622925, 'mnli-mm_test_eval_mnli-mm/acc': 0.5689585028478438, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--13-roberta-large-12983', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_19-20-14_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--13-roberta-large-12983', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias_eval_loss': 1.8648817539215088, 'mrpc_dev_bias_eval_acc': 0.78125, 'mrpc_dev_bias_eval_f1': 0.7999999999999999, 'mrpc_dev_bias_eval_acc_and_f1': 0.7906249999999999, 'mrpc_test_bias_eval_loss': 2.04614520072937, 'mrpc_test_bias_eval_acc': 0.6813725490196079, 'mrpc_test_bias_eval_f1': 0.7686832740213524, 'mrpc_test_bias_eval_acc_and_f1': 0.7250279115204801, 'mrpc_dev_eval_loss': 1.8648817539215088, 'mrpc_dev_eval_acc': 0.78125, 'mrpc_dev_eval_f1': 0.7999999999999999, 'mrpc_dev_eval_acc_and_f1': 0.7906249999999999, 'mrpc_test_eval_loss': 2.04614520072937, 'mrpc_test_eval_acc': 0.6813725490196079, 'mrpc_test_eval_f1': 0.7686832740213524, 'mrpc_test_eval_acc_and_f1': 0.7250279115204801, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16--13-roberta-large-22888', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_19-27-09_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--13-roberta-large-22888', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_adapter_eval_loss': 3.684633493423462, 'cola_dev_adapter_eval_mcc': 0.18786728732554486, 'cola_test_adapter_eval_loss': 4.594339370727539, 'cola_test_adapter_eval_mcc': 0.026221377441177182, 'cola_dev_eval_loss': 3.684633493423462, 'cola_dev_eval_mcc': 0.18786728732554486, 'cola_test_eval_loss': 4.594339370727539, 'cola_test_eval_mcc': 0.026221377441177182, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--13-roberta-large-31170', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_19-53-02_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-31170', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias_eval_loss': 2.0620012283325195, 'mnli_dev_bias_eval_mnli/acc': 0.8333333333333334, 'mnli_test_bias_eval_loss': 2.8099312782287598, 'mnli_test_bias_eval_mnli/acc': 0.7127865511971472, 'mnli-mm_test_bias_eval_loss': 2.804811716079712, 'mnli-mm_test_bias_eval_mnli-mm/acc': 0.724979658258747, 'mnli_dev_eval_loss': 2.0620012283325195, 'mnli_dev_eval_mnli/acc': 0.8333333333333334, 'mnli-mm_test_eval_loss': 2.804811716079712, 'mnli-mm_test_eval_mnli-mm/acc': 0.724979658258747, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--13-roberta-large-14430', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_19-57-56_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--13-roberta-large-14430', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_adapter_eval_loss': 7.7874860763549805, 'mrpc_dev_adapter_eval_acc': 0.6875, 'mrpc_dev_adapter_eval_f1': 0.7368421052631579, 'mrpc_dev_adapter_eval_acc_and_f1': 0.712171052631579, 'mrpc_test_adapter_eval_loss': 9.256940841674805, 'mrpc_test_adapter_eval_acc': 0.6519607843137255, 'mrpc_test_adapter_eval_f1': 0.75, 'mrpc_test_adapter_eval_acc_and_f1': 0.7009803921568627, 'mrpc_dev_eval_loss': 7.7874860763549805, 'mrpc_dev_eval_acc': 0.6875, 'mrpc_dev_eval_f1': 0.7368421052631579, 'mrpc_dev_eval_acc_and_f1': 0.712171052631579, 'mrpc_test_eval_loss': 9.256940841674805, 'mrpc_test_eval_acc': 0.6519607843137255, 'mrpc_test_eval_f1': 0.75, 'mrpc_test_eval_acc_and_f1': 0.7009803921568627, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--13-roberta-large-21587', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_19-58-00_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--13-roberta-large-21587', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_adapter_eval_loss': 0.7180733680725098, 'sst-2_dev_adapter_eval_acc': 0.5, 'sst-2_test_adapter_eval_loss': 0.7221604585647583, 'sst-2_test_adapter_eval_acc': 0.4908256880733945, 'sst-2_dev_eval_loss': 0.7180733680725098, 'sst-2_dev_eval_acc': 0.5, 'sst-2_test_eval_loss': 0.7221604585647583, 'sst-2_test_eval_acc': 0.4908256880733945, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--13-roberta-large-13507', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_19-56-36_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-13507', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_adapter_eval_loss': 6.6731414794921875, 'cola_dev_adapter_eval_mcc': -0.08606629658238704, 'cola_test_adapter_eval_loss': 4.210511684417725, 'cola_test_adapter_eval_mcc': -0.058275904451708944, 'cola_dev_eval_loss': 6.6731414794921875, 'cola_dev_eval_mcc': -0.08606629658238704, 'cola_test_eval_loss': 4.210511684417725, 'cola_test_eval_mcc': -0.058275904451708944, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--13-roberta-large-20430', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_20-23-24_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-20430', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias_eval_loss': 1.7049494981765747, 'mnli_dev_bias_eval_mnli/acc': 0.8125, 'mnli_test_bias_eval_loss': 2.0516836643218994, 'mnli_test_bias_eval_mnli/acc': 0.6899643402954662, 'mnli-mm_test_bias_eval_loss': 2.0836503505706787, 'mnli-mm_test_bias_eval_mnli-mm/acc': 0.6986371033360456, 'mnli_dev_eval_loss': 1.7049494981765747, 'mnli_dev_eval_mnli/acc': 0.8125, 'mnli-mm_test_eval_loss': 2.0836503505706787, 'mnli-mm_test_eval_mnli-mm/acc': 0.6986371033360456, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--13-roberta-large-5963', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_20-35-49_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--13-roberta-large-5963', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_adapter_eval_loss': 1.3805279731750488, 'mrpc_dev_adapter_eval_acc': 0.78125, 'mrpc_dev_adapter_eval_f1': 0.7999999999999999, 'mrpc_dev_adapter_eval_acc_and_f1': 0.7906249999999999, 'mrpc_test_adapter_eval_loss': 2.263984441757202, 'mrpc_test_adapter_eval_acc': 0.625, 'mrpc_test_adapter_eval_f1': 0.7063339731285988, 'mrpc_test_adapter_eval_acc_and_f1': 0.6656669865642995, 'mrpc_dev_eval_loss': 1.3805279731750488, 'mrpc_dev_eval_acc': 0.78125, 'mrpc_dev_eval_f1': 0.7999999999999999, 'mrpc_dev_eval_acc_and_f1': 0.7906249999999999, 'mrpc_test_eval_loss': 2.263984441757202, 'mrpc_test_eval_acc': 0.625, 'mrpc_test_eval_f1': 0.7063339731285988, 'mrpc_test_eval_acc_and_f1': 0.6656669865642995, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--13-roberta-large-20719', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_20-37-34_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--13-roberta-large-20719', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_adapter_eval_loss': 0.779009222984314, 'sst-2_dev_adapter_eval_acc': 0.9375, 'sst-2_test_adapter_eval_loss': 0.6456940174102783, 'sst-2_test_adapter_eval_acc': 0.9288990825688074, 'sst-2_dev_eval_loss': 0.779009222984314, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.6456940174102783, 'sst-2_test_eval_acc': 0.9288990825688074, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--13-roberta-large-3352', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_20-40-27_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-3352', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_adapter_eval_loss': 5.731261253356934, 'cola_dev_adapter_eval_mcc': -0.06950480468569159, 'cola_test_adapter_eval_loss': 6.72513484954834, 'cola_test_adapter_eval_mcc': -0.010743676338155787, 'cola_dev_eval_loss': 5.731261253356934, 'cola_dev_eval_mcc': -0.06950480468569159, 'cola_test_eval_loss': 6.72513484954834, 'cola_test_eval_mcc': -0.010743676338155787, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--13-roberta-large-17054', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_20-55-03_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-17054', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias_eval_loss': 1.3325557708740234, 'mnli_dev_bias_eval_mnli/acc': 0.7708333333333334, 'mnli_test_bias_eval_loss': 1.7624977827072144, 'mnli_test_bias_eval_mnli/acc': 0.6623535404992359, 'mnli-mm_test_bias_eval_loss': 1.7349445819854736, 'mnli-mm_test_bias_eval_mnli-mm/acc': 0.6814483319772172, 'mnli_dev_eval_loss': 1.3325557708740234, 'mnli_dev_eval_mnli/acc': 0.7708333333333334, 'mnli-mm_test_eval_loss': 1.7349445819854736, 'mnli-mm_test_eval_mnli-mm/acc': 0.6814483319772172, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--13-roberta-large-12293', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_21-13-35_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--13-roberta-large-12293', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_adapter_eval_loss': 1.5317295789718628, 'mrpc_dev_adapter_eval_acc': 0.8125, 'mrpc_dev_adapter_eval_f1': 0.823529411764706, 'mrpc_dev_adapter_eval_acc_and_f1': 0.818014705882353, 'mrpc_test_adapter_eval_loss': 1.6904102563858032, 'mrpc_test_adapter_eval_acc': 0.6764705882352942, 'mrpc_test_adapter_eval_f1': 0.7555555555555556, 'mrpc_test_adapter_eval_acc_and_f1': 0.716013071895425, 'mrpc_dev_eval_loss': 1.5317295789718628, 'mrpc_dev_eval_acc': 0.8125, 'mrpc_dev_eval_f1': 0.823529411764706, 'mrpc_dev_eval_acc_and_f1': 0.818014705882353, 'mrpc_test_eval_loss': 1.6904102563858032, 'mrpc_test_eval_acc': 0.6764705882352942, 'mrpc_test_eval_f1': 0.7555555555555556, 'mrpc_test_eval_acc_and_f1': 0.716013071895425, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--13-roberta-large-74', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_21-17-38_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--13-roberta-large-74', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_adapter_eval_loss': 0.621643602848053, 'sst-2_dev_adapter_eval_acc': 0.9375, 'sst-2_test_adapter_eval_loss': 0.5187414884567261, 'sst-2_test_adapter_eval_acc': 0.926605504587156, 'sst-2_dev_eval_loss': 0.621643602848053, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.5187414884567261, 'sst-2_test_eval_acc': 0.926605504587156, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--13-roberta-large-11479', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_21-24-01_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-11479', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_adapter_eval_loss': 4.461949825286865, 'cola_dev_adapter_eval_mcc': 0.0, 'cola_test_adapter_eval_loss': 5.1071014404296875, 'cola_test_adapter_eval_mcc': 0.02064262523939339, 'cola_dev_eval_loss': 4.461949825286865, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 5.1071014404296875, 'cola_test_eval_mcc': 0.02064262523939339, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--13-roberta-large-9781', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_21-31-13_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-9781', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_adapter_eval_loss': 1.635066270828247, 'mrpc_dev_adapter_eval_acc': 0.78125, 'mrpc_dev_adapter_eval_f1': 0.7999999999999999, 'mrpc_dev_adapter_eval_acc_and_f1': 0.7906249999999999, 'mrpc_test_adapter_eval_loss': 1.7055072784423828, 'mrpc_test_adapter_eval_acc': 0.6838235294117647, 'mrpc_test_adapter_eval_f1': 0.7641681901279708, 'mrpc_test_adapter_eval_acc_and_f1': 0.7239958597698677, 'mrpc_dev_eval_loss': 1.635066270828247, 'mrpc_dev_eval_acc': 0.78125, 'mrpc_dev_eval_f1': 0.7999999999999999, 'mrpc_dev_eval_acc_and_f1': 0.7906249999999999, 'mrpc_test_eval_loss': 1.7055072784423828, 'mrpc_test_eval_acc': 0.6838235294117647, 'mrpc_test_eval_f1': 0.7641681901279708, 'mrpc_test_eval_acc_and_f1': 0.7239958597698677, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--13-roberta-large-1649', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_21-56-59_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--13-roberta-large-1649', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_adapter_eval_loss': 1.9059439897537231, 'mnli_dev_adapter_eval_mnli/acc': 0.75, 'mnli_test_adapter_eval_loss': 3.3420886993408203, 'mnli_test_adapter_eval_mnli/acc': 0.6587875700458482, 'mnli-mm_test_adapter_eval_loss': 3.5172812938690186, 'mnli-mm_test_adapter_eval_mnli-mm/acc': 0.6791090317331163, 'mnli_dev_eval_loss': 1.9059439897537231, 'mnli_dev_eval_mnli/acc': 0.75, 'mnli-mm_test_eval_loss': 3.5172812938690186, 'mnli-mm_test_eval_mnli-mm/acc': 0.6791090317331163, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--13-roberta-large-19606', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_21-50-42_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--13-roberta-large-19606', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_adapter_eval_loss': 0.4955602288246155, 'sst-2_dev_adapter_eval_acc': 0.9375, 'sst-2_test_adapter_eval_loss': 0.3841671347618103, 'sst-2_test_adapter_eval_acc': 0.9254587155963303, 'sst-2_dev_eval_loss': 0.4955602288246155, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.3841671347618103, 'sst-2_test_eval_acc': 0.9254587155963303, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--13-roberta-large-26119', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_22-07-16_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-26119', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,adapter_eval_loss': 0.7032244205474854, 'cola_dev_prompt,adapter_eval_mcc': 0.0, 'cola_test_prompt,adapter_eval_loss': 0.7576872706413269, 'cola_test_prompt,adapter_eval_mcc': 0.0, 'cola_dev_eval_loss': 0.7032244205474854, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.7576872706413269, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-6877', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_22-14-59_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-6877', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,adapter_eval_loss': 2.7053446769714355, 'mrpc_dev_prompt,adapter_eval_acc': 0.78125, 'mrpc_dev_prompt,adapter_eval_f1': 0.7741935483870969, 'mrpc_dev_prompt,adapter_eval_acc_and_f1': 0.7777217741935485, 'mrpc_test_prompt,adapter_eval_loss': 4.74504280090332, 'mrpc_test_prompt,adapter_eval_acc': 0.5416666666666666, 'mrpc_test_prompt,adapter_eval_f1': 0.58165548098434, 'mrpc_test_prompt,adapter_eval_acc_and_f1': 0.5616610738255032, 'mrpc_dev_eval_loss': 2.7053446769714355, 'mrpc_dev_eval_acc': 0.78125, 'mrpc_dev_eval_f1': 0.7741935483870969, 'mrpc_dev_eval_acc_and_f1': 0.7777217741935485, 'mrpc_test_eval_loss': 4.74504280090332, 'mrpc_test_eval_acc': 0.5416666666666666, 'mrpc_test_eval_f1': 0.58165548098434, 'mrpc_test_eval_acc_and_f1': 0.5616610738255032, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-13-roberta-large-11059', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_22-37-26_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-13-roberta-large-11059', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,adapter_eval_loss': 0.6948032975196838, 'sst-2_dev_prompt,adapter_eval_acc': 0.5, 'sst-2_test_prompt,adapter_eval_loss': 0.6937457323074341, 'sst-2_test_prompt,adapter_eval_acc': 0.5091743119266054, 'sst-2_dev_eval_loss': 0.6948032975196838, 'sst-2_dev_eval_acc': 0.5, 'sst-2_test_eval_loss': 0.6937457323074341, 'sst-2_test_eval_acc': 0.5091743119266054, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-22112', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_22-50-35_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-22112', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_adapter_eval_loss': 2.7415354251861572, 'mnli_dev_adapter_eval_mnli/acc': 0.7916666666666666, 'mnli_test_adapter_eval_loss': 3.6721909046173096, 'mnli_test_adapter_eval_mnli/acc': 0.6961793173713704, 'mnli-mm_test_adapter_eval_loss': 3.3849408626556396, 'mnli-mm_test_adapter_eval_mnli-mm/acc': 0.717046379170057, 'mnli_dev_eval_loss': 2.7415354251861572, 'mnli_dev_eval_mnli/acc': 0.7916666666666666, 'mnli-mm_test_eval_loss': 3.3849408626556396, 'mnli-mm_test_eval_mnli-mm/acc': 0.717046379170057, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--13-roberta-large-2428', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_22-42-32_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--13-roberta-large-2428', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,adapter_eval_loss': 7.93669319152832, 'cola_dev_prompt,adapter_eval_mcc': 0.0, 'cola_test_prompt,adapter_eval_loss': 4.349493980407715, 'cola_test_prompt,adapter_eval_mcc': 0.053304819469816585, 'cola_dev_eval_loss': 7.93669319152832, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 4.349493980407715, 'cola_test_eval_mcc': 0.053304819469816585, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-21180', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_22-58-33_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-21180', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,adapter_eval_loss': 1.9630526304244995, 'mrpc_dev_prompt,adapter_eval_acc': 0.75, 'mrpc_dev_prompt,adapter_eval_f1': 0.7777777777777777, 'mrpc_dev_prompt,adapter_eval_acc_and_f1': 0.7638888888888888, 'mrpc_test_prompt,adapter_eval_loss': 2.1864631175994873, 'mrpc_test_prompt,adapter_eval_acc': 0.6617647058823529, 'mrpc_test_prompt,adapter_eval_f1': 0.7509025270758123, 'mrpc_test_prompt,adapter_eval_acc_and_f1': 0.7063336164790825, 'mrpc_dev_eval_loss': 1.9630526304244995, 'mrpc_dev_eval_acc': 0.75, 'mrpc_dev_eval_f1': 0.7777777777777777, 'mrpc_dev_eval_acc_and_f1': 0.7638888888888888, 'mrpc_test_eval_loss': 2.1864631175994873, 'mrpc_test_eval_acc': 0.6617647058823529, 'mrpc_test_eval_f1': 0.7509025270758123, 'mrpc_test_eval_acc_and_f1': 0.7063336164790825, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-13-roberta-large-26035', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_23-17-14_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-13-roberta-large-26035', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,adapter_eval_loss': 0.9618673324584961, 'sst-2_dev_prompt,adapter_eval_acc': 0.9375, 'sst-2_test_prompt,adapter_eval_loss': 0.9761766195297241, 'sst-2_test_prompt,adapter_eval_acc': 0.9174311926605505, 'sst-2_dev_eval_loss': 0.9618673324584961, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.9761766195297241, 'sst-2_test_eval_acc': 0.9174311926605505, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-25678', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_23-33-48_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-25678', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_adapter_eval_loss': 1.8408727645874023, 'mnli_dev_adapter_eval_mnli/acc': 0.7708333333333334, 'mnli_test_adapter_eval_loss': 2.26737904548645, 'mnli_test_adapter_eval_mnli/acc': 0.6686704024452369, 'mnli-mm_test_adapter_eval_loss': 2.1879031658172607, 'mnli-mm_test_adapter_eval_mnli-mm/acc': 0.6841944670463792, 'mnli_dev_eval_loss': 1.8408727645874023, 'mnli_dev_eval_mnli/acc': 0.7708333333333334, 'mnli-mm_test_eval_loss': 2.1879031658172607, 'mnli-mm_test_eval_mnli-mm/acc': 0.6841944670463792, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--13-roberta-large-21099', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_23-34-47_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--13-roberta-large-21099', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,adapter_eval_loss': 4.66448974609375, 'cola_dev_prompt,adapter_eval_mcc': 0.08606629658238704, 'cola_test_prompt,adapter_eval_loss': 3.7756049633026123, 'cola_test_prompt,adapter_eval_mcc': 0.024011814488569573, 'cola_dev_eval_loss': 4.66448974609375, 'cola_dev_eval_mcc': 0.08606629658238704, 'cola_test_eval_loss': 3.7756049633026123, 'cola_test_eval_mcc': 0.024011814488569573, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-21244', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_23-43-47_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-21244', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,adapter_eval_loss': 2.4453611373901367, 'mrpc_dev_prompt,adapter_eval_acc': 0.78125, 'mrpc_dev_prompt,adapter_eval_f1': 0.7999999999999999, 'mrpc_dev_prompt,adapter_eval_acc_and_f1': 0.7906249999999999, 'mrpc_test_prompt,adapter_eval_loss': 2.6733946800231934, 'mrpc_test_prompt,adapter_eval_acc': 0.6691176470588235, 'mrpc_test_prompt,adapter_eval_f1': 0.7584973166368514, 'mrpc_test_prompt,adapter_eval_acc_and_f1': 0.7138074818478375, 'mrpc_dev_eval_loss': 2.4453611373901367, 'mrpc_dev_eval_acc': 0.78125, 'mrpc_dev_eval_f1': 0.7999999999999999, 'mrpc_dev_eval_acc_and_f1': 0.7906249999999999, 'mrpc_test_eval_loss': 2.6733946800231934, 'mrpc_test_eval_acc': 0.6691176470588235, 'mrpc_test_eval_f1': 0.7584973166368514, 'mrpc_test_eval_acc_and_f1': 0.7138074818478375, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-13-roberta-large-18575', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan07_23-56-30_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-13-roberta-large-18575', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,adapter_eval_loss': 0.6079031229019165, 'sst-2_dev_prompt,adapter_eval_acc': 0.9375, 'sst-2_test_prompt,adapter_eval_loss': 0.5812902450561523, 'sst-2_test_prompt,adapter_eval_acc': 0.9174311926605505, 'sst-2_dev_eval_loss': 0.6079031229019165, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.5812902450561523, 'sst-2_test_eval_acc': 0.9174311926605505, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-2201', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_00-19-11_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-2201', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,adapter_eval_loss': 1.8844544887542725, 'cola_dev_prompt,adapter_eval_mcc': 0.07559289460184544, 'cola_test_prompt,adapter_eval_loss': 1.6377137899398804, 'cola_test_prompt,adapter_eval_mcc': -0.013546558181587069, 'cola_dev_eval_loss': 1.8844544887542725, 'cola_dev_eval_mcc': 0.07559289460184544, 'cola_test_eval_loss': 1.6377137899398804, 'cola_test_eval_mcc': -0.013546558181587069, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-2244', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_00-24-32_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-2244', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_adapter_eval_loss': 2.0318403244018555, 'mnli_dev_adapter_eval_mnli/acc': 0.7291666666666666, 'mnli_test_adapter_eval_loss': 2.2010293006896973, 'mnli_test_adapter_eval_mnli/acc': 0.6675496688741722, 'mnli-mm_test_adapter_eval_loss': 2.0995712280273438, 'mnli-mm_test_adapter_eval_mnli-mm/acc': 0.6846013018714402, 'mnli_dev_eval_loss': 2.0318403244018555, 'mnli_dev_eval_mnli/acc': 0.7291666666666666, 'mnli-mm_test_eval_loss': 2.0995712280273438, 'mnli-mm_test_eval_mnli-mm/acc': 0.6846013018714402, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--13-roberta-large-21476', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_00-23-55_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--13-roberta-large-21476', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,adapter_eval_loss': 1.16267728805542, 'mrpc_dev_prompt,adapter_eval_acc': 0.78125, 'mrpc_dev_prompt,adapter_eval_f1': 0.7999999999999999, 'mrpc_dev_prompt,adapter_eval_acc_and_f1': 0.7906249999999999, 'mrpc_test_prompt,adapter_eval_loss': 1.1258517503738403, 'mrpc_test_prompt,adapter_eval_acc': 0.6617647058823529, 'mrpc_test_prompt,adapter_eval_f1': 0.7415730337078652, 'mrpc_test_prompt,adapter_eval_acc_and_f1': 0.701668869795109, 'mrpc_dev_eval_loss': 1.16267728805542, 'mrpc_dev_eval_acc': 0.78125, 'mrpc_dev_eval_f1': 0.7999999999999999, 'mrpc_dev_eval_acc_and_f1': 0.7906249999999999, 'mrpc_test_eval_loss': 1.1258517503738403, 'mrpc_test_eval_acc': 0.6617647058823529, 'mrpc_test_eval_f1': 0.7415730337078652, 'mrpc_test_eval_acc_and_f1': 0.701668869795109, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-13-roberta-large-17535', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_00-37-20_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-13-roberta-large-17535', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias_eval_loss': 3.906186103820801, 'cola_dev_prompt,bias_eval_mcc': 0.31311214554257477, 'cola_test_prompt,bias_eval_loss': 5.880455493927002, 'cola_test_prompt,bias_eval_mcc': 0.025913087060439887, 'cola_dev_eval_loss': 3.906186103820801, 'cola_dev_eval_mcc': 0.31311214554257477, 'cola_test_eval_loss': 5.880455493927002, 'cola_test_eval_mcc': 0.025913087060439887, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-13226', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_01-07-35_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-13226', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias_eval_loss': 2.4474430084228516, 'mrpc_dev_prompt,bias_eval_acc': 0.6875, 'mrpc_dev_prompt,bias_eval_f1': 0.7368421052631579, 'mrpc_dev_prompt,bias_eval_acc_and_f1': 0.712171052631579, 'mrpc_test_prompt,bias_eval_loss': 2.7996296882629395, 'mrpc_test_prompt,bias_eval_acc': 0.5686274509803921, 'mrpc_test_prompt,bias_eval_f1': 0.6589147286821706, 'mrpc_test_prompt,bias_eval_acc_and_f1': 0.6137710898312814, 'mrpc_dev_eval_loss': 2.4474430084228516, 'mrpc_dev_eval_acc': 0.6875, 'mrpc_dev_eval_f1': 0.7368421052631579, 'mrpc_dev_eval_acc_and_f1': 0.712171052631579, 'mrpc_test_eval_loss': 2.7996296882629395, 'mrpc_test_eval_acc': 0.5686274509803921, 'mrpc_test_eval_f1': 0.6589147286821706, 'mrpc_test_eval_acc_and_f1': 0.6137710898312814, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-13-roberta-large-4829', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_01-18-07_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-13-roberta-large-4829', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,adapter_eval_loss': 0.5083684325218201, 'sst-2_dev_prompt,adapter_eval_acc': 0.9375, 'sst-2_test_prompt,adapter_eval_loss': 0.4796261787414551, 'sst-2_test_prompt,adapter_eval_acc': 0.9197247706422018, 'sst-2_dev_eval_loss': 0.5083684325218201, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.4796261787414551, 'sst-2_test_eval_acc': 0.9197247706422018, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-63', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_01-02-51_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-63', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,adapter_eval_loss': 1.1685194969177246, 'mnli_dev_prompt,adapter_eval_mnli/acc': 0.3333333333333333, 'mnli_test_prompt,adapter_eval_loss': 1.1515648365020752, 'mnli_test_prompt,adapter_eval_mnli/acc': 0.3544574630667346, 'mnli-mm_test_prompt,adapter_eval_loss': 1.1528429985046387, 'mnli-mm_test_prompt,adapter_eval_mnli-mm/acc': 0.3522172497965826, 'mnli_dev_eval_loss': 1.1685194969177246, 'mnli_dev_eval_mnli/acc': 0.3333333333333333, 'mnli_test_eval_loss': 1.1515648365020752, 'mnli_test_eval_mnli/acc': 0.3544574630667346, 'mnli-mm_test_eval_loss': 1.1528429985046387, 'mnli-mm_test_eval_mnli-mm/acc': 0.3522172497965826, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-19438', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_01-16-07_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-19438', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias_eval_loss': 5.469093322753906, 'cola_dev_prompt,bias_eval_mcc': 0.3216337604513384, 'cola_test_prompt,bias_eval_loss': 4.180451393127441, 'cola_test_prompt,bias_eval_mcc': -0.009252032508089042, 'cola_dev_eval_loss': 5.469093322753906, 'cola_dev_eval_mcc': 0.3216337604513384, 'cola_test_eval_loss': 4.180451393127441, 'cola_test_eval_mcc': -0.009252032508089042, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-16330', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_01-42-59_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-16330', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias_eval_loss': 1.5379767417907715, 'mrpc_dev_prompt,bias_eval_acc': 0.71875, 'mrpc_dev_prompt,bias_eval_f1': 0.7567567567567567, 'mrpc_dev_prompt,bias_eval_acc_and_f1': 0.7377533783783783, 'mrpc_test_prompt,bias_eval_loss': 1.8155521154403687, 'mrpc_test_prompt,bias_eval_acc': 0.6151960784313726, 'mrpc_test_prompt,bias_eval_f1': 0.7020872865275143, 'mrpc_test_prompt,bias_eval_acc_and_f1': 0.6586416824794434, 'mrpc_dev_eval_loss': 1.5379767417907715, 'mrpc_dev_eval_acc': 0.71875, 'mrpc_dev_eval_f1': 0.7567567567567567, 'mrpc_dev_eval_acc_and_f1': 0.7377533783783783, 'mrpc_test_eval_loss': 1.8155521154403687, 'mrpc_test_eval_acc': 0.6151960784313726, 'mrpc_test_eval_f1': 0.7020872865275143, 'mrpc_test_eval_acc_and_f1': 0.6586416824794434, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-13-roberta-large-31826', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_01-45-51_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-13-roberta-large-31826', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias_eval_loss': 0.5992187261581421, 'sst-2_dev_prompt,bias_eval_acc': 0.9375, 'sst-2_test_prompt,bias_eval_loss': 0.5419799089431763, 'sst-2_test_prompt,bias_eval_acc': 0.9151376146788991, 'sst-2_dev_eval_loss': 0.5992187261581421, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.5419799089431763, 'sst-2_test_eval_acc': 0.9151376146788991, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-17372', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_01-47-01_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-17372', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias_eval_loss': 1.7150521278381348, 'mrpc_dev_prompt,bias_eval_acc': 0.71875, 'mrpc_dev_prompt,bias_eval_f1': 0.7567567567567567, 'mrpc_dev_prompt,bias_eval_acc_and_f1': 0.7377533783783783, 'mrpc_test_prompt,bias_eval_loss': 1.8325390815734863, 'mrpc_test_prompt,bias_eval_acc': 0.6151960784313726, 'mrpc_test_prompt,bias_eval_f1': 0.7150635208711433, 'mrpc_test_prompt,bias_eval_acc_and_f1': 0.665129799651258, 'mrpc_dev_eval_loss': 1.7150521278381348, 'mrpc_dev_eval_acc': 0.71875, 'mrpc_dev_eval_f1': 0.7567567567567567, 'mrpc_dev_eval_acc_and_f1': 0.7377533783783783, 'mrpc_test_eval_loss': 1.8325390815734863, 'mrpc_test_eval_acc': 0.6151960784313726, 'mrpc_test_eval_f1': 0.7150635208711433, 'mrpc_test_eval_acc_and_f1': 0.665129799651258, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-13-roberta-large-31146', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_02-10-13_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-13-roberta-large-31146', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias_eval_loss': 1.8337534666061401, 'cola_dev_prompt,bias_eval_mcc': 0.0, 'cola_test_prompt,bias_eval_loss': 1.6060833930969238, 'cola_test_prompt,bias_eval_mcc': 0.01834705324263748, 'cola_dev_eval_loss': 1.8337534666061401, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 1.6060833930969238, 'cola_test_eval_mcc': 0.01834705324263748, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-19409', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_02-09-34_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-19409', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias_eval_loss': 0.6946921348571777, 'sst-2_dev_prompt,bias_eval_acc': 0.90625, 'sst-2_test_prompt,bias_eval_loss': 0.5325573682785034, 'sst-2_test_prompt,bias_eval_acc': 0.9197247706422018, 'sst-2_dev_eval_loss': 0.6946921348571777, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 0.5325573682785034, 'sst-2_test_eval_acc': 0.9197247706422018, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-21994', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_02-18-56_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-21994', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,adapter_eval_loss': 3.03478741645813, 'mnli_dev_prompt,adapter_eval_mnli/acc': 0.7083333333333334, 'mnli_test_prompt,adapter_eval_loss': 2.936108350753784, 'mnli_test_prompt,adapter_eval_mnli/acc': 0.6353540499235864, 'mnli-mm_test_prompt,adapter_eval_loss': 2.785567045211792, 'mnli-mm_test_prompt,adapter_eval_mnli-mm/acc': 0.6552074857607811, 'mnli_dev_eval_loss': 3.03478741645813, 'mnli_dev_eval_mnli/acc': 0.7083333333333334, 'mnli_test_eval_loss': 2.936108350753784, 'mnli_test_eval_mnli/acc': 0.6353540499235864, 'mnli-mm_test_eval_loss': 2.785567045211792, 'mnli-mm_test_eval_mnli-mm/acc': 0.6552074857607811, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-24897', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_02-07-34_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-24897', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias_eval_loss': 1.0413459539413452, 'mrpc_dev_prompt,bias_eval_acc': 0.71875, 'mrpc_dev_prompt,bias_eval_f1': 0.7567567567567567, 'mrpc_dev_prompt,bias_eval_acc_and_f1': 0.7377533783783783, 'mrpc_test_prompt,bias_eval_loss': 1.0623633861541748, 'mrpc_test_prompt,bias_eval_acc': 0.6495098039215687, 'mrpc_test_prompt,bias_eval_f1': 0.7423423423423424, 'mrpc_test_prompt,bias_eval_acc_and_f1': 0.6959260731319555, 'mrpc_dev_eval_loss': 1.0413459539413452, 'mrpc_dev_eval_acc': 0.71875, 'mrpc_dev_eval_f1': 0.7567567567567567, 'mrpc_dev_eval_acc_and_f1': 0.7377533783783783, 'mrpc_test_eval_loss': 1.0623633861541748, 'mrpc_test_eval_acc': 0.6495098039215687, 'mrpc_test_eval_f1': 0.7423423423423424, 'mrpc_test_eval_acc_and_f1': 0.6959260731319555, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-13-roberta-large-13', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_02-35-20_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-13-roberta-large-13', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias_eval_loss': 0.877253532409668, 'cola_dev_prompt,bias_eval_mcc': 0.0, 'cola_test_prompt,bias_eval_loss': 0.964718222618103, 'cola_test_prompt,bias_eval_mcc': -0.022935907714615785, 'cola_dev_eval_loss': 0.877253532409668, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.964718222618103, 'cola_test_eval_mcc': -0.022935907714615785, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-15981', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_02-35-29_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-15981', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias_eval_loss': 0.5684208869934082, 'sst-2_dev_prompt,bias_eval_acc': 0.90625, 'sst-2_test_prompt,bias_eval_loss': 0.43369418382644653, 'sst-2_test_prompt,bias_eval_acc': 0.9254587155963303, 'sst-2_dev_eval_loss': 0.5684208869934082, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 0.43369418382644653, 'sst-2_test_eval_acc': 0.9254587155963303, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-291', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_02-50-35_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-291', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias,adapter_eval_loss': 7.8410210609436035, 'cola_dev_bias,adapter_eval_mcc': 0.12909944487358055, 'cola_test_bias,adapter_eval_loss': 7.255195140838623, 'cola_test_bias,adapter_eval_mcc': -0.002427791795894944, 'cola_dev_eval_loss': 7.8410210609436035, 'cola_dev_eval_mcc': 0.12909944487358055, 'cola_test_eval_loss': 7.255195140838623, 'cola_test_eval_mcc': -0.002427791795894944, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--13-roberta-large-8882', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_03-01-33_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-8882', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias,adapter_eval_loss': 0.6981226205825806, 'mrpc_dev_bias,adapter_eval_acc': 0.5, 'mrpc_dev_bias,adapter_eval_f1': 0.6666666666666666, 'mrpc_dev_bias,adapter_eval_acc_and_f1': 0.5833333333333333, 'mrpc_test_bias,adapter_eval_loss': 0.6613793969154358, 'mrpc_test_bias,adapter_eval_acc': 0.6838235294117647, 'mrpc_test_bias,adapter_eval_f1': 0.8122270742358079, 'mrpc_test_bias,adapter_eval_acc_and_f1': 0.7480253018237863, 'mrpc_dev_eval_loss': 0.6981226205825806, 'mrpc_dev_eval_acc': 0.5, 'mrpc_dev_eval_f1': 0.6666666666666666, 'mrpc_dev_eval_acc_and_f1': 0.5833333333333333, 'mrpc_test_eval_loss': 0.6613793969154358, 'mrpc_test_eval_acc': 0.6838235294117647, 'mrpc_test_eval_f1': 0.8122270742358079, 'mrpc_test_eval_acc_and_f1': 0.7480253018237863, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--13-roberta-large-25539', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_03-00-34_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--13-roberta-large-25539', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,adapter_eval_loss': 2.3065836429595947, 'mnli_dev_prompt,adapter_eval_mnli/acc': 0.7708333333333334, 'mnli_test_prompt,adapter_eval_loss': 2.5475826263427734, 'mnli_test_prompt,adapter_eval_mnli/acc': 0.6626591951095262, 'mnli-mm_test_prompt,adapter_eval_loss': 2.4167540073394775, 'mnli-mm_test_prompt,adapter_eval_mnli-mm/acc': 0.6822620016273393, 'mnli_dev_eval_loss': 2.3065836429595947, 'mnli_dev_eval_mnli/acc': 0.7708333333333334, 'mnli_test_eval_loss': 2.5475826263427734, 'mnli_test_eval_mnli/acc': 0.6626591951095262, 'mnli-mm_test_eval_loss': 2.4167540073394775, 'mnli-mm_test_eval_mnli-mm/acc': 0.6822620016273393, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-9087', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_02-59-21_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-9087', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias_eval_loss': 0.31517717242240906, 'sst-2_dev_prompt,bias_eval_acc': 0.9375, 'sst-2_test_prompt,bias_eval_loss': 0.26591813564300537, 'sst-2_test_prompt,bias_eval_acc': 0.9059633027522935, 'sst-2_dev_eval_loss': 0.31517717242240906, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.26591813564300537, 'sst-2_test_eval_acc': 0.9059633027522935, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-9962', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_03-22-33_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-9962', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias,adapter_eval_loss': 2.6007566452026367, 'mrpc_dev_bias,adapter_eval_acc': 0.8125, 'mrpc_dev_bias,adapter_eval_f1': 0.823529411764706, 'mrpc_dev_bias,adapter_eval_acc_and_f1': 0.818014705882353, 'mrpc_test_bias,adapter_eval_loss': 3.254140615463257, 'mrpc_test_bias,adapter_eval_acc': 0.6764705882352942, 'mrpc_test_bias,adapter_eval_f1': 0.7471264367816093, 'mrpc_test_bias,adapter_eval_acc_and_f1': 0.7117985125084517, 'mrpc_dev_eval_loss': 2.6007566452026367, 'mrpc_dev_eval_acc': 0.8125, 'mrpc_dev_eval_f1': 0.823529411764706, 'mrpc_dev_eval_acc_and_f1': 0.818014705882353, 'mrpc_test_eval_loss': 3.254140615463257, 'mrpc_test_eval_acc': 0.6764705882352942, 'mrpc_test_eval_f1': 0.7471264367816093, 'mrpc_test_eval_acc_and_f1': 0.7117985125084517, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--13-roberta-large-14305', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_03-36-38_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--13-roberta-large-14305', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias,adapter_eval_loss': 6.516814708709717, 'cola_dev_bias,adapter_eval_mcc': 0.0, 'cola_test_bias,adapter_eval_loss': 4.51572322845459, 'cola_test_bias,adapter_eval_mcc': -0.04213205332186959, 'cola_dev_eval_loss': 6.516814708709717, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 4.51572322845459, 'cola_test_eval_mcc': -0.04213205332186959, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--13-roberta-large-19995', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_03-36-33_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-19995', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias,adapter_eval_loss': 2.1189260482788086, 'sst-2_dev_bias,adapter_eval_acc': 0.8125, 'sst-2_test_bias,adapter_eval_loss': 1.1589524745941162, 'sst-2_test_bias,adapter_eval_acc': 0.8830275229357798, 'sst-2_dev_eval_loss': 2.1189260482788086, 'sst-2_dev_eval_acc': 0.8125, 'sst-2_test_eval_loss': 1.1589524745941162, 'sst-2_test_eval_acc': 0.8830275229357798, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--13-roberta-large-3212', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_03-54-34_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-3212', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,adapter_eval_loss': 1.866289496421814, 'mnli_dev_prompt,adapter_eval_mnli/acc': 0.7291666666666666, 'mnli_test_prompt,adapter_eval_loss': 2.067322015762329, 'mnli_test_prompt,adapter_eval_mnli/acc': 0.6505348955680081, 'mnli-mm_test_prompt,adapter_eval_loss': 1.9945766925811768, 'mnli-mm_test_prompt,adapter_eval_mnli-mm/acc': 0.6648698128559805, 'mnli_dev_eval_loss': 1.866289496421814, 'mnli_dev_eval_mnli/acc': 0.7291666666666666, 'mnli_test_eval_loss': 2.067322015762329, 'mnli_test_eval_mnli/acc': 0.6505348955680081, 'mnli-mm_test_eval_loss': 1.9945766925811768, 'mnli-mm_test_eval_mnli-mm/acc': 0.6648698128559805, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-10149', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_03-51-26_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-10149', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias,adapter_eval_loss': 1.7010101079940796, 'mrpc_dev_bias,adapter_eval_acc': 0.8125, 'mrpc_dev_bias,adapter_eval_f1': 0.823529411764706, 'mrpc_dev_bias,adapter_eval_acc_and_f1': 0.818014705882353, 'mrpc_test_bias,adapter_eval_loss': 1.8481439352035522, 'mrpc_test_bias,adapter_eval_acc': 0.6911764705882353, 'mrpc_test_bias,adapter_eval_f1': 0.772563176895307, 'mrpc_test_bias,adapter_eval_acc_and_f1': 0.7318698237417711, 'mrpc_dev_eval_loss': 1.7010101079940796, 'mrpc_dev_eval_acc': 0.8125, 'mrpc_dev_eval_f1': 0.823529411764706, 'mrpc_dev_eval_acc_and_f1': 0.818014705882353, 'mrpc_test_eval_loss': 1.8481439352035522, 'mrpc_test_eval_acc': 0.6911764705882353, 'mrpc_test_eval_f1': 0.772563176895307, 'mrpc_test_eval_acc_and_f1': 0.7318698237417711, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--13-roberta-large-3911', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_04-12-15_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--13-roberta-large-3911', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias,adapter_eval_loss': 4.84277868270874, 'cola_dev_bias,adapter_eval_mcc': 0.08606629658238704, 'cola_test_bias,adapter_eval_loss': 3.2252180576324463, 'cola_test_bias,adapter_eval_mcc': -0.010226667356320277, 'cola_dev_eval_loss': 4.84277868270874, 'cola_dev_eval_mcc': 0.08606629658238704, 'cola_test_eval_loss': 3.2252180576324463, 'cola_test_eval_mcc': -0.010226667356320277, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--13-roberta-large-24729', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_04-24-34_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-24729', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias_eval_loss': 2.6757256984710693, 'mnli_dev_prompt,bias_eval_mnli/acc': 0.75, 'mnli_test_prompt,bias_eval_loss': 3.208395004272461, 'mnli_test_prompt,bias_eval_mnli/acc': 0.6664289353031075, 'mnli-mm_test_prompt,bias_eval_loss': 3.1188740730285645, 'mnli-mm_test_prompt,bias_eval_mnli-mm/acc': 0.6817534580960131, 'mnli_dev_eval_loss': 2.6757256984710693, 'mnli_dev_eval_mnli/acc': 0.75, 'mnli_test_eval_loss': 3.208395004272461, 'mnli_test_eval_mnli/acc': 0.6664289353031075, 'mnli-mm_test_eval_loss': 3.1188740730285645, 'mnli-mm_test_eval_mnli-mm/acc': 0.6817534580960131, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-2302', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_04-41-37_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-2302', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias,adapter_eval_loss': 1.6022422313690186, 'mrpc_dev_bias,adapter_eval_acc': 0.78125, 'mrpc_dev_bias,adapter_eval_f1': 0.7999999999999999, 'mrpc_dev_bias,adapter_eval_acc_and_f1': 0.7906249999999999, 'mrpc_test_bias,adapter_eval_loss': 1.5878167152404785, 'mrpc_test_bias,adapter_eval_acc': 0.6691176470588235, 'mrpc_test_bias,adapter_eval_f1': 0.7567567567567567, 'mrpc_test_bias,adapter_eval_acc_and_f1': 0.7129372019077901, 'mrpc_dev_eval_loss': 1.6022422313690186, 'mrpc_dev_eval_acc': 0.78125, 'mrpc_dev_eval_f1': 0.7999999999999999, 'mrpc_dev_eval_acc_and_f1': 0.7906249999999999, 'mrpc_test_eval_loss': 1.5878167152404785, 'mrpc_test_eval_acc': 0.6691176470588235, 'mrpc_test_eval_f1': 0.7567567567567567, 'mrpc_test_eval_acc_and_f1': 0.7129372019077901, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--13-roberta-large-24369', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_04-48-44_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--13-roberta-large-24369', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias,adapter_eval_loss': 0.8416551351547241, 'sst-2_dev_bias,adapter_eval_acc': 0.90625, 'sst-2_test_bias,adapter_eval_loss': 0.5810015201568604, 'sst-2_test_bias,adapter_eval_acc': 0.9208715596330275, 'sst-2_dev_eval_loss': 0.8416551351547241, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 0.5810015201568604, 'sst-2_test_eval_acc': 0.9208715596330275, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--13-roberta-large-15011', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_04-41-16_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-15011', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias,adapter_eval_loss': 2.6218178272247314, 'cola_dev_bias,adapter_eval_mcc': 0.0, 'cola_test_bias,adapter_eval_loss': 2.208848237991333, 'cola_test_bias,adapter_eval_mcc': 0.016479857104178708, 'cola_dev_eval_loss': 2.6218178272247314, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 2.208848237991333, 'cola_test_eval_mcc': 0.016479857104178708, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--13-roberta-large-20774', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_05-08-35_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-20774', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias_eval_loss': 2.3027307987213135, 'mnli_dev_prompt,bias_eval_mnli/acc': 0.7708333333333334, 'mnli_test_prompt,bias_eval_loss': 2.4638500213623047, 'mnli_test_prompt,bias_eval_mnli/acc': 0.6562404482934284, 'mnli-mm_test_prompt,bias_eval_loss': 2.347703695297241, 'mnli-mm_test_prompt,bias_eval_mnli-mm/acc': 0.6720911310008136, 'mnli_dev_eval_loss': 2.3027307987213135, 'mnli_dev_eval_mnli/acc': 0.7708333333333334, 'mnli_test_eval_loss': 2.4638500213623047, 'mnli_test_eval_mnli/acc': 0.6562404482934284, 'mnli-mm_test_eval_loss': 2.347703695297241, 'mnli-mm_test_eval_mnli-mm/acc': 0.6720911310008136, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-21259', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_05-18-52_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-21259', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias,adapter_eval_loss': 0.6984291076660156, 'mrpc_dev_prompt,bias,adapter_eval_acc': 0.5, 'mrpc_dev_prompt,bias,adapter_eval_f1': 0.6666666666666666, 'mrpc_dev_prompt,bias,adapter_eval_acc_and_f1': 0.5833333333333333, 'mrpc_test_prompt,bias,adapter_eval_loss': 0.6605992317199707, 'mrpc_test_prompt,bias,adapter_eval_acc': 0.6838235294117647, 'mrpc_test_prompt,bias,adapter_eval_f1': 0.8122270742358079, 'mrpc_test_prompt,bias,adapter_eval_acc_and_f1': 0.7480253018237863, 'mrpc_dev_eval_loss': 0.6984291076660156, 'mrpc_dev_eval_acc': 0.5, 'mrpc_dev_eval_f1': 0.6666666666666666, 'mrpc_dev_eval_acc_and_f1': 0.5833333333333333, 'mrpc_test_eval_loss': 0.6605992317199707, 'mrpc_test_eval_acc': 0.6838235294117647, 'mrpc_test_eval_f1': 0.8122270742358079, 'mrpc_test_eval_acc_and_f1': 0.7480253018237863, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-13-roberta-large-29463', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_05-25-06_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-13-roberta-large-29463', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias,adapter_eval_loss': 0.7248585224151611, 'sst-2_dev_bias,adapter_eval_acc': 0.9375, 'sst-2_test_bias,adapter_eval_loss': 0.559150755405426, 'sst-2_test_bias,adapter_eval_acc': 0.9208715596330275, 'sst-2_dev_eval_loss': 0.7248585224151611, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.559150755405426, 'sst-2_test_eval_acc': 0.9208715596330275, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--13-roberta-large-10192', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_05-27-24_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-10192', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias,adapter_eval_loss': 2.7496862411499023, 'mrpc_dev_prompt,bias,adapter_eval_acc': 0.78125, 'mrpc_dev_prompt,bias,adapter_eval_f1': 0.7999999999999999, 'mrpc_dev_prompt,bias,adapter_eval_acc_and_f1': 0.7906249999999999, 'mrpc_test_prompt,bias,adapter_eval_loss': 3.3360047340393066, 'mrpc_test_prompt,bias,adapter_eval_acc': 0.6176470588235294, 'mrpc_test_prompt,bias,adapter_eval_f1': 0.7132352941176471, 'mrpc_test_prompt,bias,adapter_eval_acc_and_f1': 0.6654411764705883, 'mrpc_dev_eval_loss': 2.7496862411499023, 'mrpc_dev_eval_acc': 0.78125, 'mrpc_dev_eval_f1': 0.7999999999999999, 'mrpc_dev_eval_acc_and_f1': 0.7906249999999999, 'mrpc_test_eval_loss': 3.3360047340393066, 'mrpc_test_eval_acc': 0.6176470588235294, 'mrpc_test_eval_f1': 0.7132352941176471, 'mrpc_test_eval_acc_and_f1': 0.6654411764705883, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-13-roberta-large-25280', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_06-01-39_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-13-roberta-large-25280', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias_eval_loss': 1.8873462677001953, 'mnli_dev_prompt,bias_eval_mnli/acc': 0.7708333333333334, 'mnli_test_prompt,bias_eval_loss': 2.4655849933624268, 'mnli_test_prompt,bias_eval_mnli/acc': 0.6533876719307183, 'mnli-mm_test_prompt,bias_eval_loss': 2.3887016773223877, 'mnli-mm_test_prompt,bias_eval_mnli-mm/acc': 0.673413344182262, 'mnli_dev_eval_loss': 1.8873462677001953, 'mnli_dev_eval_mnli/acc': 0.7708333333333334, 'mnli_test_eval_loss': 2.4655849933624268, 'mnli_test_eval_mnli/acc': 0.6533876719307183, 'mnli-mm_test_eval_loss': 2.3887016773223877, 'mnli-mm_test_eval_mnli-mm/acc': 0.673413344182262, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-12326', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_05-56-57_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-12326', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias,adapter_eval_loss': 0.706721305847168, 'cola_dev_prompt,bias,adapter_eval_mcc': 0.0, 'cola_test_prompt,bias,adapter_eval_loss': 0.6435227394104004, 'cola_test_prompt,bias,adapter_eval_mcc': 0.0, 'cola_dev_eval_loss': 0.706721305847168, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.6435227394104004, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-4674', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_05-55-39_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-4674', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias,adapter_eval_loss': 0.559302031993866, 'sst-2_dev_bias,adapter_eval_acc': 0.9375, 'sst-2_test_bias,adapter_eval_loss': 0.44988685846328735, 'sst-2_test_bias,adapter_eval_acc': 0.9185779816513762, 'sst-2_dev_eval_loss': 0.559302031993866, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.44988685846328735, 'sst-2_test_eval_acc': 0.9185779816513762, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--13-roberta-large-14299', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_06-13-13_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-14299', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias,adapter_eval_loss': 2.7030961513519287, 'mrpc_dev_prompt,bias,adapter_eval_acc': 0.75, 'mrpc_dev_prompt,bias,adapter_eval_f1': 0.7777777777777777, 'mrpc_dev_prompt,bias,adapter_eval_acc_and_f1': 0.7638888888888888, 'mrpc_test_prompt,bias,adapter_eval_loss': 2.803624153137207, 'mrpc_test_prompt,bias,adapter_eval_acc': 0.6911764705882353, 'mrpc_test_prompt,bias,adapter_eval_f1': 0.7789473684210526, 'mrpc_test_prompt,bias,adapter_eval_acc_and_f1': 0.735061919504644, 'mrpc_dev_eval_loss': 2.7030961513519287, 'mrpc_dev_eval_acc': 0.75, 'mrpc_dev_eval_f1': 0.7777777777777777, 'mrpc_dev_eval_acc_and_f1': 0.7638888888888888, 'mrpc_test_eval_loss': 2.803624153137207, 'mrpc_test_eval_acc': 0.6911764705882353, 'mrpc_test_eval_f1': 0.7789473684210526, 'mrpc_test_eval_acc_and_f1': 0.735061919504644, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-13-roberta-large-14529', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_06-34-07_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-13-roberta-large-14529', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias_eval_loss': 1.6450814008712769, 'mnli_dev_prompt,bias_eval_mnli/acc': 0.7708333333333334, 'mnli_test_prompt,bias_eval_loss': 2.0621631145477295, 'mnli_test_prompt,bias_eval_mnli/acc': 0.6405501782985227, 'mnli-mm_test_prompt,bias_eval_loss': 2.0106582641601562, 'mnli-mm_test_prompt,bias_eval_mnli-mm/acc': 0.6604963384865744, 'mnli_dev_eval_loss': 1.6450814008712769, 'mnli_dev_eval_mnli/acc': 0.7708333333333334, 'mnli_test_eval_loss': 2.0621631145477295, 'mnli_test_eval_mnli/acc': 0.6405501782985227, 'mnli-mm_test_eval_loss': 2.0106582641601562, 'mnli-mm_test_eval_mnli-mm/acc': 0.6604963384865744, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-18468', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_06-35-23_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-18468', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias,adapter_eval_loss': 5.740513801574707, 'cola_dev_prompt,bias,adapter_eval_mcc': 0.06950480468569159, 'cola_test_prompt,bias,adapter_eval_loss': 5.32684326171875, 'cola_test_prompt,bias,adapter_eval_mcc': -0.005102538312877722, 'cola_dev_eval_loss': 5.740513801574707, 'cola_dev_eval_mcc': 0.06950480468569159, 'cola_test_eval_loss': 5.32684326171875, 'cola_test_eval_mcc': -0.005102538312877722, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-7092', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_06-39-31_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-7092', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias,adapter_eval_loss': 1.3325215578079224, 'mrpc_dev_prompt,bias,adapter_eval_acc': 0.78125, 'mrpc_dev_prompt,bias,adapter_eval_f1': 0.7999999999999999, 'mrpc_dev_prompt,bias,adapter_eval_acc_and_f1': 0.7906249999999999, 'mrpc_test_prompt,bias,adapter_eval_loss': 1.380152702331543, 'mrpc_test_prompt,bias,adapter_eval_acc': 0.6470588235294118, 'mrpc_test_prompt,bias,adapter_eval_f1': 0.7272727272727274, 'mrpc_test_prompt,bias,adapter_eval_acc_and_f1': 0.6871657754010696, 'mrpc_dev_eval_loss': 1.3325215578079224, 'mrpc_dev_eval_acc': 0.78125, 'mrpc_dev_eval_f1': 0.7999999999999999, 'mrpc_dev_eval_acc_and_f1': 0.7906249999999999, 'mrpc_test_eval_loss': 1.380152702331543, 'mrpc_test_eval_acc': 0.6470588235294118, 'mrpc_test_eval_f1': 0.7272727272727274, 'mrpc_test_eval_acc_and_f1': 0.6871657754010696, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-13-roberta-large-4404', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_07-05-20_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-13-roberta-large-4404', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_eval_loss': 1.3814105987548828, 'mrpc_dev_eval_acc': 0.5, 'mrpc_dev_eval_f1': 0.0, 'mrpc_dev_eval_acc_and_f1': 0.25, 'mrpc_test_eval_loss': 1.8892905712127686, 'mrpc_test_eval_acc': 0.32107843137254904, 'mrpc_test_eval_f1': 0.014234875444839857, 'mrpc_test_eval_acc_and_f1': 0.16765665340869446, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16--13-roberta-large-10210', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_07-34-51_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--13-roberta-large-10210', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': None, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias,adapter_eval_loss': 0.7231623530387878, 'sst-2_dev_prompt,bias,adapter_eval_acc': 0.5, 'sst-2_test_prompt,bias,adapter_eval_loss': 0.7186423540115356, 'sst-2_test_prompt,bias,adapter_eval_acc': 0.5091743119266054, 'sst-2_dev_eval_loss': 0.7231623530387878, 'sst-2_dev_eval_acc': 0.5, 'sst-2_test_eval_loss': 0.7186423540115356, 'sst-2_test_eval_acc': 0.5091743119266054, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-109', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_07-00-35_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-109', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt_eval_loss': 1.0603021383285522, 'mrpc_dev_prompt_eval_acc': 0.5625, 'mrpc_dev_prompt_eval_f1': 0.65, 'mrpc_dev_prompt_eval_acc_and_f1': 0.60625, 'mrpc_test_prompt_eval_loss': 0.8604354858398438, 'mrpc_test_prompt_eval_acc': 0.4852941176470588, 'mrpc_test_prompt_eval_f1': 0.5643153526970954, 'mrpc_test_prompt_eval_acc_and_f1': 0.5248047351720772, 'mrpc_dev_eval_loss': 1.0603021383285522, 'mrpc_dev_eval_acc': 0.5625, 'mrpc_dev_eval_f1': 0.65, 'mrpc_dev_eval_acc_and_f1': 0.60625, 'mrpc_test_eval_loss': 0.8604354858398438, 'mrpc_test_eval_acc': 0.4852941176470588, 'mrpc_test_eval_f1': 0.5643153526970954, 'mrpc_test_eval_acc_and_f1': 0.5248047351720772, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-13-roberta-large-13340', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_07-35-24_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-13-roberta-large-13340', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias,adapter_eval_loss': 1.1293917894363403, 'mnli_dev_bias,adapter_eval_mnli/acc': 0.3333333333333333, 'mnli_test_bias,adapter_eval_loss': 1.1181005239486694, 'mnli_test_bias,adapter_eval_mnli/acc': 0.3544574630667346, 'mnli-mm_test_bias,adapter_eval_loss': 1.118994951248169, 'mnli-mm_test_bias,adapter_eval_mnli-mm/acc': 0.3522172497965826, 'mnli_dev_eval_loss': 1.1293917894363403, 'mnli_dev_eval_mnli/acc': 0.3333333333333333, 'mnli_test_eval_loss': 1.1181005239486694, 'mnli_test_eval_mnli/acc': 0.3544574630667346, 'mnli-mm_test_eval_loss': 1.118994951248169, 'mnli-mm_test_eval_mnli-mm/acc': 0.3522172497965826, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--13-roberta-large-3357', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_07-12-18_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--13-roberta-large-3357', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias,adapter_eval_loss': 4.29964017868042, 'cola_dev_prompt,bias,adapter_eval_mcc': 0.12909944487358055, 'cola_test_prompt,bias,adapter_eval_loss': 5.387047290802002, 'cola_test_prompt,bias,adapter_eval_mcc': -0.01004603501749632, 'cola_dev_eval_loss': 4.29964017868042, 'cola_dev_eval_mcc': 0.12909944487358055, 'cola_test_eval_loss': 5.387047290802002, 'cola_test_eval_mcc': -0.01004603501749632, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-25587', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_07-24-11_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-25587', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt_eval_loss': 3.3440768718719482, 'mrpc_dev_prompt_eval_acc': 0.65625, 'mrpc_dev_prompt_eval_f1': 0.6857142857142857, 'mrpc_dev_prompt_eval_acc_and_f1': 0.6709821428571429, 'mrpc_test_prompt_eval_loss': 4.451681137084961, 'mrpc_test_prompt_eval_acc': 0.49264705882352944, 'mrpc_test_prompt_eval_f1': 0.5835010060362174, 'mrpc_test_prompt_eval_acc_and_f1': 0.5380740324298734, 'mrpc_dev_eval_loss': 3.3440768718719482, 'mrpc_dev_eval_acc': 0.65625, 'mrpc_dev_eval_f1': 0.6857142857142857, 'mrpc_dev_eval_acc_and_f1': 0.6709821428571429, 'mrpc_test_eval_loss': 4.451681137084961, 'mrpc_test_eval_acc': 0.49264705882352944, 'mrpc_test_eval_f1': 0.5835010060362174, 'mrpc_test_eval_acc_and_f1': 0.5380740324298734, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-13-roberta-large-24650', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_07-53-14_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-13-roberta-large-24650', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt_eval_loss': 3.632643222808838, 'mrpc_dev_prompt_eval_acc': 0.625, 'mrpc_dev_prompt_eval_f1': 0.6666666666666665, 'mrpc_dev_prompt_eval_acc_and_f1': 0.6458333333333333, 'mrpc_test_prompt_eval_loss': 4.758169174194336, 'mrpc_test_prompt_eval_acc': 0.5147058823529411, 'mrpc_test_prompt_eval_f1': 0.6055776892430279, 'mrpc_test_prompt_eval_acc_and_f1': 0.5601417857979845, 'mrpc_dev_eval_loss': 3.632643222808838, 'mrpc_dev_eval_acc': 0.625, 'mrpc_dev_eval_f1': 0.6666666666666665, 'mrpc_dev_eval_acc_and_f1': 0.6458333333333333, 'mrpc_test_eval_loss': 4.758169174194336, 'mrpc_test_eval_acc': 0.5147058823529411, 'mrpc_test_eval_f1': 0.6055776892430279, 'mrpc_test_eval_acc_and_f1': 0.5601417857979845, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-13-roberta-large-26961', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_08-11-41_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-13-roberta-large-26961', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias,adapter_eval_loss': 0.8795157670974731, 'sst-2_dev_prompt,bias,adapter_eval_acc': 0.875, 'sst-2_test_prompt,bias,adapter_eval_loss': 0.6771456003189087, 'sst-2_test_prompt,bias,adapter_eval_acc': 0.9220183486238532, 'sst-2_dev_eval_loss': 0.8795157670974731, 'sst-2_dev_eval_acc': 0.875, 'sst-2_test_eval_loss': 0.6771456003189087, 'sst-2_test_eval_acc': 0.9220183486238532, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-11458', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_07-48-26_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-11458', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias,adapter_eval_loss': 2.241354465484619, 'cola_dev_prompt,bias,adapter_eval_mcc': 0.07559289460184544, 'cola_test_prompt,bias,adapter_eval_loss': 1.977989673614502, 'cola_test_prompt,bias,adapter_eval_mcc': 0.01058886620033453, 'cola_dev_eval_loss': 2.241354465484619, 'cola_dev_eval_mcc': 0.07559289460184544, 'cola_test_eval_loss': 1.977989673614502, 'cola_test_eval_mcc': 0.01058886620033453, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-32071', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_08-11-18_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-32071', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_eval_loss': 1.2224597930908203, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.8328907489776611, 'cola_test_eval_mcc': 0.0463559874942472, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--13-roberta-large-13652', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_08-44-35_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-13652', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': None, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt_eval_loss': 1.412327766418457, 'mrpc_dev_prompt_eval_acc': 0.46875, 'mrpc_dev_prompt_eval_f1': 0.5641025641025642, 'mrpc_dev_prompt_eval_acc_and_f1': 0.5164262820512822, 'mrpc_test_prompt_eval_loss': 1.0945583581924438, 'mrpc_test_prompt_eval_acc': 0.5563725490196079, 'mrpc_test_prompt_eval_f1': 0.6616822429906543, 'mrpc_test_prompt_eval_acc_and_f1': 0.6090273960051311, 'mrpc_dev_eval_loss': 1.412327766418457, 'mrpc_dev_eval_acc': 0.46875, 'mrpc_dev_eval_f1': 0.5641025641025642, 'mrpc_dev_eval_acc_and_f1': 0.5164262820512822, 'mrpc_test_eval_loss': 1.0945583581924438, 'mrpc_test_eval_acc': 0.5563725490196079, 'mrpc_test_eval_f1': 0.6616822429906543, 'mrpc_test_eval_acc_and_f1': 0.6090273960051311, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-13-roberta-large-29729', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_08-29-57_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-13-roberta-large-29729', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_eval_loss': 1.6232727766036987, 'qnli_dev_eval_acc': 0.5, 'qnli_test_eval_loss': 1.5716580152511597, 'qnli_test_eval_acc': 0.5081457074867289, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16--13-roberta-large-13780', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_08-57-47_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--13-roberta-large-13780', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': None, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias,adapter_eval_loss': 2.714449167251587, 'mnli_dev_bias,adapter_eval_mnli/acc': 0.8333333333333334, 'mnli_test_bias,adapter_eval_loss': 4.363613128662109, 'mnli_test_bias,adapter_eval_mnli/acc': 0.6851757514009169, 'mnli-mm_test_bias,adapter_eval_loss': 4.0518951416015625, 'mnli-mm_test_bias,adapter_eval_mnli-mm/acc': 0.7048413344182262, 'mnli_dev_eval_loss': 2.714449167251587, 'mnli_dev_eval_mnli/acc': 0.8333333333333334, 'mnli_test_eval_loss': 4.363613128662109, 'mnli_test_eval_mnli/acc': 0.6851757514009169, 'mnli-mm_test_eval_loss': 4.0518951416015625, 'mnli-mm_test_eval_mnli-mm/acc': 0.7048413344182262, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--13-roberta-large-31132', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_08-04-27_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--13-roberta-large-31132', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_eval_loss': 1.204769492149353, 'rte_dev_eval_acc': 0.5, 'rte_test_eval_loss': 1.3036892414093018, 'rte_test_eval_acc': 0.5126353790613718, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16--13-roberta-large-16066', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_09-01-29_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--13-roberta-large-16066', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': None, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt_eval_loss': 0.6259279251098633, 'cola_dev_prompt_eval_mcc': 0.40451991747794525, 'cola_test_prompt_eval_loss': 0.9696660041809082, 'cola_test_prompt_eval_mcc': 0.0233807096399483, 'cola_dev_eval_loss': 0.6259279251098633, 'cola_dev_eval_mcc': 0.40451991747794525, 'cola_test_eval_loss': 0.9696660041809082, 'cola_test_eval_mcc': 0.0233807096399483, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-22021', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_08-45-16_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-22021', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias_eval_loss': 4.017003059387207, 'mrpc_dev_bias_eval_acc': 0.59375, 'mrpc_dev_bias_eval_f1': 0.6060606060606061, 'mrpc_dev_bias_eval_acc_and_f1': 0.599905303030303, 'mrpc_test_bias_eval_loss': 5.006618499755859, 'mrpc_test_bias_eval_acc': 0.4730392156862745, 'mrpc_test_bias_eval_f1': 0.5232815964523281, 'mrpc_test_bias_eval_acc_and_f1': 0.4981604060693013, 'mrpc_dev_eval_loss': 4.017003059387207, 'mrpc_dev_eval_acc': 0.59375, 'mrpc_dev_eval_f1': 0.6060606060606061, 'mrpc_dev_eval_acc_and_f1': 0.599905303030303, 'mrpc_test_eval_loss': 5.006618499755859, 'mrpc_test_eval_acc': 0.4730392156862745, 'mrpc_test_eval_f1': 0.5232815964523281, 'mrpc_test_eval_acc_and_f1': 0.4981604060693013, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16--13-roberta-large-24199', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_08-47-46_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--13-roberta-large-24199', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_eval_loss': 1.1100637912750244, 'qqp_dev_eval_acc': 0.5, 'qqp_dev_eval_f1': 0.6190476190476191, 'qqp_dev_eval_acc_and_f1': 0.5595238095238095, 'qqp_test_eval_loss': 1.2592968940734863, 'qqp_test_eval_acc': 0.3859015582488251, 'qqp_test_eval_f1': 0.49710350415231924, 'qqp_test_eval_acc_and_f1': 0.44150253120057215, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16--13-roberta-large-13778', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_09-08-08_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--13-roberta-large-13778', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': None, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt_eval_loss': 0.6665041446685791, 'qnli_dev_prompt_eval_acc': 0.625, 'qnli_test_prompt_eval_loss': 0.8824911117553711, 'qnli_test_prompt_eval_acc': 0.5304777594728172, 'qnli_dev_eval_loss': 0.6665041446685791, 'qnli_dev_eval_acc': 0.625, 'qnli_test_eval_loss': 0.8824911117553711, 'qnli_test_eval_acc': 0.5304777594728172, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-13-roberta-large-12430', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_08-58-45_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-13-roberta-large-12430', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias,adapter_eval_loss': 0.7595686316490173, 'sst-2_dev_prompt,bias,adapter_eval_acc': 0.90625, 'sst-2_test_prompt,bias,adapter_eval_loss': 0.6155619025230408, 'sst-2_test_prompt,bias,adapter_eval_acc': 0.9174311926605505, 'sst-2_dev_eval_loss': 0.7595686316490173, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 0.6155619025230408, 'sst-2_test_eval_acc': 0.9174311926605505, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-1422', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_08-36-30_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-1422', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias_eval_loss': 3.6409618854522705, 'mrpc_dev_bias_eval_acc': 0.6875, 'mrpc_dev_bias_eval_f1': 0.7368421052631579, 'mrpc_dev_bias_eval_acc_and_f1': 0.712171052631579, 'mrpc_test_bias_eval_loss': 3.157982349395752, 'mrpc_test_bias_eval_acc': 0.6004901960784313, 'mrpc_test_bias_eval_f1': 0.7073608617594254, 'mrpc_test_bias_eval_acc_and_f1': 0.6539255289189283, 'mrpc_dev_eval_loss': 3.6409618854522705, 'mrpc_dev_eval_acc': 0.6875, 'mrpc_dev_eval_f1': 0.7368421052631579, 'mrpc_dev_eval_acc_and_f1': 0.712171052631579, 'mrpc_test_eval_loss': 3.157982349395752, 'mrpc_test_eval_acc': 0.6004901960784313, 'mrpc_test_eval_f1': 0.7073608617594254, 'mrpc_test_eval_acc_and_f1': 0.6539255289189283, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16--13-roberta-large-6398', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_09-08-39_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--13-roberta-large-6398', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt_eval_loss': 0.715823769569397, 'cola_dev_prompt_eval_mcc': 0.0, 'cola_test_prompt_eval_loss': 0.7207757830619812, 'cola_test_prompt_eval_mcc': 0.03298912474719909, 'cola_dev_eval_loss': 0.715823769569397, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.7207757830619812, 'cola_test_eval_mcc': 0.03298912474719909, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-14580', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_09-08-27_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-14580', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt_eval_loss': 0.6259827613830566, 'rte_dev_prompt_eval_acc': 0.59375, 'rte_test_prompt_eval_loss': 0.8184297680854797, 'rte_test_prompt_eval_acc': 0.5018050541516246, 'rte_dev_eval_loss': 0.6259827613830566, 'rte_dev_eval_acc': 0.59375, 'rte_test_eval_loss': 0.8184297680854797, 'rte_test_eval_acc': 0.5018050541516246, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-13-roberta-large-26840', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_09-02-16_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-13-roberta-large-26840', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt_eval_loss': 0.6555521488189697, 'qnli_dev_prompt_eval_acc': 0.6875, 'qnli_test_prompt_eval_loss': 0.8311136960983276, 'qnli_test_prompt_eval_acc': 0.5956434193666483, 'qnli_dev_eval_loss': 0.6555521488189697, 'qnli_dev_eval_acc': 0.6875, 'qnli_test_eval_loss': 0.8311136960983276, 'qnli_test_eval_acc': 0.5956434193666483, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-13-roberta-large-23108', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_09-18-04_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-13-roberta-large-23108', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt_eval_loss': 0.6274725198745728, 'cola_dev_prompt_eval_mcc': 0.3779644730092272, 'cola_test_prompt_eval_loss': 0.7883346676826477, 'cola_test_prompt_eval_mcc': 0.01647191991207847, 'cola_dev_eval_loss': 0.6274725198745728, 'cola_dev_eval_mcc': 0.3779644730092272, 'cola_test_eval_loss': 0.7883346676826477, 'cola_test_eval_mcc': 0.01647191991207847, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-19378', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_09-31-04_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-19378', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt_eval_loss': 2.323589324951172, 'qqp_dev_prompt_eval_acc': 0.78125, 'qqp_dev_prompt_eval_f1': 0.7999999999999999, 'qqp_dev_prompt_eval_acc_and_f1': 0.7906249999999999, 'qqp_test_prompt_eval_loss': 4.15665864944458, 'qqp_test_prompt_eval_acc': 0.5387830818698985, 'qqp_test_prompt_eval_f1': 0.5173297440012425, 'qqp_test_prompt_eval_acc_and_f1': 0.5280564129355705, 'qqp_dev_eval_loss': 2.323589324951172, 'qqp_dev_eval_acc': 0.78125, 'qqp_dev_eval_f1': 0.7999999999999999, 'qqp_dev_eval_acc_and_f1': 0.7906249999999999, 'qqp_test_eval_loss': 4.15665864944458, 'qqp_test_eval_acc': 0.5387830818698985, 'qqp_test_eval_f1': 0.5173297440012425, 'qqp_test_eval_acc_and_f1': 0.5280564129355705, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-13-roberta-large-30567', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_09-12-01_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-13-roberta-large-30567', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias_eval_loss': 2.7516603469848633, 'mrpc_dev_bias_eval_acc': 0.65625, 'mrpc_dev_bias_eval_f1': 0.6451612903225806, 'mrpc_dev_bias_eval_acc_and_f1': 0.6507056451612903, 'mrpc_test_bias_eval_loss': 3.4496448040008545, 'mrpc_test_bias_eval_acc': 0.4681372549019608, 'mrpc_test_bias_eval_f1': 0.5272331154684097, 'mrpc_test_bias_eval_acc_and_f1': 0.49768518518518523, 'mrpc_dev_eval_loss': 2.7516603469848633, 'mrpc_dev_eval_acc': 0.65625, 'mrpc_dev_eval_f1': 0.6451612903225806, 'mrpc_dev_eval_acc_and_f1': 0.6507056451612903, 'mrpc_test_eval_loss': 3.4496448040008545, 'mrpc_test_eval_acc': 0.4681372549019608, 'mrpc_test_eval_f1': 0.5272331154684097, 'mrpc_test_eval_acc_and_f1': 0.49768518518518523, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16--13-roberta-large-26032', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_09-30-23_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--13-roberta-large-26032', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_eval_loss': 2.678952217102051, 'sts-b_dev_eval_pearson': 0.09618039597604366, 'sts-b_dev_eval_spearmanr': 0.08763574508642726, 'sts-b_dev_eval_corr': 0.09190807053123545, 'sts-b_test_eval_loss': 2.906134843826294, 'sts-b_test_eval_pearson': -0.03285045465299691, 'sts-b_test_eval_spearmanr': -0.030667190202901175, 'sts-b_test_eval_corr': -0.03175882242794904, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16--13-roberta-large-23743', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_09-55-20_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--13-roberta-large-23743', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': None, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias,adapter_eval_loss': 1.7425802946090698, 'mnli_dev_bias,adapter_eval_mnli/acc': 0.7291666666666666, 'mnli_test_bias,adapter_eval_loss': 2.0414626598358154, 'mnli_test_bias,adapter_eval_mnli/acc': 0.6786551197147224, 'mnli-mm_test_bias,adapter_eval_loss': 1.9493701457977295, 'mnli-mm_test_bias,adapter_eval_mnli-mm/acc': 0.6952807160292921, 'mnli_dev_eval_loss': 1.7425802946090698, 'mnli_dev_eval_mnli/acc': 0.7291666666666666, 'mnli_test_eval_loss': 2.0414626598358154, 'mnli_test_eval_mnli/acc': 0.6786551197147224, 'mnli-mm_test_eval_loss': 1.9493701457977295, 'mnli-mm_test_eval_mnli-mm/acc': 0.6952807160292921, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--13-roberta-large-21152', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_09-00-41_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--13-roberta-large-21152', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt_eval_loss': 0.6692912578582764, 'qnli_dev_prompt_eval_acc': 0.6875, 'qnli_test_prompt_eval_loss': 0.8477494120597839, 'qnli_test_prompt_eval_acc': 0.5870400878638111, 'qnli_dev_eval_loss': 0.6692912578582764, 'qnli_dev_eval_acc': 0.6875, 'qnli_test_eval_loss': 0.8477494120597839, 'qnli_test_eval_acc': 0.5870400878638111, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-13-roberta-large-24506', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_09-37-26_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-13-roberta-large-24506', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.3073558807373047, 'sts-b_dev_prompt_eval_pearson': 0.26623044135545615, 'sts-b_dev_prompt_eval_spearmanr': 0.3101239784190549, 'sts-b_dev_prompt_eval_corr': 0.28817720988725554, 'sts-b_test_prompt_eval_loss': 2.325716257095337, 'sts-b_test_prompt_eval_pearson': -0.04761284847424089, 'sts-b_test_prompt_eval_spearmanr': -0.04729400162542256, 'sts-b_test_prompt_eval_corr': -0.04745342504983173, 'sts-b_dev_eval_loss': 2.3073558807373047, 'sts-b_dev_eval_pearson': 0.26623044135545615, 'sts-b_dev_eval_spearmanr': 0.3101239784190549, 'sts-b_dev_eval_corr': 0.28817720988725554, 'sts-b_test_eval_loss': 2.325716257095337, 'sts-b_test_eval_pearson': -0.04761284847424089, 'sts-b_test_eval_spearmanr': -0.04729400162542256, 'sts-b_test_eval_corr': -0.04745342504983173, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-13-roberta-large-9284', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_09-55-53_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-13-roberta-large-9284', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt_eval_loss': 1.00839102268219, 'rte_dev_prompt_eval_acc': 0.625, 'rte_test_prompt_eval_loss': 1.1008206605911255, 'rte_test_prompt_eval_acc': 0.4548736462093863, 'rte_dev_eval_loss': 1.00839102268219, 'rte_dev_eval_acc': 0.625, 'rte_test_eval_loss': 1.1008206605911255, 'rte_test_eval_acc': 0.4548736462093863, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-13-roberta-large-27999', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_09-34-31_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-13-roberta-large-27999', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt_eval_loss': 0.7667334079742432, 'cola_dev_prompt_eval_mcc': 0.19738550848793068, 'cola_test_prompt_eval_loss': 0.8345268368721008, 'cola_test_prompt_eval_mcc': 0.030446342304820788, 'cola_dev_eval_loss': 0.7667334079742432, 'cola_dev_eval_mcc': 0.19738550848793068, 'cola_test_eval_loss': 0.8345268368721008, 'cola_test_eval_mcc': 0.030446342304820788, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-11523', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_09-48-33_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-11523', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias_eval_loss': 1.8077253103256226, 'mrpc_dev_bias_eval_acc': 0.65625, 'mrpc_dev_bias_eval_f1': 0.6451612903225806, 'mrpc_dev_bias_eval_acc_and_f1': 0.6507056451612903, 'mrpc_test_bias_eval_loss': 2.757891893386841, 'mrpc_test_bias_eval_acc': 0.4362745098039216, 'mrpc_test_bias_eval_f1': 0.481981981981982, 'mrpc_test_bias_eval_acc_and_f1': 0.45912824589295176, 'mrpc_dev_eval_loss': 1.8077253103256226, 'mrpc_dev_eval_acc': 0.65625, 'mrpc_dev_eval_f1': 0.6451612903225806, 'mrpc_dev_eval_acc_and_f1': 0.6507056451612903, 'mrpc_test_eval_loss': 2.757891893386841, 'mrpc_test_eval_acc': 0.4362745098039216, 'mrpc_test_eval_f1': 0.481981981981982, 'mrpc_test_eval_acc_and_f1': 0.45912824589295176, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16--13-roberta-large-8019', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_09-52-30_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--13-roberta-large-8019', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 2), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias,adapter_eval_loss': 0.5602312088012695, 'sst-2_dev_prompt,bias,adapter_eval_acc': 0.9375, 'sst-2_test_prompt,bias,adapter_eval_loss': 0.5301756858825684, 'sst-2_test_prompt,bias,adapter_eval_acc': 0.9185779816513762, 'sst-2_dev_eval_loss': 0.5602312088012695, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.5301756858825684, 'sst-2_test_eval_acc': 0.9185779816513762, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-26161', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_09-26-05_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-26161', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.2921197414398193, 'sts-b_dev_prompt_eval_pearson': 0.6453856007900427, 'sts-b_dev_prompt_eval_spearmanr': 0.6680158682059737, 'sts-b_dev_prompt_eval_corr': 0.6567007344980083, 'sts-b_test_prompt_eval_loss': 2.548140048980713, 'sts-b_test_prompt_eval_pearson': 0.03849889871212906, 'sts-b_test_prompt_eval_spearmanr': 0.041491111410553325, 'sts-b_test_prompt_eval_corr': 0.039995005061341196, 'sts-b_dev_eval_loss': 2.2921197414398193, 'sts-b_dev_eval_pearson': 0.6453856007900427, 'sts-b_dev_eval_spearmanr': 0.6680158682059737, 'sts-b_dev_eval_corr': 0.6567007344980083, 'sts-b_test_eval_loss': 2.548140048980713, 'sts-b_test_eval_pearson': 0.03849889871212906, 'sts-b_test_eval_spearmanr': 0.041491111410553325, 'sts-b_test_eval_corr': 0.039995005061341196, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-13-roberta-large-781', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_10-05-45_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-13-roberta-large-781', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_eval_loss': 1.1278355121612549, 'sst-2_dev_eval_acc': 0.5, 'sst-2_test_eval_loss': 1.166092872619629, 'sst-2_test_eval_acc': 0.5091743119266054, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--13-roberta-large-19278', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_10-24-14_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-19278', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': None, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt_eval_loss': 0.5795002579689026, 'qnli_dev_prompt_eval_acc': 0.75, 'qnli_test_prompt_eval_loss': 0.9484924674034119, 'qnli_test_prompt_eval_acc': 0.5886875343218012, 'qnli_dev_eval_loss': 0.5795002579689026, 'qnli_dev_eval_acc': 0.75, 'qnli_test_eval_loss': 0.9484924674034119, 'qnli_test_eval_acc': 0.5886875343218012, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-13-roberta-large-22344', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_10-19-36_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-13-roberta-large-22344', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt_eval_loss': 1.2935459613800049, 'qqp_dev_prompt_eval_acc': 0.65625, 'qqp_dev_prompt_eval_f1': 0.7317073170731707, 'qqp_dev_prompt_eval_acc_and_f1': 0.6939786585365854, 'qqp_test_prompt_eval_loss': 1.5524414777755737, 'qqp_test_prompt_eval_acc': 0.5127875340093989, 'qqp_test_prompt_eval_f1': 0.5289362923282953, 'qqp_test_prompt_eval_acc_and_f1': 0.5208619131688471, 'qqp_dev_eval_loss': 1.2935459613800049, 'qqp_dev_eval_acc': 0.65625, 'qqp_dev_eval_f1': 0.7317073170731707, 'qqp_dev_eval_acc_and_f1': 0.6939786585365854, 'qqp_test_eval_loss': 1.5524414777755737, 'qqp_test_eval_acc': 0.5127875340093989, 'qqp_test_eval_f1': 0.5289362923282953, 'qqp_test_eval_acc_and_f1': 0.5208619131688471, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-13-roberta-large-11669', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_09-49-51_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-13-roberta-large-11669', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias_eval_loss': 1.5561878681182861, 'cola_dev_bias_eval_mcc': 0.4383570037596047, 'cola_test_bias_eval_loss': 3.50972056388855, 'cola_test_bias_eval_mcc': -0.0035117768451477477, 'cola_dev_eval_loss': 1.5561878681182861, 'cola_dev_eval_mcc': 0.4383570037596047, 'cola_test_eval_loss': 3.50972056388855, 'cola_test_eval_mcc': -0.0035117768451477477, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--13-roberta-large-12319', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_10-13-54_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-12319', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_adapter_eval_loss': 4.121964931488037, 'mrpc_dev_adapter_eval_acc': 0.6875, 'mrpc_dev_adapter_eval_f1': 0.7222222222222223, 'mrpc_dev_adapter_eval_acc_and_f1': 0.7048611111111112, 'mrpc_test_adapter_eval_loss': 3.6464600563049316, 'mrpc_test_adapter_eval_acc': 0.6225490196078431, 'mrpc_test_adapter_eval_f1': 0.72, 'mrpc_test_adapter_eval_acc_and_f1': 0.6712745098039216, 'mrpc_dev_eval_loss': 4.121964931488037, 'mrpc_dev_eval_acc': 0.6875, 'mrpc_dev_eval_f1': 0.7222222222222223, 'mrpc_dev_eval_acc_and_f1': 0.7048611111111112, 'mrpc_test_eval_loss': 3.6464600563049316, 'mrpc_test_eval_acc': 0.6225490196078431, 'mrpc_test_eval_f1': 0.72, 'mrpc_test_eval_acc_and_f1': 0.6712745098039216, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--13-roberta-large-14682', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_10-16-34_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--13-roberta-large-14682', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias,adapter_eval_loss': 1.8795706033706665, 'mnli_dev_bias,adapter_eval_mnli/acc': 0.8125, 'mnli_test_bias,adapter_eval_loss': 2.2814700603485107, 'mnli_test_bias,adapter_eval_mnli/acc': 0.6592969943963322, 'mnli-mm_test_bias,adapter_eval_loss': 2.1782126426696777, 'mnli-mm_test_bias,adapter_eval_mnli-mm/acc': 0.6788039056143206, 'mnli_dev_eval_loss': 1.8795706033706665, 'mnli_dev_eval_mnli/acc': 0.8125, 'mnli_test_eval_loss': 2.2814700603485107, 'mnli_test_eval_mnli/acc': 0.6592969943963322, 'mnli-mm_test_eval_loss': 2.1782126426696777, 'mnli-mm_test_eval_mnli-mm/acc': 0.6788039056143206, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--13-roberta-large-25279', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_10-07-21_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--13-roberta-large-25279', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt_eval_loss': 0.8884978890419006, 'rte_dev_prompt_eval_acc': 0.59375, 'rte_test_prompt_eval_loss': 0.8747930526733398, 'rte_test_prompt_eval_acc': 0.592057761732852, 'rte_dev_eval_loss': 0.8884978890419006, 'rte_dev_eval_acc': 0.59375, 'rte_test_eval_loss': 0.8747930526733398, 'rte_test_eval_acc': 0.592057761732852, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-13-roberta-large-25919', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_10-21-49_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-13-roberta-large-25919', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt_eval_loss': 1.5119013786315918, 'sst-2_dev_prompt_eval_acc': 0.8125, 'sst-2_test_prompt_eval_loss': 2.632718324661255, 'sst-2_test_prompt_eval_acc': 0.6502293577981652, 'sst-2_dev_eval_loss': 1.5119013786315918, 'sst-2_dev_eval_acc': 0.8125, 'sst-2_test_eval_loss': 2.632718324661255, 'sst-2_test_eval_acc': 0.6502293577981652, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-29094', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_10-24-46_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-29094', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.3371329307556152, 'sts-b_dev_prompt_eval_pearson': 0.6841072937368945, 'sts-b_dev_prompt_eval_spearmanr': 0.7389328443136487, 'sts-b_dev_prompt_eval_corr': 0.7115200690252717, 'sts-b_test_prompt_eval_loss': 2.5538127422332764, 'sts-b_test_prompt_eval_pearson': 0.22109682218455856, 'sts-b_test_prompt_eval_spearmanr': 0.21968064962932984, 'sts-b_test_prompt_eval_corr': 0.2203887359069442, 'sts-b_dev_eval_loss': 2.3371329307556152, 'sts-b_dev_eval_pearson': 0.6841072937368945, 'sts-b_dev_eval_spearmanr': 0.7389328443136487, 'sts-b_dev_eval_corr': 0.7115200690252717, 'sts-b_test_eval_loss': 2.5538127422332764, 'sts-b_test_eval_pearson': 0.22109682218455856, 'sts-b_test_eval_spearmanr': 0.21968064962932984, 'sts-b_test_eval_corr': 0.2203887359069442, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-13-roberta-large-30350', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_10-19-42_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-13-roberta-large-30350', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias_eval_loss': 2.1774377822875977, 'qnli_dev_bias_eval_acc': 0.78125, 'qnli_test_bias_eval_loss': 4.7497663497924805, 'qnli_test_bias_eval_acc': 0.5396302397949845, 'qnli_dev_eval_loss': 2.1774377822875977, 'qnli_dev_eval_acc': 0.78125, 'qnli_test_eval_loss': 4.7497663497924805, 'qnli_test_eval_acc': 0.5396302397949845, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16--13-roberta-large-30572', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_10-28-00_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--13-roberta-large-30572', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias_eval_loss': 6.272532939910889, 'cola_dev_bias_eval_mcc': 0.1259881576697424, 'cola_test_bias_eval_loss': 7.124468803405762, 'cola_test_bias_eval_mcc': 0.027048123027946527, 'cola_dev_eval_loss': 6.272532939910889, 'cola_dev_eval_mcc': 0.1259881576697424, 'cola_test_eval_loss': 7.124468803405762, 'cola_test_eval_mcc': 0.027048123027946527, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--13-roberta-large-2391', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_10-28-36_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-2391', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_adapter_eval_loss': 2.5322265625, 'mrpc_dev_adapter_eval_acc': 0.625, 'mrpc_dev_adapter_eval_f1': 0.6666666666666665, 'mrpc_dev_adapter_eval_acc_and_f1': 0.6458333333333333, 'mrpc_test_adapter_eval_loss': 3.4528372287750244, 'mrpc_test_adapter_eval_acc': 0.49019607843137253, 'mrpc_test_adapter_eval_f1': 0.5611814345991561, 'mrpc_test_adapter_eval_acc_and_f1': 0.5256887565152644, 'mrpc_dev_eval_loss': 2.5322265625, 'mrpc_dev_eval_acc': 0.625, 'mrpc_dev_eval_f1': 0.6666666666666665, 'mrpc_dev_eval_acc_and_f1': 0.6458333333333333, 'mrpc_test_eval_loss': 3.4528372287750244, 'mrpc_test_eval_acc': 0.49019607843137253, 'mrpc_test_eval_f1': 0.5611814345991561, 'mrpc_test_eval_acc_and_f1': 0.5256887565152644, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--13-roberta-large-20256', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_10-29-39_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--13-roberta-large-20256', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt_eval_loss': 1.9898180961608887, 'sst-2_dev_prompt_eval_acc': 0.71875, 'sst-2_test_prompt_eval_loss': 2.8252205848693848, 'sst-2_test_prompt_eval_acc': 0.6307339449541285, 'sst-2_dev_eval_loss': 1.9898180961608887, 'sst-2_dev_eval_acc': 0.71875, 'sst-2_test_eval_loss': 2.8252205848693848, 'sst-2_test_eval_acc': 0.6307339449541285, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-28289', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_10-34-08_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-28289', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt_eval_loss': 0.7449479103088379, 'rte_dev_prompt_eval_acc': 0.5625, 'rte_test_prompt_eval_loss': 0.8190611600875854, 'rte_test_prompt_eval_acc': 0.5848375451263538, 'rte_dev_eval_loss': 0.7449479103088379, 'rte_dev_eval_acc': 0.5625, 'rte_test_eval_loss': 0.8190611600875854, 'rte_test_eval_acc': 0.5848375451263538, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-13-roberta-large-12767', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_10-33-44_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-13-roberta-large-12767', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt_eval_loss': 0.8294272422790527, 'qqp_dev_prompt_eval_acc': 0.53125, 'qqp_dev_prompt_eval_f1': 0.6341463414634146, 'qqp_dev_prompt_eval_acc_and_f1': 0.5826981707317074, 'qqp_test_prompt_eval_loss': 0.9617786407470703, 'qqp_test_prompt_eval_acc': 0.4320306702943359, 'qqp_test_prompt_eval_f1': 0.502351385909022, 'qqp_test_prompt_eval_acc_and_f1': 0.4671910281016789, 'qqp_dev_eval_loss': 0.8294272422790527, 'qqp_dev_eval_acc': 0.53125, 'qqp_dev_eval_f1': 0.6341463414634146, 'qqp_dev_eval_acc_and_f1': 0.5826981707317074, 'qqp_test_eval_loss': 0.9617786407470703, 'qqp_test_eval_acc': 0.4320306702943359, 'qqp_test_eval_f1': 0.502351385909022, 'qqp_test_eval_acc_and_f1': 0.4671910281016789, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-13-roberta-large-2183', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_10-28-28_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-13-roberta-large-2183', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.4433743953704834, 'sts-b_dev_prompt_eval_pearson': 0.4457963472292984, 'sts-b_dev_prompt_eval_spearmanr': 0.42972747957474494, 'sts-b_dev_prompt_eval_corr': 0.43776191340202164, 'sts-b_test_prompt_eval_loss': 2.664207696914673, 'sts-b_test_prompt_eval_pearson': 0.02482660185079933, 'sts-b_test_prompt_eval_spearmanr': 0.02682281208117245, 'sts-b_test_prompt_eval_corr': 0.02582470696598589, 'sts-b_dev_eval_loss': 2.4433743953704834, 'sts-b_dev_eval_pearson': 0.4457963472292984, 'sts-b_dev_eval_spearmanr': 0.42972747957474494, 'sts-b_dev_eval_corr': 0.43776191340202164, 'sts-b_test_eval_loss': 2.664207696914673, 'sts-b_test_eval_pearson': 0.02482660185079933, 'sts-b_test_eval_spearmanr': 0.02682281208117245, 'sts-b_test_eval_corr': 0.02582470696598589, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-13-roberta-large-2721', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_10-34-28_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-13-roberta-large-2721', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias_eval_loss': 1.4191358089447021, 'qnli_dev_bias_eval_acc': 0.71875, 'qnli_test_bias_eval_loss': 2.128138542175293, 'qnli_test_bias_eval_acc': 0.6542192934285191, 'qnli_dev_eval_loss': 1.4191358089447021, 'qnli_dev_eval_acc': 0.71875, 'qnli_test_eval_loss': 2.128138542175293, 'qnli_test_eval_acc': 0.6542192934285191, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16--13-roberta-large-20258', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_10-39-47_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--13-roberta-large-20258', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt_eval_loss': 0.5305567979812622, 'sst-2_dev_prompt_eval_acc': 0.6875, 'sst-2_test_prompt_eval_loss': 0.6188548803329468, 'sst-2_test_prompt_eval_acc': 0.6846330275229358, 'sst-2_dev_eval_loss': 0.5305567979812622, 'sst-2_dev_eval_acc': 0.6875, 'sst-2_test_eval_loss': 0.6188548803329468, 'sst-2_test_eval_acc': 0.6846330275229358, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-13237', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_10-45-14_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-13237', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_adapter_eval_loss': 2.5836970806121826, 'mrpc_dev_adapter_eval_acc': 0.65625, 'mrpc_dev_adapter_eval_f1': 0.6857142857142857, 'mrpc_dev_adapter_eval_acc_and_f1': 0.6709821428571429, 'mrpc_test_adapter_eval_loss': 3.967900037765503, 'mrpc_test_adapter_eval_acc': 0.5098039215686274, 'mrpc_test_adapter_eval_f1': 0.5833333333333334, 'mrpc_test_adapter_eval_acc_and_f1': 0.5465686274509804, 'mrpc_dev_eval_loss': 2.5836970806121826, 'mrpc_dev_eval_acc': 0.65625, 'mrpc_dev_eval_f1': 0.6857142857142857, 'mrpc_dev_eval_acc_and_f1': 0.6709821428571429, 'mrpc_test_eval_loss': 3.967900037765503, 'mrpc_test_eval_acc': 0.5098039215686274, 'mrpc_test_eval_f1': 0.5833333333333334, 'mrpc_test_eval_acc_and_f1': 0.5465686274509804, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--13-roberta-large-23281', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_10-43-05_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--13-roberta-large-23281', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias,adapter_eval_loss': 2.8724420070648193, 'mnli_dev_prompt,bias,adapter_eval_mnli/acc': 0.6666666666666666, 'mnli_test_prompt,bias,adapter_eval_loss': 4.009685039520264, 'mnli_test_prompt,bias,adapter_eval_mnli/acc': 0.5938869077941925, 'mnli-mm_test_prompt,bias,adapter_eval_loss': 3.8380157947540283, 'mnli-mm_test_prompt,bias,adapter_eval_mnli-mm/acc': 0.6095402766476811, 'mnli_dev_eval_loss': 2.8724420070648193, 'mnli_dev_eval_mnli/acc': 0.6666666666666666, 'mnli_test_eval_loss': 4.009685039520264, 'mnli_test_eval_mnli/acc': 0.5938869077941925, 'mnli-mm_test_eval_loss': 3.8380157947540283, 'mnli-mm_test_eval_mnli-mm/acc': 0.6095402766476811, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-26969', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_10-30-45_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-26969', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias_eval_loss': 2.6907734870910645, 'cola_dev_bias_eval_mcc': 0.20851441405707474, 'cola_test_bias_eval_loss': 2.332536458969116, 'cola_test_bias_eval_mcc': 0.04828589848169037, 'cola_dev_eval_loss': 2.6907734870910645, 'cola_dev_eval_mcc': 0.20851441405707474, 'cola_test_eval_loss': 2.332536458969116, 'cola_test_eval_mcc': 0.04828589848169037, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--13-roberta-large-5677', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_10-43-02_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-5677', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias_eval_loss': 5.558962821960449, 'rte_dev_bias_eval_acc': 0.59375, 'rte_test_bias_eval_loss': 6.493759632110596, 'rte_test_bias_eval_acc': 0.48375451263537905, 'rte_dev_eval_loss': 5.558962821960449, 'rte_dev_eval_acc': 0.59375, 'rte_test_eval_loss': 6.493759632110596, 'rte_test_eval_acc': 0.48375451263537905, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16--13-roberta-large-24480', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_10-45-27_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--13-roberta-large-24480', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt_eval_loss': 0.8141849040985107, 'qqp_dev_prompt_eval_acc': 0.53125, 'qqp_dev_prompt_eval_f1': 0.6511627906976744, 'qqp_dev_prompt_eval_acc_and_f1': 0.5912063953488371, 'qqp_test_prompt_eval_loss': 0.9992545247077942, 'qqp_test_prompt_eval_acc': 0.3908731140242394, 'qqp_test_prompt_eval_f1': 0.47663372649027735, 'qqp_test_prompt_eval_acc_and_f1': 0.4337534202572584, 'qqp_dev_eval_loss': 0.8141849040985107, 'qqp_dev_eval_acc': 0.53125, 'qqp_dev_eval_f1': 0.6511627906976744, 'qqp_dev_eval_acc_and_f1': 0.5912063953488371, 'qqp_test_eval_loss': 0.9992545247077942, 'qqp_test_eval_acc': 0.3908731140242394, 'qqp_test_eval_f1': 0.47663372649027735, 'qqp_test_eval_acc_and_f1': 0.4337534202572584, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-13-roberta-large-7351', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_10-46-51_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-13-roberta-large-7351', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt_eval_loss': 0.5217490196228027, 'sst-2_dev_prompt_eval_acc': 0.75, 'sst-2_test_prompt_eval_loss': 0.5213370323181152, 'sst-2_test_prompt_eval_acc': 0.7534403669724771, 'sst-2_dev_eval_loss': 0.5217490196228027, 'sst-2_dev_eval_acc': 0.75, 'sst-2_test_eval_loss': 0.5213370323181152, 'sst-2_test_eval_acc': 0.7534403669724771, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-2165', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_10-53-47_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-2165', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias_eval_loss': 1.7630387544631958, 'qnli_dev_bias_eval_acc': 0.71875, 'qnli_test_bias_eval_loss': 2.3356263637542725, 'qnli_test_bias_eval_acc': 0.6699615595826469, 'qnli_dev_eval_loss': 1.7630387544631958, 'qnli_dev_eval_acc': 0.71875, 'qnli_test_eval_loss': 2.3356263637542725, 'qnli_test_eval_acc': 0.6699615595826469, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16--13-roberta-large-12769', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_10-51-34_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--13-roberta-large-12769', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.376110553741455, 'sts-b_dev_prompt_eval_pearson': 0.45547610160500135, 'sts-b_dev_prompt_eval_spearmanr': 0.4292158358232805, 'sts-b_dev_prompt_eval_corr': 0.4423459687141409, 'sts-b_test_prompt_eval_loss': 2.3721656799316406, 'sts-b_test_prompt_eval_pearson': 0.1295671520107479, 'sts-b_test_prompt_eval_spearmanr': 0.1361915814106887, 'sts-b_test_prompt_eval_corr': 0.13287936671071832, 'sts-b_dev_eval_loss': 2.376110553741455, 'sts-b_dev_eval_pearson': 0.45547610160500135, 'sts-b_dev_eval_spearmanr': 0.4292158358232805, 'sts-b_dev_eval_corr': 0.4423459687141409, 'sts-b_test_eval_loss': 2.3721656799316406, 'sts-b_test_eval_pearson': 0.1295671520107479, 'sts-b_test_eval_spearmanr': 0.1361915814106887, 'sts-b_test_eval_corr': 0.13287936671071832, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-21-roberta-large-20696', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_10-49-25_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-21-roberta-large-20696', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_adapter_eval_loss': 1.746494174003601, 'mrpc_dev_adapter_eval_acc': 0.6875, 'mrpc_dev_adapter_eval_f1': 0.7058823529411765, 'mrpc_dev_adapter_eval_acc_and_f1': 0.6966911764705883, 'mrpc_test_adapter_eval_loss': 2.679579734802246, 'mrpc_test_adapter_eval_acc': 0.49019607843137253, 'mrpc_test_adapter_eval_f1': 0.5630252100840337, 'mrpc_test_adapter_eval_acc_and_f1': 0.5266106442577031, 'mrpc_dev_eval_loss': 1.746494174003601, 'mrpc_dev_eval_acc': 0.6875, 'mrpc_dev_eval_f1': 0.7058823529411765, 'mrpc_dev_eval_acc_and_f1': 0.6966911764705883, 'mrpc_test_eval_loss': 2.679579734802246, 'mrpc_test_eval_acc': 0.49019607843137253, 'mrpc_test_eval_f1': 0.5630252100840337, 'mrpc_test_eval_acc_and_f1': 0.5266106442577031, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--13-roberta-large-14994', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_10-55-56_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--13-roberta-large-14994', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias_eval_loss': 4.732728958129883, 'rte_dev_bias_eval_acc': 0.59375, 'rte_test_bias_eval_loss': 3.6244399547576904, 'rte_test_bias_eval_acc': 0.6173285198555957, 'rte_dev_eval_loss': 4.732728958129883, 'rte_dev_eval_acc': 0.59375, 'rte_test_eval_loss': 3.6244399547576904, 'rte_test_eval_acc': 0.6173285198555957, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16--13-roberta-large-32548', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_10-59-11_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--13-roberta-large-32548', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias_eval_loss': 2.715796709060669, 'cola_dev_bias_eval_mcc': 0.18786728732554486, 'cola_test_bias_eval_loss': 3.294757127761841, 'cola_test_bias_eval_mcc': 0.049473020853933444, 'cola_dev_eval_loss': 2.715796709060669, 'cola_dev_eval_mcc': 0.18786728732554486, 'cola_test_eval_loss': 3.294757127761841, 'cola_test_eval_mcc': 0.049473020853933444, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--13-roberta-large-15195', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_10-58-24_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-15195', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias_eval_loss': 1.0610263347625732, 'sst-2_dev_bias_eval_acc': 0.875, 'sst-2_test_bias_eval_loss': 1.6381210088729858, 'sst-2_test_bias_eval_acc': 0.8211009174311926, 'sst-2_dev_eval_loss': 1.0610263347625732, 'sst-2_dev_eval_acc': 0.875, 'sst-2_test_eval_loss': 1.6381210088729858, 'sst-2_test_eval_acc': 0.8211009174311926, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--13-roberta-large-31217', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_11-01-32_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-31217', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias_eval_loss': 1.3094749450683594, 'qnli_dev_bias_eval_acc': 0.6875, 'qnli_test_bias_eval_loss': 1.5553903579711914, 'qnli_test_bias_eval_acc': 0.6456159619256818, 'qnli_dev_eval_loss': 1.3094749450683594, 'qnli_dev_eval_acc': 0.6875, 'qnli_test_eval_loss': 1.5553903579711914, 'qnli_test_eval_acc': 0.6456159619256818, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16--13-roberta-large-21038', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_11-03-22_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--13-roberta-large-21038', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.4718611240386963, 'sts-b_dev_prompt_eval_pearson': 0.2511578384523498, 'sts-b_dev_prompt_eval_spearmanr': 0.2588891749464907, 'sts-b_dev_prompt_eval_corr': 0.25502350669942025, 'sts-b_test_prompt_eval_loss': 2.6360340118408203, 'sts-b_test_prompt_eval_pearson': 0.14841208671104306, 'sts-b_test_prompt_eval_spearmanr': 0.1436995349839104, 'sts-b_test_prompt_eval_corr': 0.1460558108474767, 'sts-b_dev_eval_loss': 2.4718611240386963, 'sts-b_dev_eval_pearson': 0.2511578384523498, 'sts-b_dev_eval_spearmanr': 0.2588891749464907, 'sts-b_dev_eval_corr': 0.25502350669942025, 'sts-b_test_eval_loss': 2.6360340118408203, 'sts-b_test_eval_pearson': 0.14841208671104306, 'sts-b_test_eval_spearmanr': 0.1436995349839104, 'sts-b_test_eval_corr': 0.1460558108474767, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-21-roberta-large-23501', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_11-03-49_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-21-roberta-large-23501', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias_eval_loss': 3.3532328605651855, 'qqp_dev_bias_eval_acc': 0.78125, 'qqp_dev_bias_eval_f1': 0.8108108108108109, 'qqp_dev_bias_eval_acc_and_f1': 0.7960304054054055, 'qqp_test_bias_eval_loss': 4.750272750854492, 'qqp_test_bias_eval_acc': 0.6549344546129112, 'qqp_test_bias_eval_f1': 0.6503421138374396, 'qqp_test_bias_eval_acc_and_f1': 0.6526382842251754, 'qqp_dev_eval_loss': 3.3532328605651855, 'qqp_dev_eval_acc': 0.78125, 'qqp_dev_eval_f1': 0.8108108108108109, 'qqp_dev_eval_acc_and_f1': 0.7960304054054055, 'qqp_test_eval_loss': 4.750272750854492, 'qqp_test_eval_acc': 0.6549344546129112, 'qqp_test_eval_f1': 0.6503421138374396, 'qqp_test_eval_acc_and_f1': 0.6526382842251754, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16--13-roberta-large-20302', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_11-00-24_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--13-roberta-large-20302', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,adapter_eval_loss': 4.382570266723633, 'mrpc_dev_prompt,adapter_eval_acc': 0.6875, 'mrpc_dev_prompt,adapter_eval_f1': 0.7368421052631579, 'mrpc_dev_prompt,adapter_eval_acc_and_f1': 0.712171052631579, 'mrpc_test_prompt,adapter_eval_loss': 5.274172306060791, 'mrpc_test_prompt,adapter_eval_acc': 0.5588235294117647, 'mrpc_test_prompt,adapter_eval_f1': 0.6470588235294118, 'mrpc_test_prompt,adapter_eval_acc_and_f1': 0.6029411764705883, 'mrpc_dev_eval_loss': 4.382570266723633, 'mrpc_dev_eval_acc': 0.6875, 'mrpc_dev_eval_f1': 0.7368421052631579, 'mrpc_dev_eval_acc_and_f1': 0.712171052631579, 'mrpc_test_eval_loss': 5.274172306060791, 'mrpc_test_eval_acc': 0.5588235294117647, 'mrpc_test_eval_f1': 0.6470588235294118, 'mrpc_test_eval_acc_and_f1': 0.6029411764705883, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-13-roberta-large-19931', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_11-08-56_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-13-roberta-large-19931', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias,adapter_eval_loss': 2.6429426670074463, 'mnli_dev_prompt,bias,adapter_eval_mnli/acc': 0.8125, 'mnli_test_prompt,bias,adapter_eval_loss': 2.754870891571045, 'mnli_test_prompt,bias,adapter_eval_mnli/acc': 0.6854814060112073, 'mnli-mm_test_prompt,bias,adapter_eval_loss': 2.663245677947998, 'mnli-mm_test_prompt,bias,adapter_eval_mnli-mm/acc': 0.6957892595606184, 'mnli_dev_eval_loss': 2.6429426670074463, 'mnli_dev_eval_mnli/acc': 0.8125, 'mnli_test_eval_loss': 2.754870891571045, 'mnli_test_eval_mnli/acc': 0.6854814060112073, 'mnli-mm_test_eval_loss': 2.663245677947998, 'mnli-mm_test_eval_mnli-mm/acc': 0.6957892595606184, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-26991', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_10-58-14_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-26991', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias_eval_loss': 2.4560728073120117, 'rte_dev_bias_eval_acc': 0.75, 'rte_test_bias_eval_loss': 2.537431478500366, 'rte_test_bias_eval_acc': 0.6787003610108303, 'rte_dev_eval_loss': 2.4560728073120117, 'rte_dev_eval_acc': 0.75, 'rte_test_eval_loss': 2.537431478500366, 'rte_test_eval_acc': 0.6787003610108303, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16--13-roberta-large-7791', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_11-13-05_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--13-roberta-large-7791', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias_eval_loss': 1.2825044393539429, 'sst-2_dev_bias_eval_acc': 0.875, 'sst-2_test_bias_eval_loss': 0.7821699976921082, 'sst-2_test_bias_eval_acc': 0.9013761467889908, 'sst-2_dev_eval_loss': 1.2825044393539429, 'sst-2_dev_eval_acc': 0.875, 'sst-2_test_eval_loss': 0.7821699976921082, 'sst-2_test_eval_acc': 0.9013761467889908, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--13-roberta-large-6977', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_11-14-49_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-6977', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_adapter_eval_loss': 2.3700766563415527, 'qnli_dev_adapter_eval_acc': 0.8125, 'qnli_test_adapter_eval_loss': 3.0216434001922607, 'qnli_test_adapter_eval_acc': 0.676368295808164, 'qnli_dev_eval_loss': 2.3700766563415527, 'qnli_dev_eval_acc': 0.8125, 'qnli_test_eval_loss': 3.0216434001922607, 'qnli_test_eval_acc': 0.676368295808164, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--13-roberta-large-18370', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_11-14-53_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--13-roberta-large-18370', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.4110593795776367, 'sts-b_dev_prompt_eval_pearson': 0.41857412670891303, 'sts-b_dev_prompt_eval_spearmanr': 0.4152516219865642, 'sts-b_dev_prompt_eval_corr': 0.4169128743477386, 'sts-b_test_prompt_eval_loss': 2.6482133865356445, 'sts-b_test_prompt_eval_pearson': 0.1518677777495617, 'sts-b_test_prompt_eval_spearmanr': 0.15237761672325592, 'sts-b_test_prompt_eval_corr': 0.1521226972364088, 'sts-b_dev_eval_loss': 2.4110593795776367, 'sts-b_dev_eval_pearson': 0.41857412670891303, 'sts-b_dev_eval_spearmanr': 0.4152516219865642, 'sts-b_dev_eval_corr': 0.4169128743477386, 'sts-b_test_eval_loss': 2.6482133865356445, 'sts-b_test_eval_pearson': 0.1518677777495617, 'sts-b_test_eval_spearmanr': 0.15237761672325592, 'sts-b_test_eval_corr': 0.1521226972364088, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-21-roberta-large-2481', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_11-18-02_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-21-roberta-large-2481', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_adapter_eval_loss': 0.6931474208831787, 'cola_dev_adapter_eval_mcc': 0.10721125348377948, 'cola_test_adapter_eval_loss': 0.6931802034378052, 'cola_test_adapter_eval_mcc': 0.0555290647355159, 'cola_dev_eval_loss': 0.6931474208831787, 'cola_dev_eval_mcc': 0.10721125348377948, 'cola_test_eval_loss': 0.6931802034378052, 'cola_test_eval_mcc': 0.0555290647355159, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--13-roberta-large-4099', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_11-13-58_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-4099', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,adapter_eval_loss': 3.921400547027588, 'mrpc_dev_prompt,adapter_eval_acc': 0.625, 'mrpc_dev_prompt,adapter_eval_f1': 0.6842105263157896, 'mrpc_dev_prompt,adapter_eval_acc_and_f1': 0.6546052631578948, 'mrpc_test_prompt,adapter_eval_loss': 4.258417129516602, 'mrpc_test_prompt,adapter_eval_acc': 0.5588235294117647, 'mrpc_test_prompt,adapter_eval_f1': 0.6525096525096525, 'mrpc_test_prompt,adapter_eval_acc_and_f1': 0.6056665909607086, 'mrpc_dev_eval_loss': 3.921400547027588, 'mrpc_dev_eval_acc': 0.625, 'mrpc_dev_eval_f1': 0.6842105263157896, 'mrpc_dev_eval_acc_and_f1': 0.6546052631578948, 'mrpc_test_eval_loss': 4.258417129516602, 'mrpc_test_eval_acc': 0.5588235294117647, 'mrpc_test_eval_f1': 0.6525096525096525, 'mrpc_test_eval_acc_and_f1': 0.6056665909607086, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-13-roberta-large-17805', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_11-23-15_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-13-roberta-large-17805', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias_eval_loss': 0.9727024435997009, 'rte_dev_bias_eval_acc': 0.71875, 'rte_test_bias_eval_loss': 1.0195997953414917, 'rte_test_bias_eval_acc': 0.6642599277978339, 'rte_dev_eval_loss': 0.9727024435997009, 'rte_dev_eval_acc': 0.71875, 'rte_test_eval_loss': 1.0195997953414917, 'rte_test_eval_acc': 0.6642599277978339, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16--13-roberta-large-13057', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_11-26-41_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--13-roberta-large-13057', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias_eval_loss': 0.45386072993278503, 'sst-2_dev_bias_eval_acc': 0.96875, 'sst-2_test_bias_eval_loss': 0.7056466937065125, 'sst-2_test_bias_eval_acc': 0.9334862385321101, 'sst-2_dev_eval_loss': 0.45386072993278503, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.7056466937065125, 'sst-2_test_eval_acc': 0.9334862385321101, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--13-roberta-large-5702', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_11-28-16_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-5702', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias_eval_loss': 5.213393688201904, 'qqp_dev_bias_eval_acc': 0.71875, 'qqp_dev_bias_eval_f1': 0.7692307692307693, 'qqp_dev_bias_eval_acc_and_f1': 0.7439903846153846, 'qqp_test_bias_eval_loss': 5.37968635559082, 'qqp_test_bias_eval_acc': 0.6435072965619589, 'qqp_test_bias_eval_f1': 0.6443078897361861, 'qqp_test_bias_eval_acc_and_f1': 0.6439075931490725, 'qqp_dev_eval_loss': 5.213393688201904, 'qqp_dev_eval_acc': 0.71875, 'qqp_dev_eval_f1': 0.7692307692307693, 'qqp_dev_eval_acc_and_f1': 0.7439903846153846, 'qqp_test_eval_loss': 5.37968635559082, 'qqp_test_eval_acc': 0.6435072965619589, 'qqp_test_eval_f1': 0.6443078897361861, 'qqp_test_eval_acc_and_f1': 0.6439075931490725, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16--13-roberta-large-5263', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_11-21-02_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--13-roberta-large-5263', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_adapter_eval_loss': 2.401005744934082, 'qnli_dev_adapter_eval_acc': 0.75, 'qnli_test_adapter_eval_loss': 3.4823215007781982, 'qnli_test_adapter_eval_acc': 0.6798462383305875, 'qnli_dev_eval_loss': 2.401005744934082, 'qnli_dev_eval_acc': 0.75, 'qnli_test_eval_loss': 3.4823215007781982, 'qnli_test_eval_acc': 0.6798462383305875, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--13-roberta-large-23661', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_11-28-47_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--13-roberta-large-23661', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.4532878398895264, 'sts-b_dev_prompt_eval_pearson': 0.31843784202678294, 'sts-b_dev_prompt_eval_spearmanr': 0.32521919067089317, 'sts-b_dev_prompt_eval_corr': 0.321828516348838, 'sts-b_test_prompt_eval_loss': 2.7147536277770996, 'sts-b_test_prompt_eval_pearson': 0.1161920531732755, 'sts-b_test_prompt_eval_spearmanr': 0.12009355796681408, 'sts-b_test_prompt_eval_corr': 0.11814280557004478, 'sts-b_dev_eval_loss': 2.4532878398895264, 'sts-b_dev_eval_pearson': 0.31843784202678294, 'sts-b_dev_eval_spearmanr': 0.32521919067089317, 'sts-b_dev_eval_corr': 0.321828516348838, 'sts-b_test_eval_loss': 2.7147536277770996, 'sts-b_test_eval_pearson': 0.1161920531732755, 'sts-b_test_eval_spearmanr': 0.12009355796681408, 'sts-b_test_eval_corr': 0.11814280557004478, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-21-roberta-large-1649', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_11-31-44_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-21-roberta-large-1649', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,adapter_eval_loss': 4.145547866821289, 'mrpc_dev_prompt,adapter_eval_acc': 0.53125, 'mrpc_dev_prompt,adapter_eval_f1': 0.5945945945945946, 'mrpc_dev_prompt,adapter_eval_acc_and_f1': 0.5629222972972974, 'mrpc_test_prompt,adapter_eval_loss': 4.449445724487305, 'mrpc_test_prompt,adapter_eval_acc': 0.5, 'mrpc_test_prompt,adapter_eval_f1': 0.5887096774193549, 'mrpc_test_prompt,adapter_eval_acc_and_f1': 0.5443548387096775, 'mrpc_dev_eval_loss': 4.145547866821289, 'mrpc_dev_eval_acc': 0.53125, 'mrpc_dev_eval_f1': 0.5945945945945946, 'mrpc_dev_eval_acc_and_f1': 0.5629222972972974, 'mrpc_test_eval_loss': 4.449445724487305, 'mrpc_test_eval_acc': 0.5, 'mrpc_test_eval_f1': 0.5887096774193549, 'mrpc_test_eval_acc_and_f1': 0.5443548387096775, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-13-roberta-large-21925', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_11-36-51_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-13-roberta-large-21925', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_adapter_eval_loss': 5.320286273956299, 'cola_dev_adapter_eval_mcc': 0.06362847629757777, 'cola_test_adapter_eval_loss': 5.860276222229004, 'cola_test_adapter_eval_mcc': 0.12111096000268053, 'cola_dev_eval_loss': 5.320286273956299, 'cola_dev_eval_mcc': 0.06362847629757777, 'cola_test_eval_loss': 5.860276222229004, 'cola_test_eval_mcc': 0.12111096000268053, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--13-roberta-large-3102', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_11-32-49_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-3102', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias,adapter_eval_loss': 2.7139368057250977, 'mnli_dev_prompt,bias,adapter_eval_mnli/acc': 0.7708333333333334, 'mnli_test_prompt,bias,adapter_eval_loss': 2.966437578201294, 'mnli_test_prompt,bias,adapter_eval_mnli/acc': 0.6687722873153337, 'mnli-mm_test_prompt,bias,adapter_eval_loss': 2.972806215286255, 'mnli-mm_test_prompt,bias,adapter_eval_mnli-mm/acc': 0.6793124491456468, 'mnli_dev_eval_loss': 2.7139368057250977, 'mnli_dev_eval_mnli/acc': 0.7708333333333334, 'mnli_test_eval_loss': 2.966437578201294, 'mnli_test_eval_mnli/acc': 0.6687722873153337, 'mnli-mm_test_eval_loss': 2.972806215286255, 'mnli-mm_test_eval_mnli-mm/acc': 0.6793124491456468, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-6011', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_11-24-05_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-6011', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_adapter_eval_loss': 2.5662381649017334, 'rte_dev_adapter_eval_acc': 0.84375, 'rte_test_adapter_eval_loss': 3.293144702911377, 'rte_test_adapter_eval_acc': 0.7436823104693141, 'rte_dev_eval_loss': 2.5662381649017334, 'rte_dev_eval_acc': 0.84375, 'rte_test_eval_loss': 3.293144702911377, 'rte_test_eval_acc': 0.7436823104693141, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--13-roberta-large-3414', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_11-40-22_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--13-roberta-large-3414', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias_eval_loss': 0.30721765756607056, 'sst-2_dev_bias_eval_acc': 0.90625, 'sst-2_test_bias_eval_loss': 0.35937899351119995, 'sst-2_test_bias_eval_acc': 0.9346330275229358, 'sst-2_dev_eval_loss': 0.30721765756607056, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 0.35937899351119995, 'sst-2_test_eval_acc': 0.9346330275229358, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--13-roberta-large-12891', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_11-41-47_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-12891', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_adapter_eval_loss': 0.9280543327331543, 'qnli_dev_adapter_eval_acc': 0.75, 'qnli_test_adapter_eval_loss': 1.5235751867294312, 'qnli_test_adapter_eval_acc': 0.6756360973823906, 'qnli_dev_eval_loss': 0.9280543327331543, 'qnli_dev_eval_acc': 0.75, 'qnli_test_eval_loss': 1.5235751867294312, 'qnli_test_eval_acc': 0.6756360973823906, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--13-roberta-large-14141', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_11-43-12_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--13-roberta-large-14141', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.4036788940429688, 'sts-b_dev_prompt_eval_pearson': 0.2533263257125345, 'sts-b_dev_prompt_eval_spearmanr': 0.26501431489559285, 'sts-b_dev_prompt_eval_corr': 0.2591703203040637, 'sts-b_test_prompt_eval_loss': 2.515767812728882, 'sts-b_test_prompt_eval_pearson': 0.045631021783080365, 'sts-b_test_prompt_eval_spearmanr': 0.060863883639826366, 'sts-b_test_prompt_eval_corr': 0.05324745271145337, 'sts-b_dev_eval_loss': 2.4036788940429688, 'sts-b_dev_eval_pearson': 0.2533263257125345, 'sts-b_dev_eval_spearmanr': 0.26501431489559285, 'sts-b_dev_eval_corr': 0.2591703203040637, 'sts-b_test_eval_loss': 2.515767812728882, 'sts-b_test_eval_pearson': 0.045631021783080365, 'sts-b_test_eval_spearmanr': 0.060863883639826366, 'sts-b_test_eval_corr': 0.05324745271145337, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-42-roberta-large-30731', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_11-46-20_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-42-roberta-large-30731', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,adapter_eval_loss': 3.488462448120117, 'mrpc_dev_prompt,adapter_eval_acc': 0.59375, 'mrpc_dev_prompt,adapter_eval_f1': 0.5517241379310345, 'mrpc_dev_prompt,adapter_eval_acc_and_f1': 0.5727370689655172, 'mrpc_test_prompt,adapter_eval_loss': 5.177722454071045, 'mrpc_test_prompt,adapter_eval_acc': 0.4215686274509804, 'mrpc_test_prompt,adapter_eval_f1': 0.456221198156682, 'mrpc_test_prompt,adapter_eval_acc_and_f1': 0.4388949128038312, 'mrpc_dev_eval_loss': 3.488462448120117, 'mrpc_dev_eval_acc': 0.59375, 'mrpc_dev_eval_f1': 0.5517241379310345, 'mrpc_dev_eval_acc_and_f1': 0.5727370689655172, 'mrpc_test_eval_loss': 5.177722454071045, 'mrpc_test_eval_acc': 0.4215686274509804, 'mrpc_test_eval_f1': 0.456221198156682, 'mrpc_test_eval_acc_and_f1': 0.4388949128038312, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-13-roberta-large-22759', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_11-50-29_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-13-roberta-large-22759', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias_eval_loss': 2.7907071113586426, 'qqp_dev_bias_eval_acc': 0.75, 'qqp_dev_bias_eval_f1': 0.7777777777777777, 'qqp_dev_bias_eval_acc_and_f1': 0.7638888888888888, 'qqp_test_bias_eval_loss': 3.8632795810699463, 'qqp_test_bias_eval_acc': 0.6813999505317834, 'qqp_test_bias_eval_f1': 0.6607852948147368, 'qqp_test_bias_eval_acc_and_f1': 0.6710926226732601, 'qqp_dev_eval_loss': 2.7907071113586426, 'qqp_dev_eval_acc': 0.75, 'qqp_dev_eval_f1': 0.7777777777777777, 'qqp_dev_eval_acc_and_f1': 0.7638888888888888, 'qqp_test_eval_loss': 3.8632795810699463, 'qqp_test_eval_acc': 0.6813999505317834, 'qqp_test_eval_f1': 0.6607852948147368, 'qqp_test_eval_acc_and_f1': 0.6710926226732601, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16--13-roberta-large-9858', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_11-43-10_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--13-roberta-large-9858', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_adapter_eval_loss': 2.2667629718780518, 'cola_dev_adapter_eval_mcc': 0.125, 'cola_test_adapter_eval_loss': 3.651604652404785, 'cola_test_adapter_eval_mcc': 0.014414092670087301, 'cola_dev_eval_loss': 2.2667629718780518, 'cola_dev_eval_mcc': 0.125, 'cola_test_eval_loss': 3.651604652404785, 'cola_test_eval_mcc': 0.014414092670087301, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--13-roberta-large-7812', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_11-50-45_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-7812', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_adapter_eval_loss': 3.7144248485565186, 'rte_dev_adapter_eval_acc': 0.6875, 'rte_test_adapter_eval_loss': 3.7711405754089355, 'rte_test_adapter_eval_acc': 0.6353790613718412, 'rte_dev_eval_loss': 3.7144248485565186, 'rte_dev_eval_acc': 0.6875, 'rte_test_eval_loss': 3.7711405754089355, 'rte_test_eval_acc': 0.6353790613718412, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--13-roberta-large-25156', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_11-54-49_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--13-roberta-large-25156', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_adapter_eval_loss': 1.696885585784912, 'sst-2_dev_adapter_eval_acc': 0.90625, 'sst-2_test_adapter_eval_loss': 1.7626690864562988, 'sst-2_test_adapter_eval_acc': 0.8841743119266054, 'sst-2_dev_eval_loss': 1.696885585784912, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 1.7626690864562988, 'sst-2_test_eval_acc': 0.8841743119266054, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--13-roberta-large-12692', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_11-54-51_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-12692', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_adapter_eval_loss': 1.1829395294189453, 'qnli_dev_adapter_eval_acc': 0.75, 'qnli_test_adapter_eval_loss': 1.9617490768432617, 'qnli_test_adapter_eval_acc': 0.6743547501372872, 'qnli_dev_eval_loss': 1.1829395294189453, 'qnli_dev_eval_acc': 0.75, 'qnli_test_eval_loss': 1.9617490768432617, 'qnli_test_eval_acc': 0.6743547501372872, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--13-roberta-large-32472', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_11-56-53_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--13-roberta-large-32472', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.1693978309631348, 'sts-b_dev_prompt_eval_pearson': 0.392260230811027, 'sts-b_dev_prompt_eval_spearmanr': 0.45675024334396347, 'sts-b_dev_prompt_eval_corr': 0.4245052370774952, 'sts-b_test_prompt_eval_loss': 2.3926007747650146, 'sts-b_test_prompt_eval_pearson': 0.09951451251951826, 'sts-b_test_prompt_eval_spearmanr': 0.11573327570118012, 'sts-b_test_prompt_eval_corr': 0.1076238941103492, 'sts-b_dev_eval_loss': 2.1693978309631348, 'sts-b_dev_eval_pearson': 0.392260230811027, 'sts-b_dev_eval_spearmanr': 0.45675024334396347, 'sts-b_dev_eval_corr': 0.4245052370774952, 'sts-b_test_eval_loss': 2.3926007747650146, 'sts-b_test_eval_pearson': 0.09951451251951826, 'sts-b_test_eval_spearmanr': 0.11573327570118012, 'sts-b_test_eval_corr': 0.1076238941103492, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-42-roberta-large-9443', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_11-59-40_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-42-roberta-large-9443', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias_eval_loss': 3.2066781520843506, 'mrpc_dev_prompt,bias_eval_acc': 0.625, 'mrpc_dev_prompt,bias_eval_f1': 0.6842105263157896, 'mrpc_dev_prompt,bias_eval_acc_and_f1': 0.6546052631578948, 'mrpc_test_prompt,bias_eval_loss': 4.022909164428711, 'mrpc_test_prompt,bias_eval_acc': 0.5171568627450981, 'mrpc_test_prompt,bias_eval_f1': 0.6004056795131846, 'mrpc_test_prompt,bias_eval_acc_and_f1': 0.5587812711291413, 'mrpc_dev_eval_loss': 3.2066781520843506, 'mrpc_dev_eval_acc': 0.625, 'mrpc_dev_eval_f1': 0.6842105263157896, 'mrpc_dev_eval_acc_and_f1': 0.6546052631578948, 'mrpc_test_eval_loss': 4.022909164428711, 'mrpc_test_eval_acc': 0.5171568627450981, 'mrpc_test_eval_f1': 0.6004056795131846, 'mrpc_test_eval_acc_and_f1': 0.5587812711291413, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-13-roberta-large-8832', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_12-04-30_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-13-roberta-large-8832', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias,adapter_eval_loss': 1.9555765390396118, 'mnli_dev_prompt,bias,adapter_eval_mnli/acc': 0.7708333333333334, 'mnli_test_prompt,bias,adapter_eval_loss': 2.23929500579834, 'mnli_test_prompt,bias,adapter_eval_mnli/acc': 0.6526744778400407, 'mnli-mm_test_prompt,bias,adapter_eval_loss': 2.1835389137268066, 'mnli-mm_test_prompt,bias,adapter_eval_mnli-mm/acc': 0.6660903173311635, 'mnli_dev_eval_loss': 1.9555765390396118, 'mnli_dev_eval_mnli/acc': 0.7708333333333334, 'mnli_test_eval_loss': 2.23929500579834, 'mnli_test_eval_mnli/acc': 0.6526744778400407, 'mnli-mm_test_eval_loss': 2.1835389137268066, 'mnli-mm_test_eval_mnli-mm/acc': 0.6660903173311635, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-16404', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_11-51-05_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-16404', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_eval_loss': 1.7473950386047363, 'mnli_dev_eval_mnli/acc': 0.3541666666666667, 'mnli_test_eval_loss': 1.578155755996704, 'mnli_test_eval_mnli/acc': 0.34192562404482935, 'mnli-mm_test_eval_loss': 1.5886532068252563, 'mnli-mm_test_eval_mnli-mm/acc': 0.33899511798209925, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--13-roberta-large-26743', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_12-18-06_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--13-roberta-large-26743', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': None, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_adapter_eval_loss': 1.745760440826416, 'rte_dev_adapter_eval_acc': 0.71875, 'rte_test_adapter_eval_loss': 1.6529682874679565, 'rte_test_adapter_eval_acc': 0.6750902527075813, 'rte_dev_eval_loss': 1.745760440826416, 'rte_dev_eval_acc': 0.71875, 'rte_test_eval_loss': 1.6529682874679565, 'rte_test_eval_acc': 0.6750902527075813, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--13-roberta-large-27351', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_12-09-23_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--13-roberta-large-27351', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,adapter_eval_loss': 3.1328277587890625, 'qnli_dev_prompt,adapter_eval_acc': 0.6875, 'qnli_test_prompt,adapter_eval_loss': 3.8711302280426025, 'qnli_test_prompt,adapter_eval_acc': 0.6558667398865092, 'qnli_dev_eval_loss': 3.1328277587890625, 'qnli_dev_eval_acc': 0.6875, 'qnli_test_eval_loss': 3.8711302280426025, 'qnli_test_eval_acc': 0.6558667398865092, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-13-roberta-large-10638', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_12-10-55_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-13-roberta-large-10638', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_adapter_eval_loss': 0.7055604457855225, 'sst-2_dev_adapter_eval_acc': 0.90625, 'sst-2_test_adapter_eval_loss': 0.796745240688324, 'sst-2_test_adapter_eval_acc': 0.9151376146788991, 'sst-2_dev_eval_loss': 0.7055604457855225, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 0.796745240688324, 'sst-2_test_eval_acc': 0.9151376146788991, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--13-roberta-large-25480', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_12-10-47_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-25480', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias_eval_loss': 3.3134593963623047, 'mrpc_dev_prompt,bias_eval_acc': 0.59375, 'mrpc_dev_prompt,bias_eval_f1': 0.6285714285714286, 'mrpc_dev_prompt,bias_eval_acc_and_f1': 0.6111607142857143, 'mrpc_test_prompt,bias_eval_loss': 3.9391722679138184, 'mrpc_test_prompt,bias_eval_acc': 0.5220588235294118, 'mrpc_test_prompt,bias_eval_f1': 0.6123260437375745, 'mrpc_test_prompt,bias_eval_acc_and_f1': 0.5671924336334931, 'mrpc_dev_eval_loss': 3.3134593963623047, 'mrpc_dev_eval_acc': 0.59375, 'mrpc_dev_eval_f1': 0.6285714285714286, 'mrpc_dev_eval_acc_and_f1': 0.6111607142857143, 'mrpc_test_eval_loss': 3.9391722679138184, 'mrpc_test_eval_acc': 0.5220588235294118, 'mrpc_test_eval_f1': 0.6123260437375745, 'mrpc_test_eval_acc_and_f1': 0.5671924336334931, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-13-roberta-large-21655', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_12-15-35_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-13-roberta-large-21655', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_adapter_eval_loss': 2.8524487018585205, 'cola_dev_adapter_eval_mcc': 0.31311214554257477, 'cola_test_adapter_eval_loss': 4.108613967895508, 'cola_test_adapter_eval_mcc': 0.060390978976924165, 'cola_dev_eval_loss': 2.8524487018585205, 'cola_dev_eval_mcc': 0.31311214554257477, 'cola_test_eval_loss': 4.108613967895508, 'cola_test_eval_mcc': 0.060390978976924165, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--13-roberta-large-20244', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_12-08-35_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-20244', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias_eval_loss': 2.786513328552246, 'qqp_dev_bias_eval_acc': 0.71875, 'qqp_dev_bias_eval_f1': 0.7567567567567567, 'qqp_dev_bias_eval_acc_and_f1': 0.7377533783783783, 'qqp_test_bias_eval_loss': 2.544684886932373, 'qqp_test_bias_eval_acc': 0.7027702201335642, 'qqp_test_bias_eval_f1': 0.6733179285034661, 'qqp_test_bias_eval_acc_and_f1': 0.6880440743185151, 'qqp_dev_eval_loss': 2.786513328552246, 'qqp_dev_eval_acc': 0.71875, 'qqp_dev_eval_f1': 0.7567567567567567, 'qqp_dev_eval_acc_and_f1': 0.7377533783783783, 'qqp_test_eval_loss': 2.544684886932373, 'qqp_test_eval_acc': 0.7027702201335642, 'qqp_test_eval_f1': 0.6733179285034661, 'qqp_test_eval_acc_and_f1': 0.6880440743185151, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16--13-roberta-large-15824', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_12-05-21_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--13-roberta-large-15824', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.227126359939575, 'sts-b_dev_prompt_eval_pearson': 0.35098981085348013, 'sts-b_dev_prompt_eval_spearmanr': 0.3625351750546779, 'sts-b_dev_prompt_eval_corr': 0.356762492954079, 'sts-b_test_prompt_eval_loss': 2.4854133129119873, 'sts-b_test_prompt_eval_pearson': 0.16265907010391228, 'sts-b_test_prompt_eval_spearmanr': 0.16862653629979807, 'sts-b_test_prompt_eval_corr': 0.16564280320185518, 'sts-b_dev_eval_loss': 2.227126359939575, 'sts-b_dev_eval_pearson': 0.35098981085348013, 'sts-b_dev_eval_spearmanr': 0.3625351750546779, 'sts-b_dev_eval_corr': 0.356762492954079, 'sts-b_test_eval_loss': 2.4854133129119873, 'sts-b_test_eval_pearson': 0.16265907010391228, 'sts-b_test_eval_spearmanr': 0.16862653629979807, 'sts-b_test_eval_corr': 0.16564280320185518, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-42-roberta-large-731', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_12-14-35_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-42-roberta-large-731', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias_eval_loss': 1.4871087074279785, 'mrpc_dev_prompt,bias_eval_acc': 0.5, 'mrpc_dev_prompt,bias_eval_f1': 0.5555555555555556, 'mrpc_dev_prompt,bias_eval_acc_and_f1': 0.5277777777777778, 'mrpc_test_prompt,bias_eval_loss': 1.8780319690704346, 'mrpc_test_prompt,bias_eval_acc': 0.49019607843137253, 'mrpc_test_prompt,bias_eval_f1': 0.5755102040816327, 'mrpc_test_prompt,bias_eval_acc_and_f1': 0.5328531412565026, 'mrpc_dev_eval_loss': 1.4871087074279785, 'mrpc_dev_eval_acc': 0.5, 'mrpc_dev_eval_f1': 0.5555555555555556, 'mrpc_dev_eval_acc_and_f1': 0.5277777777777778, 'mrpc_test_eval_loss': 1.8780319690704346, 'mrpc_test_eval_acc': 0.49019607843137253, 'mrpc_test_eval_f1': 0.5755102040816327, 'mrpc_test_eval_acc_and_f1': 0.5328531412565026, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-13-roberta-large-17293', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_12-26-42_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-13-roberta-large-17293', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_adapter_eval_loss': 0.8891506195068359, 'rte_dev_adapter_eval_acc': 0.75, 'rte_test_adapter_eval_loss': 1.0140455961227417, 'rte_test_adapter_eval_acc': 0.6678700361010831, 'rte_dev_eval_loss': 0.8891506195068359, 'rte_dev_eval_acc': 0.75, 'rte_test_eval_loss': 1.0140455961227417, 'rte_test_eval_acc': 0.6678700361010831, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--13-roberta-large-12078', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_12-23-57_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--13-roberta-large-12078', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,adapter_eval_loss': 1.445311427116394, 'qnli_dev_prompt,adapter_eval_acc': 0.84375, 'qnli_test_prompt,adapter_eval_loss': 2.8533763885498047, 'qnli_test_prompt,adapter_eval_acc': 0.7349441698700347, 'qnli_dev_eval_loss': 1.445311427116394, 'qnli_dev_eval_acc': 0.84375, 'qnli_test_eval_loss': 2.8533763885498047, 'qnli_test_eval_acc': 0.7349441698700347, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-13-roberta-large-8032', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_12-24-37_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-13-roberta-large-8032', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt_eval_loss': 3.6642162799835205, 'mnli_dev_prompt_eval_mnli/acc': 0.5, 'mnli_test_prompt_eval_loss': 4.0515618324279785, 'mnli_test_prompt_eval_mnli/acc': 0.32042791645440655, 'mnli-mm_test_prompt_eval_loss': 3.786407709121704, 'mnli-mm_test_prompt_eval_mnli-mm/acc': 0.3233319772172498, 'mnli_dev_eval_loss': 3.6642162799835205, 'mnli_dev_eval_mnli/acc': 0.5, 'mnli_test_eval_loss': 4.0515618324279785, 'mnli_test_eval_mnli/acc': 0.32042791645440655, 'mnli-mm_test_eval_loss': 3.786407709121704, 'mnli-mm_test_eval_mnli-mm/acc': 0.3233319772172498, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-20228', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_12-21-46_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-20228', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_adapter_eval_loss': 0.721451997756958, 'sst-2_dev_adapter_eval_acc': 0.9375, 'sst-2_test_adapter_eval_loss': 0.6383795738220215, 'sst-2_test_adapter_eval_acc': 0.930045871559633, 'sst-2_dev_eval_loss': 0.721451997756958, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.6383795738220215, 'sst-2_test_eval_acc': 0.930045871559633, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--13-roberta-large-10284', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_12-26-02_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-10284', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.2132580280303955, 'sts-b_dev_prompt_eval_pearson': 0.3932686231667152, 'sts-b_dev_prompt_eval_spearmanr': 0.4890735416264475, 'sts-b_dev_prompt_eval_corr': 0.4411710823965813, 'sts-b_test_prompt_eval_loss': 2.5149333477020264, 'sts-b_test_prompt_eval_pearson': 0.11466573763146232, 'sts-b_test_prompt_eval_spearmanr': 0.13028574815876512, 'sts-b_test_prompt_eval_corr': 0.12247574289511372, 'sts-b_dev_eval_loss': 2.2132580280303955, 'sts-b_dev_eval_pearson': 0.3932686231667152, 'sts-b_dev_eval_spearmanr': 0.4890735416264475, 'sts-b_dev_eval_corr': 0.4411710823965813, 'sts-b_test_eval_loss': 2.5149333477020264, 'sts-b_test_eval_pearson': 0.11466573763146232, 'sts-b_test_eval_spearmanr': 0.13028574815876512, 'sts-b_test_eval_corr': 0.12247574289511372, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-42-roberta-large-19746', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_12-29-07_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-42-roberta-large-19746', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,adapter_eval_loss': 0.7014775276184082, 'cola_dev_prompt,adapter_eval_mcc': 0.0, 'cola_test_prompt,adapter_eval_loss': 0.6520100831985474, 'cola_test_prompt,adapter_eval_mcc': 0.0, 'cola_dev_eval_loss': 0.7014775276184082, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.6520100831985474, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-9118', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_12-26-58_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-9118', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias_eval_loss': 1.1482442617416382, 'mrpc_dev_prompt,bias_eval_acc': 0.4375, 'mrpc_dev_prompt,bias_eval_f1': 0.47058823529411764, 'mrpc_dev_prompt,bias_eval_acc_and_f1': 0.4540441176470588, 'mrpc_test_prompt,bias_eval_loss': 1.4879732131958008, 'mrpc_test_prompt,bias_eval_acc': 0.4681372549019608, 'mrpc_test_prompt,bias_eval_f1': 0.5488565488565488, 'mrpc_test_prompt,bias_eval_acc_and_f1': 0.5084969018792548, 'mrpc_dev_eval_loss': 1.1482442617416382, 'mrpc_dev_eval_acc': 0.4375, 'mrpc_dev_eval_f1': 0.47058823529411764, 'mrpc_dev_eval_acc_and_f1': 0.4540441176470588, 'mrpc_test_eval_loss': 1.4879732131958008, 'mrpc_test_eval_acc': 0.4681372549019608, 'mrpc_test_eval_f1': 0.5488565488565488, 'mrpc_test_eval_acc_and_f1': 0.5084969018792548, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-13-roberta-large-11089', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_12-37-22_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-13-roberta-large-11089', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_adapter_eval_loss': 3.909663438796997, 'qqp_dev_adapter_eval_acc': 0.75, 'qqp_dev_adapter_eval_f1': 0.7777777777777777, 'qqp_dev_adapter_eval_acc_and_f1': 0.7638888888888888, 'qqp_test_adapter_eval_loss': 4.900712966918945, 'qqp_test_adapter_eval_acc': 0.6954983922829582, 'qqp_test_adapter_eval_f1': 0.6773762415157629, 'qqp_test_adapter_eval_acc_and_f1': 0.6864373168993605, 'qqp_dev_eval_loss': 3.909663438796997, 'qqp_dev_eval_acc': 0.75, 'qqp_dev_eval_f1': 0.7777777777777777, 'qqp_dev_eval_acc_and_f1': 0.7638888888888888, 'qqp_test_eval_loss': 4.900712966918945, 'qqp_test_eval_acc': 0.6954983922829582, 'qqp_test_eval_f1': 0.6773762415157629, 'qqp_test_eval_acc_and_f1': 0.6864373168993605, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16--13-roberta-large-3687', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_12-27-15_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--13-roberta-large-3687', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,adapter_eval_loss': 1.1514275074005127, 'qnli_dev_prompt,adapter_eval_acc': 0.84375, 'qnli_test_prompt,adapter_eval_loss': 1.900635838508606, 'qnli_test_prompt,adapter_eval_acc': 0.7151748123741534, 'qnli_dev_eval_loss': 1.1514275074005127, 'qnli_dev_eval_acc': 0.84375, 'qnli_test_eval_loss': 1.900635838508606, 'qnli_test_eval_acc': 0.7151748123741534, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-13-roberta-large-6165', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_12-38-59_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-13-roberta-large-6165', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,adapter_eval_loss': 3.77168345451355, 'rte_dev_prompt,adapter_eval_acc': 0.75, 'rte_test_prompt,adapter_eval_loss': 4.42040491104126, 'rte_test_prompt,adapter_eval_acc': 0.6750902527075813, 'rte_dev_eval_loss': 3.77168345451355, 'rte_dev_eval_acc': 0.75, 'rte_test_eval_loss': 4.42040491104126, 'rte_test_eval_acc': 0.6750902527075813, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-13-roberta-large-6861', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_12-38-55_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-13-roberta-large-6861', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.6021814346313477, 'sts-b_dev_prompt_eval_pearson': 0.5353633558202242, 'sts-b_dev_prompt_eval_spearmanr': 0.5255242058149542, 'sts-b_dev_prompt_eval_corr': 0.5304437808175892, 'sts-b_test_prompt_eval_loss': 2.75072979927063, 'sts-b_test_prompt_eval_pearson': 0.08279147798900895, 'sts-b_test_prompt_eval_spearmanr': 0.06854828923785677, 'sts-b_test_prompt_eval_corr': 0.07566988361343285, 'sts-b_dev_eval_loss': 2.6021814346313477, 'sts-b_dev_eval_pearson': 0.5353633558202242, 'sts-b_dev_eval_spearmanr': 0.5255242058149542, 'sts-b_dev_eval_corr': 0.5304437808175892, 'sts-b_test_eval_loss': 2.75072979927063, 'sts-b_test_eval_pearson': 0.08279147798900895, 'sts-b_test_eval_spearmanr': 0.06854828923785677, 'sts-b_test_eval_corr': 0.07566988361343285, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-87-roberta-large-19504', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_12-42-27_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-87-roberta-large-19504', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_adapter_eval_loss': 0.3744097948074341, 'sst-2_dev_adapter_eval_acc': 0.96875, 'sst-2_test_adapter_eval_loss': 0.5565057992935181, 'sst-2_test_adapter_eval_acc': 0.9334862385321101, 'sst-2_dev_eval_loss': 0.3744097948074341, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.5565057992935181, 'sst-2_test_eval_acc': 0.9334862385321101, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--13-roberta-large-2377', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_12-41-36_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-2377', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt_eval_loss': 1.9667835235595703, 'mnli_dev_prompt_eval_mnli/acc': 0.4375, 'mnli_test_prompt_eval_loss': 2.0879697799682617, 'mnli_test_prompt_eval_mnli/acc': 0.35160468670402445, 'mnli-mm_test_prompt_eval_loss': 1.9097001552581787, 'mnli-mm_test_prompt_eval_mnli-mm/acc': 0.3572009764035802, 'mnli_dev_eval_loss': 1.9667835235595703, 'mnli_dev_eval_mnli/acc': 0.4375, 'mnli_test_eval_loss': 2.0879697799682617, 'mnli_test_eval_mnli/acc': 0.35160468670402445, 'mnli-mm_test_eval_loss': 1.9097001552581787, 'mnli-mm_test_eval_mnli-mm/acc': 0.3572009764035802, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-21401', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_12-40-03_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-21401', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,adapter_eval_loss': 5.607151985168457, 'cola_dev_prompt,adapter_eval_mcc': 0.20851441405707474, 'cola_test_prompt,adapter_eval_loss': 8.60617733001709, 'cola_test_prompt,adapter_eval_mcc': 0.11828759092086372, 'cola_dev_eval_loss': 5.607151985168457, 'cola_dev_eval_mcc': 0.20851441405707474, 'cola_test_eval_loss': 8.60617733001709, 'cola_test_eval_mcc': 0.11828759092086372, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-16694', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_12-44-52_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-16694', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias,adapter_eval_loss': 0.7014449238777161, 'mrpc_dev_bias,adapter_eval_acc': 0.5, 'mrpc_dev_bias,adapter_eval_f1': 0.6666666666666666, 'mrpc_dev_bias,adapter_eval_acc_and_f1': 0.5833333333333333, 'mrpc_test_bias,adapter_eval_loss': 0.6540409326553345, 'mrpc_test_bias,adapter_eval_acc': 0.6838235294117647, 'mrpc_test_bias,adapter_eval_f1': 0.8122270742358079, 'mrpc_test_bias,adapter_eval_acc_and_f1': 0.7480253018237863, 'mrpc_dev_eval_loss': 0.7014449238777161, 'mrpc_dev_eval_acc': 0.5, 'mrpc_dev_eval_f1': 0.6666666666666666, 'mrpc_dev_eval_acc_and_f1': 0.5833333333333333, 'mrpc_test_eval_loss': 0.6540409326553345, 'mrpc_test_eval_acc': 0.6838235294117647, 'mrpc_test_eval_f1': 0.8122270742358079, 'mrpc_test_eval_acc_and_f1': 0.7480253018237863, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--13-roberta-large-21347', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_12-48-19_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--13-roberta-large-21347', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,adapter_eval_loss': 0.9417613744735718, 'qnli_dev_prompt,adapter_eval_acc': 0.8125, 'qnli_test_prompt,adapter_eval_loss': 1.5158637762069702, 'qnli_test_prompt,adapter_eval_acc': 0.6899139666849716, 'qnli_dev_eval_loss': 0.9417613744735718, 'qnli_dev_eval_acc': 0.8125, 'qnli_test_eval_loss': 1.5158637762069702, 'qnli_test_eval_acc': 0.6899139666849716, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-13-roberta-large-13069', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_12-53-10_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-13-roberta-large-13069', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,adapter_eval_loss': 3.684121608734131, 'rte_dev_prompt,adapter_eval_acc': 0.75, 'rte_test_prompt,adapter_eval_loss': 5.131755352020264, 'rte_test_prompt,adapter_eval_acc': 0.6714801444043321, 'rte_dev_eval_loss': 3.684121608734131, 'rte_dev_eval_acc': 0.75, 'rte_test_eval_loss': 5.131755352020264, 'rte_test_eval_acc': 0.6714801444043321, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-13-roberta-large-4389', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_12-54-48_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-13-roberta-large-4389', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.372619390487671, 'sts-b_dev_prompt_eval_pearson': 0.2013590162443561, 'sts-b_dev_prompt_eval_spearmanr': 0.15112034290206405, 'sts-b_dev_prompt_eval_corr': 0.17623967957321007, 'sts-b_test_prompt_eval_loss': 2.5114078521728516, 'sts-b_test_prompt_eval_pearson': 0.010740762701231879, 'sts-b_test_prompt_eval_spearmanr': 0.02006559213929424, 'sts-b_test_prompt_eval_corr': 0.01540317742026306, 'sts-b_dev_eval_loss': 2.372619390487671, 'sts-b_dev_eval_pearson': 0.2013590162443561, 'sts-b_dev_eval_spearmanr': 0.15112034290206405, 'sts-b_dev_eval_corr': 0.17623967957321007, 'sts-b_test_eval_loss': 2.5114078521728516, 'sts-b_test_eval_pearson': 0.010740762701231879, 'sts-b_test_eval_spearmanr': 0.02006559213929424, 'sts-b_test_eval_corr': 0.01540317742026306, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-87-roberta-large-13322', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_12-56-45_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-87-roberta-large-13322', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt_eval_loss': 4.655598163604736, 'mnli_dev_prompt_eval_mnli/acc': 0.4375, 'mnli_test_prompt_eval_loss': 5.3389892578125, 'mnli_test_prompt_eval_mnli/acc': 0.3252165053489557, 'mnli-mm_test_prompt_eval_loss': 5.280345916748047, 'mnli-mm_test_prompt_eval_mnli-mm/acc': 0.3360455655004068, 'mnli_dev_eval_loss': 4.655598163604736, 'mnli_dev_eval_mnli/acc': 0.4375, 'mnli_test_eval_loss': 5.3389892578125, 'mnli_test_eval_mnli/acc': 0.3252165053489557, 'mnli-mm_test_eval_loss': 5.280345916748047, 'mnli-mm_test_eval_mnli-mm/acc': 0.3360455655004068, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-15878', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_12-58-06_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-15878', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,adapter_eval_loss': 0.6971210241317749, 'sst-2_dev_prompt,adapter_eval_acc': 0.5, 'sst-2_test_prompt,adapter_eval_loss': 0.6955038905143738, 'sst-2_test_prompt,adapter_eval_acc': 0.5091743119266054, 'sst-2_dev_eval_loss': 0.6971210241317749, 'sst-2_dev_eval_acc': 0.5, 'sst-2_test_eval_loss': 0.6955038905143738, 'sst-2_test_eval_acc': 0.5091743119266054, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-2129', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_12-57-09_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-2129', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias_eval_loss': 1.500727891921997, 'qnli_dev_prompt,bias_eval_acc': 0.875, 'qnli_test_prompt,bias_eval_loss': 2.22841477394104, 'qnli_test_prompt,bias_eval_acc': 0.7777777777777778, 'qnli_dev_eval_loss': 1.500727891921997, 'qnli_dev_eval_acc': 0.875, 'qnli_test_eval_loss': 2.22841477394104, 'qnli_test_eval_acc': 0.7777777777777778, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-13-roberta-large-6782', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_13-07-06_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-13-roberta-large-6782', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,adapter_eval_loss': 5.746255874633789, 'cola_dev_prompt,adapter_eval_mcc': 0.22677868380553634, 'cola_test_prompt,adapter_eval_loss': 4.0638251304626465, 'cola_test_prompt,adapter_eval_mcc': 0.11485532965786252, 'cola_dev_eval_loss': 5.746255874633789, 'cola_dev_eval_mcc': 0.22677868380553634, 'cola_test_eval_loss': 4.0638251304626465, 'cola_test_eval_mcc': 0.11485532965786252, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-26883', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_13-02-53_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-26883', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias,adapter_eval_loss': 2.4145097732543945, 'mrpc_dev_bias,adapter_eval_acc': 0.6875, 'mrpc_dev_bias,adapter_eval_f1': 0.7368421052631579, 'mrpc_dev_bias,adapter_eval_acc_and_f1': 0.712171052631579, 'mrpc_test_bias,adapter_eval_loss': 3.4898197650909424, 'mrpc_test_bias,adapter_eval_acc': 0.4730392156862745, 'mrpc_test_bias,adapter_eval_f1': 0.549266247379455, 'mrpc_test_bias,adapter_eval_acc_and_f1': 0.5111527315328648, 'mrpc_dev_eval_loss': 2.4145097732543945, 'mrpc_dev_eval_acc': 0.6875, 'mrpc_dev_eval_f1': 0.7368421052631579, 'mrpc_dev_eval_acc_and_f1': 0.712171052631579, 'mrpc_test_eval_loss': 3.4898197650909424, 'mrpc_test_eval_acc': 0.4730392156862745, 'mrpc_test_eval_f1': 0.549266247379455, 'mrpc_test_eval_acc_and_f1': 0.5111527315328648, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--13-roberta-large-17005', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_13-05-08_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--13-roberta-large-17005', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_adapter_eval_loss': 3.7497596740722656, 'qqp_dev_adapter_eval_acc': 0.71875, 'qqp_dev_adapter_eval_f1': 0.742857142857143, 'qqp_dev_adapter_eval_acc_and_f1': 0.7308035714285714, 'qqp_test_adapter_eval_loss': 3.2801401615142822, 'qqp_test_adapter_eval_acc': 0.7014098441751175, 'qqp_test_adapter_eval_f1': 0.6504517025712301, 'qqp_test_adapter_eval_acc_and_f1': 0.6759307733731739, 'qqp_dev_eval_loss': 3.7497596740722656, 'qqp_dev_eval_acc': 0.71875, 'qqp_dev_eval_f1': 0.742857142857143, 'qqp_dev_eval_acc_and_f1': 0.7308035714285714, 'qqp_test_eval_loss': 3.2801401615142822, 'qqp_test_eval_acc': 0.7014098441751175, 'qqp_test_eval_f1': 0.6504517025712301, 'qqp_test_eval_acc_and_f1': 0.6759307733731739, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16--13-roberta-large-6441', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_12-51-41_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--13-roberta-large-6441', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.404639482498169, 'sts-b_dev_prompt_eval_pearson': 0.20711309229572317, 'sts-b_dev_prompt_eval_spearmanr': 0.24733791238041344, 'sts-b_dev_prompt_eval_corr': 0.22722550233806832, 'sts-b_test_prompt_eval_loss': 2.6029226779937744, 'sts-b_test_prompt_eval_pearson': -0.009537003737710091, 'sts-b_test_prompt_eval_spearmanr': -0.00014640757460731844, 'sts-b_test_prompt_eval_corr': -0.004841705656158705, 'sts-b_dev_eval_loss': 2.404639482498169, 'sts-b_dev_eval_pearson': 0.20711309229572317, 'sts-b_dev_eval_spearmanr': 0.24733791238041344, 'sts-b_dev_eval_corr': 0.22722550233806832, 'sts-b_test_eval_loss': 2.6029226779937744, 'sts-b_test_eval_pearson': -0.009537003737710091, 'sts-b_test_eval_spearmanr': -0.00014640757460731844, 'sts-b_test_eval_corr': -0.004841705656158705, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-87-roberta-large-8169', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_13-11-29_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-87-roberta-large-8169', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,adapter_eval_loss': 1.3757243156433105, 'rte_dev_prompt,adapter_eval_acc': 0.78125, 'rte_test_prompt,adapter_eval_loss': 1.7864997386932373, 'rte_test_prompt,adapter_eval_acc': 0.6642599277978339, 'rte_dev_eval_loss': 1.3757243156433105, 'rte_dev_eval_acc': 0.78125, 'rte_test_eval_loss': 1.7864997386932373, 'rte_test_eval_acc': 0.6642599277978339, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-13-roberta-large-2996', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_13-11-00_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-13-roberta-large-2996', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias_eval_loss': 1.2907814979553223, 'qnli_dev_prompt,bias_eval_acc': 0.875, 'qnli_test_prompt,bias_eval_loss': 1.9743330478668213, 'qnli_test_prompt,bias_eval_acc': 0.7375068643602416, 'qnli_dev_eval_loss': 1.2907814979553223, 'qnli_dev_eval_acc': 0.875, 'qnli_test_eval_loss': 1.9743330478668213, 'qnli_test_eval_acc': 0.7375068643602416, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-13-roberta-large-6650', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_13-18-39_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-13-roberta-large-6650', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt_eval_loss': 1.4295693635940552, 'mnli_dev_prompt_eval_mnli/acc': 0.3333333333333333, 'mnli_test_prompt_eval_loss': 1.3113420009613037, 'mnli_test_prompt_eval_mnli/acc': 0.33662761079979625, 'mnli-mm_test_prompt_eval_loss': 1.3096933364868164, 'mnli-mm_test_prompt_eval_mnli-mm/acc': 0.3365541090317331, 'mnli_dev_eval_loss': 1.4295693635940552, 'mnli_dev_eval_mnli/acc': 0.3333333333333333, 'mnli_test_eval_loss': 1.3113420009613037, 'mnli_test_eval_mnli/acc': 0.33662761079979625, 'mnli-mm_test_eval_loss': 1.3096933364868164, 'mnli-mm_test_eval_mnli-mm/acc': 0.3365541090317331, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-6023', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_13-15-37_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-6023', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,adapter_eval_loss': 0.8574352264404297, 'sst-2_dev_prompt,adapter_eval_acc': 0.90625, 'sst-2_test_prompt,adapter_eval_loss': 0.954683244228363, 'sst-2_test_prompt,adapter_eval_acc': 0.8864678899082569, 'sst-2_dev_eval_loss': 0.8574352264404297, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 0.954683244228363, 'sst-2_test_eval_acc': 0.8864678899082569, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-9695', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_13-15-40_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-9695', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias,adapter_eval_loss': 3.2191050052642822, 'mrpc_dev_bias,adapter_eval_acc': 0.59375, 'mrpc_dev_bias,adapter_eval_f1': 0.5806451612903225, 'mrpc_dev_bias,adapter_eval_acc_and_f1': 0.5871975806451613, 'mrpc_test_bias,adapter_eval_loss': 4.070354461669922, 'mrpc_test_bias,adapter_eval_acc': 0.48284313725490197, 'mrpc_test_bias,adapter_eval_f1': 0.5442764578833693, 'mrpc_test_bias,adapter_eval_acc_and_f1': 0.5135597975691356, 'mrpc_dev_eval_loss': 3.2191050052642822, 'mrpc_dev_eval_acc': 0.59375, 'mrpc_dev_eval_f1': 0.5806451612903225, 'mrpc_dev_eval_acc_and_f1': 0.5871975806451613, 'mrpc_test_eval_loss': 4.070354461669922, 'mrpc_test_eval_acc': 0.48284313725490197, 'mrpc_test_eval_f1': 0.5442764578833693, 'mrpc_test_eval_acc_and_f1': 0.5135597975691356, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--13-roberta-large-3256', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_13-21-45_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--13-roberta-large-3256', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,adapter_eval_loss': 4.666744232177734, 'cola_dev_prompt,adapter_eval_mcc': 0.12909944487358055, 'cola_test_prompt,adapter_eval_loss': 5.041096210479736, 'cola_test_prompt,adapter_eval_mcc': 0.05431634134614111, 'cola_dev_eval_loss': 4.666744232177734, 'cola_dev_eval_mcc': 0.12909944487358055, 'cola_test_eval_loss': 5.041096210479736, 'cola_test_eval_mcc': 0.05431634134614111, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-19410', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_13-20-37_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-19410', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.452482223510742, 'sts-b_dev_prompt_eval_pearson': 0.07557985915610066, 'sts-b_dev_prompt_eval_spearmanr': 0.09603394816255102, 'sts-b_dev_prompt_eval_corr': 0.08580690365932583, 'sts-b_test_prompt_eval_loss': 2.624377727508545, 'sts-b_test_prompt_eval_pearson': -0.04493214561004023, 'sts-b_test_prompt_eval_spearmanr': -0.03585397666863714, 'sts-b_test_prompt_eval_corr': -0.04039306113933869, 'sts-b_dev_eval_loss': 2.452482223510742, 'sts-b_dev_eval_pearson': 0.07557985915610066, 'sts-b_dev_eval_spearmanr': 0.09603394816255102, 'sts-b_dev_eval_corr': 0.08580690365932583, 'sts-b_test_eval_loss': 2.624377727508545, 'sts-b_test_eval_pearson': -0.04493214561004023, 'sts-b_test_eval_spearmanr': -0.03585397666863714, 'sts-b_test_eval_corr': -0.04039306113933869, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-87-roberta-large-31837', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_13-26-18_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 87, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-87-roberta-large-31837', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-87', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias_eval_loss': 0.7561496496200562, 'qnli_dev_prompt,bias_eval_acc': 0.75, 'qnli_test_prompt,bias_eval_loss': 1.0139081478118896, 'qnli_test_prompt,bias_eval_acc': 0.6725242540728538, 'qnli_dev_eval_loss': 0.7561496496200562, 'qnli_dev_eval_acc': 0.75, 'qnli_test_eval_loss': 1.0139081478118896, 'qnli_test_eval_acc': 0.6725242540728538, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-13-roberta-large-22904', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_13-30-23_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-13-roberta-large-22904', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,adapter_eval_loss': 0.923930823802948, 'rte_dev_prompt,adapter_eval_acc': 0.75, 'rte_test_prompt,adapter_eval_loss': 1.1126102209091187, 'rte_test_prompt,adapter_eval_acc': 0.6642599277978339, 'rte_dev_eval_loss': 0.923930823802948, 'rte_dev_eval_acc': 0.75, 'rte_test_eval_loss': 1.1126102209091187, 'rte_test_eval_acc': 0.6642599277978339, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-13-roberta-large-8397', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_13-26-49_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-13-roberta-large-8397', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_adapter_eval_loss': 3.4033830165863037, 'qqp_dev_adapter_eval_acc': 0.6875, 'qqp_dev_adapter_eval_f1': 0.7222222222222223, 'qqp_dev_adapter_eval_acc_and_f1': 0.7048611111111112, 'qqp_test_adapter_eval_loss': 2.7995548248291016, 'qqp_test_adapter_eval_acc': 0.6868909225822409, 'qqp_test_adapter_eval_f1': 0.6619308318867673, 'qqp_test_adapter_eval_acc_and_f1': 0.6744108772345041, 'qqp_dev_eval_loss': 3.4033830165863037, 'qqp_dev_eval_acc': 0.6875, 'qqp_dev_eval_f1': 0.7222222222222223, 'qqp_dev_eval_acc_and_f1': 0.7048611111111112, 'qqp_test_eval_loss': 2.7995548248291016, 'qqp_test_eval_acc': 0.6868909225822409, 'qqp_test_eval_f1': 0.6619308318867673, 'qqp_test_eval_acc_and_f1': 0.6744108772345041, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16--13-roberta-large-18717', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_13-21-48_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--13-roberta-large-18717', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias_eval_loss': 1.1302881240844727, 'mnli_dev_bias_eval_mnli/acc': 0.3333333333333333, 'mnli_test_bias_eval_loss': 1.1195868253707886, 'mnli_test_bias_eval_mnli/acc': 0.3544574630667346, 'mnli-mm_test_bias_eval_loss': 1.1201143264770508, 'mnli-mm_test_bias_eval_mnli-mm/acc': 0.3522172497965826, 'mnli_dev_eval_loss': 1.1302881240844727, 'mnli_dev_eval_mnli/acc': 0.3333333333333333, 'mnli_test_eval_loss': 1.1195868253707886, 'mnli_test_eval_mnli/acc': 0.3544574630667346, 'mnli-mm_test_eval_loss': 1.1201143264770508, 'mnli-mm_test_eval_mnli-mm/acc': 0.3522172497965826, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--13-roberta-large-27693', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_13-32-58_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--13-roberta-large-27693', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,adapter_eval_loss': 0.5928151607513428, 'sst-2_dev_prompt,adapter_eval_acc': 0.9375, 'sst-2_test_prompt,adapter_eval_loss': 0.8752040863037109, 'sst-2_test_prompt,adapter_eval_acc': 0.8876146788990825, 'sst-2_dev_eval_loss': 0.5928151607513428, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.8752040863037109, 'sst-2_test_eval_acc': 0.8876146788990825, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-1546', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_13-34-09_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-1546', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias_eval_loss': 0.8557461500167847, 'qnli_dev_prompt,bias_eval_acc': 0.75, 'qnli_test_prompt,bias_eval_loss': 1.1535735130310059, 'qnli_test_prompt,bias_eval_acc': 0.6747208493501738, 'qnli_dev_eval_loss': 0.8557461500167847, 'qnli_dev_eval_acc': 0.75, 'qnli_test_eval_loss': 1.1535735130310059, 'qnli_test_eval_acc': 0.6747208493501738, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-13-roberta-large-8272', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_13-41-45_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-13-roberta-large-8272', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.1151599884033203, 'sts-b_dev_prompt_eval_pearson': 0.5598198938981284, 'sts-b_dev_prompt_eval_spearmanr': 0.5348570455180769, 'sts-b_dev_prompt_eval_corr': 0.5473384697081026, 'sts-b_test_prompt_eval_loss': 2.2875537872314453, 'sts-b_test_prompt_eval_pearson': 0.0015161670912646756, 'sts-b_test_prompt_eval_spearmanr': -0.004889451781531729, 'sts-b_test_prompt_eval_corr': -0.0016866423451335265, 'sts-b_dev_eval_loss': 2.1151599884033203, 'sts-b_dev_eval_pearson': 0.5598198938981284, 'sts-b_dev_eval_spearmanr': 0.5348570455180769, 'sts-b_dev_eval_corr': 0.5473384697081026, 'sts-b_test_eval_loss': 2.2875537872314453, 'sts-b_test_eval_pearson': 0.0015161670912646756, 'sts-b_test_eval_spearmanr': -0.004889451781531729, 'sts-b_test_eval_corr': -0.0016866423451335265, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-100-roberta-large-17504', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_13-40-37_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-100-roberta-large-17504', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias,adapter_eval_loss': 1.9589433670043945, 'mrpc_dev_bias,adapter_eval_acc': 0.625, 'mrpc_dev_bias,adapter_eval_f1': 0.6666666666666665, 'mrpc_dev_bias,adapter_eval_acc_and_f1': 0.6458333333333333, 'mrpc_test_bias,adapter_eval_loss': 2.6820483207702637, 'mrpc_test_bias,adapter_eval_acc': 0.4950980392156863, 'mrpc_test_bias,adapter_eval_f1': 0.5726141078838175, 'mrpc_test_bias,adapter_eval_acc_and_f1': 0.533856073549752, 'mrpc_dev_eval_loss': 1.9589433670043945, 'mrpc_dev_eval_acc': 0.625, 'mrpc_dev_eval_f1': 0.6666666666666665, 'mrpc_dev_eval_acc_and_f1': 0.6458333333333333, 'mrpc_test_eval_loss': 2.6820483207702637, 'mrpc_test_eval_acc': 0.4950980392156863, 'mrpc_test_eval_f1': 0.5726141078838175, 'mrpc_test_eval_acc_and_f1': 0.533856073549752, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--13-roberta-large-26243', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_13-38-01_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--13-roberta-large-26243', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias_eval_loss': 3.82204532623291, 'cola_dev_prompt,bias_eval_mcc': 0.2581988897471611, 'cola_test_prompt,bias_eval_loss': 4.419283390045166, 'cola_test_prompt,bias_eval_mcc': -0.003484201710708457, 'cola_dev_eval_loss': 3.82204532623291, 'cola_dev_eval_mcc': 0.2581988897471611, 'cola_test_eval_loss': 4.419283390045166, 'cola_test_eval_mcc': -0.003484201710708457, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-129', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_13-40-09_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-129', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias_eval_loss': 3.131305694580078, 'rte_dev_prompt,bias_eval_acc': 0.8125, 'rte_test_prompt,bias_eval_loss': 4.549980640411377, 'rte_test_prompt,bias_eval_acc': 0.6570397111913358, 'rte_dev_eval_loss': 3.131305694580078, 'rte_dev_eval_acc': 0.8125, 'rte_test_eval_loss': 4.549980640411377, 'rte_test_eval_acc': 0.6570397111913358, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-13-roberta-large-25251', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_13-42-32_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-13-roberta-large-25251', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.23464035987854, 'sts-b_dev_prompt_eval_pearson': 0.3510427102645882, 'sts-b_dev_prompt_eval_spearmanr': 0.33971147285828335, 'sts-b_dev_prompt_eval_corr': 0.3453770915614358, 'sts-b_test_prompt_eval_loss': 2.4456429481506348, 'sts-b_test_prompt_eval_pearson': -0.015535336524338026, 'sts-b_test_prompt_eval_spearmanr': -0.011688056998437222, 'sts-b_test_prompt_eval_corr': -0.013611696761387624, 'sts-b_dev_eval_loss': 2.23464035987854, 'sts-b_dev_eval_pearson': 0.3510427102645882, 'sts-b_dev_eval_spearmanr': 0.33971147285828335, 'sts-b_dev_eval_corr': 0.3453770915614358, 'sts-b_test_eval_loss': 2.4456429481506348, 'sts-b_test_eval_pearson': -0.015535336524338026, 'sts-b_test_eval_spearmanr': -0.011688056998437222, 'sts-b_test_eval_corr': -0.013611696761387624, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-100-roberta-large-13584', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_13-54-28_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-100-roberta-large-13584', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias_eval_loss': 6.107436180114746, 'cola_dev_prompt,bias_eval_mcc': 0.18786728732554486, 'cola_test_prompt,bias_eval_loss': 5.95728874206543, 'cola_test_prompt,bias_eval_mcc': 0.07148706057398195, 'cola_dev_eval_loss': 6.107436180114746, 'cola_dev_eval_mcc': 0.18786728732554486, 'cola_test_eval_loss': 5.95728874206543, 'cola_test_eval_mcc': 0.07148706057398195, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-121', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_13-55-56_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-121', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias,adapter_eval_loss': 0.7054268717765808, 'qnli_dev_bias,adapter_eval_acc': 0.5, 'qnli_test_bias,adapter_eval_loss': 0.7037122249603271, 'qnli_test_bias,adapter_eval_acc': 0.5053999633900788, 'qnli_dev_eval_loss': 0.7054268717765808, 'qnli_dev_eval_acc': 0.5, 'qnli_test_eval_loss': 0.7037122249603271, 'qnli_test_eval_acc': 0.5053999633900788, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--13-roberta-large-15295', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_13-53-08_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--13-roberta-large-15295', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,adapter_eval_loss': 0.2813318967819214, 'sst-2_dev_prompt,adapter_eval_acc': 0.9375, 'sst-2_test_prompt,adapter_eval_loss': 0.5097091794013977, 'sst-2_test_prompt,adapter_eval_acc': 0.9094036697247706, 'sst-2_dev_eval_loss': 0.2813318967819214, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.5097091794013977, 'sst-2_test_eval_acc': 0.9094036697247706, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-9450', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_13-52-22_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-9450', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias_eval_loss': 3.756108522415161, 'mnli_dev_bias_eval_mnli/acc': 0.6666666666666666, 'mnli_test_bias_eval_loss': 3.4945852756500244, 'mnli_test_bias_eval_mnli/acc': 0.6600101884870097, 'mnli-mm_test_bias_eval_loss': 3.514639377593994, 'mnli-mm_test_bias_eval_mnli-mm/acc': 0.6616151342554922, 'mnli_dev_eval_loss': 3.756108522415161, 'mnli_dev_eval_mnli/acc': 0.6666666666666666, 'mnli_test_eval_loss': 3.4945852756500244, 'mnli_test_eval_mnli/acc': 0.6600101884870097, 'mnli-mm_test_eval_loss': 3.514639377593994, 'mnli-mm_test_eval_mnli-mm/acc': 0.6616151342554922, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--13-roberta-large-6882', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_13-52-07_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--13-roberta-large-6882', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias_eval_loss': 1.8552169799804688, 'rte_dev_prompt,bias_eval_acc': 0.65625, 'rte_test_prompt,bias_eval_loss': 1.8987091779708862, 'rte_test_prompt,bias_eval_acc': 0.6498194945848376, 'rte_dev_eval_loss': 1.8552169799804688, 'rte_dev_eval_acc': 0.65625, 'rte_test_eval_loss': 1.8987091779708862, 'rte_test_eval_acc': 0.6498194945848376, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-13-roberta-large-962', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_13-57-23_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-13-roberta-large-962', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias,adapter_eval_loss': 6.064457893371582, 'mrpc_dev_prompt,bias,adapter_eval_acc': 0.65625, 'mrpc_dev_prompt,bias,adapter_eval_f1': 0.7027027027027026, 'mrpc_dev_prompt,bias,adapter_eval_acc_and_f1': 0.6794763513513513, 'mrpc_test_prompt,bias,adapter_eval_loss': 5.90892219543457, 'mrpc_test_prompt,bias,adapter_eval_acc': 0.5931372549019608, 'mrpc_test_prompt,bias,adapter_eval_f1': 0.6981818181818182, 'mrpc_test_prompt,bias,adapter_eval_acc_and_f1': 0.6456595365418896, 'mrpc_dev_eval_loss': 6.064457893371582, 'mrpc_dev_eval_acc': 0.65625, 'mrpc_dev_eval_f1': 0.7027027027027026, 'mrpc_dev_eval_acc_and_f1': 0.6794763513513513, 'mrpc_test_eval_loss': 5.90892219543457, 'mrpc_test_eval_acc': 0.5931372549019608, 'mrpc_test_eval_f1': 0.6981818181818182, 'mrpc_test_eval_acc_and_f1': 0.6456595365418896, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-13-roberta-large-232', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_13-55-25_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-13-roberta-large-232', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_adapter_eval_loss': 1.1857191324234009, 'qqp_dev_adapter_eval_acc': 0.6875, 'qqp_dev_adapter_eval_f1': 0.7222222222222223, 'qqp_dev_adapter_eval_acc_and_f1': 0.7048611111111112, 'qqp_test_adapter_eval_loss': 0.9660624861717224, 'qqp_test_adapter_eval_acc': 0.6909473163492456, 'qqp_test_adapter_eval_f1': 0.6569098547461489, 'qqp_test_adapter_eval_acc_and_f1': 0.6739285855476973, 'qqp_dev_eval_loss': 1.1857191324234009, 'qqp_dev_eval_acc': 0.6875, 'qqp_dev_eval_f1': 0.7222222222222223, 'qqp_dev_eval_acc_and_f1': 0.7048611111111112, 'qqp_test_eval_loss': 0.9660624861717224, 'qqp_test_eval_acc': 0.6909473163492456, 'qqp_test_eval_f1': 0.6569098547461489, 'qqp_test_eval_acc_and_f1': 0.6739285855476973, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16--13-roberta-large-24520', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_13-51-38_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--13-roberta-large-24520', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.2216522693634033, 'sts-b_dev_prompt_eval_pearson': 0.40823999017602075, 'sts-b_dev_prompt_eval_spearmanr': 0.4371922961473414, 'sts-b_dev_prompt_eval_corr': 0.42271614316168105, 'sts-b_test_prompt_eval_loss': 2.592183828353882, 'sts-b_test_prompt_eval_pearson': 0.07090406888385474, 'sts-b_test_prompt_eval_spearmanr': 0.07842851504816205, 'sts-b_test_prompt_eval_corr': 0.0746662919660084, 'sts-b_dev_eval_loss': 2.2216522693634033, 'sts-b_dev_eval_pearson': 0.40823999017602075, 'sts-b_dev_eval_spearmanr': 0.4371922961473414, 'sts-b_dev_eval_corr': 0.42271614316168105, 'sts-b_test_eval_loss': 2.592183828353882, 'sts-b_test_eval_pearson': 0.07090406888385474, 'sts-b_test_eval_spearmanr': 0.07842851504816205, 'sts-b_test_eval_corr': 0.0746662919660084, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-100-roberta-large-126', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_14-08-54_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-100-roberta-large-126', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias_eval_loss': 1.2110280990600586, 'cola_dev_prompt,bias_eval_mcc': 0.13483997249264842, 'cola_test_prompt,bias_eval_loss': 0.8622682094573975, 'cola_test_prompt,bias_eval_mcc': 0.03880110545933893, 'cola_dev_eval_loss': 1.2110280990600586, 'cola_dev_eval_mcc': 0.13483997249264842, 'cola_test_eval_loss': 0.8622682094573975, 'cola_test_eval_mcc': 0.03880110545933893, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-3537', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_14-09-12_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-3537', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias_eval_loss': 2.04776668548584, 'rte_dev_prompt,bias_eval_acc': 0.75, 'rte_test_prompt,bias_eval_loss': 2.3374083042144775, 'rte_test_prompt,bias_eval_acc': 0.6642599277978339, 'rte_dev_eval_loss': 2.04776668548584, 'rte_dev_eval_acc': 0.75, 'rte_test_eval_loss': 2.3374083042144775, 'rte_test_eval_acc': 0.6642599277978339, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-13-roberta-large-30514', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_14-12-22_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-13-roberta-large-30514', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias_eval_loss': 0.9526739120483398, 'sst-2_dev_prompt,bias_eval_acc': 0.90625, 'sst-2_test_prompt,bias_eval_loss': 0.7749765515327454, 'sst-2_test_prompt,bias_eval_acc': 0.9071100917431193, 'sst-2_dev_eval_loss': 0.9526739120483398, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 0.7749765515327454, 'sst-2_test_eval_acc': 0.9071100917431193, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-1453', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_14-10-45_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-1453', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias,adapter_eval_loss': 1.0610105991363525, 'qnli_dev_bias,adapter_eval_acc': 0.75, 'qnli_test_bias,adapter_eval_loss': 1.7063591480255127, 'qnli_test_bias,adapter_eval_acc': 0.6977850997620355, 'qnli_dev_eval_loss': 1.0610105991363525, 'qnli_dev_eval_acc': 0.75, 'qnli_test_eval_loss': 1.7063591480255127, 'qnli_test_eval_acc': 0.6977850997620355, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--13-roberta-large-23282', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_14-10-22_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--13-roberta-large-23282', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias,adapter_eval_loss': 5.455289840698242, 'mrpc_dev_prompt,bias,adapter_eval_acc': 0.53125, 'mrpc_dev_prompt,bias,adapter_eval_f1': 0.5454545454545455, 'mrpc_dev_prompt,bias,adapter_eval_acc_and_f1': 0.5383522727272727, 'mrpc_test_prompt,bias,adapter_eval_loss': 5.569569110870361, 'mrpc_test_prompt,bias,adapter_eval_acc': 0.5465686274509803, 'mrpc_test_prompt,bias,adapter_eval_f1': 0.6336633663366337, 'mrpc_test_prompt,bias,adapter_eval_acc_and_f1': 0.590115996893807, 'mrpc_dev_eval_loss': 5.455289840698242, 'mrpc_dev_eval_acc': 0.53125, 'mrpc_dev_eval_f1': 0.5454545454545455, 'mrpc_dev_eval_acc_and_f1': 0.5383522727272727, 'mrpc_test_eval_loss': 5.569569110870361, 'mrpc_test_eval_acc': 0.5465686274509803, 'mrpc_test_eval_f1': 0.6336633663366337, 'mrpc_test_eval_acc_and_f1': 0.590115996893807, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-13-roberta-large-11646', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_14-12-29_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-13-roberta-large-11646', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias_eval_loss': 3.668450355529785, 'mnli_dev_bias_eval_mnli/acc': 0.5208333333333334, 'mnli_test_bias_eval_loss': 2.6732871532440186, 'mnli_test_bias_eval_mnli/acc': 0.5888945491594498, 'mnli-mm_test_bias_eval_loss': 2.6938230991363525, 'mnli-mm_test_bias_eval_mnli-mm/acc': 0.5906224572823434, 'mnli_dev_eval_loss': 3.668450355529785, 'mnli_dev_eval_mnli/acc': 0.5208333333333334, 'mnli_test_eval_loss': 2.6732871532440186, 'mnli_test_eval_mnli/acc': 0.5888945491594498, 'mnli-mm_test_eval_loss': 2.6938230991363525, 'mnli-mm_test_eval_mnli-mm/acc': 0.5906224572823434, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--13-roberta-large-13200', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_14-11-18_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--13-roberta-large-13200', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.1896908283233643, 'sts-b_dev_prompt_eval_pearson': 0.3741542708026251, 'sts-b_dev_prompt_eval_spearmanr': 0.43296199626875964, 'sts-b_dev_prompt_eval_corr': 0.40355813353569236, 'sts-b_test_prompt_eval_loss': 2.407641649246216, 'sts-b_test_prompt_eval_pearson': 0.009950323644377574, 'sts-b_test_prompt_eval_spearmanr': 0.009332600738281554, 'sts-b_test_prompt_eval_corr': 0.009641462191329563, 'sts-b_dev_eval_loss': 2.1896908283233643, 'sts-b_dev_eval_pearson': 0.3741542708026251, 'sts-b_dev_eval_spearmanr': 0.43296199626875964, 'sts-b_dev_eval_corr': 0.40355813353569236, 'sts-b_test_eval_loss': 2.407641649246216, 'sts-b_test_eval_pearson': 0.009950323644377574, 'sts-b_test_eval_spearmanr': 0.009332600738281554, 'sts-b_test_eval_corr': 0.009641462191329563, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-100-roberta-large-3357', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_14-23-47_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-100-roberta-large-3357', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias_eval_loss': 0.6776928305625916, 'cola_dev_prompt,bias_eval_mcc': 0.31814238148788887, 'cola_test_prompt,bias_eval_loss': 0.7004640102386475, 'cola_test_prompt,bias_eval_mcc': 0.0008589819266450572, 'cola_dev_eval_loss': 0.6776928305625916, 'cola_dev_eval_mcc': 0.31814238148788887, 'cola_test_eval_loss': 0.7004640102386475, 'cola_test_eval_mcc': 0.0008589819266450572, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-18641', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_14-23-48_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-18641', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias_eval_loss': 0.8477784395217896, 'rte_dev_prompt,bias_eval_acc': 0.71875, 'rte_test_prompt,bias_eval_loss': 0.9979019165039062, 'rte_test_prompt,bias_eval_acc': 0.6714801444043321, 'rte_dev_eval_loss': 0.8477784395217896, 'rte_dev_eval_acc': 0.71875, 'rte_test_eval_loss': 0.9979019165039062, 'rte_test_eval_acc': 0.6714801444043321, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-13-roberta-large-4475', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_14-27-18_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-13-roberta-large-4475', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias_eval_loss': 0.587007999420166, 'sst-2_dev_prompt,bias_eval_acc': 0.9375, 'sst-2_test_prompt,bias_eval_loss': 0.6549456119537354, 'sst-2_test_prompt,bias_eval_acc': 0.9185779816513762, 'sst-2_dev_eval_loss': 0.587007999420166, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.6549456119537354, 'sst-2_test_eval_acc': 0.9185779816513762, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-17611', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_14-27-34_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-17611', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias,adapter_eval_loss': 1.456601858139038, 'qnli_dev_bias,adapter_eval_acc': 0.6875, 'qnli_test_bias,adapter_eval_loss': 1.92385995388031, 'qnli_test_bias,adapter_eval_acc': 0.6829580816401245, 'qnli_dev_eval_loss': 1.456601858139038, 'qnli_dev_eval_acc': 0.6875, 'qnli_test_eval_loss': 1.92385995388031, 'qnli_test_eval_acc': 0.6829580816401245, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--13-roberta-large-30452', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_14-27-58_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--13-roberta-large-30452', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias,adapter_eval_loss': 3.5608084201812744, 'mrpc_dev_prompt,bias,adapter_eval_acc': 0.5625, 'mrpc_dev_prompt,bias,adapter_eval_f1': 0.5625, 'mrpc_dev_prompt,bias,adapter_eval_acc_and_f1': 0.5625, 'mrpc_test_prompt,bias,adapter_eval_loss': 4.053804874420166, 'mrpc_test_prompt,bias,adapter_eval_acc': 0.4583333333333333, 'mrpc_test_prompt,bias,adapter_eval_f1': 0.5307855626326964, 'mrpc_test_prompt,bias,adapter_eval_acc_and_f1': 0.4945594479830149, 'mrpc_dev_eval_loss': 3.5608084201812744, 'mrpc_dev_eval_acc': 0.5625, 'mrpc_dev_eval_f1': 0.5625, 'mrpc_dev_eval_acc_and_f1': 0.5625, 'mrpc_test_eval_loss': 4.053804874420166, 'mrpc_test_eval_acc': 0.4583333333333333, 'mrpc_test_eval_f1': 0.5307855626326964, 'mrpc_test_eval_acc_and_f1': 0.4945594479830149, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-13-roberta-large-12930', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_14-29-13_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-13-roberta-large-12930', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias_eval_loss': 3.173053741455078, 'mnli_dev_bias_eval_mnli/acc': 0.5416666666666666, 'mnli_test_bias_eval_loss': 2.2661094665527344, 'mnli_test_bias_eval_mnli/acc': 0.5971472236372899, 'mnli-mm_test_bias_eval_loss': 2.2634084224700928, 'mnli-mm_test_bias_eval_mnli-mm/acc': 0.6044548413344182, 'mnli_dev_eval_loss': 3.173053741455078, 'mnli_dev_eval_mnli/acc': 0.5416666666666666, 'mnli_test_eval_loss': 2.2661094665527344, 'mnli_test_eval_mnli/acc': 0.5971472236372899, 'mnli-mm_test_eval_loss': 2.2634084224700928, 'mnli-mm_test_eval_mnli-mm/acc': 0.6044548413344182, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--13-roberta-large-10247', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_14-30-25_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--13-roberta-large-10247', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,adapter_eval_loss': 2.207404136657715, 'qqp_dev_prompt,adapter_eval_acc': 0.75, 'qqp_dev_prompt,adapter_eval_f1': 0.7647058823529411, 'qqp_dev_prompt,adapter_eval_acc_and_f1': 0.7573529411764706, 'qqp_test_prompt,adapter_eval_loss': 3.6355888843536377, 'qqp_test_prompt,adapter_eval_acc': 0.612540192926045, 'qqp_test_prompt,adapter_eval_f1': 0.5482335976928623, 'qqp_test_prompt,adapter_eval_acc_and_f1': 0.5803868953094536, 'qqp_dev_eval_loss': 2.207404136657715, 'qqp_dev_eval_acc': 0.75, 'qqp_dev_eval_f1': 0.7647058823529411, 'qqp_dev_eval_acc_and_f1': 0.7573529411764706, 'qqp_test_eval_loss': 3.6355888843536377, 'qqp_test_eval_acc': 0.612540192926045, 'qqp_test_eval_f1': 0.5482335976928623, 'qqp_test_eval_acc_and_f1': 0.5803868953094536, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16-prompt-13-roberta-large-7342', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_14-21-50_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-13-roberta-large-7342', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias_eval_loss': 2.1858901977539062, 'sts-b_dev_bias_eval_pearson': 0.8158397555651915, 'sts-b_dev_bias_eval_spearmanr': 0.8160963934463519, 'sts-b_dev_bias_eval_corr': 0.8159680745057717, 'sts-b_test_bias_eval_loss': 2.17995285987854, 'sts-b_test_bias_eval_pearson': 0.6811779494110054, 'sts-b_test_bias_eval_spearmanr': 0.6829110609009515, 'sts-b_test_bias_eval_corr': 0.6820445051559785, 'sts-b_dev_eval_loss': 2.1858901977539062, 'sts-b_dev_eval_pearson': 0.8158397555651915, 'sts-b_dev_eval_spearmanr': 0.8160963934463519, 'sts-b_dev_eval_corr': 0.8159680745057717, 'sts-b_test_eval_loss': 2.17995285987854, 'sts-b_test_eval_pearson': 0.6811779494110054, 'sts-b_test_eval_spearmanr': 0.6829110609009515, 'sts-b_test_eval_corr': 0.6820445051559785, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16--13-roberta-large-964', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_14-38-15_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--13-roberta-large-964', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias_eval_loss': 0.4350975751876831, 'sst-2_dev_prompt,bias_eval_acc': 0.9375, 'sst-2_test_prompt,bias_eval_loss': 0.49637851119041443, 'sst-2_test_prompt,bias_eval_acc': 0.9151376146788991, 'sst-2_dev_eval_loss': 0.4350975751876831, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.49637851119041443, 'sst-2_test_eval_acc': 0.9151376146788991, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-26210', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_14-44-15_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-26210', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias,adapter_eval_loss': 5.911172389984131, 'rte_dev_bias,adapter_eval_acc': 0.53125, 'rte_test_bias,adapter_eval_loss': 5.419849395751953, 'rte_test_bias,adapter_eval_acc': 0.5379061371841155, 'rte_dev_eval_loss': 5.911172389984131, 'rte_dev_eval_acc': 0.53125, 'rte_test_eval_loss': 5.419849395751953, 'rte_test_eval_acc': 0.5379061371841155, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--13-roberta-large-2447', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_14-42-43_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--13-roberta-large-2447', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias,adapter_eval_loss': 0.6954869031906128, 'cola_dev_bias,adapter_eval_mcc': 0.0, 'cola_test_bias,adapter_eval_loss': 0.6692713499069214, 'cola_test_bias,adapter_eval_mcc': 0.0, 'cola_dev_eval_loss': 0.6954869031906128, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.6692713499069214, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--13-roberta-large-4681', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_14-39-10_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-4681', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias,adapter_eval_loss': 1.2794725894927979, 'qnli_dev_bias,adapter_eval_acc': 0.75, 'qnli_test_bias,adapter_eval_loss': 1.8979490995407104, 'qnli_test_bias,adapter_eval_acc': 0.6673988650924401, 'qnli_dev_eval_loss': 1.2794725894927979, 'qnli_dev_eval_acc': 0.75, 'qnli_test_eval_loss': 1.8979490995407104, 'qnli_test_eval_acc': 0.6673988650924401, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--13-roberta-large-23557', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_14-45-56_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--13-roberta-large-23557', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias,adapter_eval_loss': 2.9575111865997314, 'mrpc_dev_prompt,bias,adapter_eval_acc': 0.5625, 'mrpc_dev_prompt,bias,adapter_eval_f1': 0.5333333333333333, 'mrpc_dev_prompt,bias,adapter_eval_acc_and_f1': 0.5479166666666666, 'mrpc_test_prompt,bias,adapter_eval_loss': 4.106495380401611, 'mrpc_test_prompt,bias,adapter_eval_acc': 0.41911764705882354, 'mrpc_test_prompt,bias,adapter_eval_f1': 0.46258503401360546, 'mrpc_test_prompt,bias,adapter_eval_acc_and_f1': 0.4408513405362145, 'mrpc_dev_eval_loss': 2.9575111865997314, 'mrpc_dev_eval_acc': 0.5625, 'mrpc_dev_eval_f1': 0.5333333333333333, 'mrpc_dev_eval_acc_and_f1': 0.5479166666666666, 'mrpc_test_eval_loss': 4.106495380401611, 'mrpc_test_eval_acc': 0.41911764705882354, 'mrpc_test_eval_f1': 0.46258503401360546, 'mrpc_test_eval_acc_and_f1': 0.4408513405362145, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-13-roberta-large-19914', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_14-47-54_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-13-roberta-large-19914', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_adapter_eval_loss': 1.1457242965698242, 'mnli_dev_adapter_eval_mnli/acc': 0.3333333333333333, 'mnli_test_adapter_eval_loss': 1.132319450378418, 'mnli_test_adapter_eval_mnli/acc': 0.3544574630667346, 'mnli-mm_test_adapter_eval_loss': 1.1330446004867554, 'mnli-mm_test_adapter_eval_mnli-mm/acc': 0.3522172497965826, 'mnli_dev_eval_loss': 1.1457242965698242, 'mnli_dev_eval_mnli/acc': 0.3333333333333333, 'mnli_test_eval_loss': 1.132319450378418, 'mnli_test_eval_mnli/acc': 0.3544574630667346, 'mnli-mm_test_eval_loss': 1.1330446004867554, 'mnli-mm_test_eval_mnli-mm/acc': 0.3522172497965826, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--13-roberta-large-8053', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_14-49-49_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--13-roberta-large-8053', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias_eval_loss': 2.1765048503875732, 'sts-b_dev_bias_eval_pearson': 0.8809521178727295, 'sts-b_dev_bias_eval_spearmanr': 0.8651503639664275, 'sts-b_dev_bias_eval_corr': 0.8730512409195785, 'sts-b_test_bias_eval_loss': 2.1670424938201904, 'sts-b_test_bias_eval_pearson': 0.7775864829670867, 'sts-b_test_bias_eval_spearmanr': 0.7785111733798662, 'sts-b_test_bias_eval_corr': 0.7780488281734764, 'sts-b_dev_eval_loss': 2.1765048503875732, 'sts-b_dev_eval_pearson': 0.8809521178727295, 'sts-b_dev_eval_spearmanr': 0.8651503639664275, 'sts-b_dev_eval_corr': 0.8730512409195785, 'sts-b_test_eval_loss': 2.1670424938201904, 'sts-b_test_eval_pearson': 0.7775864829670867, 'sts-b_test_eval_spearmanr': 0.7785111733798662, 'sts-b_test_eval_corr': 0.7780488281734764, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16--13-roberta-large-911', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_14-56-28_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--13-roberta-large-911', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias_eval_loss': 0.2626199722290039, 'sst-2_dev_prompt,bias_eval_acc': 0.9375, 'sst-2_test_prompt,bias_eval_loss': 0.3313649296760559, 'sst-2_test_prompt,bias_eval_acc': 0.9162844036697247, 'sst-2_dev_eval_loss': 0.2626199722290039, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.3313649296760559, 'sst-2_test_eval_acc': 0.9162844036697247, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-17026', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_15-01-03_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-17026', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias,adapter_eval_loss': 4.65617561340332, 'rte_dev_bias,adapter_eval_acc': 0.71875, 'rte_test_bias,adapter_eval_loss': 3.399746894836426, 'rte_test_bias,adapter_eval_acc': 0.7184115523465704, 'rte_dev_eval_loss': 4.65617561340332, 'rte_dev_eval_acc': 0.71875, 'rte_test_eval_loss': 3.399746894836426, 'rte_test_eval_acc': 0.7184115523465704, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--13-roberta-large-31332', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_15-02-04_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--13-roberta-large-31332', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias,adapter_eval_loss': 0.7026509046554565, 'qnli_dev_prompt,bias,adapter_eval_acc': 0.5, 'qnli_test_prompt,bias,adapter_eval_loss': 0.7011600732803345, 'qnli_test_prompt,bias,adapter_eval_acc': 0.5053999633900788, 'qnli_dev_eval_loss': 0.7026509046554565, 'qnli_dev_eval_acc': 0.5, 'qnli_test_eval_loss': 0.7011600732803345, 'qnli_test_eval_acc': 0.5053999633900788, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-13-roberta-large-2995', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_15-05-05_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-13-roberta-large-2995', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias,adapter_eval_loss': 5.505136013031006, 'cola_dev_bias,adapter_eval_mcc': 0.25819888974716115, 'cola_test_bias,adapter_eval_loss': 9.763354301452637, 'cola_test_bias,adapter_eval_mcc': 0.04811977322378962, 'cola_dev_eval_loss': 5.505136013031006, 'cola_dev_eval_mcc': 0.25819888974716115, 'cola_test_eval_loss': 9.763354301452637, 'cola_test_eval_mcc': 0.04811977322378962, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--13-roberta-large-29314', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_15-02-09_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-29314', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,adapter_eval_loss': 3.5808486938476562, 'qqp_dev_prompt,adapter_eval_acc': 0.75, 'qqp_dev_prompt,adapter_eval_f1': 0.7777777777777777, 'qqp_dev_prompt,adapter_eval_acc_and_f1': 0.7638888888888888, 'qqp_test_prompt,adapter_eval_loss': 4.391962051391602, 'qqp_test_prompt,adapter_eval_acc': 0.6362602028196883, 'qqp_test_prompt,adapter_eval_f1': 0.627205435003042, 'qqp_test_prompt,adapter_eval_acc_and_f1': 0.6317328189113651, 'qqp_dev_eval_loss': 3.5808486938476562, 'qqp_dev_eval_acc': 0.75, 'qqp_dev_eval_f1': 0.7777777777777777, 'qqp_dev_eval_acc_and_f1': 0.7638888888888888, 'qqp_test_eval_loss': 4.391962051391602, 'qqp_test_eval_acc': 0.6362602028196883, 'qqp_test_eval_f1': 0.627205435003042, 'qqp_test_eval_acc_and_f1': 0.6317328189113651, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16-prompt-13-roberta-large-16825', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_14-53-51_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-13-roberta-large-16825', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_adapter_eval_loss': 3.83081316947937, 'mnli_dev_adapter_eval_mnli/acc': 0.625, 'mnli_test_adapter_eval_loss': 4.415926456451416, 'mnli_test_adapter_eval_mnli/acc': 0.5484462557310239, 'mnli-mm_test_adapter_eval_loss': 3.975384473800659, 'mnli-mm_test_adapter_eval_mnli-mm/acc': 0.5728234336859235, 'mnli_dev_eval_loss': 3.83081316947937, 'mnli_dev_eval_mnli/acc': 0.625, 'mnli_test_eval_loss': 4.415926456451416, 'mnli_test_eval_mnli/acc': 0.5484462557310239, 'mnli-mm_test_eval_loss': 3.975384473800659, 'mnli-mm_test_eval_mnli-mm/acc': 0.5728234336859235, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--13-roberta-large-11590', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_15-10-05_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--13-roberta-large-11590', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias_eval_loss': 2.1825931072235107, 'sts-b_dev_bias_eval_pearson': 0.8269576685204534, 'sts-b_dev_bias_eval_spearmanr': 0.8127893841978076, 'sts-b_dev_bias_eval_corr': 0.8198735263591305, 'sts-b_test_bias_eval_loss': 2.1743836402893066, 'sts-b_test_bias_eval_pearson': 0.7369412024223122, 'sts-b_test_bias_eval_spearmanr': 0.736493350553593, 'sts-b_test_bias_eval_corr': 0.7367172764879526, 'sts-b_dev_eval_loss': 2.1825931072235107, 'sts-b_dev_eval_pearson': 0.8269576685204534, 'sts-b_dev_eval_spearmanr': 0.8127893841978076, 'sts-b_dev_eval_corr': 0.8198735263591305, 'sts-b_test_eval_loss': 2.1743836402893066, 'sts-b_test_eval_pearson': 0.7369412024223122, 'sts-b_test_eval_spearmanr': 0.736493350553593, 'sts-b_test_eval_corr': 0.7367172764879526, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16--13-roberta-large-10196', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_15-14-17_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--13-roberta-large-10196', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias,adapter_eval_loss': 0.6575869917869568, 'sst-2_dev_bias,adapter_eval_acc': 0.9375, 'sst-2_test_bias,adapter_eval_loss': 1.7764678001403809, 'sst-2_test_bias,adapter_eval_acc': 0.875, 'sst-2_dev_eval_loss': 0.6575869917869568, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 1.7764678001403809, 'sst-2_test_eval_acc': 0.875, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--13-roberta-large-30918', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_15-18-01_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-30918', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias,adapter_eval_loss': 2.4237470626831055, 'rte_dev_bias,adapter_eval_acc': 0.78125, 'rte_test_bias,adapter_eval_loss': 2.8735787868499756, 'rte_test_bias,adapter_eval_acc': 0.6642599277978339, 'rte_dev_eval_loss': 2.4237470626831055, 'rte_dev_eval_acc': 0.78125, 'rte_test_eval_loss': 2.8735787868499756, 'rte_test_eval_acc': 0.6642599277978339, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--13-roberta-large-11361', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_15-22-11_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--13-roberta-large-11361', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias,adapter_eval_loss': 1.1618332862854004, 'qnli_dev_prompt,bias,adapter_eval_acc': 0.8125, 'qnli_test_prompt,bias,adapter_eval_loss': 1.7581696510314941, 'qnli_test_prompt,bias,adapter_eval_acc': 0.7536152297272561, 'qnli_dev_eval_loss': 1.1618332862854004, 'qnli_dev_eval_acc': 0.8125, 'qnli_test_eval_loss': 1.7581696510314941, 'qnli_test_eval_acc': 0.7536152297272561, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-13-roberta-large-3071', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_15-24-40_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-13-roberta-large-3071', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias,adapter_eval_loss': 5.258323669433594, 'cola_dev_bias,adapter_eval_mcc': 0.13483997249264842, 'cola_test_bias,adapter_eval_loss': 4.645709037780762, 'cola_test_bias,adapter_eval_mcc': 0.06682377955918699, 'cola_dev_eval_loss': 5.258323669433594, 'cola_dev_eval_mcc': 0.13483997249264842, 'cola_test_eval_loss': 4.645709037780762, 'cola_test_eval_mcc': 0.06682377955918699, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--13-roberta-large-3294', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_15-26-00_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-3294', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias_eval_loss': 2.1881752014160156, 'sts-b_dev_bias_eval_pearson': 0.7972547447626348, 'sts-b_dev_bias_eval_spearmanr': 0.8074614248529304, 'sts-b_dev_bias_eval_corr': 0.8023580848077826, 'sts-b_test_bias_eval_loss': 2.1928458213806152, 'sts-b_test_bias_eval_pearson': 0.6251637698606634, 'sts-b_test_bias_eval_spearmanr': 0.6253288096599646, 'sts-b_test_bias_eval_corr': 0.6252462897603139, 'sts-b_dev_eval_loss': 2.1881752014160156, 'sts-b_dev_eval_pearson': 0.7972547447626348, 'sts-b_dev_eval_spearmanr': 0.8074614248529304, 'sts-b_dev_eval_corr': 0.8023580848077826, 'sts-b_test_eval_loss': 2.1928458213806152, 'sts-b_test_eval_pearson': 0.6251637698606634, 'sts-b_test_eval_spearmanr': 0.6253288096599646, 'sts-b_test_eval_corr': 0.6252462897603139, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16--13-roberta-large-19457', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_15-31-43_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--13-roberta-large-19457', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_adapter_eval_loss': 2.688945770263672, 'mnli_dev_adapter_eval_mnli/acc': 0.4791666666666667, 'mnli_test_adapter_eval_loss': 2.435786247253418, 'mnli_test_adapter_eval_mnli/acc': 0.48201732042791645, 'mnli-mm_test_adapter_eval_loss': 2.311114549636841, 'mnli-mm_test_adapter_eval_mnli-mm/acc': 0.49410089503661514, 'mnli_dev_eval_loss': 2.688945770263672, 'mnli_dev_eval_mnli/acc': 0.4791666666666667, 'mnli_test_eval_loss': 2.435786247253418, 'mnli_test_eval_mnli/acc': 0.48201732042791645, 'mnli-mm_test_eval_loss': 2.311114549636841, 'mnli-mm_test_eval_mnli-mm/acc': 0.49410089503661514, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--13-roberta-large-11114', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_15-31-25_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--13-roberta-large-11114', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,adapter_eval_loss': 3.6732845306396484, 'qqp_dev_prompt,adapter_eval_acc': 0.6875, 'qqp_dev_prompt,adapter_eval_f1': 0.7222222222222223, 'qqp_dev_prompt,adapter_eval_acc_and_f1': 0.7048611111111112, 'qqp_test_prompt,adapter_eval_loss': 3.2149317264556885, 'qqp_test_prompt,adapter_eval_acc': 0.6600791491466733, 'qqp_test_prompt,adapter_eval_f1': 0.6424166731714932, 'qqp_test_prompt,adapter_eval_acc_and_f1': 0.6512479111590832, 'qqp_dev_eval_loss': 3.6732845306396484, 'qqp_dev_eval_acc': 0.6875, 'qqp_dev_eval_f1': 0.7222222222222223, 'qqp_dev_eval_acc_and_f1': 0.7048611111111112, 'qqp_test_eval_loss': 3.2149317264556885, 'qqp_test_eval_acc': 0.6600791491466733, 'qqp_test_eval_f1': 0.6424166731714932, 'qqp_test_eval_acc_and_f1': 0.6512479111590832, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16-prompt-13-roberta-large-21177', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_15-26-07_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-13-roberta-large-21177', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias,adapter_eval_loss': 0.8192824125289917, 'sst-2_dev_bias,adapter_eval_acc': 0.9375, 'sst-2_test_bias,adapter_eval_loss': 1.0889872312545776, 'sst-2_test_bias,adapter_eval_acc': 0.9025229357798165, 'sst-2_dev_eval_loss': 0.8192824125289917, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 1.0889872312545776, 'sst-2_test_eval_acc': 0.9025229357798165, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--13-roberta-large-10266', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_15-38-21_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-10266', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias,adapter_eval_loss': 1.5637357234954834, 'rte_dev_bias,adapter_eval_acc': 0.71875, 'rte_test_bias,adapter_eval_loss': 1.6181081533432007, 'rte_test_bias,adapter_eval_acc': 0.6714801444043321, 'rte_dev_eval_loss': 1.5637357234954834, 'rte_dev_eval_acc': 0.71875, 'rte_test_eval_loss': 1.6181081533432007, 'rte_test_eval_acc': 0.6714801444043321, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--13-roberta-large-3360', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_15-42-00_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--13-roberta-large-3360', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias,adapter_eval_loss': 0.5983679294586182, 'qnli_dev_prompt,bias,adapter_eval_acc': 0.875, 'qnli_test_prompt,bias,adapter_eval_loss': 1.4548382759094238, 'qnli_test_prompt,bias,adapter_eval_acc': 0.7224967966318873, 'qnli_dev_eval_loss': 0.5983679294586182, 'qnli_dev_eval_acc': 0.875, 'qnli_test_eval_loss': 1.4548382759094238, 'qnli_test_eval_acc': 0.7224967966318873, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-13-roberta-large-31830', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_15-43-50_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-13-roberta-large-31830', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias_eval_loss': 2.221234083175659, 'sts-b_dev_bias_eval_pearson': 0.2883044838657143, 'sts-b_dev_bias_eval_spearmanr': 0.2585453903965744, 'sts-b_dev_bias_eval_corr': 0.27342493713114435, 'sts-b_test_bias_eval_loss': 2.214287519454956, 'sts-b_test_bias_eval_pearson': 0.06825315540074013, 'sts-b_test_bias_eval_spearmanr': 0.05236443763703569, 'sts-b_test_bias_eval_corr': 0.06030879651888791, 'sts-b_dev_eval_loss': 2.221234083175659, 'sts-b_dev_eval_pearson': 0.2883044838657143, 'sts-b_dev_eval_spearmanr': 0.2585453903965744, 'sts-b_dev_eval_corr': 0.27342493713114435, 'sts-b_test_eval_loss': 2.214287519454956, 'sts-b_test_eval_pearson': 0.06825315540074013, 'sts-b_test_eval_spearmanr': 0.05236443763703569, 'sts-b_test_eval_corr': 0.06030879651888791, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16--21-roberta-large-1850', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_15-50-44_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 21, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--21-roberta-large-1850', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-21', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias,adapter_eval_loss': 4.256701469421387, 'cola_dev_bias,adapter_eval_mcc': 0.31311214554257477, 'cola_test_bias,adapter_eval_loss': 6.190070152282715, 'cola_test_bias,adapter_eval_mcc': 0.06740144851074882, 'cola_dev_eval_loss': 4.256701469421387, 'cola_dev_eval_mcc': 0.31311214554257477, 'cola_test_eval_loss': 6.190070152282715, 'cola_test_eval_mcc': 0.06740144851074882, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--13-roberta-large-16010', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_15-46-27_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--13-roberta-large-16010', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_adapter_eval_loss': 2.0640480518341064, 'mnli_dev_adapter_eval_mnli/acc': 0.4583333333333333, 'mnli_test_adapter_eval_loss': 1.9293324947357178, 'mnli_test_adapter_eval_mnli/acc': 0.4381049414161997, 'mnli-mm_test_adapter_eval_loss': 1.8539091348648071, 'mnli-mm_test_adapter_eval_mnli-mm/acc': 0.4416192026037429, 'mnli_dev_eval_loss': 2.0640480518341064, 'mnli_dev_eval_mnli/acc': 0.4583333333333333, 'mnli_test_eval_loss': 1.9293324947357178, 'mnli_test_eval_mnli/acc': 0.4381049414161997, 'mnli-mm_test_eval_loss': 1.8539091348648071, 'mnli-mm_test_eval_mnli-mm/acc': 0.4416192026037429, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--13-roberta-large-26723', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_15-52-33_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--13-roberta-large-26723', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias,adapter_eval_loss': 0.7855944037437439, 'sst-2_dev_bias,adapter_eval_acc': 0.9375, 'sst-2_test_bias,adapter_eval_loss': 0.7324950098991394, 'sst-2_test_bias,adapter_eval_acc': 0.9208715596330275, 'sst-2_dev_eval_loss': 0.7855944037437439, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.7324950098991394, 'sst-2_test_eval_acc': 0.9208715596330275, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--13-roberta-large-25475', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_15-59-04_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-25475', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias,adapter_eval_loss': 1.1205283403396606, 'qnli_dev_prompt,bias,adapter_eval_acc': 0.8125, 'qnli_test_prompt,bias,adapter_eval_loss': 1.757680892944336, 'qnli_test_prompt,bias,adapter_eval_acc': 0.6990664470071389, 'qnli_dev_eval_loss': 1.1205283403396606, 'qnli_dev_eval_acc': 0.8125, 'qnli_test_eval_loss': 1.757680892944336, 'qnli_test_eval_acc': 0.6990664470071389, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-13-roberta-large-2151', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_16-02-31_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-13-roberta-large-2151', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias,adapter_eval_loss': 4.7918806076049805, 'rte_dev_prompt,bias,adapter_eval_acc': 0.53125, 'rte_test_prompt,bias,adapter_eval_loss': 4.815296173095703, 'rte_test_prompt,bias,adapter_eval_acc': 0.5126353790613718, 'rte_dev_eval_loss': 4.7918806076049805, 'rte_dev_eval_acc': 0.53125, 'rte_test_eval_loss': 4.815296173095703, 'rte_test_eval_acc': 0.5126353790613718, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-13-roberta-large-24262', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_16-01-07_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-13-roberta-large-24262', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,adapter_eval_loss': 2.386166572570801, 'qqp_dev_prompt,adapter_eval_acc': 0.75, 'qqp_dev_prompt,adapter_eval_f1': 0.7777777777777777, 'qqp_dev_prompt,adapter_eval_acc_and_f1': 0.7638888888888888, 'qqp_test_prompt,adapter_eval_loss': 2.5197577476501465, 'qqp_test_prompt,adapter_eval_acc': 0.694607964382884, 'qqp_test_prompt,adapter_eval_f1': 0.6646203992937662, 'qqp_test_prompt,adapter_eval_acc_and_f1': 0.679614181838325, 'qqp_dev_eval_loss': 2.386166572570801, 'qqp_dev_eval_acc': 0.75, 'qqp_dev_eval_f1': 0.7777777777777777, 'qqp_dev_eval_acc_and_f1': 0.7638888888888888, 'qqp_test_eval_loss': 2.5197577476501465, 'qqp_test_eval_acc': 0.694607964382884, 'qqp_test_eval_f1': 0.6646203992937662, 'qqp_test_eval_acc_and_f1': 0.679614181838325, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16-prompt-13-roberta-large-6914', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_15-58-38_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-13-roberta-large-6914', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_adapter_eval_loss': 2.2445852756500244, 'sts-b_dev_adapter_eval_pearson': 0.3146127373866358, 'sts-b_dev_adapter_eval_spearmanr': 0.21643271628932614, 'sts-b_dev_adapter_eval_corr': 0.26552272683798095, 'sts-b_test_adapter_eval_loss': 2.2157554626464844, 'sts-b_test_adapter_eval_pearson': -0.0390698413362068, 'sts-b_test_adapter_eval_spearmanr': -0.04366465099365894, 'sts-b_test_adapter_eval_corr': -0.04136724616493287, 'sts-b_dev_eval_loss': 2.2445852756500244, 'sts-b_dev_eval_pearson': 0.3146127373866358, 'sts-b_dev_eval_spearmanr': 0.21643271628932614, 'sts-b_dev_eval_corr': 0.26552272683798095, 'sts-b_test_eval_loss': 2.2157554626464844, 'sts-b_test_eval_pearson': -0.0390698413362068, 'sts-b_test_eval_spearmanr': -0.04366465099365894, 'sts-b_test_eval_corr': -0.04136724616493287, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--13-roberta-large-25310', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_16-14-10_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--13-roberta-large-25310', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias,adapter_eval_loss': 0.6992349624633789, 'cola_dev_prompt,bias,adapter_eval_mcc': 0.0, 'cola_test_prompt,bias,adapter_eval_loss': 0.6550722122192383, 'cola_test_prompt,bias,adapter_eval_mcc': 0.0, 'cola_dev_eval_loss': 0.6992349624633789, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.6550722122192383, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-20690', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_16-15-25_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-20690', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias,adapter_eval_loss': 0.2997276484966278, 'sst-2_dev_bias,adapter_eval_acc': 0.96875, 'sst-2_test_bias,adapter_eval_loss': 0.45143958926200867, 'sst-2_test_bias,adapter_eval_acc': 0.9357798165137615, 'sst-2_dev_eval_loss': 0.2997276484966278, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.45143958926200867, 'sst-2_test_eval_acc': 0.9357798165137615, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--13-roberta-large-13971', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_16-19-00_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--13-roberta-large-13971', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,adapter_eval_loss': 6.544997692108154, 'mnli_dev_prompt,adapter_eval_mnli/acc': 0.5625, 'mnli_test_prompt,adapter_eval_loss': 6.6345109939575195, 'mnli_test_prompt,adapter_eval_mnli/acc': 0.5343861436576668, 'mnli-mm_test_prompt,adapter_eval_loss': 6.172625541687012, 'mnli-mm_test_prompt,adapter_eval_mnli-mm/acc': 0.5557363710333605, 'mnli_dev_eval_loss': 6.544997692108154, 'mnli_dev_eval_mnli/acc': 0.5625, 'mnli_test_eval_loss': 6.6345109939575195, 'mnli_test_eval_mnli/acc': 0.5343861436576668, 'mnli-mm_test_eval_loss': 6.172625541687012, 'mnli-mm_test_eval_mnli-mm/acc': 0.5557363710333605, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-29696', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_16-17-03_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-29696', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias,adapter_eval_loss': 3.4413890838623047, 'rte_dev_prompt,bias,adapter_eval_acc': 0.75, 'rte_test_prompt,bias,adapter_eval_loss': 3.873054265975952, 'rte_test_prompt,bias,adapter_eval_acc': 0.7184115523465704, 'rte_dev_eval_loss': 3.4413890838623047, 'rte_dev_eval_acc': 0.75, 'rte_test_eval_loss': 3.873054265975952, 'rte_test_eval_acc': 0.7184115523465704, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-13-roberta-large-40', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_16-22-33_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-13-roberta-large-40', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_adapter_eval_loss': 2.182338237762451, 'sts-b_dev_adapter_eval_pearson': 0.852316289133321, 'sts-b_dev_adapter_eval_spearmanr': 0.8164638389184123, 'sts-b_dev_adapter_eval_corr': 0.8343900640258667, 'sts-b_test_adapter_eval_loss': 2.174107789993286, 'sts-b_test_adapter_eval_pearson': 0.7067577769995923, 'sts-b_test_adapter_eval_spearmanr': 0.708812897522335, 'sts-b_test_adapter_eval_corr': 0.7077853372609637, 'sts-b_dev_eval_loss': 2.182338237762451, 'sts-b_dev_eval_pearson': 0.852316289133321, 'sts-b_dev_eval_spearmanr': 0.8164638389184123, 'sts-b_dev_eval_corr': 0.8343900640258667, 'sts-b_test_eval_loss': 2.174107789993286, 'sts-b_test_eval_pearson': 0.7067577769995923, 'sts-b_test_eval_spearmanr': 0.708812897522335, 'sts-b_test_eval_corr': 0.7077853372609637, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--13-roberta-large-27007', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_16-31-22_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--13-roberta-large-27007', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,bias_eval_loss': 2.936774492263794, 'qqp_dev_prompt,bias_eval_acc': 0.71875, 'qqp_dev_prompt,bias_eval_f1': 0.7567567567567567, 'qqp_dev_prompt,bias_eval_acc_and_f1': 0.7377533783783783, 'qqp_test_prompt,bias_eval_loss': 2.8982903957366943, 'qqp_test_prompt,bias_eval_acc': 0.7170912688597576, 'qqp_test_prompt,bias_eval_f1': 0.6813217430067982, 'qqp_test_prompt,bias_eval_acc_and_f1': 0.6992065059332779, 'qqp_dev_eval_loss': 2.936774492263794, 'qqp_dev_eval_acc': 0.71875, 'qqp_dev_eval_f1': 0.7567567567567567, 'qqp_dev_eval_acc_and_f1': 0.7377533783783783, 'qqp_test_eval_loss': 2.8982903957366943, 'qqp_test_eval_acc': 0.7170912688597576, 'qqp_test_eval_f1': 0.6813217430067982, 'qqp_test_eval_acc_and_f1': 0.6992065059332779, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-13-roberta-large-12552', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_16-31-22_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-13-roberta-large-12552', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias,adapter_eval_loss': 4.7751946449279785, 'cola_dev_prompt,bias,adapter_eval_mcc': 0.16012815380508713, 'cola_test_prompt,bias,adapter_eval_loss': 6.472034454345703, 'cola_test_prompt,bias,adapter_eval_mcc': 0.1405957573156261, 'cola_dev_eval_loss': 4.7751946449279785, 'cola_dev_eval_mcc': 0.16012815380508713, 'cola_test_eval_loss': 6.472034454345703, 'cola_test_eval_mcc': 0.1405957573156261, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-19746', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_16-34-30_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-19746', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias,adapter_eval_loss': 0.6985783576965332, 'sst-2_dev_prompt,bias,adapter_eval_acc': 0.5, 'sst-2_test_prompt,bias,adapter_eval_loss': 0.6966849565505981, 'sst-2_test_prompt,bias,adapter_eval_acc': 0.5091743119266054, 'sst-2_dev_eval_loss': 0.6985783576965332, 'sst-2_dev_eval_acc': 0.5, 'sst-2_test_eval_loss': 0.6966849565505981, 'sst-2_test_eval_acc': 0.5091743119266054, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-15915', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_16-37-55_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-15915', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_adapter_eval_loss': 2.1830086708068848, 'sts-b_dev_adapter_eval_pearson': 0.8268510936764322, 'sts-b_dev_adapter_eval_spearmanr': 0.820689461847108, 'sts-b_dev_adapter_eval_corr': 0.8237702777617701, 'sts-b_test_adapter_eval_loss': 2.174307346343994, 'sts-b_test_adapter_eval_pearson': 0.715880778920952, 'sts-b_test_adapter_eval_spearmanr': 0.7159186564976346, 'sts-b_test_adapter_eval_corr': 0.7158997177092934, 'sts-b_dev_eval_loss': 2.1830086708068848, 'sts-b_dev_eval_pearson': 0.8268510936764322, 'sts-b_dev_eval_spearmanr': 0.820689461847108, 'sts-b_dev_eval_corr': 0.8237702777617701, 'sts-b_test_eval_loss': 2.174307346343994, 'sts-b_test_eval_pearson': 0.715880778920952, 'sts-b_test_eval_spearmanr': 0.7159186564976346, 'sts-b_test_eval_corr': 0.7158997177092934, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--13-roberta-large-19863', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_16-44-51_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--13-roberta-large-19863', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,adapter_eval_loss': 4.03783655166626, 'mnli_dev_prompt,adapter_eval_mnli/acc': 0.625, 'mnli_test_prompt,adapter_eval_loss': 4.023741245269775, 'mnli_test_prompt,adapter_eval_mnli/acc': 0.5713703515028018, 'mnli-mm_test_prompt,adapter_eval_loss': 3.636873722076416, 'mnli-mm_test_prompt,adapter_eval_mnli-mm/acc': 0.5871643612693247, 'mnli_dev_eval_loss': 4.03783655166626, 'mnli_dev_eval_mnli/acc': 0.625, 'mnli_test_eval_loss': 4.023741245269775, 'mnli_test_eval_mnli/acc': 0.5713703515028018, 'mnli-mm_test_eval_loss': 3.636873722076416, 'mnli-mm_test_eval_mnli-mm/acc': 0.5871643612693247, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-3001', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_16-39-03_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-3001', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias,adapter_eval_loss': 2.4620583057403564, 'rte_dev_prompt,bias,adapter_eval_acc': 0.71875, 'rte_test_prompt,bias,adapter_eval_loss': 2.79994535446167, 'rte_test_prompt,bias,adapter_eval_acc': 0.6534296028880866, 'rte_dev_eval_loss': 2.4620583057403564, 'rte_dev_eval_acc': 0.71875, 'rte_test_eval_loss': 2.79994535446167, 'rte_test_eval_acc': 0.6534296028880866, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-13-roberta-large-20265', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_16-43-19_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-13-roberta-large-20265', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,bias_eval_loss': 1.8354294300079346, 'qqp_dev_prompt,bias_eval_acc': 0.78125, 'qqp_dev_prompt,bias_eval_f1': 0.7999999999999999, 'qqp_dev_prompt,bias_eval_acc_and_f1': 0.7906249999999999, 'qqp_test_prompt,bias_eval_loss': 2.6259829998016357, 'qqp_test_prompt,bias_eval_acc': 0.6960672767746723, 'qqp_test_prompt,bias_eval_f1': 0.6736601689063578, 'qqp_test_prompt,bias_eval_acc_and_f1': 0.684863722840515, 'qqp_dev_eval_loss': 1.8354294300079346, 'qqp_dev_eval_acc': 0.78125, 'qqp_dev_eval_f1': 0.7999999999999999, 'qqp_dev_eval_acc_and_f1': 0.7906249999999999, 'qqp_test_eval_loss': 2.6259829998016357, 'qqp_test_eval_acc': 0.6960672767746723, 'qqp_test_eval_f1': 0.6736601689063578, 'qqp_test_eval_acc_and_f1': 0.684863722840515, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-13-roberta-large-11534', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_16-48-30_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-13-roberta-large-11534', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias,adapter_eval_loss': 7.070357322692871, 'cola_dev_prompt,bias,adapter_eval_mcc': 0.1889822365046136, 'cola_test_prompt,bias,adapter_eval_loss': 5.339484214782715, 'cola_test_prompt,bias,adapter_eval_mcc': 0.06856916002686159, 'cola_dev_eval_loss': 7.070357322692871, 'cola_dev_eval_mcc': 0.1889822365046136, 'cola_test_eval_loss': 5.339484214782715, 'cola_test_eval_mcc': 0.06856916002686159, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-7503', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_16-50-15_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-7503', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_adapter_eval_loss': 2.1893715858459473, 'sts-b_dev_adapter_eval_pearson': 0.7789724632618873, 'sts-b_dev_adapter_eval_spearmanr': 0.8087474840051421, 'sts-b_dev_adapter_eval_corr': 0.7938599736335147, 'sts-b_test_adapter_eval_loss': 2.187791347503662, 'sts-b_test_adapter_eval_pearson': 0.5953811799676778, 'sts-b_test_adapter_eval_spearmanr': 0.5970568689717286, 'sts-b_test_adapter_eval_corr': 0.5962190244697032, 'sts-b_dev_eval_loss': 2.1893715858459473, 'sts-b_dev_eval_pearson': 0.7789724632618873, 'sts-b_dev_eval_spearmanr': 0.8087474840051421, 'sts-b_dev_eval_corr': 0.7938599736335147, 'sts-b_test_eval_loss': 2.187791347503662, 'sts-b_test_eval_pearson': 0.5953811799676778, 'sts-b_test_eval_spearmanr': 0.5970568689717286, 'sts-b_test_eval_corr': 0.5962190244697032, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--13-roberta-large-7207', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_16-58-25_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--13-roberta-large-7207', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias,adapter_eval_loss': 0.6836496591567993, 'sst-2_dev_prompt,bias,adapter_eval_acc': 0.9375, 'sst-2_test_prompt,bias,adapter_eval_loss': 0.8893203735351562, 'sst-2_test_prompt,bias,adapter_eval_acc': 0.908256880733945, 'sst-2_dev_eval_loss': 0.6836496591567993, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.8893203735351562, 'sst-2_test_eval_acc': 0.908256880733945, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-31434', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_16-54-45_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-31434', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,adapter_eval_loss': 3.8275511264801025, 'mnli_dev_prompt,adapter_eval_mnli/acc': 0.5833333333333334, 'mnli_test_prompt,adapter_eval_loss': 3.695863723754883, 'mnli_test_prompt,adapter_eval_mnli/acc': 0.5719816607233825, 'mnli-mm_test_prompt,adapter_eval_loss': 3.499284505844116, 'mnli-mm_test_prompt,adapter_eval_mnli-mm/acc': 0.5759764035801465, 'mnli_dev_eval_loss': 3.8275511264801025, 'mnli_dev_eval_mnli/acc': 0.5833333333333334, 'mnli_test_eval_loss': 3.695863723754883, 'mnli_test_eval_mnli/acc': 0.5719816607233825, 'mnli-mm_test_eval_loss': 3.499284505844116, 'mnli-mm_test_eval_mnli-mm/acc': 0.5759764035801465, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-28', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_17-01-34_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-28', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias,adapter_eval_loss': 7.299214839935303, 'cola_dev_prompt,bias,adapter_eval_mcc': 0.14433756729740646, 'cola_test_prompt,bias,adapter_eval_loss': 5.307129383087158, 'cola_test_prompt,bias,adapter_eval_mcc': 0.03836210948970893, 'cola_dev_eval_loss': 7.299214839935303, 'cola_dev_eval_mcc': 0.14433756729740646, 'cola_test_eval_loss': 5.307129383087158, 'cola_test_eval_mcc': 0.03836210948970893, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-13-roberta-large-23777', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_17-06-49_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-13-roberta-large-23777', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias,adapter_eval_loss': 1.0718915462493896, 'rte_dev_prompt,bias,adapter_eval_acc': 0.75, 'rte_test_prompt,bias,adapter_eval_loss': 1.3967881202697754, 'rte_test_prompt,bias,adapter_eval_acc': 0.6570397111913358, 'rte_dev_eval_loss': 1.0718915462493896, 'rte_dev_eval_acc': 0.75, 'rte_test_eval_loss': 1.3967881202697754, 'rte_test_eval_acc': 0.6570397111913358, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-13-roberta-large-4390', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_17-04-06_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-13-roberta-large-4390', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_eval_loss': 1.2749302387237549, 'rte_dev_eval_acc': 0.5, 'rte_test_eval_loss': 1.228467345237732, 'rte_test_eval_acc': 0.47653429602888087, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16--13-roberta-large-22973', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_17-24-48_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--13-roberta-large-22973', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': None, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,adapter_eval_loss': 2.240247964859009, 'sts-b_dev_prompt,adapter_eval_pearson': 0.4500835804255618, 'sts-b_dev_prompt,adapter_eval_spearmanr': 0.4276517689261517, 'sts-b_dev_prompt,adapter_eval_corr': 0.43886767467585674, 'sts-b_test_prompt,adapter_eval_loss': 2.2118642330169678, 'sts-b_test_prompt,adapter_eval_pearson': -0.022935879218871257, 'sts-b_test_prompt,adapter_eval_spearmanr': -0.024576042952588275, 'sts-b_test_prompt,adapter_eval_corr': -0.023755961085729766, 'sts-b_dev_eval_loss': 2.240247964859009, 'sts-b_dev_eval_pearson': 0.4500835804255618, 'sts-b_dev_eval_spearmanr': 0.4276517689261517, 'sts-b_dev_eval_corr': 0.43886767467585674, 'sts-b_test_eval_loss': 2.2118642330169678, 'sts-b_test_eval_pearson': -0.022935879218871257, 'sts-b_test_eval_spearmanr': -0.024576042952588275, 'sts-b_test_eval_corr': -0.023755961085729766, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-13-roberta-large-9383', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_17-11-55_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-13-roberta-large-9383', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias,adapter_eval_loss': 0.73671954870224, 'sst-2_dev_prompt,bias,adapter_eval_acc': 0.9375, 'sst-2_test_prompt,bias,adapter_eval_loss': 1.0933775901794434, 'sst-2_test_prompt,bias,adapter_eval_acc': 0.8956422018348624, 'sst-2_dev_eval_loss': 0.73671954870224, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 1.0933775901794434, 'sst-2_test_eval_acc': 0.8956422018348624, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-21363', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_17-12-58_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-21363', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt_eval_loss': 0.8337167501449585, 'rte_dev_prompt_eval_acc': 0.65625, 'rte_test_prompt_eval_loss': 1.110615849494934, 'rte_test_prompt_eval_acc': 0.5018050541516246, 'rte_dev_eval_loss': 0.8337167501449585, 'rte_dev_eval_acc': 0.65625, 'rte_test_eval_loss': 1.110615849494934, 'rte_test_eval_acc': 0.5018050541516246, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-13-roberta-large-4863', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_17-25-19_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-13-roberta-large-4863', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,adapter_eval_loss': 2.1839866638183594, 'sts-b_dev_prompt,adapter_eval_pearson': 0.8611189732969181, 'sts-b_dev_prompt,adapter_eval_spearmanr': 0.8381431217699814, 'sts-b_dev_prompt,adapter_eval_corr': 0.8496310475334498, 'sts-b_test_prompt,adapter_eval_loss': 2.1764180660247803, 'sts-b_test_prompt,adapter_eval_pearson': 0.6923829330832637, 'sts-b_test_prompt,adapter_eval_spearmanr': 0.69611007237785, 'sts-b_test_prompt,adapter_eval_corr': 0.6942465027305569, 'sts-b_dev_eval_loss': 2.1839866638183594, 'sts-b_dev_eval_pearson': 0.8611189732969181, 'sts-b_dev_eval_spearmanr': 0.8381431217699814, 'sts-b_dev_eval_corr': 0.8496310475334498, 'sts-b_test_eval_loss': 2.1764180660247803, 'sts-b_test_eval_pearson': 0.6923829330832637, 'sts-b_test_eval_spearmanr': 0.69611007237785, 'sts-b_test_eval_corr': 0.6942465027305569, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-13-roberta-large-179', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_17-26-22_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-13-roberta-large-179', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias,adapter_eval_loss': 0.45677000284194946, 'sst-2_dev_prompt,bias,adapter_eval_acc': 0.9375, 'sst-2_test_prompt,bias,adapter_eval_loss': 0.5484389066696167, 'sst-2_test_prompt,bias,adapter_eval_acc': 0.9162844036697247, 'sst-2_dev_eval_loss': 0.45677000284194946, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.5484389066696167, 'sst-2_test_eval_acc': 0.9162844036697247, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-13-roberta-large-7835', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_17-29-18_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-13-roberta-large-7835', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,adapter_eval_loss': 3.1242482662200928, 'mnli_dev_prompt,adapter_eval_mnli/acc': 0.5625, 'mnli_test_prompt,adapter_eval_loss': 2.6247024536132812, 'mnli_test_prompt,adapter_eval_mnli/acc': 0.5725929699439634, 'mnli-mm_test_prompt,adapter_eval_loss': 2.5024333000183105, 'mnli-mm_test_prompt,adapter_eval_mnli-mm/acc': 0.5987591537835639, 'mnli_dev_eval_loss': 3.1242482662200928, 'mnli_dev_eval_mnli/acc': 0.5625, 'mnli_test_eval_loss': 2.6247024536132812, 'mnli_test_eval_mnli/acc': 0.5725929699439634, 'mnli-mm_test_eval_loss': 2.5024333000183105, 'mnli-mm_test_eval_mnli-mm/acc': 0.5987591537835639, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-12756', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_17-24-11_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-12756', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt_eval_loss': 0.8641326427459717, 'rte_dev_prompt_eval_acc': 0.5625, 'rte_test_prompt_eval_loss': 0.8838521838188171, 'rte_test_prompt_eval_acc': 0.5018050541516246, 'rte_dev_eval_loss': 0.8641326427459717, 'rte_dev_eval_acc': 0.5625, 'rte_test_eval_loss': 0.8838521838188171, 'rte_test_eval_acc': 0.5018050541516246, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-13-roberta-large-31989', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_17-37-23_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-13-roberta-large-31989', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,adapter_eval_loss': 2.187666893005371, 'sts-b_dev_prompt,adapter_eval_pearson': 0.80154499499769, 'sts-b_dev_prompt,adapter_eval_spearmanr': 0.7806379053925144, 'sts-b_dev_prompt,adapter_eval_corr': 0.7910914501951023, 'sts-b_test_prompt,adapter_eval_loss': 2.181157112121582, 'sts-b_test_prompt,adapter_eval_pearson': 0.6570807282890432, 'sts-b_test_prompt,adapter_eval_spearmanr': 0.6591303916839796, 'sts-b_test_prompt,adapter_eval_corr': 0.6581055599865113, 'sts-b_dev_eval_loss': 2.187666893005371, 'sts-b_dev_eval_pearson': 0.80154499499769, 'sts-b_dev_eval_spearmanr': 0.7806379053925144, 'sts-b_dev_eval_corr': 0.7910914501951023, 'sts-b_test_eval_loss': 2.181157112121582, 'sts-b_test_eval_pearson': 0.6570807282890432, 'sts-b_test_eval_spearmanr': 0.6591303916839796, 'sts-b_test_eval_corr': 0.6581055599865113, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-13-roberta-large-21281', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_17-41-13_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-13-roberta-large-21281', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt_eval_loss': 3.187694787979126, 'rte_dev_prompt_eval_acc': 0.71875, 'rte_test_prompt_eval_loss': 5.3170881271362305, 'rte_test_prompt_eval_acc': 0.5234657039711191, 'rte_dev_eval_loss': 3.187694787979126, 'rte_dev_eval_acc': 0.71875, 'rte_test_eval_loss': 5.3170881271362305, 'rte_test_eval_acc': 0.5234657039711191, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-13-roberta-large-25356', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_17-49-34_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-13-roberta-large-25356', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias_eval_loss': 3.885329008102417, 'mnli_dev_prompt,bias_eval_mnli/acc': 0.6666666666666666, 'mnli_test_prompt,bias_eval_loss': 3.943169355392456, 'mnli_test_prompt,bias_eval_mnli/acc': 0.6483953132959756, 'mnli-mm_test_prompt,bias_eval_loss': 3.809464693069458, 'mnli-mm_test_prompt,bias_eval_mnli-mm/acc': 0.6583604556550041, 'mnli_dev_eval_loss': 3.885329008102417, 'mnli_dev_eval_mnli/acc': 0.6666666666666666, 'mnli_test_eval_loss': 3.943169355392456, 'mnli_test_eval_mnli/acc': 0.6483953132959756, 'mnli-mm_test_eval_loss': 3.809464693069458, 'mnli-mm_test_eval_mnli-mm/acc': 0.6583604556550041, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-32685', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_17-45-52_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-32685', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,adapter_eval_loss': 2.1868767738342285, 'sts-b_dev_prompt,adapter_eval_pearson': 0.7994127934191254, 'sts-b_dev_prompt,adapter_eval_spearmanr': 0.8133405524058983, 'sts-b_dev_prompt,adapter_eval_corr': 0.8063766729125119, 'sts-b_test_prompt,adapter_eval_loss': 2.1883814334869385, 'sts-b_test_prompt,adapter_eval_pearson': 0.5819830823737968, 'sts-b_test_prompt,adapter_eval_spearmanr': 0.588404788049768, 'sts-b_test_prompt,adapter_eval_corr': 0.5851939352117824, 'sts-b_dev_eval_loss': 2.1868767738342285, 'sts-b_dev_eval_pearson': 0.7994127934191254, 'sts-b_dev_eval_spearmanr': 0.8133405524058983, 'sts-b_dev_eval_corr': 0.8063766729125119, 'sts-b_test_eval_loss': 2.1883814334869385, 'sts-b_test_eval_pearson': 0.5819830823737968, 'sts-b_test_eval_spearmanr': 0.588404788049768, 'sts-b_test_eval_corr': 0.5851939352117824, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-13-roberta-large-28083', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_17-55-51_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-13-roberta-large-28083', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt_eval_loss': 1.080249547958374, 'rte_dev_prompt_eval_acc': 0.65625, 'rte_test_prompt_eval_loss': 1.3861349821090698, 'rte_test_prompt_eval_acc': 0.516245487364621, 'rte_dev_eval_loss': 1.080249547958374, 'rte_dev_eval_acc': 0.65625, 'rte_test_eval_loss': 1.3861349821090698, 'rte_test_eval_acc': 0.516245487364621, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-13-roberta-large-634', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_18-01-50_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-13-roberta-large-634', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias_eval_loss': 2.1737325191497803, 'sts-b_dev_prompt,bias_eval_pearson': 0.8885470795458141, 'sts-b_dev_prompt,bias_eval_spearmanr': 0.8585363454693387, 'sts-b_dev_prompt,bias_eval_corr': 0.8735417125075764, 'sts-b_test_prompt,bias_eval_loss': 2.1655614376068115, 'sts-b_test_prompt,bias_eval_pearson': 0.7988266622182002, 'sts-b_test_prompt,bias_eval_spearmanr': 0.8000260424985793, 'sts-b_test_prompt,bias_eval_corr': 0.7994263523583898, 'sts-b_dev_eval_loss': 2.1737325191497803, 'sts-b_dev_eval_pearson': 0.8885470795458141, 'sts-b_dev_eval_spearmanr': 0.8585363454693387, 'sts-b_dev_eval_corr': 0.8735417125075764, 'sts-b_test_eval_loss': 2.1655614376068115, 'sts-b_test_eval_pearson': 0.7988266622182002, 'sts-b_test_eval_spearmanr': 0.8000260424985793, 'sts-b_test_eval_corr': 0.7994263523583898, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-13-roberta-large-11059', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_18-11-14_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-13-roberta-large-11059', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias_eval_loss': 2.94742751121521, 'mnli_dev_prompt,bias_eval_mnli/acc': 0.7291666666666666, 'mnli_test_prompt,bias_eval_loss': 2.902672290802002, 'mnli_test_prompt,bias_eval_mnli/acc': 0.6688741721854304, 'mnli-mm_test_prompt,bias_eval_loss': 2.793036699295044, 'mnli-mm_test_prompt,bias_eval_mnli-mm/acc': 0.6906021155410903, 'mnli_dev_eval_loss': 2.94742751121521, 'mnli_dev_eval_mnli/acc': 0.7291666666666666, 'mnli_test_eval_loss': 2.902672290802002, 'mnli_test_eval_mnli/acc': 0.6688741721854304, 'mnli-mm_test_eval_loss': 2.793036699295044, 'mnli-mm_test_eval_mnli-mm/acc': 0.6906021155410903, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-21990', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_18-07-02_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-21990', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias_eval_loss': 4.959375858306885, 'rte_dev_bias_eval_acc': 0.53125, 'rte_test_bias_eval_loss': 4.407090663909912, 'rte_test_bias_eval_acc': 0.555956678700361, 'rte_dev_eval_loss': 4.959375858306885, 'rte_dev_eval_acc': 0.53125, 'rte_test_eval_loss': 4.407090663909912, 'rte_test_eval_acc': 0.555956678700361, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16--13-roberta-large-8045', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_18-13-53_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--13-roberta-large-8045', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias_eval_loss': 2.1808760166168213, 'sts-b_dev_prompt,bias_eval_pearson': 0.8401726946551649, 'sts-b_dev_prompt,bias_eval_spearmanr': 0.8293244304405295, 'sts-b_dev_prompt,bias_eval_corr': 0.8347485625478472, 'sts-b_test_prompt,bias_eval_loss': 2.1728763580322266, 'sts-b_test_prompt,bias_eval_pearson': 0.7253420843911688, 'sts-b_test_prompt,bias_eval_spearmanr': 0.7259850915130311, 'sts-b_test_prompt,bias_eval_corr': 0.7256635879521, 'sts-b_dev_eval_loss': 2.1808760166168213, 'sts-b_dev_eval_pearson': 0.8401726946551649, 'sts-b_dev_eval_spearmanr': 0.8293244304405295, 'sts-b_dev_eval_corr': 0.8347485625478472, 'sts-b_test_eval_loss': 2.1728763580322266, 'sts-b_test_eval_pearson': 0.7253420843911688, 'sts-b_test_eval_spearmanr': 0.7259850915130311, 'sts-b_test_eval_corr': 0.7256635879521, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-13-roberta-large-21853', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_18-22-49_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-13-roberta-large-21853', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias_eval_loss': 6.60059928894043, 'rte_dev_bias_eval_acc': 0.46875, 'rte_test_bias_eval_loss': 5.528243064880371, 'rte_test_bias_eval_acc': 0.48375451263537905, 'rte_dev_eval_loss': 6.60059928894043, 'rte_dev_eval_acc': 0.46875, 'rte_test_eval_loss': 5.528243064880371, 'rte_test_eval_acc': 0.48375451263537905, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16--13-roberta-large-9847', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_18-28-26_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--13-roberta-large-9847', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias_eval_loss': 2.1367478370666504, 'mnli_dev_prompt,bias_eval_mnli/acc': 0.625, 'mnli_test_prompt,bias_eval_loss': 2.1351563930511475, 'mnli_test_prompt,bias_eval_mnli/acc': 0.6294447274579725, 'mnli-mm_test_prompt,bias_eval_loss': 2.026303768157959, 'mnli-mm_test_prompt,bias_eval_mnli-mm/acc': 0.6517493897477624, 'mnli_dev_eval_loss': 2.1367478370666504, 'mnli_dev_eval_mnli/acc': 0.625, 'mnli_test_eval_loss': 2.1351563930511475, 'mnli_test_eval_mnli/acc': 0.6294447274579725, 'mnli-mm_test_eval_loss': 2.026303768157959, 'mnli-mm_test_eval_mnli-mm/acc': 0.6517493897477624, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-30648', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_18-28-10_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-30648', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias_eval_loss': 2.5427494049072266, 'rte_dev_bias_eval_acc': 0.625, 'rte_test_bias_eval_loss': 2.8266773223876953, 'rte_test_bias_eval_acc': 0.5090252707581228, 'rte_dev_eval_loss': 2.5427494049072266, 'rte_dev_eval_acc': 0.625, 'rte_test_eval_loss': 2.8266773223876953, 'rte_test_eval_acc': 0.5090252707581228, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16--13-roberta-large-23303', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_18-43-16_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--13-roberta-large-23303', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias_eval_loss': 2.193589687347412, 'sts-b_dev_prompt,bias_eval_pearson': 0.7519879859041466, 'sts-b_dev_prompt,bias_eval_spearmanr': 0.7872519238896032, 'sts-b_dev_prompt,bias_eval_corr': 0.769619954896875, 'sts-b_test_prompt,bias_eval_loss': 2.1924190521240234, 'sts-b_test_prompt,bias_eval_pearson': 0.5968998832178519, 'sts-b_test_prompt,bias_eval_spearmanr': 0.6001640855316253, 'sts-b_test_prompt,bias_eval_corr': 0.5985319843747385, 'sts-b_dev_eval_loss': 2.193589687347412, 'sts-b_dev_eval_pearson': 0.7519879859041466, 'sts-b_dev_eval_spearmanr': 0.7872519238896032, 'sts-b_dev_eval_corr': 0.769619954896875, 'sts-b_test_eval_loss': 2.1924190521240234, 'sts-b_test_eval_pearson': 0.5968998832178519, 'sts-b_test_eval_spearmanr': 0.6001640855316253, 'sts-b_test_eval_corr': 0.5985319843747385, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-13-roberta-large-17177', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_18-42-46_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-13-roberta-large-17177', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias_eval_loss': 1.6691499948501587, 'mnli_dev_prompt,bias_eval_mnli/acc': 0.5833333333333334, 'mnli_test_prompt,bias_eval_loss': 1.5910825729370117, 'mnli_test_prompt,bias_eval_mnli/acc': 0.5814569536423841, 'mnli-mm_test_prompt,bias_eval_loss': 1.5341421365737915, 'mnli-mm_test_prompt,bias_eval_mnli-mm/acc': 0.6002847843775427, 'mnli_dev_eval_loss': 1.6691499948501587, 'mnli_dev_eval_mnli/acc': 0.5833333333333334, 'mnli_test_eval_loss': 1.5910825729370117, 'mnli_test_eval_mnli/acc': 0.5814569536423841, 'mnli-mm_test_eval_loss': 1.5341421365737915, 'mnli-mm_test_eval_mnli-mm/acc': 0.6002847843775427, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-5927', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_18-49-05_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-5927', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias_eval_loss': 2.4870190620422363, 'rte_dev_bias_eval_acc': 0.625, 'rte_test_bias_eval_loss': 2.6448075771331787, 'rte_test_bias_eval_acc': 0.5342960288808665, 'rte_dev_eval_loss': 2.4870190620422363, 'rte_dev_eval_acc': 0.625, 'rte_test_eval_loss': 2.6448075771331787, 'rte_test_eval_acc': 0.5342960288808665, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16--13-roberta-large-3438', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_18-57-37_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--13-roberta-large-3438', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias_eval_loss': 2.2084031105041504, 'sts-b_dev_prompt,bias_eval_pearson': 0.6718889994376585, 'sts-b_dev_prompt,bias_eval_spearmanr': 0.6950231104024198, 'sts-b_dev_prompt,bias_eval_corr': 0.6834560549200391, 'sts-b_test_prompt,bias_eval_loss': 2.2370190620422363, 'sts-b_test_prompt,bias_eval_pearson': 0.38232663556911206, 'sts-b_test_prompt,bias_eval_spearmanr': 0.3916045250469537, 'sts-b_test_prompt,bias_eval_corr': 0.38696558030803285, 'sts-b_dev_eval_loss': 2.2084031105041504, 'sts-b_dev_eval_pearson': 0.6718889994376585, 'sts-b_dev_eval_spearmanr': 0.6950231104024198, 'sts-b_dev_eval_corr': 0.6834560549200391, 'sts-b_test_eval_loss': 2.2370190620422363, 'sts-b_test_eval_pearson': 0.38232663556911206, 'sts-b_test_eval_spearmanr': 0.3916045250469537, 'sts-b_test_eval_corr': 0.38696558030803285, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-13-roberta-large-1975', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_19-01-49_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-13-roberta-large-1975', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_adapter_eval_loss': 4.31954288482666, 'rte_dev_adapter_eval_acc': 0.5625, 'rte_test_adapter_eval_loss': 3.523003339767456, 'rte_test_adapter_eval_acc': 0.5090252707581228, 'rte_dev_eval_loss': 4.31954288482666, 'rte_dev_eval_acc': 0.5625, 'rte_test_eval_loss': 3.523003339767456, 'rte_test_eval_acc': 0.5090252707581228, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--13-roberta-large-11774', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_19-12-20_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--13-roberta-large-11774', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias,adapter_eval_loss': 5.148519039154053, 'mnli_dev_bias,adapter_eval_mnli/acc': 0.5208333333333334, 'mnli_test_bias,adapter_eval_loss': 6.106340408325195, 'mnli_test_bias,adapter_eval_mnli/acc': 0.3990830361691289, 'mnli-mm_test_bias,adapter_eval_loss': 5.065760135650635, 'mnli-mm_test_bias,adapter_eval_mnli-mm/acc': 0.41720911310008135, 'mnli_dev_eval_loss': 5.148519039154053, 'mnli_dev_eval_mnli/acc': 0.5208333333333334, 'mnli_test_eval_loss': 6.106340408325195, 'mnli_test_eval_mnli/acc': 0.3990830361691289, 'mnli-mm_test_eval_loss': 5.065760135650635, 'mnli-mm_test_eval_mnli-mm/acc': 0.41720911310008135, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--13-roberta-large-25545', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_19-10-34_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--13-roberta-large-25545', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_adapter_eval_loss': 6.612307548522949, 'rte_dev_adapter_eval_acc': 0.5625, 'rte_test_adapter_eval_loss': 5.424379825592041, 'rte_test_adapter_eval_acc': 0.5703971119133574, 'rte_dev_eval_loss': 6.612307548522949, 'rte_dev_eval_acc': 0.5625, 'rte_test_eval_loss': 5.424379825592041, 'rte_test_eval_acc': 0.5703971119133574, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--13-roberta-large-1900', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_19-27-50_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--13-roberta-large-1900', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias,adapter_eval_loss': 2.244755268096924, 'sts-b_dev_bias,adapter_eval_pearson': 0.370055756560708, 'sts-b_dev_bias,adapter_eval_spearmanr': 0.3466599600184026, 'sts-b_dev_bias,adapter_eval_corr': 0.3583578582895553, 'sts-b_test_bias,adapter_eval_loss': 2.215921640396118, 'sts-b_test_bias,adapter_eval_pearson': -0.0393408936213412, 'sts-b_test_bias,adapter_eval_spearmanr': -0.036984960789470264, 'sts-b_test_bias,adapter_eval_corr': -0.03816292720540573, 'sts-b_dev_eval_loss': 2.244755268096924, 'sts-b_dev_eval_pearson': 0.370055756560708, 'sts-b_dev_eval_spearmanr': 0.3466599600184026, 'sts-b_dev_eval_corr': 0.3583578582895553, 'sts-b_test_eval_loss': 2.215921640396118, 'sts-b_test_eval_pearson': -0.0393408936213412, 'sts-b_test_eval_spearmanr': -0.036984960789470264, 'sts-b_test_eval_corr': -0.03816292720540573, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--13-roberta-large-16428', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_19-20-05_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--13-roberta-large-16428', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_adapter_eval_loss': 3.922370195388794, 'rte_dev_adapter_eval_acc': 0.625, 'rte_test_adapter_eval_loss': 3.607163906097412, 'rte_test_adapter_eval_acc': 0.5631768953068592, 'rte_dev_eval_loss': 3.922370195388794, 'rte_dev_eval_acc': 0.625, 'rte_test_eval_loss': 3.607163906097412, 'rte_test_eval_acc': 0.5631768953068592, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--13-roberta-large-2722', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_19-44-02_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--13-roberta-large-2722', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias,adapter_eval_loss': 3.798046827316284, 'mnli_dev_bias,adapter_eval_mnli/acc': 0.6458333333333334, 'mnli_test_bias,adapter_eval_loss': 2.9138240814208984, 'mnli_test_bias,adapter_eval_mnli/acc': 0.6144676515537443, 'mnli-mm_test_bias,adapter_eval_loss': 2.663515567779541, 'mnli-mm_test_bias,adapter_eval_mnli-mm/acc': 0.6387306753458096, 'mnli_dev_eval_loss': 3.798046827316284, 'mnli_dev_eval_mnli/acc': 0.6458333333333334, 'mnli_test_eval_loss': 2.9138240814208984, 'mnli_test_eval_mnli/acc': 0.6144676515537443, 'mnli-mm_test_eval_loss': 2.663515567779541, 'mnli-mm_test_eval_mnli-mm/acc': 0.6387306753458096, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--13-roberta-large-3921', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_19-34-54_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--13-roberta-large-3921', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias,adapter_eval_loss': 2.1777231693267822, 'sts-b_dev_bias,adapter_eval_pearson': 0.8985688194090353, 'sts-b_dev_bias,adapter_eval_spearmanr': 0.8787458464326656, 'sts-b_dev_bias,adapter_eval_corr': 0.8886573329208505, 'sts-b_test_bias,adapter_eval_loss': 2.1691057682037354, 'sts-b_test_bias,adapter_eval_pearson': 0.766705078856871, 'sts-b_test_bias,adapter_eval_spearmanr': 0.7714431667966692, 'sts-b_test_bias,adapter_eval_corr': 0.7690741228267701, 'sts-b_dev_eval_loss': 2.1777231693267822, 'sts-b_dev_eval_pearson': 0.8985688194090353, 'sts-b_dev_eval_spearmanr': 0.8787458464326656, 'sts-b_dev_eval_corr': 0.8886573329208505, 'sts-b_test_eval_loss': 2.1691057682037354, 'sts-b_test_eval_pearson': 0.766705078856871, 'sts-b_test_eval_spearmanr': 0.7714431667966692, 'sts-b_test_eval_corr': 0.7690741228267701, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--13-roberta-large-22068', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_19-48-21_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--13-roberta-large-22068', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_adapter_eval_loss': 3.8487741947174072, 'rte_dev_adapter_eval_acc': 0.53125, 'rte_test_adapter_eval_loss': 3.3752975463867188, 'rte_test_adapter_eval_acc': 0.5379061371841155, 'rte_dev_eval_loss': 3.8487741947174072, 'rte_dev_eval_acc': 0.53125, 'rte_test_eval_loss': 3.3752975463867188, 'rte_test_eval_acc': 0.5379061371841155, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--13-roberta-large-8835', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_20-00-13_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--13-roberta-large-8835', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias,adapter_eval_loss': 4.131340980529785, 'mnli_dev_bias,adapter_eval_mnli/acc': 0.5416666666666666, 'mnli_test_bias,adapter_eval_loss': 3.7923710346221924, 'mnli_test_bias,adapter_eval_mnli/acc': 0.5407030056036679, 'mnli-mm_test_bias,adapter_eval_loss': 3.45390248298645, 'mnli-mm_test_bias,adapter_eval_mnli-mm/acc': 0.5510577705451587, 'mnli_dev_eval_loss': 4.131340980529785, 'mnli_dev_eval_mnli/acc': 0.5416666666666666, 'mnli_test_eval_loss': 3.7923710346221924, 'mnli_test_eval_mnli/acc': 0.5407030056036679, 'mnli-mm_test_eval_loss': 3.45390248298645, 'mnli-mm_test_eval_mnli-mm/acc': 0.5510577705451587, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--13-roberta-large-32197', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_20-00-26_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--13-roberta-large-32197', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,adapter_eval_loss': 5.362393379211426, 'rte_dev_prompt,adapter_eval_acc': 0.5, 'rte_test_prompt,adapter_eval_loss': 3.198928117752075, 'rte_test_prompt,adapter_eval_acc': 0.555956678700361, 'rte_dev_eval_loss': 5.362393379211426, 'rte_dev_eval_acc': 0.5, 'rte_test_eval_loss': 3.198928117752075, 'rte_test_eval_acc': 0.555956678700361, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-13-roberta-large-20742', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_20-18-08_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-13-roberta-large-20742', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias,adapter_eval_loss': 2.181640863418579, 'sts-b_dev_bias,adapter_eval_pearson': 0.8349118498690588, 'sts-b_dev_bias,adapter_eval_spearmanr': 0.8170150071265031, 'sts-b_dev_bias,adapter_eval_corr': 0.8259634284977809, 'sts-b_test_bias,adapter_eval_loss': 2.176656484603882, 'sts-b_test_bias,adapter_eval_pearson': 0.7147270732812078, 'sts-b_test_bias,adapter_eval_spearmanr': 0.7133858574624388, 'sts-b_test_bias,adapter_eval_corr': 0.7140564653718233, 'sts-b_dev_eval_loss': 2.181640863418579, 'sts-b_dev_eval_pearson': 0.8349118498690588, 'sts-b_dev_eval_spearmanr': 0.8170150071265031, 'sts-b_dev_eval_corr': 0.8259634284977809, 'sts-b_test_eval_loss': 2.176656484603882, 'sts-b_test_eval_pearson': 0.7147270732812078, 'sts-b_test_eval_spearmanr': 0.7133858574624388, 'sts-b_test_eval_corr': 0.7140564653718233, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--13-roberta-large-18786', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_20-14-37_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--13-roberta-large-18786', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias,adapter_eval_loss': 3.7161569595336914, 'mnli_dev_bias,adapter_eval_mnli/acc': 0.4791666666666667, 'mnli_test_bias,adapter_eval_loss': 2.9065563678741455, 'mnli_test_bias,adapter_eval_mnli/acc': 0.5238920020376974, 'mnli-mm_test_bias,adapter_eval_loss': 2.6824378967285156, 'mnli-mm_test_bias,adapter_eval_mnli-mm/acc': 0.544039869812856, 'mnli_dev_eval_loss': 3.7161569595336914, 'mnli_dev_eval_mnli/acc': 0.4791666666666667, 'mnli_test_eval_loss': 2.9065563678741455, 'mnli_test_eval_mnli/acc': 0.5238920020376974, 'mnli-mm_test_eval_loss': 2.6824378967285156, 'mnli-mm_test_eval_mnli-mm/acc': 0.544039869812856, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--13-roberta-large-18697', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_20-24-36_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--13-roberta-large-18697', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,adapter_eval_loss': 4.016420364379883, 'rte_dev_prompt,adapter_eval_acc': 0.53125, 'rte_test_prompt,adapter_eval_loss': 4.297262191772461, 'rte_test_prompt,adapter_eval_acc': 0.5018050541516246, 'rte_dev_eval_loss': 4.016420364379883, 'rte_dev_eval_acc': 0.53125, 'rte_test_eval_loss': 4.297262191772461, 'rte_test_eval_acc': 0.5018050541516246, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-13-roberta-large-21990', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_20-36-56_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-13-roberta-large-21990', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias,adapter_eval_loss': 2.187840700149536, 'sts-b_dev_bias,adapter_eval_pearson': 0.7881016372765709, 'sts-b_dev_bias,adapter_eval_spearmanr': 0.8126056614617773, 'sts-b_dev_bias,adapter_eval_corr': 0.8003536493691741, 'sts-b_test_bias,adapter_eval_loss': 2.1834795475006104, 'sts-b_test_bias,adapter_eval_pearson': 0.6492600812596118, 'sts-b_test_bias,adapter_eval_spearmanr': 0.6477528191691354, 'sts-b_test_bias,adapter_eval_corr': 0.6485064502143736, 'sts-b_dev_eval_loss': 2.187840700149536, 'sts-b_dev_eval_pearson': 0.7881016372765709, 'sts-b_dev_eval_spearmanr': 0.8126056614617773, 'sts-b_dev_eval_corr': 0.8003536493691741, 'sts-b_test_eval_loss': 2.1834795475006104, 'sts-b_test_eval_pearson': 0.6492600812596118, 'sts-b_test_eval_spearmanr': 0.6477528191691354, 'sts-b_test_eval_corr': 0.6485064502143736, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--13-roberta-large-11125', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_20-42-14_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--13-roberta-large-11125', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,adapter_eval_loss': 4.208866596221924, 'rte_dev_prompt,adapter_eval_acc': 0.46875, 'rte_test_prompt,adapter_eval_loss': 3.9324421882629395, 'rte_test_prompt,adapter_eval_acc': 0.5595667870036101, 'rte_dev_eval_loss': 4.208866596221924, 'rte_dev_eval_acc': 0.46875, 'rte_test_eval_loss': 3.9324421882629395, 'rte_test_eval_acc': 0.5595667870036101, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-13-roberta-large-21794', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_20-55-23_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-13-roberta-large-21794', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias,adapter_eval_loss': 1.148209571838379, 'mnli_dev_prompt,bias,adapter_eval_mnli/acc': 0.3333333333333333, 'mnli_test_prompt,bias,adapter_eval_loss': 1.1348074674606323, 'mnli_test_prompt,bias,adapter_eval_mnli/acc': 0.3544574630667346, 'mnli-mm_test_prompt,bias,adapter_eval_loss': 1.135427474975586, 'mnli-mm_test_prompt,bias,adapter_eval_mnli-mm/acc': 0.3522172497965826, 'mnli_dev_eval_loss': 1.148209571838379, 'mnli_dev_eval_mnli/acc': 0.3333333333333333, 'mnli_test_eval_loss': 1.1348074674606323, 'mnli_test_eval_mnli/acc': 0.3544574630667346, 'mnli-mm_test_eval_loss': 1.135427474975586, 'mnli-mm_test_eval_mnli-mm/acc': 0.3522172497965826, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-21717', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_20-48-30_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-21717', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,adapter_eval_loss': 1.369779348373413, 'rte_dev_prompt,adapter_eval_acc': 0.5, 'rte_test_prompt,adapter_eval_loss': 1.3296163082122803, 'rte_test_prompt,adapter_eval_acc': 0.51985559566787, 'rte_dev_eval_loss': 1.369779348373413, 'rte_dev_eval_acc': 0.5, 'rte_test_eval_loss': 1.3296163082122803, 'rte_test_eval_acc': 0.51985559566787, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-13-roberta-large-5956', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_21-13-45_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-13-roberta-large-5956', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias,adapter_eval_loss': 2.2390923500061035, 'sts-b_dev_prompt,bias,adapter_eval_pearson': 0.2607232382083021, 'sts-b_dev_prompt,bias,adapter_eval_spearmanr': 0.25255004598324743, 'sts-b_dev_prompt,bias,adapter_eval_corr': 0.25663664209577475, 'sts-b_test_prompt,bias,adapter_eval_loss': 2.2110068798065186, 'sts-b_test_prompt,bias,adapter_eval_pearson': -0.02677755836539789, 'sts-b_test_prompt,bias,adapter_eval_spearmanr': -0.02609178837197611, 'sts-b_test_prompt,bias,adapter_eval_corr': -0.026434673368687, 'sts-b_dev_eval_loss': 2.2390923500061035, 'sts-b_dev_eval_pearson': 0.2607232382083021, 'sts-b_dev_eval_spearmanr': 0.25255004598324743, 'sts-b_dev_eval_corr': 0.25663664209577475, 'sts-b_test_eval_loss': 2.2110068798065186, 'sts-b_test_eval_pearson': -0.02677755836539789, 'sts-b_test_eval_spearmanr': -0.02609178837197611, 'sts-b_test_eval_corr': -0.026434673368687, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-13-roberta-large-14775', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_21-12-15_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-13-roberta-large-14775', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias,adapter_eval_loss': 2.7385387420654297, 'mnli_dev_prompt,bias,adapter_eval_mnli/acc': 0.7083333333333334, 'mnli_test_prompt,bias,adapter_eval_loss': 3.2980034351348877, 'mnli_test_prompt,bias,adapter_eval_mnli/acc': 0.5943963321446765, 'mnli-mm_test_prompt,bias,adapter_eval_loss': 3.278545618057251, 'mnli-mm_test_prompt,bias,adapter_eval_mnli-mm/acc': 0.5947925142392189, 'mnli_dev_eval_loss': 2.7385387420654297, 'mnli_dev_eval_mnli/acc': 0.7083333333333334, 'mnli_test_eval_loss': 3.2980034351348877, 'mnli_test_eval_mnli/acc': 0.5943963321446765, 'mnli-mm_test_eval_loss': 3.278545618057251, 'mnli-mm_test_eval_mnli-mm/acc': 0.5947925142392189, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-24545', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_21-13-53_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-24545', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias_eval_loss': 2.9351749420166016, 'rte_dev_prompt,bias_eval_acc': 0.4375, 'rte_test_prompt,bias_eval_loss': 2.9488277435302734, 'rte_test_prompt,bias_eval_acc': 0.4657039711191336, 'rte_dev_eval_loss': 2.9351749420166016, 'rte_dev_eval_acc': 0.4375, 'rte_test_eval_loss': 2.9488277435302734, 'rte_test_eval_acc': 0.4657039711191336, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-13-roberta-large-24620', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_21-30-59_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-13-roberta-large-24620', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias_eval_loss': 4.358251571655273, 'rte_dev_prompt,bias_eval_acc': 0.46875, 'rte_test_prompt,bias_eval_loss': 3.9635627269744873, 'rte_test_prompt,bias_eval_acc': 0.5126353790613718, 'rte_dev_eval_loss': 4.358251571655273, 'rte_dev_eval_acc': 0.46875, 'rte_test_eval_loss': 3.9635627269744873, 'rte_test_eval_acc': 0.5126353790613718, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-13-roberta-large-17782', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_21-46-59_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-13-roberta-large-17782', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias,adapter_eval_loss': 3.0867412090301514, 'mnli_dev_prompt,bias,adapter_eval_mnli/acc': 0.6666666666666666, 'mnli_test_prompt,bias,adapter_eval_loss': 3.2238495349884033, 'mnli_test_prompt,bias,adapter_eval_mnli/acc': 0.630667345899134, 'mnli-mm_test_prompt,bias,adapter_eval_loss': 3.0978593826293945, 'mnli-mm_test_prompt,bias,adapter_eval_mnli-mm/acc': 0.6503254678600489, 'mnli_dev_eval_loss': 3.0867412090301514, 'mnli_dev_eval_mnli/acc': 0.6666666666666666, 'mnli_test_eval_loss': 3.2238495349884033, 'mnli_test_eval_mnli/acc': 0.630667345899134, 'mnli-mm_test_eval_loss': 3.0978593826293945, 'mnli-mm_test_eval_mnli-mm/acc': 0.6503254678600489, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-8323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_21-40-07_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-8323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias,adapter_eval_loss': 2.182591438293457, 'sts-b_dev_prompt,bias,adapter_eval_pearson': 0.8624204664591184, 'sts-b_dev_prompt,bias,adapter_eval_spearmanr': 0.8359384489376185, 'sts-b_dev_prompt,bias,adapter_eval_corr': 0.8491794576983684, 'sts-b_test_prompt,bias,adapter_eval_loss': 2.172088384628296, 'sts-b_test_prompt,bias,adapter_eval_pearson': 0.7385706738819553, 'sts-b_test_prompt,bias,adapter_eval_spearmanr': 0.7431616402903835, 'sts-b_test_prompt,bias,adapter_eval_corr': 0.7408661570861694, 'sts-b_dev_eval_loss': 2.182591438293457, 'sts-b_dev_eval_pearson': 0.8624204664591184, 'sts-b_dev_eval_spearmanr': 0.8359384489376185, 'sts-b_dev_eval_corr': 0.8491794576983684, 'sts-b_test_eval_loss': 2.172088384628296, 'sts-b_test_eval_pearson': 0.7385706738819553, 'sts-b_test_eval_spearmanr': 0.7431616402903835, 'sts-b_test_eval_corr': 0.7408661570861694, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-13-roberta-large-15843', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_21-38-21_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-13-roberta-large-15843', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias_eval_loss': 1.136268138885498, 'rte_dev_prompt,bias_eval_acc': 0.5625, 'rte_test_prompt,bias_eval_loss': 1.2135573625564575, 'rte_test_prompt,bias_eval_acc': 0.48014440433212996, 'rte_dev_eval_loss': 1.136268138885498, 'rte_dev_eval_acc': 0.5625, 'rte_test_eval_loss': 1.2135573625564575, 'rte_test_eval_acc': 0.48014440433212996, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-13-roberta-large-11690', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_22-02-41_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-13-roberta-large-11690', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias,adapter_eval_loss': 3.1240336894989014, 'mnli_dev_prompt,bias,adapter_eval_mnli/acc': 0.5833333333333334, 'mnli_test_prompt,bias,adapter_eval_loss': 2.915755033493042, 'mnli_test_prompt,bias,adapter_eval_mnli/acc': 0.6012226184411615, 'mnli-mm_test_prompt,bias,adapter_eval_loss': 2.8118326663970947, 'mnli-mm_test_prompt,bias,adapter_eval_mnli-mm/acc': 0.6192026037428804, 'mnli_dev_eval_loss': 3.1240336894989014, 'mnli_dev_eval_mnli/acc': 0.5833333333333334, 'mnli_test_eval_loss': 2.915755033493042, 'mnli_test_eval_mnli/acc': 0.6012226184411615, 'mnli-mm_test_eval_loss': 2.8118326663970947, 'mnli-mm_test_eval_mnli-mm/acc': 0.6192026037428804, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-13-roberta-large-22498', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_22-06-11_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-13-roberta-large-22498', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias_eval_loss': 2.2268569469451904, 'rte_dev_prompt,bias_eval_acc': 0.5625, 'rte_test_prompt,bias_eval_loss': 2.3922078609466553, 'rte_test_prompt,bias_eval_acc': 0.5018050541516246, 'rte_dev_eval_loss': 2.2268569469451904, 'rte_dev_eval_acc': 0.5625, 'rte_test_eval_loss': 2.3922078609466553, 'rte_test_eval_acc': 0.5018050541516246, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-13-roberta-large-9479', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_22-18-12_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-13-roberta-large-9479', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias,adapter_eval_loss': 2.181400775909424, 'sts-b_dev_prompt,bias,adapter_eval_pearson': 0.8528435490755244, 'sts-b_dev_prompt,bias,adapter_eval_spearmanr': 0.8159126707103216, 'sts-b_dev_prompt,bias,adapter_eval_corr': 0.834378109892923, 'sts-b_test_prompt,bias,adapter_eval_loss': 2.1757333278656006, 'sts-b_test_prompt,bias,adapter_eval_pearson': 0.7110758731923831, 'sts-b_test_prompt,bias,adapter_eval_spearmanr': 0.7189895550391725, 'sts-b_test_prompt,bias,adapter_eval_corr': 0.7150327141157777, 'sts-b_dev_eval_loss': 2.181400775909424, 'sts-b_dev_eval_pearson': 0.8528435490755244, 'sts-b_dev_eval_spearmanr': 0.8159126707103216, 'sts-b_dev_eval_corr': 0.834378109892923, 'sts-b_test_eval_loss': 2.1757333278656006, 'sts-b_test_eval_pearson': 0.7110758731923831, 'sts-b_test_eval_spearmanr': 0.7189895550391725, 'sts-b_test_eval_corr': 0.7150327141157777, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-13-roberta-large-1740', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_22-11-16_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-13-roberta-large-1740', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias,adapter_eval_loss': 0.6984195709228516, 'rte_dev_bias,adapter_eval_acc': 0.5, 'rte_test_bias,adapter_eval_loss': 0.7040078043937683, 'rte_test_bias,adapter_eval_acc': 0.4729241877256318, 'rte_dev_eval_loss': 0.6984195709228516, 'rte_dev_eval_acc': 0.5, 'rte_test_eval_loss': 0.7040078043937683, 'rte_test_eval_acc': 0.4729241877256318, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--13-roberta-large-5714', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_22-34-09_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--13-roberta-large-5714', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias,adapter_eval_loss': 5.28390645980835, 'rte_dev_bias,adapter_eval_acc': 0.5625, 'rte_test_bias,adapter_eval_loss': 4.696613311767578, 'rte_test_bias,adapter_eval_acc': 0.48375451263537905, 'rte_dev_eval_loss': 5.28390645980835, 'rte_dev_eval_acc': 0.5625, 'rte_test_eval_loss': 4.696613311767578, 'rte_test_eval_acc': 0.48375451263537905, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--13-roberta-large-2599', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_22-53-51_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--13-roberta-large-2599', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias,adapter_eval_loss': 2.186030864715576, 'sts-b_dev_prompt,bias,adapter_eval_pearson': 0.808545677290489, 'sts-b_dev_prompt,bias,adapter_eval_spearmanr': 0.8175661753345937, 'sts-b_dev_prompt,bias,adapter_eval_corr': 0.8130559263125414, 'sts-b_test_prompt,bias,adapter_eval_loss': 2.184372663497925, 'sts-b_test_prompt,bias,adapter_eval_pearson': 0.6177344743320845, 'sts-b_test_prompt,bias,adapter_eval_spearmanr': 0.6197938115170336, 'sts-b_test_prompt,bias,adapter_eval_corr': 0.6187641429245591, 'sts-b_dev_eval_loss': 2.186030864715576, 'sts-b_dev_eval_pearson': 0.808545677290489, 'sts-b_dev_eval_spearmanr': 0.8175661753345937, 'sts-b_dev_eval_corr': 0.8130559263125414, 'sts-b_test_eval_loss': 2.184372663497925, 'sts-b_test_eval_pearson': 0.6177344743320845, 'sts-b_test_eval_spearmanr': 0.6197938115170336, 'sts-b_test_eval_corr': 0.6187641429245591, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-13-roberta-large-30434', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_22-44-41_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-13-roberta-large-30434', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_eval_loss': 2.9508652687072754, 'sts-b_dev_eval_pearson': 0.21049707733436585, 'sts-b_dev_eval_spearmanr': 0.19401120924793958, 'sts-b_dev_eval_corr': 0.2022541432911527, 'sts-b_test_eval_loss': 2.8391613960266113, 'sts-b_test_eval_pearson': -0.06161700445355284, 'sts-b_test_eval_spearmanr': -0.13659844136455207, 'sts-b_test_eval_corr': -0.09910772290905245, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16--13-roberta-large-32532', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_23-18-28_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--13-roberta-large-32532', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': None, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias,adapter_eval_loss': 4.368994235992432, 'rte_dev_bias,adapter_eval_acc': 0.5625, 'rte_test_bias,adapter_eval_loss': 3.8237783908843994, 'rte_test_bias,adapter_eval_acc': 0.5379061371841155, 'rte_dev_eval_loss': 4.368994235992432, 'rte_dev_eval_acc': 0.5625, 'rte_test_eval_loss': 3.8237783908843994, 'rte_test_eval_acc': 0.5379061371841155, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--13-roberta-large-24673', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_23-13-47_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--13-roberta-large-24673', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.235327959060669, 'sts-b_dev_prompt_eval_pearson': 0.32826750968168694, 'sts-b_dev_prompt_eval_spearmanr': 0.35072670308173926, 'sts-b_dev_prompt_eval_corr': 0.3394971063817131, 'sts-b_test_prompt_eval_loss': 2.2533769607543945, 'sts-b_test_prompt_eval_pearson': -0.08768389398731449, 'sts-b_test_prompt_eval_spearmanr': -0.08439327443287023, 'sts-b_test_prompt_eval_corr': -0.08603858421009236, 'sts-b_dev_eval_loss': 2.235327959060669, 'sts-b_dev_eval_pearson': 0.32826750968168694, 'sts-b_dev_eval_spearmanr': 0.35072670308173926, 'sts-b_dev_eval_corr': 0.3394971063817131, 'sts-b_test_eval_loss': 2.2533769607543945, 'sts-b_test_eval_pearson': -0.08768389398731449, 'sts-b_test_eval_spearmanr': -0.08439327443287023, 'sts-b_test_eval_corr': -0.08603858421009236, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-13-roberta-large-25054', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_23-19-25_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-13-roberta-large-25054', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.243546724319458, 'sts-b_dev_prompt_eval_pearson': 0.25102280091853457, 'sts-b_dev_prompt_eval_spearmanr': 0.3257404109816258, 'sts-b_dev_prompt_eval_corr': 0.2883816059500802, 'sts-b_test_prompt_eval_loss': 2.242063522338867, 'sts-b_test_prompt_eval_pearson': 0.027309327543048816, 'sts-b_test_prompt_eval_spearmanr': 0.023391465430956174, 'sts-b_test_prompt_eval_corr': 0.025350396487002495, 'sts-b_dev_eval_loss': 2.243546724319458, 'sts-b_dev_eval_pearson': 0.25102280091853457, 'sts-b_dev_eval_spearmanr': 0.3257404109816258, 'sts-b_dev_eval_corr': 0.2883816059500802, 'sts-b_test_eval_loss': 2.242063522338867, 'sts-b_test_eval_pearson': 0.027309327543048816, 'sts-b_test_eval_spearmanr': 0.023391465430956174, 'sts-b_test_eval_corr': 0.025350396487002495, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-13-roberta-large-13551', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_23-33-51_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-13-roberta-large-13551', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias,adapter_eval_loss': 2.705571174621582, 'rte_dev_bias,adapter_eval_acc': 0.5625, 'rte_test_bias,adapter_eval_loss': 2.435206890106201, 'rte_test_bias,adapter_eval_acc': 0.5379061371841155, 'rte_dev_eval_loss': 2.705571174621582, 'rte_dev_eval_acc': 0.5625, 'rte_test_eval_loss': 2.435206890106201, 'rte_test_eval_acc': 0.5379061371841155, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--13-roberta-large-9690', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_23-31-42_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--13-roberta-large-9690', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_eval_loss': 0.9912174344062805, 'qnli_dev_eval_acc': 0.5, 'qnli_test_eval_loss': 0.926990270614624, 'qnli_test_eval_acc': 0.5063152114222954, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16--13-roberta-large-16538', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_00-01-49_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--13-roberta-large-16538', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': None, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.2553582191467285, 'sts-b_dev_prompt_eval_pearson': 0.19916391410585296, 'sts-b_dev_prompt_eval_spearmanr': 0.1840901815023063, 'sts-b_dev_prompt_eval_corr': 0.19162704780407963, 'sts-b_test_prompt_eval_loss': 2.2591872215270996, 'sts-b_test_prompt_eval_pearson': 0.045205192931758904, 'sts-b_test_prompt_eval_spearmanr': 0.07505255528657492, 'sts-b_test_prompt_eval_corr': 0.06012887410916691, 'sts-b_dev_eval_loss': 2.2553582191467285, 'sts-b_dev_eval_pearson': 0.19916391410585296, 'sts-b_dev_eval_spearmanr': 0.1840901815023063, 'sts-b_dev_eval_corr': 0.19162704780407963, 'sts-b_test_eval_loss': 2.2591872215270996, 'sts-b_test_eval_pearson': 0.045205192931758904, 'sts-b_test_eval_spearmanr': 0.07505255528657492, 'sts-b_test_eval_corr': 0.06012887410916691, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-13-roberta-large-9405', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_23-49-33_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-13-roberta-large-9405', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias,adapter_eval_loss': 0.7020252346992493, 'rte_dev_prompt,bias,adapter_eval_acc': 0.5, 'rte_test_prompt,bias,adapter_eval_loss': 0.7092300653457642, 'rte_test_prompt,bias,adapter_eval_acc': 0.4729241877256318, 'rte_dev_eval_loss': 0.7020252346992493, 'rte_dev_eval_acc': 0.5, 'rte_test_eval_loss': 0.7092300653457642, 'rte_test_eval_acc': 0.4729241877256318, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-13-roberta-large-2892', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan08_23-49-38_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-13-roberta-large-2892', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.240579605102539, 'sts-b_dev_prompt_eval_pearson': 0.3429112381376406, 'sts-b_dev_prompt_eval_spearmanr': 0.34907319845746704, 'sts-b_dev_prompt_eval_corr': 0.3459922182975538, 'sts-b_test_prompt_eval_loss': 2.2434163093566895, 'sts-b_test_prompt_eval_pearson': 0.0609704136656276, 'sts-b_test_prompt_eval_spearmanr': 0.059953787975906836, 'sts-b_test_prompt_eval_corr': 0.06046210082076722, 'sts-b_dev_eval_loss': 2.240579605102539, 'sts-b_dev_eval_pearson': 0.3429112381376406, 'sts-b_dev_eval_spearmanr': 0.34907319845746704, 'sts-b_dev_eval_corr': 0.3459922182975538, 'sts-b_test_eval_loss': 2.2434163093566895, 'sts-b_test_eval_pearson': 0.0609704136656276, 'sts-b_test_eval_spearmanr': 0.059953787975906836, 'sts-b_test_eval_corr': 0.06046210082076722, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-13-roberta-large-15269', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_00-04-37_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-13-roberta-large-15269', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_eval_loss': 0.9912174344062805, 'qnli_dev_eval_acc': 0.5, 'qnli_test_eval_loss': 0.926990270614624, 'qnli_test_eval_acc': 0.5063152114222954, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16--13-roberta-large-1080', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_00-20-40_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--13-roberta-large-1080', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': None, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias,adapter_eval_loss': 4.116728782653809, 'rte_dev_prompt,bias,adapter_eval_acc': 0.46875, 'rte_test_prompt,bias,adapter_eval_loss': 3.0849688053131104, 'rte_test_prompt,bias,adapter_eval_acc': 0.5126353790613718, 'rte_dev_eval_loss': 4.116728782653809, 'rte_dev_eval_acc': 0.46875, 'rte_test_eval_loss': 3.0849688053131104, 'rte_test_eval_acc': 0.5126353790613718, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-13-roberta-large-13999', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_00-08-55_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-13-roberta-large-13999', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt_eval_loss': 0.8458898067474365, 'qnli_dev_prompt_eval_acc': 0.59375, 'qnli_test_prompt_eval_loss': 0.9324705004692078, 'qnli_test_prompt_eval_acc': 0.5410946366465312, 'qnli_dev_eval_loss': 0.8458898067474365, 'qnli_dev_eval_acc': 0.59375, 'qnli_test_eval_loss': 0.9324705004692078, 'qnli_test_eval_acc': 0.5410946366465312, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-13-roberta-large-18070', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_00-21-58_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-13-roberta-large-18070', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias_eval_loss': 2.250558376312256, 'sts-b_dev_bias_eval_pearson': 0.23833976706900442, 'sts-b_dev_bias_eval_spearmanr': 0.20687180077005676, 'sts-b_dev_bias_eval_corr': 0.2226057839195306, 'sts-b_test_bias_eval_loss': 2.221667528152466, 'sts-b_test_bias_eval_pearson': -0.046676809161158024, 'sts-b_test_bias_eval_spearmanr': -0.0425730337483008, 'sts-b_test_bias_eval_corr': -0.04462492145472941, 'sts-b_dev_eval_loss': 2.250558376312256, 'sts-b_dev_eval_pearson': 0.23833976706900442, 'sts-b_dev_eval_spearmanr': 0.20687180077005676, 'sts-b_dev_eval_corr': 0.2226057839195306, 'sts-b_test_eval_loss': 2.221667528152466, 'sts-b_test_eval_pearson': -0.046676809161158024, 'sts-b_test_eval_spearmanr': -0.0425730337483008, 'sts-b_test_eval_corr': -0.04462492145472941, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16--13-roberta-large-11712', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_00-20-36_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--13-roberta-large-11712', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,bias_eval_loss': 1.6540504693984985, 'qqp_dev_prompt,bias_eval_acc': 0.71875, 'qqp_dev_prompt,bias_eval_f1': 0.7567567567567567, 'qqp_dev_prompt,bias_eval_acc_and_f1': 0.7377533783783783, 'qqp_test_prompt,bias_eval_loss': 1.711572527885437, 'qqp_test_prompt,bias_eval_acc': 0.6959188721246599, 'qqp_test_prompt,bias_eval_f1': 0.6618625887012486, 'qqp_test_prompt,bias_eval_acc_and_f1': 0.6788907304129542, 'qqp_dev_eval_loss': 1.6540504693984985, 'qqp_dev_eval_acc': 0.71875, 'qqp_dev_eval_f1': 0.7567567567567567, 'qqp_dev_eval_acc_and_f1': 0.7377533783783783, 'qqp_test_eval_loss': 1.711572527885437, 'qqp_test_eval_acc': 0.6959188721246599, 'qqp_test_eval_f1': 0.6618625887012486, 'qqp_test_eval_acc_and_f1': 0.6788907304129542, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-13-roberta-large-9305', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_00-25-57_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-13-roberta-large-9305', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias,adapter_eval_loss': 3.244677782058716, 'rte_dev_prompt,bias,adapter_eval_acc': 0.46875, 'rte_test_prompt,bias,adapter_eval_loss': 3.3226428031921387, 'rte_test_prompt,bias,adapter_eval_acc': 0.5487364620938628, 'rte_dev_eval_loss': 3.244677782058716, 'rte_dev_eval_acc': 0.46875, 'rte_test_eval_loss': 3.3226428031921387, 'rte_test_eval_acc': 0.5487364620938628, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-13-roberta-large-3821', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_00-27-57_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-13-roberta-large-3821', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt_eval_loss': 0.7544169425964355, 'qnli_dev_prompt_eval_acc': 0.625, 'qnli_test_prompt_eval_loss': 0.9475616216659546, 'qnli_test_prompt_eval_acc': 0.52462017206663, 'qnli_dev_eval_loss': 0.7544169425964355, 'qnli_dev_eval_acc': 0.625, 'qnli_test_eval_loss': 0.9475616216659546, 'qnli_test_eval_acc': 0.52462017206663, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-13-roberta-large-24095', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_00-35-19_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-13-roberta-large-24095', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt_eval_loss': 0.16729730367660522, 'sst-2_dev_prompt_eval_acc': 0.96875, 'sst-2_test_prompt_eval_loss': 0.3798552453517914, 'sst-2_test_prompt_eval_acc': 0.911697247706422, 'sst-2_dev_eval_loss': 0.16729730367660522, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.3798552453517914, 'sst-2_test_eval_acc': 0.911697247706422, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-9402', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_00-48-15_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-9402', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt_eval_loss': 1.416487455368042, 'qnli_dev_prompt_eval_acc': 0.65625, 'qnli_test_prompt_eval_loss': 2.209779977798462, 'qnli_test_prompt_eval_acc': 0.551528464213802, 'qnli_dev_eval_loss': 1.416487455368042, 'qnli_dev_eval_acc': 0.65625, 'qnli_test_eval_loss': 2.209779977798462, 'qnli_test_eval_acc': 0.551528464213802, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-13-roberta-large-21504', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_00-48-39_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-13-roberta-large-21504', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias_eval_loss': 2.189401626586914, 'sts-b_dev_bias_eval_pearson': 0.8562673108960106, 'sts-b_dev_bias_eval_spearmanr': 0.8506362678200381, 'sts-b_dev_bias_eval_corr': 0.8534517893580243, 'sts-b_test_bias_eval_loss': 2.173025608062744, 'sts-b_test_bias_eval_pearson': 0.7502607726141791, 'sts-b_test_bias_eval_spearmanr': 0.7552230981529147, 'sts-b_test_bias_eval_corr': 0.752741935383547, 'sts-b_dev_eval_loss': 2.189401626586914, 'sts-b_dev_eval_pearson': 0.8562673108960106, 'sts-b_dev_eval_spearmanr': 0.8506362678200381, 'sts-b_dev_eval_corr': 0.8534517893580243, 'sts-b_test_eval_loss': 2.173025608062744, 'sts-b_test_eval_pearson': 0.7502607726141791, 'sts-b_test_eval_spearmanr': 0.7552230981529147, 'sts-b_test_eval_corr': 0.752741935383547, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16--13-roberta-large-26130', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_00-40-47_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--13-roberta-large-26130', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,bias_eval_loss': 1.7442455291748047, 'qqp_dev_prompt,bias_eval_acc': 0.71875, 'qqp_dev_prompt,bias_eval_f1': 0.7692307692307693, 'qqp_dev_prompt,bias_eval_acc_and_f1': 0.7439903846153846, 'qqp_test_prompt,bias_eval_loss': 1.8490715026855469, 'qqp_test_prompt,bias_eval_acc': 0.6813010140984418, 'qqp_test_prompt,bias_eval_f1': 0.664741237998595, 'qqp_test_prompt,bias_eval_acc_and_f1': 0.6730211260485184, 'qqp_dev_eval_loss': 1.7442455291748047, 'qqp_dev_eval_acc': 0.71875, 'qqp_dev_eval_f1': 0.7692307692307693, 'qqp_dev_eval_acc_and_f1': 0.7439903846153846, 'qqp_test_eval_loss': 1.8490715026855469, 'qqp_test_eval_acc': 0.6813010140984418, 'qqp_test_eval_f1': 0.664741237998595, 'qqp_test_eval_acc_and_f1': 0.6730211260485184, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-13-roberta-large-25725', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_00-42-33_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-13-roberta-large-25725', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias,adapter_eval_loss': 3.9212779998779297, 'rte_dev_prompt,bias,adapter_eval_acc': 0.46875, 'rte_test_prompt,bias,adapter_eval_loss': 3.6477768421173096, 'rte_test_prompt,bias,adapter_eval_acc': 0.5234657039711191, 'rte_dev_eval_loss': 3.9212779998779297, 'rte_dev_eval_acc': 0.46875, 'rte_test_eval_loss': 3.6477768421173096, 'rte_test_eval_acc': 0.5234657039711191, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-13-roberta-large-1662', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_00-47-16_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-13-roberta-large-1662', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt_eval_loss': 0.16801568865776062, 'sst-2_dev_prompt_eval_acc': 0.96875, 'sst-2_test_prompt_eval_loss': 0.5239762663841248, 'sst-2_test_prompt_eval_acc': 0.9036697247706422, 'sst-2_dev_eval_loss': 0.16801568865776062, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.5239762663841248, 'sst-2_test_eval_acc': 0.9036697247706422, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-24744', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_00-59-27_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-24744', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt_eval_loss': 0.6917264461517334, 'qnli_dev_prompt_eval_acc': 0.65625, 'qnli_test_prompt_eval_loss': 0.7215501666069031, 'qnli_test_prompt_eval_acc': 0.5290133626212704, 'qnli_dev_eval_loss': 0.6917264461517334, 'qnli_dev_eval_acc': 0.65625, 'qnli_test_eval_loss': 0.7215501666069031, 'qnli_test_eval_acc': 0.5290133626212704, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-13-roberta-large-8653', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_01-02-01_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-13-roberta-large-8653', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt_eval_loss': 0.2072182595729828, 'sst-2_dev_prompt_eval_acc': 0.9375, 'sst-2_test_prompt_eval_loss': 0.24872571229934692, 'sst-2_test_prompt_eval_acc': 0.8967889908256881, 'sst-2_dev_eval_loss': 0.2072182595729828, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.24872571229934692, 'sst-2_test_eval_acc': 0.8967889908256881, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-5677', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_01-10-41_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-5677', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias_eval_loss': 2.181473970413208, 'sts-b_dev_bias_eval_pearson': 0.86012111749667, 'sts-b_dev_bias_eval_spearmanr': 0.8493502086678263, 'sts-b_dev_bias_eval_corr': 0.8547356630822481, 'sts-b_test_bias_eval_loss': 2.1794841289520264, 'sts-b_test_bias_eval_pearson': 0.6585009446064464, 'sts-b_test_bias_eval_spearmanr': 0.6509414085638957, 'sts-b_test_bias_eval_corr': 0.654721176585171, 'sts-b_dev_eval_loss': 2.181473970413208, 'sts-b_dev_eval_pearson': 0.86012111749667, 'sts-b_dev_eval_spearmanr': 0.8493502086678263, 'sts-b_dev_eval_corr': 0.8547356630822481, 'sts-b_test_eval_loss': 2.1794841289520264, 'sts-b_test_eval_pearson': 0.6585009446064464, 'sts-b_test_eval_spearmanr': 0.6509414085638957, 'sts-b_test_eval_corr': 0.654721176585171, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16--13-roberta-large-7852', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_01-02-10_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--13-roberta-large-7852', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt_eval_loss': 3.504974842071533, 'rte_dev_prompt_eval_acc': 0.65625, 'rte_test_prompt_eval_loss': 4.377663612365723, 'rte_test_prompt_eval_acc': 0.5270758122743683, 'rte_dev_eval_loss': 3.504974842071533, 'rte_dev_eval_acc': 0.65625, 'rte_test_eval_loss': 4.377663612365723, 'rte_test_eval_acc': 0.5270758122743683, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-42-roberta-large-28438', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_01-15-30_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-42-roberta-large-28438', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias_eval_loss': 2.767548084259033, 'qnli_dev_bias_eval_acc': 0.71875, 'qnli_test_bias_eval_loss': 4.096767425537109, 'qnli_test_bias_eval_acc': 0.5460369760205016, 'qnli_dev_eval_loss': 2.767548084259033, 'qnli_dev_eval_acc': 0.71875, 'qnli_test_eval_loss': 4.096767425537109, 'qnli_test_eval_acc': 0.5460369760205016, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16--13-roberta-large-8772', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_01-15-50_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--13-roberta-large-8772', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias,adapter_eval_loss': 0.70522141456604, 'qqp_dev_bias,adapter_eval_acc': 0.5, 'qqp_dev_bias,adapter_eval_f1': 0.6666666666666666, 'qqp_dev_bias,adapter_eval_acc_and_f1': 0.5833333333333333, 'qqp_test_bias,adapter_eval_loss': 0.7462277412414551, 'qqp_test_bias,adapter_eval_acc': 0.36816720257234725, 'qqp_test_bias,adapter_eval_f1': 0.5381903642773208, 'qqp_test_bias,adapter_eval_acc_and_f1': 0.45317878342483403, 'qqp_dev_eval_loss': 0.70522141456604, 'qqp_dev_eval_acc': 0.5, 'qqp_dev_eval_f1': 0.6666666666666666, 'qqp_dev_eval_acc_and_f1': 0.5833333333333333, 'qqp_test_eval_loss': 0.7462277412414551, 'qqp_test_eval_acc': 0.36816720257234725, 'qqp_test_eval_f1': 0.5381903642773208, 'qqp_test_eval_acc_and_f1': 0.45317878342483403, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16--13-roberta-large-27372', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_01-04-03_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--13-roberta-large-27372', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt_eval_loss': 0.6875870227813721, 'mrpc_dev_prompt_eval_acc': 0.625, 'mrpc_dev_prompt_eval_f1': 0.6666666666666665, 'mrpc_dev_prompt_eval_acc_and_f1': 0.6458333333333333, 'mrpc_test_prompt_eval_loss': 0.8035022616386414, 'mrpc_test_prompt_eval_acc': 0.5343137254901961, 'mrpc_test_prompt_eval_f1': 0.6494464944649446, 'mrpc_test_prompt_eval_acc_and_f1': 0.5918801099775703, 'mrpc_dev_eval_loss': 0.6875870227813721, 'mrpc_dev_eval_acc': 0.625, 'mrpc_dev_eval_f1': 0.6666666666666665, 'mrpc_dev_eval_acc_and_f1': 0.6458333333333333, 'mrpc_test_eval_loss': 0.8035022616386414, 'mrpc_test_eval_acc': 0.5343137254901961, 'mrpc_test_eval_f1': 0.6494464944649446, 'mrpc_test_eval_acc_and_f1': 0.5918801099775703, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-42-roberta-large-20184', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_01-24-53_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-42-roberta-large-20184', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt_eval_loss': 0.2670031785964966, 'sst-2_dev_prompt_eval_acc': 0.96875, 'sst-2_test_prompt_eval_loss': 0.44346490502357483, 'sst-2_test_prompt_eval_acc': 0.8715596330275229, 'sst-2_dev_eval_loss': 0.2670031785964966, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.44346490502357483, 'sst-2_test_eval_acc': 0.8715596330275229, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-23390', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_01-21-04_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-23390', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt_eval_loss': 0.9573516249656677, 'cola_dev_prompt_eval_mcc': 0.43033148291193524, 'cola_test_prompt_eval_loss': 1.2278752326965332, 'cola_test_prompt_eval_mcc': -0.04527072126948271, 'cola_dev_eval_loss': 0.9573516249656677, 'cola_dev_eval_mcc': 0.43033148291193524, 'cola_test_eval_loss': 1.2278752326965332, 'cola_test_eval_mcc': -0.04527072126948271, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-13315', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_01-27-51_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-13315', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt_eval_loss': 2.6356329917907715, 'rte_dev_prompt_eval_acc': 0.5625, 'rte_test_prompt_eval_loss': 2.112614870071411, 'rte_test_prompt_eval_acc': 0.5270758122743683, 'rte_dev_eval_loss': 2.6356329917907715, 'rte_dev_eval_acc': 0.5625, 'rte_test_eval_loss': 2.112614870071411, 'rte_test_eval_acc': 0.5270758122743683, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-42-roberta-large-24031', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_01-27-17_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-42-roberta-large-24031', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt_eval_loss': 0.8037806749343872, 'mrpc_dev_prompt_eval_acc': 0.8125, 'mrpc_dev_prompt_eval_f1': 0.8421052631578948, 'mrpc_dev_prompt_eval_acc_and_f1': 0.8273026315789473, 'mrpc_test_prompt_eval_loss': 1.0470126867294312, 'mrpc_test_prompt_eval_acc': 0.6642156862745098, 'mrpc_test_prompt_eval_f1': 0.781499202551834, 'mrpc_test_prompt_eval_acc_and_f1': 0.7228574444131719, 'mrpc_dev_eval_loss': 0.8037806749343872, 'mrpc_dev_eval_acc': 0.8125, 'mrpc_dev_eval_f1': 0.8421052631578948, 'mrpc_dev_eval_acc_and_f1': 0.8273026315789473, 'mrpc_test_eval_loss': 1.0470126867294312, 'mrpc_test_eval_acc': 0.6642156862745098, 'mrpc_test_eval_f1': 0.781499202551834, 'mrpc_test_eval_acc_and_f1': 0.7228574444131719, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-42-roberta-large-32705', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_01-32-23_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-42-roberta-large-32705', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt_eval_loss': 0.8738276958465576, 'cola_dev_prompt_eval_mcc': 0.2519763153394848, 'cola_test_prompt_eval_loss': 0.8503334522247314, 'cola_test_prompt_eval_mcc': 0.030244259774947366, 'cola_dev_eval_loss': 0.8738276958465576, 'cola_dev_eval_mcc': 0.2519763153394848, 'cola_test_eval_loss': 0.8503334522247314, 'cola_test_eval_mcc': 0.030244259774947366, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-18953', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_01-35-40_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-18953', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt_eval_loss': 0.11109410226345062, 'sst-2_dev_prompt_eval_acc': 0.96875, 'sst-2_test_prompt_eval_loss': 0.5559222102165222, 'sst-2_test_prompt_eval_acc': 0.9002293577981652, 'sst-2_dev_eval_loss': 0.11109410226345062, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.5559222102165222, 'sst-2_test_eval_acc': 0.9002293577981652, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-3065', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_01-33-23_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-3065', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt_eval_loss': 1.0620310306549072, 'mnli_dev_prompt_eval_mnli/acc': 0.6458333333333334, 'mnli_test_prompt_eval_loss': 1.2720341682434082, 'mnli_test_prompt_eval_mnli/acc': 0.50952623535405, 'mnli-mm_test_prompt_eval_loss': 1.2206417322158813, 'mnli-mm_test_prompt_eval_mnli-mm/acc': 0.5184092758340114, 'mnli_dev_eval_loss': 1.0620310306549072, 'mnli_dev_eval_mnli/acc': 0.6458333333333334, 'mnli_test_eval_loss': 1.2720341682434082, 'mnli_test_eval_mnli/acc': 0.50952623535405, 'mnli-mm_test_eval_loss': 1.2206417322158813, 'mnli-mm_test_eval_mnli-mm/acc': 0.5184092758340114, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-13272', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_01-04-56_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-13272', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias_eval_loss': 3.3436543941497803, 'qnli_dev_bias_eval_acc': 0.71875, 'qnli_test_bias_eval_loss': 3.6672823429107666, 'qnli_test_bias_eval_acc': 0.6479956068094453, 'qnli_dev_eval_loss': 3.3436543941497803, 'qnli_dev_eval_acc': 0.71875, 'qnli_test_eval_loss': 3.6672823429107666, 'qnli_test_eval_acc': 0.6479956068094453, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16--13-roberta-large-4040', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_01-31-33_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--13-roberta-large-4040', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt_eval_loss': 0.6556525230407715, 'mrpc_dev_prompt_eval_acc': 0.59375, 'mrpc_dev_prompt_eval_f1': 0.6976744186046512, 'mrpc_dev_prompt_eval_acc_and_f1': 0.6457122093023255, 'mrpc_test_prompt_eval_loss': 0.6850574016571045, 'mrpc_test_prompt_eval_acc': 0.6568627450980392, 'mrpc_test_prompt_eval_f1': 0.7666666666666667, 'mrpc_test_prompt_eval_acc_and_f1': 0.711764705882353, 'mrpc_dev_eval_loss': 0.6556525230407715, 'mrpc_dev_eval_acc': 0.59375, 'mrpc_dev_eval_f1': 0.6976744186046512, 'mrpc_dev_eval_acc_and_f1': 0.6457122093023255, 'mrpc_test_eval_loss': 0.6850574016571045, 'mrpc_test_eval_acc': 0.6568627450980392, 'mrpc_test_eval_f1': 0.7666666666666667, 'mrpc_test_eval_acc_and_f1': 0.711764705882353, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-42-roberta-large-4886', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_01-39-59_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-42-roberta-large-4886', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt_eval_loss': 0.8191368579864502, 'cola_dev_prompt_eval_mcc': 0.0657951694959769, 'cola_test_prompt_eval_loss': 0.8389585018157959, 'cola_test_prompt_eval_mcc': -0.01970272901437814, 'cola_dev_eval_loss': 0.8191368579864502, 'cola_dev_eval_mcc': 0.0657951694959769, 'cola_test_eval_loss': 0.8389585018157959, 'cola_test_eval_mcc': -0.01970272901437814, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-6088', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_01-43-02_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-6088', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias_eval_loss': 2.1809771060943604, 'sts-b_dev_bias_eval_pearson': 0.8447151814117624, 'sts-b_dev_bias_eval_spearmanr': 0.8245476393037432, 'sts-b_dev_bias_eval_corr': 0.8346314103577528, 'sts-b_test_bias_eval_loss': 2.185161828994751, 'sts-b_test_bias_eval_pearson': 0.5957580499587875, 'sts-b_test_bias_eval_spearmanr': 0.5790525691642173, 'sts-b_test_bias_eval_corr': 0.5874053095615024, 'sts-b_dev_eval_loss': 2.1809771060943604, 'sts-b_dev_eval_pearson': 0.8447151814117624, 'sts-b_dev_eval_spearmanr': 0.8245476393037432, 'sts-b_dev_eval_corr': 0.8346314103577528, 'sts-b_test_eval_loss': 2.185161828994751, 'sts-b_test_eval_pearson': 0.5957580499587875, 'sts-b_test_eval_spearmanr': 0.5790525691642173, 'sts-b_test_eval_corr': 0.5874053095615024, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16--13-roberta-large-13985', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_01-26-12_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--13-roberta-large-13985', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt_eval_loss': 3.594897747039795, 'rte_dev_prompt_eval_acc': 0.53125, 'rte_test_prompt_eval_loss': 3.374457836151123, 'rte_test_prompt_eval_acc': 0.4981949458483754, 'rte_dev_eval_loss': 3.594897747039795, 'rte_dev_eval_acc': 0.53125, 'rte_test_eval_loss': 3.374457836151123, 'rte_test_eval_acc': 0.4981949458483754, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-42-roberta-large-9591', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_01-39-12_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-42-roberta-large-9591', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt_eval_loss': 0.7999424934387207, 'mrpc_dev_prompt_eval_acc': 0.65625, 'mrpc_dev_prompt_eval_f1': 0.6857142857142857, 'mrpc_dev_prompt_eval_acc_and_f1': 0.6709821428571429, 'mrpc_test_prompt_eval_loss': 0.7924759984016418, 'mrpc_test_prompt_eval_acc': 0.6470588235294118, 'mrpc_test_prompt_eval_f1': 0.740072202166065, 'mrpc_test_prompt_eval_acc_and_f1': 0.6935655128477384, 'mrpc_dev_eval_loss': 0.7999424934387207, 'mrpc_dev_eval_acc': 0.65625, 'mrpc_dev_eval_f1': 0.6857142857142857, 'mrpc_dev_eval_acc_and_f1': 0.6709821428571429, 'mrpc_test_eval_loss': 0.7924759984016418, 'mrpc_test_eval_acc': 0.6470588235294118, 'mrpc_test_eval_f1': 0.740072202166065, 'mrpc_test_eval_acc_and_f1': 0.6935655128477384, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-42-roberta-large-20036', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_01-47-51_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-42-roberta-large-20036', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt_eval_loss': 1.0666062831878662, 'cola_dev_prompt_eval_mcc': 0.14433756729740646, 'cola_test_prompt_eval_loss': 1.3832719326019287, 'cola_test_prompt_eval_mcc': 0.036106614142396874, 'cola_dev_eval_loss': 1.0666062831878662, 'cola_dev_eval_mcc': 0.14433756729740646, 'cola_test_eval_loss': 1.3832719326019287, 'cola_test_eval_mcc': 0.036106614142396874, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-14931', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_01-50-22_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-14931', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt_eval_loss': 0.02530069090425968, 'sst-2_dev_prompt_eval_acc': 1.0, 'sst-2_test_prompt_eval_loss': 0.41334983706474304, 'sst-2_test_prompt_eval_acc': 0.9174311926605505, 'sst-2_dev_eval_loss': 0.02530069090425968, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.41334983706474304, 'sst-2_test_eval_acc': 0.9174311926605505, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-9895', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_01-43-55_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-9895', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias_eval_loss': 2.3268933296203613, 'qnli_dev_bias_eval_acc': 0.65625, 'qnli_test_bias_eval_loss': 2.3586277961730957, 'qnli_test_bias_eval_acc': 0.6093721398498994, 'qnli_dev_eval_loss': 2.3268933296203613, 'qnli_dev_eval_acc': 0.65625, 'qnli_test_eval_loss': 2.3586277961730957, 'qnli_test_eval_acc': 0.6093721398498994, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16--13-roberta-large-27738', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_01-47-09_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--13-roberta-large-27738', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt_eval_loss': 1.3517554998397827, 'rte_dev_prompt_eval_acc': 0.4375, 'rte_test_prompt_eval_loss': 1.0697972774505615, 'rte_test_prompt_eval_acc': 0.51985559566787, 'rte_dev_eval_loss': 1.3517554998397827, 'rte_dev_eval_acc': 0.4375, 'rte_test_eval_loss': 1.0697972774505615, 'rte_test_eval_acc': 0.51985559566787, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-42-roberta-large-1454', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_01-51-08_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-42-roberta-large-1454', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt_eval_loss': 0.5943730473518372, 'mrpc_dev_prompt_eval_acc': 0.6875, 'mrpc_dev_prompt_eval_f1': 0.7368421052631579, 'mrpc_dev_prompt_eval_acc_and_f1': 0.712171052631579, 'mrpc_test_prompt_eval_loss': 0.7877968549728394, 'mrpc_test_prompt_eval_acc': 0.5490196078431373, 'mrpc_test_prompt_eval_f1': 0.667870036101083, 'mrpc_test_prompt_eval_acc_and_f1': 0.6084448219721101, 'mrpc_dev_eval_loss': 0.5943730473518372, 'mrpc_dev_eval_acc': 0.6875, 'mrpc_dev_eval_f1': 0.7368421052631579, 'mrpc_dev_eval_acc_and_f1': 0.712171052631579, 'mrpc_test_eval_loss': 0.7877968549728394, 'mrpc_test_eval_acc': 0.5490196078431373, 'mrpc_test_eval_f1': 0.667870036101083, 'mrpc_test_eval_acc_and_f1': 0.6084448219721101, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-100-roberta-large-18501', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_01-55-37_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-100-roberta-large-18501', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt_eval_loss': 1.0791095495224, 'cola_dev_prompt_eval_mcc': 0.3216337604513384, 'cola_test_prompt_eval_loss': 1.121111512184143, 'cola_test_prompt_eval_mcc': -0.002000486664258994, 'cola_dev_eval_loss': 1.0791095495224, 'cola_dev_eval_mcc': 0.3216337604513384, 'cola_test_eval_loss': 1.121111512184143, 'cola_test_eval_mcc': -0.002000486664258994, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-19615', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_01-57-42_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-19615', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias,adapter_eval_loss': 2.377521276473999, 'qqp_dev_bias,adapter_eval_acc': 0.75, 'qqp_dev_bias,adapter_eval_f1': 0.7333333333333334, 'qqp_dev_bias,adapter_eval_acc_and_f1': 0.7416666666666667, 'qqp_test_bias,adapter_eval_loss': 2.7577626705169678, 'qqp_test_bias,adapter_eval_acc': 0.759683403413307, 'qqp_test_bias,adapter_eval_f1': 0.6588003933136677, 'qqp_test_bias,adapter_eval_acc_and_f1': 0.7092418983634874, 'qqp_dev_eval_loss': 2.377521276473999, 'qqp_dev_eval_acc': 0.75, 'qqp_dev_eval_f1': 0.7333333333333334, 'qqp_dev_eval_acc_and_f1': 0.7416666666666667, 'qqp_test_eval_loss': 2.7577626705169678, 'qqp_test_eval_acc': 0.759683403413307, 'qqp_test_eval_f1': 0.6588003933136677, 'qqp_test_eval_acc_and_f1': 0.7092418983634874, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16--13-roberta-large-8176', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_01-32-22_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--13-roberta-large-8176', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_adapter_eval_loss': 2.2410202026367188, 'sts-b_dev_adapter_eval_pearson': 0.47927869344927787, 'sts-b_dev_adapter_eval_spearmanr': 0.6086734244682044, 'sts-b_dev_adapter_eval_corr': 0.5439760589587411, 'sts-b_test_adapter_eval_loss': 2.212540626525879, 'sts-b_test_adapter_eval_pearson': 0.01852168893130063, 'sts-b_test_adapter_eval_spearmanr': 0.01286394792080222, 'sts-b_test_adapter_eval_corr': 0.015692818426051424, 'sts-b_dev_eval_loss': 2.2410202026367188, 'sts-b_dev_eval_pearson': 0.47927869344927787, 'sts-b_dev_eval_spearmanr': 0.6086734244682044, 'sts-b_dev_eval_corr': 0.5439760589587411, 'sts-b_test_eval_loss': 2.212540626525879, 'sts-b_test_eval_pearson': 0.01852168893130063, 'sts-b_test_eval_spearmanr': 0.01286394792080222, 'sts-b_test_eval_corr': 0.015692818426051424, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--13-roberta-large-17618', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_01-50-35_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--13-roberta-large-17618', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt_eval_loss': 0.6812573671340942, 'mrpc_dev_prompt_eval_acc': 0.65625, 'mrpc_dev_prompt_eval_f1': 0.6666666666666667, 'mrpc_dev_prompt_eval_acc_and_f1': 0.6614583333333334, 'mrpc_test_prompt_eval_loss': 0.7875258326530457, 'mrpc_test_prompt_eval_acc': 0.5563725490196079, 'mrpc_test_prompt_eval_f1': 0.6429980276134122, 'mrpc_test_prompt_eval_acc_and_f1': 0.59968528831651, 'mrpc_dev_eval_loss': 0.6812573671340942, 'mrpc_dev_eval_acc': 0.65625, 'mrpc_dev_eval_f1': 0.6666666666666667, 'mrpc_dev_eval_acc_and_f1': 0.6614583333333334, 'mrpc_test_eval_loss': 0.7875258326530457, 'mrpc_test_eval_acc': 0.5563725490196079, 'mrpc_test_eval_f1': 0.6429980276134122, 'mrpc_test_eval_acc_and_f1': 0.59968528831651, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-100-roberta-large-548', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_02-03-15_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-100-roberta-large-548', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt_eval_loss': 3.6822099685668945, 'cola_dev_prompt_eval_mcc': 0.19738550848793068, 'cola_test_prompt_eval_loss': 4.980454921722412, 'cola_test_prompt_eval_mcc': -0.0074760356833829, 'cola_dev_eval_loss': 3.6822099685668945, 'cola_dev_eval_mcc': 0.19738550848793068, 'cola_test_eval_loss': 4.980454921722412, 'cola_test_eval_mcc': -0.0074760356833829, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-16970', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_02-05-21_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-16970', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt_eval_loss': 0.6077696084976196, 'rte_dev_prompt_eval_acc': 0.75, 'rte_test_prompt_eval_loss': 0.8434655070304871, 'rte_test_prompt_eval_acc': 0.5270758122743683, 'rte_dev_eval_loss': 0.6077696084976196, 'rte_dev_eval_acc': 0.75, 'rte_test_eval_loss': 0.8434655070304871, 'rte_test_eval_acc': 0.5270758122743683, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-100-roberta-large-21135', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_02-02-55_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-100-roberta-large-21135', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt_eval_loss': 1.1669584512710571, 'mrpc_dev_prompt_eval_acc': 0.65625, 'mrpc_dev_prompt_eval_f1': 0.6451612903225806, 'mrpc_dev_prompt_eval_acc_and_f1': 0.6507056451612903, 'mrpc_test_prompt_eval_loss': 1.359929084777832, 'mrpc_test_prompt_eval_acc': 0.5931372549019608, 'mrpc_test_prompt_eval_f1': 0.6612244897959184, 'mrpc_test_prompt_eval_acc_and_f1': 0.6271808723489396, 'mrpc_dev_eval_loss': 1.1669584512710571, 'mrpc_dev_eval_acc': 0.65625, 'mrpc_dev_eval_f1': 0.6451612903225806, 'mrpc_dev_eval_acc_and_f1': 0.6507056451612903, 'mrpc_test_eval_loss': 1.359929084777832, 'mrpc_test_eval_acc': 0.5931372549019608, 'mrpc_test_eval_f1': 0.6612244897959184, 'mrpc_test_eval_acc_and_f1': 0.6271808723489396, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-100-roberta-large-31146', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_02-10-36_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-100-roberta-large-31146', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias_eval_loss': 2.29695200920105, 'qnli_dev_bias_eval_acc': 0.6875, 'qnli_test_bias_eval_loss': 2.2291016578674316, 'qnli_test_bias_eval_acc': 0.6124839831594362, 'qnli_dev_eval_loss': 2.29695200920105, 'qnli_dev_eval_acc': 0.6875, 'qnli_test_eval_loss': 2.2291016578674316, 'qnli_test_eval_acc': 0.6124839831594362, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16--13-roberta-large-13319', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_02-02-44_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--13-roberta-large-13319', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt_eval_loss': 1.0887852907180786, 'mnli_dev_prompt_eval_mnli/acc': 0.5625, 'mnli_test_prompt_eval_loss': 1.2287945747375488, 'mnli_test_prompt_eval_mnli/acc': 0.4793683138053999, 'mnli-mm_test_prompt_eval_loss': 1.2633755207061768, 'mnli-mm_test_prompt_eval_mnli-mm/acc': 0.4997965825874695, 'mnli_dev_eval_loss': 1.0887852907180786, 'mnli_dev_eval_mnli/acc': 0.5625, 'mnli_test_eval_loss': 1.2287945747375488, 'mnli_test_eval_mnli/acc': 0.4793683138053999, 'mnli-mm_test_eval_loss': 1.2633755207061768, 'mnli-mm_test_eval_mnli-mm/acc': 0.4997965825874695, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-12484', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_01-46-57_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-12484', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt_eval_loss': 0.01753220148384571, 'sst-2_dev_prompt_eval_acc': 1.0, 'sst-2_test_prompt_eval_loss': 0.52085942029953, 'sst-2_test_prompt_eval_acc': 0.9243119266055045, 'sst-2_dev_eval_loss': 0.01753220148384571, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.52085942029953, 'sst-2_test_eval_acc': 0.9243119266055045, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-25084', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_02-01-25_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-25084', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt_eval_loss': 0.6869027614593506, 'cola_dev_prompt_eval_mcc': 0.4605661864718383, 'cola_test_prompt_eval_loss': 0.9068281650543213, 'cola_test_prompt_eval_mcc': 0.012581519744777373, 'cola_dev_eval_loss': 0.6869027614593506, 'cola_dev_eval_mcc': 0.4605661864718383, 'cola_test_eval_loss': 0.9068281650543213, 'cola_test_eval_mcc': 0.012581519744777373, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-17033', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_02-13-09_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-17033', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt_eval_loss': 0.7857550382614136, 'mrpc_dev_prompt_eval_acc': 0.625, 'mrpc_dev_prompt_eval_f1': 0.6470588235294118, 'mrpc_dev_prompt_eval_acc_and_f1': 0.6360294117647058, 'mrpc_test_prompt_eval_loss': 0.8701316118240356, 'mrpc_test_prompt_eval_acc': 0.5245098039215687, 'mrpc_test_prompt_eval_f1': 0.6072874493927126, 'mrpc_test_prompt_eval_acc_and_f1': 0.5658986266571406, 'mrpc_dev_eval_loss': 0.7857550382614136, 'mrpc_dev_eval_acc': 0.625, 'mrpc_dev_eval_f1': 0.6470588235294118, 'mrpc_dev_eval_acc_and_f1': 0.6360294117647058, 'mrpc_test_eval_loss': 0.8701316118240356, 'mrpc_test_eval_acc': 0.5245098039215687, 'mrpc_test_eval_f1': 0.6072874493927126, 'mrpc_test_eval_acc_and_f1': 0.5658986266571406, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-100-roberta-large-18453', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_02-18-02_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-100-roberta-large-18453', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt_eval_loss': 1.0623546838760376, 'rte_dev_prompt_eval_acc': 0.65625, 'rte_test_prompt_eval_loss': 1.2883570194244385, 'rte_test_prompt_eval_acc': 0.5667870036101083, 'rte_dev_eval_loss': 1.0623546838760376, 'rte_dev_eval_acc': 0.65625, 'rte_test_eval_loss': 1.2883570194244385, 'rte_test_eval_acc': 0.5667870036101083, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-100-roberta-large-11194', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_02-15-03_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-100-roberta-large-11194', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_adapter_eval_loss': 2.1816186904907227, 'sts-b_dev_adapter_eval_pearson': 0.8650941570617047, 'sts-b_dev_adapter_eval_spearmanr': 0.8581688999972782, 'sts-b_dev_adapter_eval_corr': 0.8616315285294914, 'sts-b_test_adapter_eval_loss': 2.1736221313476562, 'sts-b_test_adapter_eval_pearson': 0.7209266124659227, 'sts-b_test_adapter_eval_spearmanr': 0.7264207536495713, 'sts-b_test_adapter_eval_corr': 0.723673683057747, 'sts-b_dev_eval_loss': 2.1816186904907227, 'sts-b_dev_eval_pearson': 0.8650941570617047, 'sts-b_dev_eval_spearmanr': 0.8581688999972782, 'sts-b_dev_eval_corr': 0.8616315285294914, 'sts-b_test_eval_loss': 2.1736221313476562, 'sts-b_test_eval_pearson': 0.7209266124659227, 'sts-b_test_eval_spearmanr': 0.7264207536495713, 'sts-b_test_eval_corr': 0.723673683057747, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--13-roberta-large-16908', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_02-10-12_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--13-roberta-large-16908', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt_eval_loss': 0.8675091862678528, 'cola_dev_prompt_eval_mcc': 0.43033148291193524, 'cola_test_prompt_eval_loss': 1.2714802026748657, 'cola_test_prompt_eval_mcc': -0.00549689055149894, 'cola_dev_eval_loss': 0.8675091862678528, 'cola_dev_eval_mcc': 0.43033148291193524, 'cola_test_eval_loss': 1.2714802026748657, 'cola_test_eval_mcc': -0.00549689055149894, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-19470', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_02-20-23_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-19470', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_adapter_eval_loss': 3.909095048904419, 'qnli_dev_adapter_eval_acc': 0.6875, 'qnli_test_adapter_eval_loss': 4.635339260101318, 'qnli_test_adapter_eval_acc': 0.6523887973640856, 'qnli_dev_eval_loss': 3.909095048904419, 'qnli_dev_eval_acc': 0.6875, 'qnli_test_eval_loss': 4.635339260101318, 'qnli_test_eval_acc': 0.6523887973640856, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--13-roberta-large-7206', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_02-18-20_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--13-roberta-large-7206', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias_eval_loss': 4.889605522155762, 'mrpc_dev_bias_eval_acc': 0.625, 'mrpc_dev_bias_eval_f1': 0.6842105263157896, 'mrpc_dev_bias_eval_acc_and_f1': 0.6546052631578948, 'mrpc_test_bias_eval_loss': 4.439940929412842, 'mrpc_test_bias_eval_acc': 0.6299019607843137, 'mrpc_test_bias_eval_f1': 0.7249544626593807, 'mrpc_test_bias_eval_acc_and_f1': 0.6774282117218472, 'mrpc_dev_eval_loss': 4.889605522155762, 'mrpc_dev_eval_acc': 0.625, 'mrpc_dev_eval_f1': 0.6842105263157896, 'mrpc_dev_eval_acc_and_f1': 0.6546052631578948, 'mrpc_test_eval_loss': 4.439940929412842, 'mrpc_test_eval_acc': 0.6299019607843137, 'mrpc_test_eval_f1': 0.7249544626593807, 'mrpc_test_eval_acc_and_f1': 0.6774282117218472, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16--42-roberta-large-30926', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_02-25-27_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--42-roberta-large-30926', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt_eval_loss': 0.051293183118104935, 'sst-2_dev_prompt_eval_acc': 1.0, 'sst-2_test_prompt_eval_loss': 0.3062431216239929, 'sst-2_test_prompt_eval_acc': 0.9025229357798165, 'sst-2_dev_eval_loss': 0.051293183118104935, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.3062431216239929, 'sst-2_test_eval_acc': 0.9025229357798165, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-27695', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_02-19-43_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-27695', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias_eval_loss': 0.7045522332191467, 'cola_dev_bias_eval_mcc': 0.0, 'cola_test_bias_eval_loss': 0.7624071836471558, 'cola_test_bias_eval_mcc': 0.0, 'cola_dev_eval_loss': 0.7045522332191467, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.7624071836471558, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--42-roberta-large-4705', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_02-28-16_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-4705', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt_eval_loss': 1.2782211303710938, 'rte_dev_prompt_eval_acc': 0.6875, 'rte_test_prompt_eval_loss': 1.1675972938537598, 'rte_test_prompt_eval_acc': 0.5992779783393501, 'rte_dev_eval_loss': 1.2782211303710938, 'rte_dev_eval_acc': 0.6875, 'rte_test_eval_loss': 1.1675972938537598, 'rte_test_eval_acc': 0.5992779783393501, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-100-roberta-large-32039', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_02-27-16_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-100-roberta-large-32039', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_adapter_eval_loss': 2.1816763877868652, 'sts-b_dev_adapter_eval_pearson': 0.8671707759175611, 'sts-b_dev_adapter_eval_spearmanr': 0.8605572955656713, 'sts-b_dev_adapter_eval_corr': 0.8638640357416162, 'sts-b_test_adapter_eval_loss': 2.1774487495422363, 'sts-b_test_adapter_eval_pearson': 0.6800028613916503, 'sts-b_test_adapter_eval_spearmanr': 0.6752509864818557, 'sts-b_test_adapter_eval_corr': 0.677626923936753, 'sts-b_dev_eval_loss': 2.1816763877868652, 'sts-b_dev_eval_pearson': 0.8671707759175611, 'sts-b_dev_eval_spearmanr': 0.8605572955656713, 'sts-b_dev_eval_corr': 0.8638640357416162, 'sts-b_test_eval_loss': 2.1774487495422363, 'sts-b_test_eval_pearson': 0.6800028613916503, 'sts-b_test_eval_spearmanr': 0.6752509864818557, 'sts-b_test_eval_corr': 0.677626923936753, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--13-roberta-large-26065', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_02-27-23_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--13-roberta-large-26065', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias_eval_loss': 1.7295584678649902, 'mrpc_dev_bias_eval_acc': 0.75, 'mrpc_dev_bias_eval_f1': 0.7894736842105263, 'mrpc_dev_bias_eval_acc_and_f1': 0.7697368421052632, 'mrpc_test_bias_eval_loss': 2.112130641937256, 'mrpc_test_bias_eval_acc': 0.6617647058823529, 'mrpc_test_bias_eval_f1': 0.7490909090909091, 'mrpc_test_bias_eval_acc_and_f1': 0.705427807486631, 'mrpc_dev_eval_loss': 1.7295584678649902, 'mrpc_dev_eval_acc': 0.75, 'mrpc_dev_eval_f1': 0.7894736842105263, 'mrpc_dev_eval_acc_and_f1': 0.7697368421052632, 'mrpc_test_eval_loss': 2.112130641937256, 'mrpc_test_eval_acc': 0.6617647058823529, 'mrpc_test_eval_f1': 0.7490909090909091, 'mrpc_test_eval_acc_and_f1': 0.705427807486631, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16--42-roberta-large-19119', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_02-35-33_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--42-roberta-large-19119', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt_eval_loss': 1.0076724290847778, 'mnli_dev_prompt_eval_mnli/acc': 0.625, 'mnli_test_prompt_eval_loss': 1.1673773527145386, 'mnli_test_prompt_eval_mnli/acc': 0.48976057055527256, 'mnli-mm_test_prompt_eval_loss': 1.135098934173584, 'mnli-mm_test_prompt_eval_mnli-mm/acc': 0.48993083807973964, 'mnli_dev_eval_loss': 1.0076724290847778, 'mnli_dev_eval_mnli/acc': 0.625, 'mnli_test_eval_loss': 1.1673773527145386, 'mnli_test_eval_mnli/acc': 0.48976057055527256, 'mnli-mm_test_eval_loss': 1.135098934173584, 'mnli-mm_test_eval_mnli-mm/acc': 0.48993083807973964, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-1118', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_02-19-09_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-1118', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias,adapter_eval_loss': 3.0714263916015625, 'qqp_dev_bias,adapter_eval_acc': 0.6875, 'qqp_dev_bias,adapter_eval_f1': 0.7222222222222223, 'qqp_dev_bias,adapter_eval_acc_and_f1': 0.7048611111111112, 'qqp_test_bias,adapter_eval_loss': 3.0933964252471924, 'qqp_test_bias,adapter_eval_acc': 0.6736829087311402, 'qqp_test_bias,adapter_eval_f1': 0.652843196589743, 'qqp_test_bias,adapter_eval_acc_and_f1': 0.6632630526604416, 'qqp_dev_eval_loss': 3.0714263916015625, 'qqp_dev_eval_acc': 0.6875, 'qqp_dev_eval_f1': 0.7222222222222223, 'qqp_dev_eval_acc_and_f1': 0.7048611111111112, 'qqp_test_eval_loss': 3.0933964252471924, 'qqp_test_eval_acc': 0.6736829087311402, 'qqp_test_eval_f1': 0.652843196589743, 'qqp_test_eval_acc_and_f1': 0.6632630526604416, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16--13-roberta-large-20905', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_02-07-41_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--13-roberta-large-20905', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias_eval_loss': 2.78873872756958, 'cola_dev_bias_eval_mcc': 0.3289758474798845, 'cola_test_bias_eval_loss': 2.8228819370269775, 'cola_test_bias_eval_mcc': 0.049017722924620394, 'cola_dev_eval_loss': 2.78873872756958, 'cola_dev_eval_mcc': 0.3289758474798845, 'cola_test_eval_loss': 2.8228819370269775, 'cola_test_eval_mcc': 0.049017722924620394, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--42-roberta-large-24141', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_02-38-38_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-24141', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt_eval_loss': 0.9090437293052673, 'rte_dev_prompt_eval_acc': 0.625, 'rte_test_prompt_eval_loss': 0.9012831449508667, 'rte_test_prompt_eval_acc': 0.5631768953068592, 'rte_dev_eval_loss': 0.9090437293052673, 'rte_dev_eval_acc': 0.625, 'rte_test_eval_loss': 0.9012831449508667, 'rte_test_eval_acc': 0.5631768953068592, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-100-roberta-large-24998', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_02-39-10_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-100-roberta-large-24998', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_adapter_eval_loss': 3.3653721809387207, 'qnli_dev_adapter_eval_acc': 0.75, 'qnli_test_adapter_eval_loss': 4.730529308319092, 'qnli_test_adapter_eval_acc': 0.6796631887241442, 'qnli_dev_eval_loss': 3.3653721809387207, 'qnli_dev_eval_acc': 0.75, 'qnli_test_eval_loss': 4.730529308319092, 'qnli_test_eval_acc': 0.6796631887241442, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--13-roberta-large-29475', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_02-35-26_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--13-roberta-large-29475', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias_eval_loss': 1.357771635055542, 'mrpc_dev_bias_eval_acc': 0.71875, 'mrpc_dev_bias_eval_f1': 0.7567567567567567, 'mrpc_dev_bias_eval_acc_and_f1': 0.7377533783783783, 'mrpc_test_bias_eval_loss': 1.3710434436798096, 'mrpc_test_bias_eval_acc': 0.6200980392156863, 'mrpc_test_bias_eval_f1': 0.7113594040968343, 'mrpc_test_bias_eval_acc_and_f1': 0.6657287216562603, 'mrpc_dev_eval_loss': 1.357771635055542, 'mrpc_dev_eval_acc': 0.71875, 'mrpc_dev_eval_f1': 0.7567567567567567, 'mrpc_dev_eval_acc_and_f1': 0.7377533783783783, 'mrpc_test_eval_loss': 1.3710434436798096, 'mrpc_test_eval_acc': 0.6200980392156863, 'mrpc_test_eval_f1': 0.7113594040968343, 'mrpc_test_eval_acc_and_f1': 0.6657287216562603, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16--42-roberta-large-6173', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_02-45-31_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--42-roberta-large-6173', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias_eval_loss': 0.19456955790519714, 'sst-2_dev_bias_eval_acc': 0.96875, 'sst-2_test_bias_eval_loss': 1.055370807647705, 'sst-2_test_bias_eval_acc': 0.8623853211009175, 'sst-2_dev_eval_loss': 0.19456955790519714, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 1.055370807647705, 'sst-2_test_eval_acc': 0.8623853211009175, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--42-roberta-large-7897', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_02-38-39_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--42-roberta-large-7897', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias_eval_loss': 3.953150749206543, 'cola_dev_bias_eval_mcc': 0.3289758474798845, 'cola_test_bias_eval_loss': 4.5175580978393555, 'cola_test_bias_eval_mcc': 0.01806135587532526, 'cola_dev_eval_loss': 3.953150749206543, 'cola_dev_eval_mcc': 0.3289758474798845, 'cola_test_eval_loss': 4.5175580978393555, 'cola_test_eval_mcc': 0.01806135587532526, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--42-roberta-large-27332', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_02-49-00_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-27332', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_adapter_eval_loss': 2.1836981773376465, 'sts-b_dev_adapter_eval_pearson': 0.8370262970868887, 'sts-b_dev_adapter_eval_spearmanr': 0.8388780127141023, 'sts-b_dev_adapter_eval_corr': 0.8379521549004956, 'sts-b_test_adapter_eval_loss': 2.1835570335388184, 'sts-b_test_adapter_eval_pearson': 0.6059319707808527, 'sts-b_test_adapter_eval_spearmanr': 0.5932557796839039, 'sts-b_test_adapter_eval_corr': 0.5995938752323783, 'sts-b_dev_eval_loss': 2.1836981773376465, 'sts-b_dev_eval_pearson': 0.8370262970868887, 'sts-b_dev_eval_spearmanr': 0.8388780127141023, 'sts-b_dev_eval_corr': 0.8379521549004956, 'sts-b_test_eval_loss': 2.1835570335388184, 'sts-b_test_eval_pearson': 0.6059319707808527, 'sts-b_test_eval_spearmanr': 0.5932557796839039, 'sts-b_test_eval_corr': 0.5995938752323783, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--13-roberta-large-28555', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_02-45-01_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--13-roberta-large-28555', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias_eval_loss': 2.4670028686523438, 'rte_dev_bias_eval_acc': 0.71875, 'rte_test_bias_eval_loss': 2.9967403411865234, 'rte_test_bias_eval_acc': 0.6534296028880866, 'rte_dev_eval_loss': 2.4670028686523438, 'rte_dev_eval_acc': 0.71875, 'rte_test_eval_loss': 2.9967403411865234, 'rte_test_eval_acc': 0.6534296028880866, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16--42-roberta-large-9824', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_02-51-19_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--42-roberta-large-9824', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias_eval_loss': 1.5440878868103027, 'mrpc_dev_bias_eval_acc': 0.71875, 'mrpc_dev_bias_eval_f1': 0.742857142857143, 'mrpc_dev_bias_eval_acc_and_f1': 0.7308035714285714, 'mrpc_test_bias_eval_loss': 1.9566584825515747, 'mrpc_test_bias_eval_acc': 0.5759803921568627, 'mrpc_test_bias_eval_f1': 0.6627680311890838, 'mrpc_test_bias_eval_acc_and_f1': 0.6193742116729732, 'mrpc_dev_eval_loss': 1.5440878868103027, 'mrpc_dev_eval_acc': 0.71875, 'mrpc_dev_eval_f1': 0.742857142857143, 'mrpc_dev_eval_acc_and_f1': 0.7308035714285714, 'mrpc_test_eval_loss': 1.9566584825515747, 'mrpc_test_eval_acc': 0.5759803921568627, 'mrpc_test_eval_f1': 0.6627680311890838, 'mrpc_test_eval_acc_and_f1': 0.6193742116729732, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16--42-roberta-large-31494', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_02-55-44_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--42-roberta-large-31494', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_adapter_eval_loss': 2.7353060245513916, 'qnli_dev_adapter_eval_acc': 0.6875, 'qnli_test_adapter_eval_loss': 2.4920828342437744, 'qnli_test_adapter_eval_acc': 0.643053267435475, 'qnli_dev_eval_loss': 2.7353060245513916, 'qnli_dev_eval_acc': 0.6875, 'qnli_test_eval_loss': 2.4920828342437744, 'qnli_test_eval_acc': 0.643053267435475, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--13-roberta-large-10157', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_02-52-15_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--13-roberta-large-10157', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias_eval_loss': 3.4965081214904785, 'cola_dev_bias_eval_mcc': 0.2519763153394848, 'cola_test_bias_eval_loss': 3.7460577487945557, 'cola_test_bias_eval_mcc': 0.03113271670170015, 'cola_dev_eval_loss': 3.4965081214904785, 'cola_dev_eval_mcc': 0.2519763153394848, 'cola_test_eval_loss': 3.7460577487945557, 'cola_test_eval_mcc': 0.03113271670170015, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--42-roberta-large-20587', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_02-59-19_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-20587', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt_eval_loss': 1.448622703552246, 'mnli_dev_prompt_eval_mnli/acc': 0.5416666666666666, 'mnli_test_prompt_eval_loss': 1.3205450773239136, 'mnli_test_prompt_eval_mnli/acc': 0.521141110545084, 'mnli-mm_test_prompt_eval_loss': 1.2844746112823486, 'mnli-mm_test_prompt_eval_mnli-mm/acc': 0.5322416598860863, 'mnli_dev_eval_loss': 1.448622703552246, 'mnli_dev_eval_mnli/acc': 0.5416666666666666, 'mnli_test_eval_loss': 1.3205450773239136, 'mnli_test_eval_mnli/acc': 0.521141110545084, 'mnli-mm_test_eval_loss': 1.2844746112823486, 'mnli-mm_test_eval_mnli-mm/acc': 0.5322416598860863, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-14094', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_02-47-06_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-14094', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias_eval_loss': 0.706069827079773, 'mrpc_dev_bias_eval_acc': 0.5, 'mrpc_dev_bias_eval_f1': 0.6666666666666666, 'mrpc_dev_bias_eval_acc_and_f1': 0.5833333333333333, 'mrpc_test_bias_eval_loss': 0.6467845439910889, 'mrpc_test_bias_eval_acc': 0.6838235294117647, 'mrpc_test_bias_eval_f1': 0.8122270742358079, 'mrpc_test_bias_eval_acc_and_f1': 0.7480253018237863, 'mrpc_dev_eval_loss': 0.706069827079773, 'mrpc_dev_eval_acc': 0.5, 'mrpc_dev_eval_f1': 0.6666666666666666, 'mrpc_dev_eval_acc_and_f1': 0.5833333333333333, 'mrpc_test_eval_loss': 0.6467845439910889, 'mrpc_test_eval_acc': 0.6838235294117647, 'mrpc_test_eval_f1': 0.8122270742358079, 'mrpc_test_eval_acc_and_f1': 0.7480253018237863, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16--100-roberta-large-27504', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_03-06-42_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--100-roberta-large-27504', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias_eval_loss': 0.4241710901260376, 'sst-2_dev_bias_eval_acc': 0.96875, 'sst-2_test_bias_eval_loss': 0.638904333114624, 'sst-2_test_bias_eval_acc': 0.9311926605504587, 'sst-2_dev_eval_loss': 0.4241710901260376, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.638904333114624, 'sst-2_test_eval_acc': 0.9311926605504587, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--42-roberta-large-26990', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_02-58-37_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--42-roberta-large-26990', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias_eval_loss': 4.868846416473389, 'rte_dev_bias_eval_acc': 0.65625, 'rte_test_bias_eval_loss': 3.4555773735046387, 'rte_test_bias_eval_acc': 0.6606498194945848, 'rte_dev_eval_loss': 4.868846416473389, 'rte_dev_eval_acc': 0.65625, 'rte_test_eval_loss': 3.4555773735046387, 'rte_test_eval_acc': 0.6606498194945848, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16--42-roberta-large-25062', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_03-04-58_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--42-roberta-large-25062', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias_eval_loss': 0.9891924262046814, 'cola_dev_bias_eval_mcc': 0.0, 'cola_test_bias_eval_loss': 1.2985689640045166, 'cola_test_bias_eval_mcc': 0.0, 'cola_dev_eval_loss': 0.9891924262046814, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 1.2985689640045166, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--100-roberta-large-30570', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_03-09-44_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-30570', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,adapter_eval_loss': 2.2407000064849854, 'sts-b_dev_prompt,adapter_eval_pearson': 0.25231797215533014, 'sts-b_dev_prompt,adapter_eval_spearmanr': 0.18985519409210308, 'sts-b_dev_prompt,adapter_eval_corr': 0.2210865831237166, 'sts-b_test_prompt,adapter_eval_loss': 2.2122457027435303, 'sts-b_test_prompt,adapter_eval_pearson': -0.017117058762698176, 'sts-b_test_prompt,adapter_eval_spearmanr': -0.018851120904623538, 'sts-b_test_prompt,adapter_eval_corr': -0.017984089833660857, 'sts-b_dev_eval_loss': 2.2407000064849854, 'sts-b_dev_eval_pearson': 0.25231797215533014, 'sts-b_dev_eval_spearmanr': 0.18985519409210308, 'sts-b_dev_eval_corr': 0.2210865831237166, 'sts-b_test_eval_loss': 2.2122457027435303, 'sts-b_test_eval_pearson': -0.017117058762698176, 'sts-b_test_eval_spearmanr': -0.018851120904623538, 'sts-b_test_eval_corr': -0.017984089833660857, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-13-roberta-large-19735', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_03-02-05_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-13-roberta-large-19735', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_adapter_eval_loss': 2.376913070678711, 'qnli_dev_adapter_eval_acc': 0.625, 'qnli_test_adapter_eval_loss': 2.056997776031494, 'qnli_test_adapter_eval_acc': 0.6223686619073769, 'qnli_dev_eval_loss': 2.376913070678711, 'qnli_dev_eval_acc': 0.625, 'qnli_test_eval_loss': 2.056997776031494, 'qnli_test_eval_acc': 0.6223686619073769, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--13-roberta-large-29294', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_03-09-13_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--13-roberta-large-29294', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias_eval_loss': 2.6247196197509766, 'mrpc_dev_bias_eval_acc': 0.65625, 'mrpc_dev_bias_eval_f1': 0.6451612903225806, 'mrpc_dev_bias_eval_acc_and_f1': 0.6507056451612903, 'mrpc_test_bias_eval_loss': 3.4776504039764404, 'mrpc_test_bias_eval_acc': 0.5833333333333334, 'mrpc_test_bias_eval_f1': 0.6558704453441295, 'mrpc_test_bias_eval_acc_and_f1': 0.6196018893387314, 'mrpc_dev_eval_loss': 2.6247196197509766, 'mrpc_dev_eval_acc': 0.65625, 'mrpc_dev_eval_f1': 0.6451612903225806, 'mrpc_dev_eval_acc_and_f1': 0.6507056451612903, 'mrpc_test_eval_loss': 3.4776504039764404, 'mrpc_test_eval_acc': 0.5833333333333334, 'mrpc_test_eval_f1': 0.6558704453441295, 'mrpc_test_eval_acc_and_f1': 0.6196018893387314, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16--100-roberta-large-2502', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_03-16-50_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--100-roberta-large-2502', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias,adapter_eval_loss': 1.5908923149108887, 'qqp_dev_bias,adapter_eval_acc': 0.6875, 'qqp_dev_bias,adapter_eval_f1': 0.7222222222222223, 'qqp_dev_bias,adapter_eval_acc_and_f1': 0.7048611111111112, 'qqp_test_bias,adapter_eval_loss': 1.3311325311660767, 'qqp_test_bias,adapter_eval_acc': 0.6799406381399951, 'qqp_test_bias,adapter_eval_f1': 0.6545464253297026, 'qqp_test_bias,adapter_eval_acc_and_f1': 0.6672435317348488, 'qqp_dev_eval_loss': 1.5908923149108887, 'qqp_dev_eval_acc': 0.6875, 'qqp_dev_eval_f1': 0.7222222222222223, 'qqp_dev_eval_acc_and_f1': 0.7048611111111112, 'qqp_test_eval_loss': 1.3311325311660767, 'qqp_test_eval_acc': 0.6799406381399951, 'qqp_test_eval_f1': 0.6545464253297026, 'qqp_test_eval_acc_and_f1': 0.6672435317348488, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16--13-roberta-large-7120', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_02-48-20_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--13-roberta-large-7120', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias_eval_loss': 3.1765851974487305, 'cola_dev_bias_eval_mcc': 0.4383570037596047, 'cola_test_bias_eval_loss': 4.58420991897583, 'cola_test_bias_eval_mcc': 0.10599969524898512, 'cola_dev_eval_loss': 3.1765851974487305, 'cola_dev_eval_mcc': 0.4383570037596047, 'cola_test_eval_loss': 4.58420991897583, 'cola_test_eval_mcc': 0.10599969524898512, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--100-roberta-large-3493', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_03-20-43_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-3493', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias_eval_loss': 2.1312263011932373, 'rte_dev_bias_eval_acc': 0.6875, 'rte_test_bias_eval_loss': 1.965909719467163, 'rte_test_bias_eval_acc': 0.6606498194945848, 'rte_dev_eval_loss': 2.1312263011932373, 'rte_dev_eval_acc': 0.6875, 'rte_test_eval_loss': 1.965909719467163, 'rte_test_eval_acc': 0.6606498194945848, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16--42-roberta-large-30476', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_03-19-19_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--42-roberta-large-30476', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias_eval_loss': 2.080453872680664, 'mrpc_dev_bias_eval_acc': 0.6875, 'mrpc_dev_bias_eval_f1': 0.6875, 'mrpc_dev_bias_eval_acc_and_f1': 0.6875, 'mrpc_test_bias_eval_loss': 1.5330798625946045, 'mrpc_test_bias_eval_acc': 0.6470588235294118, 'mrpc_test_bias_eval_f1': 0.7251908396946565, 'mrpc_test_bias_eval_acc_and_f1': 0.6861248316120341, 'mrpc_dev_eval_loss': 2.080453872680664, 'mrpc_dev_eval_acc': 0.6875, 'mrpc_dev_eval_f1': 0.6875, 'mrpc_dev_eval_acc_and_f1': 0.6875, 'mrpc_test_eval_loss': 1.5330798625946045, 'mrpc_test_eval_acc': 0.6470588235294118, 'mrpc_test_eval_f1': 0.7251908396946565, 'mrpc_test_eval_acc_and_f1': 0.6861248316120341, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16--100-roberta-large-15836', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_03-27-22_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--100-roberta-large-15836', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias_eval_loss': 0.3909454941749573, 'sst-2_dev_bias_eval_acc': 0.96875, 'sst-2_test_bias_eval_loss': 0.5942884087562561, 'sst-2_test_bias_eval_acc': 0.9231651376146789, 'sst-2_dev_eval_loss': 0.3909454941749573, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.5942884087562561, 'sst-2_test_eval_acc': 0.9231651376146789, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--42-roberta-large-6753', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_03-18-51_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--42-roberta-large-6753', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,adapter_eval_loss': 2.1874465942382812, 'sts-b_dev_prompt,adapter_eval_pearson': 0.8430007397237563, 'sts-b_dev_prompt,adapter_eval_spearmanr': 0.8331826078971647, 'sts-b_dev_prompt,adapter_eval_corr': 0.8380916738104605, 'sts-b_test_prompt,adapter_eval_loss': 2.1843230724334717, 'sts-b_test_prompt,adapter_eval_pearson': 0.6184569250426775, 'sts-b_test_prompt,adapter_eval_spearmanr': 0.606957291132536, 'sts-b_test_prompt,adapter_eval_corr': 0.6127071080876068, 'sts-b_dev_eval_loss': 2.1874465942382812, 'sts-b_dev_eval_pearson': 0.8430007397237563, 'sts-b_dev_eval_spearmanr': 0.8331826078971647, 'sts-b_dev_eval_corr': 0.8380916738104605, 'sts-b_test_eval_loss': 2.1843230724334717, 'sts-b_test_eval_pearson': 0.6184569250426775, 'sts-b_test_eval_spearmanr': 0.606957291132536, 'sts-b_test_eval_corr': 0.6127071080876068, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-13-roberta-large-316', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_03-21-00_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-13-roberta-large-316', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt_eval_loss': 1.3099956512451172, 'mnli_dev_prompt_eval_mnli/acc': 0.4375, 'mnli_test_prompt_eval_loss': 1.2459546327590942, 'mnli_test_prompt_eval_mnli/acc': 0.44849719816607236, 'mnli-mm_test_prompt_eval_loss': 1.2529813051223755, 'mnli-mm_test_prompt_eval_mnli-mm/acc': 0.4553498779495525, 'mnli_dev_eval_loss': 1.3099956512451172, 'mnli_dev_eval_mnli/acc': 0.4375, 'mnli_test_eval_loss': 1.2459546327590942, 'mnli_test_eval_mnli/acc': 0.44849719816607236, 'mnli-mm_test_eval_loss': 1.2529813051223755, 'mnli-mm_test_eval_mnli-mm/acc': 0.4553498779495525, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-2641', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_03-14-33_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-2641', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias_eval_loss': 2.303034543991089, 'cola_dev_bias_eval_mcc': 0.3289758474798845, 'cola_test_bias_eval_loss': 2.9814507961273193, 'cola_test_bias_eval_mcc': 0.07229259996801789, 'cola_dev_eval_loss': 2.303034543991089, 'cola_dev_eval_mcc': 0.3289758474798845, 'cola_test_eval_loss': 2.9814507961273193, 'cola_test_eval_mcc': 0.07229259996801789, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--100-roberta-large-31427', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_03-31-12_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-31427', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,adapter_eval_loss': 3.367582321166992, 'qnli_dev_prompt,adapter_eval_acc': 0.6875, 'qnli_test_prompt,adapter_eval_loss': 3.500061511993408, 'qnli_test_prompt,adapter_eval_acc': 0.6721581548599671, 'qnli_dev_eval_loss': 3.367582321166992, 'qnli_dev_eval_acc': 0.6875, 'qnli_test_eval_loss': 3.500061511993408, 'qnli_test_eval_acc': 0.6721581548599671, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-13-roberta-large-8592', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_03-26-00_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-13-roberta-large-8592', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias_eval_loss': 2.0285181999206543, 'rte_dev_bias_eval_acc': 0.59375, 'rte_test_bias_eval_loss': 1.63127601146698, 'rte_test_bias_eval_acc': 0.6462093862815884, 'rte_dev_eval_loss': 2.0285181999206543, 'rte_dev_eval_acc': 0.59375, 'rte_test_eval_loss': 1.63127601146698, 'rte_test_eval_acc': 0.6462093862815884, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16--42-roberta-large-26549', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_03-33-15_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--42-roberta-large-26549', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias_eval_loss': 1.853607416152954, 'mrpc_dev_bias_eval_acc': 0.71875, 'mrpc_dev_bias_eval_f1': 0.6896551724137931, 'mrpc_dev_bias_eval_acc_and_f1': 0.7042025862068966, 'mrpc_test_bias_eval_loss': 1.5965560674667358, 'mrpc_test_bias_eval_acc': 0.6862745098039216, 'mrpc_test_bias_eval_f1': 0.7620817843866171, 'mrpc_test_bias_eval_acc_and_f1': 0.7241781470952693, 'mrpc_dev_eval_loss': 1.853607416152954, 'mrpc_dev_eval_acc': 0.71875, 'mrpc_dev_eval_f1': 0.6896551724137931, 'mrpc_dev_eval_acc_and_f1': 0.7042025862068966, 'mrpc_test_eval_loss': 1.5965560674667358, 'mrpc_test_eval_acc': 0.6862745098039216, 'mrpc_test_eval_f1': 0.7620817843866171, 'mrpc_test_eval_acc_and_f1': 0.7241781470952693, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16--100-roberta-large-18784', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_03-37-40_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--100-roberta-large-18784', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias_eval_loss': 0.8868016004562378, 'cola_dev_bias_eval_mcc': 0.40451991747794525, 'cola_test_bias_eval_loss': 1.442865014076233, 'cola_test_bias_eval_mcc': 0.015840926574872467, 'cola_dev_eval_loss': 0.8868016004562378, 'cola_dev_eval_mcc': 0.40451991747794525, 'cola_test_eval_loss': 1.442865014076233, 'cola_test_eval_mcc': 0.015840926574872467, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--100-roberta-large-11704', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_03-41-38_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-11704', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias_eval_loss': 0.7852979302406311, 'sst-2_dev_bias_eval_acc': 0.9375, 'sst-2_test_bias_eval_loss': 0.5612987875938416, 'sst-2_test_bias_eval_acc': 0.9288990825688074, 'sst-2_dev_eval_loss': 0.7852979302406311, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.5612987875938416, 'sst-2_test_eval_acc': 0.9288990825688074, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--42-roberta-large-28464', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_03-38-49_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--42-roberta-large-28464', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,adapter_eval_loss': 2.190636157989502, 'sts-b_dev_prompt,adapter_eval_pearson': 0.8439172045687116, 'sts-b_dev_prompt,adapter_eval_spearmanr': 0.8313453805368622, 'sts-b_dev_prompt,adapter_eval_corr': 0.8376312925527869, 'sts-b_test_prompt,adapter_eval_loss': 2.183229923248291, 'sts-b_test_prompt,adapter_eval_pearson': 0.6122109356616057, 'sts-b_test_prompt,adapter_eval_spearmanr': 0.601873342766115, 'sts-b_test_prompt,adapter_eval_corr': 0.6070421392138603, 'sts-b_dev_eval_loss': 2.190636157989502, 'sts-b_dev_eval_pearson': 0.8439172045687116, 'sts-b_dev_eval_spearmanr': 0.8313453805368622, 'sts-b_dev_eval_corr': 0.8376312925527869, 'sts-b_test_eval_loss': 2.183229923248291, 'sts-b_test_eval_pearson': 0.6122109356616057, 'sts-b_test_eval_spearmanr': 0.601873342766115, 'sts-b_test_eval_corr': 0.6070421392138603, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-13-roberta-large-16565', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_03-40-36_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-13-roberta-large-16565', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_adapter_eval_loss': 1.0463871955871582, 'mrpc_dev_adapter_eval_acc': 0.5, 'mrpc_dev_adapter_eval_f1': 0.6666666666666666, 'mrpc_dev_adapter_eval_acc_and_f1': 0.5833333333333333, 'mrpc_test_adapter_eval_loss': 0.7195316553115845, 'mrpc_test_adapter_eval_acc': 0.6838235294117647, 'mrpc_test_adapter_eval_f1': 0.8122270742358079, 'mrpc_test_adapter_eval_acc_and_f1': 0.7480253018237863, 'mrpc_dev_eval_loss': 1.0463871955871582, 'mrpc_dev_eval_acc': 0.5, 'mrpc_dev_eval_f1': 0.6666666666666666, 'mrpc_dev_eval_acc_and_f1': 0.5833333333333333, 'mrpc_test_eval_loss': 0.7195316553115845, 'mrpc_test_eval_acc': 0.6838235294117647, 'mrpc_test_eval_f1': 0.8122270742358079, 'mrpc_test_eval_acc_and_f1': 0.7480253018237863, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--42-roberta-large-6764', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_03-48-26_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--42-roberta-large-6764', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias_eval_loss': 2.4503934383392334, 'rte_dev_bias_eval_acc': 0.6875, 'rte_test_bias_eval_loss': 3.1252005100250244, 'rte_test_bias_eval_acc': 0.6606498194945848, 'rte_dev_eval_loss': 2.4503934383392334, 'rte_dev_eval_acc': 0.6875, 'rte_test_eval_loss': 3.1252005100250244, 'rte_test_eval_acc': 0.6606498194945848, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16--100-roberta-large-29579', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_03-47-28_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--100-roberta-large-29579', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,adapter_eval_loss': 3.1679630279541016, 'qnli_dev_prompt,adapter_eval_acc': 0.75, 'qnli_test_prompt,adapter_eval_loss': 3.5292108058929443, 'qnli_test_prompt,adapter_eval_acc': 0.7027274391360059, 'qnli_dev_eval_loss': 3.1679630279541016, 'qnli_dev_eval_acc': 0.75, 'qnli_test_eval_loss': 3.5292108058929443, 'qnli_test_eval_acc': 0.7027274391360059, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-13-roberta-large-31822', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_03-44-09_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-13-roberta-large-31822', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_adapter_eval_loss': 4.6789774894714355, 'cola_dev_adapter_eval_mcc': 0.48038446141526137, 'cola_test_adapter_eval_loss': 3.678252696990967, 'cola_test_adapter_eval_mcc': 0.23467562712224727, 'cola_dev_eval_loss': 4.6789774894714355, 'cola_dev_eval_mcc': 0.48038446141526137, 'cola_test_eval_loss': 3.678252696990967, 'cola_test_eval_mcc': 0.23467562712224727, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--42-roberta-large-17247', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_03-52-16_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-17247', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt_eval_loss': 1.6212472915649414, 'mnli_dev_prompt_eval_mnli/acc': 0.625, 'mnli_test_prompt_eval_loss': 2.203965663909912, 'mnli_test_prompt_eval_mnli/acc': 0.47019867549668876, 'mnli-mm_test_prompt_eval_loss': 2.136265516281128, 'mnli-mm_test_prompt_eval_mnli-mm/acc': 0.48911716842961755, 'mnli_dev_eval_loss': 1.6212472915649414, 'mnli_dev_eval_mnli/acc': 0.625, 'mnli_test_eval_loss': 2.203965663909912, 'mnli_test_eval_mnli/acc': 0.47019867549668876, 'mnli-mm_test_eval_loss': 2.136265516281128, 'mnli-mm_test_eval_mnli-mm/acc': 0.48911716842961755, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-1554', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_03-41-32_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-1554', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_adapter_eval_loss': 2.2158148288726807, 'mrpc_dev_adapter_eval_acc': 0.65625, 'mrpc_dev_adapter_eval_f1': 0.7027027027027026, 'mrpc_dev_adapter_eval_acc_and_f1': 0.6794763513513513, 'mrpc_test_adapter_eval_loss': 2.078352928161621, 'mrpc_test_adapter_eval_acc': 0.6887254901960784, 'mrpc_test_adapter_eval_f1': 0.7703435804701627, 'mrpc_test_adapter_eval_acc_and_f1': 0.7295345353331206, 'mrpc_dev_eval_loss': 2.2158148288726807, 'mrpc_dev_eval_acc': 0.65625, 'mrpc_dev_eval_f1': 0.7027027027027026, 'mrpc_dev_eval_acc_and_f1': 0.6794763513513513, 'mrpc_test_eval_loss': 2.078352928161621, 'mrpc_test_eval_acc': 0.6887254901960784, 'mrpc_test_eval_f1': 0.7703435804701627, 'mrpc_test_eval_acc_and_f1': 0.7295345353331206, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--42-roberta-large-6340', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_04-01-09_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--42-roberta-large-6340', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,bias,adapter_eval_loss': 0.6953909397125244, 'qqp_dev_prompt,bias,adapter_eval_acc': 0.5, 'qqp_dev_prompt,bias,adapter_eval_f1': 0.6666666666666666, 'qqp_dev_prompt,bias,adapter_eval_acc_and_f1': 0.5833333333333333, 'qqp_test_prompt,bias,adapter_eval_loss': 0.7131847143173218, 'qqp_test_prompt,bias,adapter_eval_acc': 0.36816720257234725, 'qqp_test_prompt,bias,adapter_eval_f1': 0.5381903642773208, 'qqp_test_prompt,bias,adapter_eval_acc_and_f1': 0.45317878342483403, 'qqp_dev_eval_loss': 0.6953909397125244, 'qqp_dev_eval_acc': 0.5, 'qqp_dev_eval_f1': 0.6666666666666666, 'qqp_dev_eval_acc_and_f1': 0.5833333333333333, 'qqp_test_eval_loss': 0.7131847143173218, 'qqp_test_eval_acc': 0.36816720257234725, 'qqp_test_eval_f1': 0.5381903642773208, 'qqp_test_eval_acc_and_f1': 0.45317878342483403, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16-prompt-13-roberta-large-21715', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_03-29-58_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-13-roberta-large-21715', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias_eval_loss': 1.616841197013855, 'rte_dev_bias_eval_acc': 0.84375, 'rte_test_bias_eval_loss': 2.7910354137420654, 'rte_test_bias_eval_acc': 0.740072202166065, 'rte_dev_eval_loss': 1.616841197013855, 'rte_dev_eval_acc': 0.84375, 'rte_test_eval_loss': 2.7910354137420654, 'rte_test_eval_acc': 0.740072202166065, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16--100-roberta-large-27574', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_04-01-40_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--100-roberta-large-27574', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_adapter_eval_loss': 3.377084732055664, 'cola_dev_adapter_eval_mcc': 0.44539933408304444, 'cola_test_adapter_eval_loss': 4.769564151763916, 'cola_test_adapter_eval_mcc': 0.0690987674420377, 'cola_dev_eval_loss': 3.377084732055664, 'cola_dev_eval_mcc': 0.44539933408304444, 'cola_test_eval_loss': 4.769564151763916, 'cola_test_eval_mcc': 0.0690987674420377, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--42-roberta-large-1808', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_04-05-04_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-1808', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias_eval_loss': 0.7767497301101685, 'sst-2_dev_bias_eval_acc': 0.5, 'sst-2_test_bias_eval_loss': 0.7690727114677429, 'sst-2_test_bias_eval_acc': 0.5091743119266054, 'sst-2_dev_eval_loss': 0.7767497301101685, 'sst-2_dev_eval_acc': 0.5, 'sst-2_test_eval_loss': 0.7690727114677429, 'sst-2_test_eval_acc': 0.5091743119266054, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--100-roberta-large-32242', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_03-58-03_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--100-roberta-large-32242', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,adapter_eval_loss': 1.725224256515503, 'qnli_dev_prompt,adapter_eval_acc': 0.71875, 'qnli_test_prompt,adapter_eval_loss': 1.6292541027069092, 'qnli_test_prompt,adapter_eval_acc': 0.6593446824089328, 'qnli_dev_eval_loss': 1.725224256515503, 'qnli_dev_eval_acc': 0.71875, 'qnli_test_eval_loss': 1.6292541027069092, 'qnli_test_eval_acc': 0.6593446824089328, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-13-roberta-large-28933', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_04-02-15_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-13-roberta-large-28933', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,adapter_eval_loss': 2.191375255584717, 'sts-b_dev_prompt,adapter_eval_pearson': 0.7967788017831209, 'sts-b_dev_prompt,adapter_eval_spearmanr': 0.7944171105947828, 'sts-b_dev_prompt,adapter_eval_corr': 0.7955979561889519, 'sts-b_test_prompt,adapter_eval_loss': 2.186811923980713, 'sts-b_test_prompt,adapter_eval_pearson': 0.5720831072363063, 'sts-b_test_prompt,adapter_eval_spearmanr': 0.5593476813854703, 'sts-b_test_prompt,adapter_eval_corr': 0.5657153943108884, 'sts-b_dev_eval_loss': 2.191375255584717, 'sts-b_dev_eval_pearson': 0.7967788017831209, 'sts-b_dev_eval_spearmanr': 0.7944171105947828, 'sts-b_dev_eval_corr': 0.7955979561889519, 'sts-b_test_eval_loss': 2.186811923980713, 'sts-b_test_eval_pearson': 0.5720831072363063, 'sts-b_test_eval_spearmanr': 0.5593476813854703, 'sts-b_test_eval_corr': 0.5657153943108884, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-13-roberta-large-14047', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_03-59-52_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-13-roberta-large-14047', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_adapter_eval_loss': 2.8624954223632812, 'mrpc_dev_adapter_eval_acc': 0.6875, 'mrpc_dev_adapter_eval_f1': 0.75, 'mrpc_dev_adapter_eval_acc_and_f1': 0.71875, 'mrpc_test_adapter_eval_loss': 2.54595947265625, 'mrpc_test_adapter_eval_acc': 0.6936274509803921, 'mrpc_test_adapter_eval_f1': 0.7892074198988195, 'mrpc_test_adapter_eval_acc_and_f1': 0.7414174354396058, 'mrpc_dev_eval_loss': 2.8624954223632812, 'mrpc_dev_eval_acc': 0.6875, 'mrpc_dev_eval_f1': 0.75, 'mrpc_dev_eval_acc_and_f1': 0.71875, 'mrpc_test_eval_loss': 2.54595947265625, 'mrpc_test_eval_acc': 0.6936274509803921, 'mrpc_test_eval_f1': 0.7892074198988195, 'mrpc_test_eval_acc_and_f1': 0.7414174354396058, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--42-roberta-large-31303', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_04-13-42_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--42-roberta-large-31303', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias_eval_loss': 1.8481910228729248, 'rte_dev_bias_eval_acc': 0.75, 'rte_test_bias_eval_loss': 2.2563557624816895, 'rte_test_bias_eval_acc': 0.6750902527075813, 'rte_dev_eval_loss': 1.8481910228729248, 'rte_dev_eval_acc': 0.75, 'rte_test_eval_loss': 2.2563557624816895, 'rte_test_eval_acc': 0.6750902527075813, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16--100-roberta-large-24403', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_04-15-45_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--100-roberta-large-24403', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_adapter_eval_loss': 2.467935085296631, 'cola_dev_adapter_eval_mcc': 0.31814238148788887, 'cola_test_adapter_eval_loss': 2.9183967113494873, 'cola_test_adapter_eval_mcc': 0.03711705286239601, 'cola_dev_eval_loss': 2.467935085296631, 'cola_dev_eval_mcc': 0.31814238148788887, 'cola_test_eval_loss': 2.9183967113494873, 'cola_test_eval_mcc': 0.03711705286239601, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--42-roberta-large-26145', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_04-17-58_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-26145', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,adapter_eval_loss': 2.5764613151550293, 'qnli_dev_prompt,adapter_eval_acc': 0.65625, 'qnli_test_prompt,adapter_eval_loss': 2.556938409805298, 'qnli_test_prompt,adapter_eval_acc': 0.657331136738056, 'qnli_dev_eval_loss': 2.5764613151550293, 'qnli_dev_eval_acc': 0.65625, 'qnli_test_eval_loss': 2.556938409805298, 'qnli_test_eval_acc': 0.657331136738056, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-13-roberta-large-26479', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_04-20-02_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-13-roberta-large-26479', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias_eval_loss': 0.007129591424018145, 'sst-2_dev_bias_eval_acc': 1.0, 'sst-2_test_bias_eval_loss': 0.6792779564857483, 'sst-2_test_bias_eval_acc': 0.9185779816513762, 'sst-2_dev_eval_loss': 0.007129591424018145, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.6792779564857483, 'sst-2_test_eval_acc': 0.9185779816513762, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--100-roberta-large-27344', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_04-18-38_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--100-roberta-large-27344', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_adapter_eval_loss': 1.9205918312072754, 'mrpc_dev_adapter_eval_acc': 0.65625, 'mrpc_dev_adapter_eval_f1': 0.7317073170731707, 'mrpc_dev_adapter_eval_acc_and_f1': 0.6939786585365854, 'mrpc_test_adapter_eval_loss': 2.032681703567505, 'mrpc_test_adapter_eval_acc': 0.6764705882352942, 'mrpc_test_adapter_eval_f1': 0.7708333333333333, 'mrpc_test_adapter_eval_acc_and_f1': 0.7236519607843137, 'mrpc_dev_eval_loss': 1.9205918312072754, 'mrpc_dev_eval_acc': 0.65625, 'mrpc_dev_eval_f1': 0.7317073170731707, 'mrpc_dev_eval_acc_and_f1': 0.6939786585365854, 'mrpc_test_eval_loss': 2.032681703567505, 'mrpc_test_eval_acc': 0.6764705882352942, 'mrpc_test_eval_f1': 0.7708333333333333, 'mrpc_test_eval_acc_and_f1': 0.7236519607843137, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--42-roberta-large-23333', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_04-26-46_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--42-roberta-large-23333', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias_eval_loss': 1.889346718788147, 'rte_dev_bias_eval_acc': 0.6875, 'rte_test_bias_eval_loss': 1.957091212272644, 'rte_test_bias_eval_acc': 0.6967509025270758, 'rte_dev_eval_loss': 1.889346718788147, 'rte_dev_eval_acc': 0.6875, 'rte_test_eval_loss': 1.957091212272644, 'rte_test_eval_acc': 0.6967509025270758, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16--100-roberta-large-9952', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_04-29-38_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--100-roberta-large-9952', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_adapter_eval_loss': 3.4325075149536133, 'cola_dev_adapter_eval_mcc': 0.31311214554257477, 'cola_test_adapter_eval_loss': 4.785203456878662, 'cola_test_adapter_eval_mcc': 0.06259452661590564, 'cola_dev_eval_loss': 3.4325075149536133, 'cola_dev_eval_mcc': 0.31311214554257477, 'cola_test_eval_loss': 4.785203456878662, 'cola_test_eval_mcc': 0.06259452661590564, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--42-roberta-large-16334', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_04-31-01_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-16334', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt_eval_loss': 1.9460835456848145, 'mnli_dev_prompt_eval_mnli/acc': 0.5625, 'mnli_test_prompt_eval_loss': 1.6848862171173096, 'mnli_test_prompt_eval_mnli/acc': 0.5505858380030565, 'mnli-mm_test_prompt_eval_loss': 1.668906569480896, 'mnli-mm_test_prompt_eval_mnli-mm/acc': 0.5644833197721725, 'mnli_dev_eval_loss': 1.9460835456848145, 'mnli_dev_eval_mnli/acc': 0.5625, 'mnli_test_eval_loss': 1.6848862171173096, 'mnli_test_eval_mnli/acc': 0.5505858380030565, 'mnli-mm_test_eval_loss': 1.668906569480896, 'mnli-mm_test_eval_mnli-mm/acc': 0.5644833197721725, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-2099', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_04-09-02_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-2099', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias_eval_loss': 2.182147741317749, 'sts-b_dev_prompt,bias_eval_pearson': 0.8901019821837884, 'sts-b_dev_prompt,bias_eval_spearmanr': 0.8752551144480912, 'sts-b_dev_prompt,bias_eval_corr': 0.8826785483159398, 'sts-b_test_prompt,bias_eval_loss': 2.1819467544555664, 'sts-b_test_prompt,bias_eval_pearson': 0.6238475905562447, 'sts-b_test_prompt,bias_eval_spearmanr': 0.6100816240657247, 'sts-b_test_prompt,bias_eval_corr': 0.6169646073109847, 'sts-b_dev_eval_loss': 2.182147741317749, 'sts-b_dev_eval_pearson': 0.8901019821837884, 'sts-b_dev_eval_spearmanr': 0.8752551144480912, 'sts-b_dev_eval_corr': 0.8826785483159398, 'sts-b_test_eval_loss': 2.1819467544555664, 'sts-b_test_eval_pearson': 0.6238475905562447, 'sts-b_test_eval_spearmanr': 0.6100816240657247, 'sts-b_test_eval_corr': 0.6169646073109847, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-13-roberta-large-4048', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_04-25-46_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-13-roberta-large-4048', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_adapter_eval_loss': 2.343518018722534, 'mrpc_dev_adapter_eval_acc': 0.75, 'mrpc_dev_adapter_eval_f1': 0.7142857142857143, 'mrpc_dev_adapter_eval_acc_and_f1': 0.7321428571428572, 'mrpc_test_adapter_eval_loss': 3.310896396636963, 'mrpc_test_adapter_eval_acc': 0.5465686274509803, 'mrpc_test_adapter_eval_f1': 0.5842696629213484, 'mrpc_test_adapter_eval_acc_and_f1': 0.5654191451861643, 'mrpc_dev_eval_loss': 2.343518018722534, 'mrpc_dev_eval_acc': 0.75, 'mrpc_dev_eval_f1': 0.7142857142857143, 'mrpc_dev_eval_acc_and_f1': 0.7321428571428572, 'mrpc_test_eval_loss': 3.310896396636963, 'mrpc_test_eval_acc': 0.5465686274509803, 'mrpc_test_eval_f1': 0.5842696629213484, 'mrpc_test_eval_acc_and_f1': 0.5654191451861643, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--100-roberta-large-6413', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_04-39-52_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--100-roberta-large-6413', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias_eval_loss': 3.1224255561828613, 'qnli_dev_prompt,bias_eval_acc': 0.625, 'qnli_test_prompt,bias_eval_loss': 2.7442872524261475, 'qnli_test_prompt,bias_eval_acc': 0.6154127768625297, 'qnli_dev_eval_loss': 3.1224255561828613, 'qnli_dev_eval_acc': 0.625, 'qnli_test_eval_loss': 2.7442872524261475, 'qnli_test_eval_acc': 0.6154127768625297, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-13-roberta-large-10701', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_04-37-47_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-13-roberta-large-10701', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_adapter_eval_loss': 0.7437093257904053, 'cola_dev_adapter_eval_mcc': 0.0, 'cola_test_adapter_eval_loss': 0.8664107918739319, 'cola_test_adapter_eval_mcc': 0.0, 'cola_dev_eval_loss': 0.7437093257904053, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.8664107918739319, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--100-roberta-large-18201', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_04-43-42_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-18201', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,bias,adapter_eval_loss': 4.357883453369141, 'qqp_dev_prompt,bias,adapter_eval_acc': 0.6875, 'qqp_dev_prompt,bias,adapter_eval_f1': 0.7368421052631579, 'qqp_dev_prompt,bias,adapter_eval_acc_and_f1': 0.712171052631579, 'qqp_test_prompt,bias,adapter_eval_loss': 4.762004375457764, 'qqp_test_prompt,bias,adapter_eval_acc': 0.6405144694533762, 'qqp_test_prompt,bias,adapter_eval_f1': 0.6316589791677226, 'qqp_test_prompt,bias,adapter_eval_acc_and_f1': 0.6360867243105495, 'qqp_dev_eval_loss': 4.357883453369141, 'qqp_dev_eval_acc': 0.6875, 'qqp_dev_eval_f1': 0.7368421052631579, 'qqp_dev_eval_acc_and_f1': 0.712171052631579, 'qqp_test_eval_loss': 4.762004375457764, 'qqp_test_eval_acc': 0.6405144694533762, 'qqp_test_eval_f1': 0.6316589791677226, 'qqp_test_eval_acc_and_f1': 0.6360867243105495, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16-prompt-13-roberta-large-21455', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_04-14-07_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-13-roberta-large-21455', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias_eval_loss': 0.0021317768841981888, 'sst-2_dev_bias_eval_acc': 1.0, 'sst-2_test_bias_eval_loss': 0.5338160395622253, 'sst-2_test_bias_eval_acc': 0.9231651376146789, 'sst-2_dev_eval_loss': 0.0021317768841981888, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.5338160395622253, 'sst-2_test_eval_acc': 0.9231651376146789, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--100-roberta-large-21360', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_04-37-47_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--100-roberta-large-21360', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_adapter_eval_loss': 5.0530171394348145, 'rte_dev_adapter_eval_acc': 0.5625, 'rte_test_adapter_eval_loss': 3.7871670722961426, 'rte_test_adapter_eval_acc': 0.6570397111913358, 'rte_dev_eval_loss': 5.0530171394348145, 'rte_dev_eval_acc': 0.5625, 'rte_test_eval_loss': 3.7871670722961426, 'rte_test_eval_acc': 0.6570397111913358, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--42-roberta-large-18987', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_04-43-42_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--42-roberta-large-18987', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_adapter_eval_loss': 2.941617488861084, 'mrpc_dev_adapter_eval_acc': 0.65625, 'mrpc_dev_adapter_eval_f1': 0.6666666666666667, 'mrpc_dev_adapter_eval_acc_and_f1': 0.6614583333333334, 'mrpc_test_adapter_eval_loss': 2.5661563873291016, 'mrpc_test_adapter_eval_acc': 0.6666666666666666, 'mrpc_test_adapter_eval_f1': 0.7453183520599251, 'mrpc_test_adapter_eval_acc_and_f1': 0.7059925093632959, 'mrpc_dev_eval_loss': 2.941617488861084, 'mrpc_dev_eval_acc': 0.65625, 'mrpc_dev_eval_f1': 0.6666666666666667, 'mrpc_dev_eval_acc_and_f1': 0.6614583333333334, 'mrpc_test_eval_loss': 2.5661563873291016, 'mrpc_test_eval_acc': 0.6666666666666666, 'mrpc_test_eval_f1': 0.7453183520599251, 'mrpc_test_eval_acc_and_f1': 0.7059925093632959, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--100-roberta-large-7862', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_04-52-38_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--100-roberta-large-7862', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_adapter_eval_loss': 3.656277656555176, 'cola_dev_adapter_eval_mcc': 0.3779644730092272, 'cola_test_adapter_eval_loss': 3.3162760734558105, 'cola_test_adapter_eval_mcc': 0.30282521685982067, 'cola_dev_eval_loss': 3.656277656555176, 'cola_dev_eval_mcc': 0.3779644730092272, 'cola_test_eval_loss': 3.3162760734558105, 'cola_test_eval_mcc': 0.30282521685982067, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--100-roberta-large-23719', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_04-56-26_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-23719', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias_eval_loss': 1.3748959302902222, 'qnli_dev_prompt,bias_eval_acc': 0.75, 'qnli_test_prompt,bias_eval_loss': 1.5330958366394043, 'qnli_test_prompt,bias_eval_acc': 0.6644700713893466, 'qnli_dev_eval_loss': 1.3748959302902222, 'qnli_dev_eval_acc': 0.75, 'qnli_test_eval_loss': 1.5330958366394043, 'qnli_test_eval_acc': 0.6644700713893466, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-13-roberta-large-19336', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_04-54-32_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-13-roberta-large-19336', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_adapter_eval_loss': 2.727992534637451, 'rte_dev_adapter_eval_acc': 0.6875, 'rte_test_adapter_eval_loss': 1.7759137153625488, 'rte_test_adapter_eval_acc': 0.6642599277978339, 'rte_dev_eval_loss': 2.727992534637451, 'rte_dev_eval_acc': 0.6875, 'rte_test_eval_loss': 1.7759137153625488, 'rte_test_eval_acc': 0.6642599277978339, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--42-roberta-large-5486', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_04-58-46_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--42-roberta-large-5486', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias_eval_loss': 2.187558174133301, 'sts-b_dev_prompt,bias_eval_pearson': 0.8284247012030088, 'sts-b_dev_prompt,bias_eval_spearmanr': 0.8166475616544425, 'sts-b_dev_prompt,bias_eval_corr': 0.8225361314287256, 'sts-b_test_prompt,bias_eval_loss': 2.186060667037964, 'sts-b_test_prompt,bias_eval_pearson': 0.582065671656918, 'sts-b_test_prompt,bias_eval_spearmanr': 0.5661245065804544, 'sts-b_test_prompt,bias_eval_corr': 0.5740950891186862, 'sts-b_dev_eval_loss': 2.187558174133301, 'sts-b_dev_eval_pearson': 0.8284247012030088, 'sts-b_dev_eval_spearmanr': 0.8166475616544425, 'sts-b_dev_eval_corr': 0.8225361314287256, 'sts-b_test_eval_loss': 2.186060667037964, 'sts-b_test_eval_pearson': 0.582065671656918, 'sts-b_test_eval_spearmanr': 0.5661245065804544, 'sts-b_test_eval_corr': 0.5740950891186862, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-13-roberta-large-14278', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_04-50-36_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-13-roberta-large-14278', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias_eval_loss': 0.007601876277476549, 'sst-2_dev_bias_eval_acc': 1.0, 'sst-2_test_bias_eval_loss': 0.4151742160320282, 'sst-2_test_bias_eval_acc': 0.930045871559633, 'sst-2_dev_eval_loss': 0.007601876277476549, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.4151742160320282, 'sst-2_test_eval_acc': 0.930045871559633, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--100-roberta-large-27008', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_04-58-31_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--100-roberta-large-27008', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_adapter_eval_loss': 1.615304708480835, 'mrpc_dev_adapter_eval_acc': 0.71875, 'mrpc_dev_adapter_eval_f1': 0.7272727272727272, 'mrpc_dev_adapter_eval_acc_and_f1': 0.7230113636363635, 'mrpc_test_adapter_eval_loss': 1.2792539596557617, 'mrpc_test_adapter_eval_acc': 0.6985294117647058, 'mrpc_test_adapter_eval_f1': 0.7717996289424861, 'mrpc_test_adapter_eval_acc_and_f1': 0.7351645203535959, 'mrpc_dev_eval_loss': 1.615304708480835, 'mrpc_dev_eval_acc': 0.71875, 'mrpc_dev_eval_f1': 0.7272727272727272, 'mrpc_dev_eval_acc_and_f1': 0.7230113636363635, 'mrpc_test_eval_loss': 1.2792539596557617, 'mrpc_test_eval_acc': 0.6985294117647058, 'mrpc_test_eval_f1': 0.7717996289424861, 'mrpc_test_eval_acc_and_f1': 0.7351645203535959, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--100-roberta-large-3833', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_05-05-13_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--100-roberta-large-3833', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_adapter_eval_loss': 3.324727773666382, 'cola_dev_adapter_eval_mcc': 0.3289758474798845, 'cola_test_adapter_eval_loss': 4.45269250869751, 'cola_test_adapter_eval_mcc': 0.1045020938817423, 'cola_dev_eval_loss': 3.324727773666382, 'cola_dev_eval_mcc': 0.3289758474798845, 'cola_test_eval_loss': 4.45269250869751, 'cola_test_eval_mcc': 0.1045020938817423, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--100-roberta-large-19044', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_05-09-25_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-19044', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias_eval_loss': 1.2716844081878662, 'qnli_dev_prompt,bias_eval_acc': 0.8125, 'qnli_test_prompt,bias_eval_loss': 2.0390000343322754, 'qnli_test_prompt,bias_eval_acc': 0.680578436756361, 'qnli_dev_eval_loss': 1.2716844081878662, 'qnli_dev_eval_acc': 0.8125, 'qnli_test_eval_loss': 2.0390000343322754, 'qnli_test_eval_acc': 0.680578436756361, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-13-roberta-large-15689', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_05-11-11_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-13-roberta-large-15689', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_adapter_eval_loss': 3.353024959564209, 'rte_dev_adapter_eval_acc': 0.625, 'rte_test_adapter_eval_loss': 2.8406176567077637, 'rte_test_adapter_eval_acc': 0.6353790613718412, 'rte_dev_eval_loss': 3.353024959564209, 'rte_dev_eval_acc': 0.625, 'rte_test_eval_loss': 2.8406176567077637, 'rte_test_eval_acc': 0.6353790613718412, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--42-roberta-large-8560', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_05-13-30_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--42-roberta-large-8560', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt_eval_loss': 1.5978364944458008, 'mnli_dev_prompt_eval_mnli/acc': 0.5208333333333334, 'mnli_test_prompt_eval_loss': 1.4205232858657837, 'mnli_test_prompt_eval_mnli/acc': 0.5084055017829853, 'mnli-mm_test_prompt_eval_loss': 1.3760042190551758, 'mnli-mm_test_prompt_eval_mnli-mm/acc': 0.5133238405207485, 'mnli_dev_eval_loss': 1.5978364944458008, 'mnli_dev_eval_mnli/acc': 0.5208333333333334, 'mnli_test_eval_loss': 1.4205232858657837, 'mnli_test_eval_mnli/acc': 0.5084055017829853, 'mnli-mm_test_eval_loss': 1.3760042190551758, 'mnli-mm_test_eval_mnli-mm/acc': 0.5133238405207485, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-1268', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_04-49-34_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-1268', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_adapter_eval_loss': 1.610818862915039, 'mrpc_dev_adapter_eval_acc': 0.75, 'mrpc_dev_adapter_eval_f1': 0.75, 'mrpc_dev_adapter_eval_acc_and_f1': 0.75, 'mrpc_test_adapter_eval_loss': 1.4536207914352417, 'mrpc_test_adapter_eval_acc': 0.7058823529411765, 'mrpc_test_adapter_eval_f1': 0.7802197802197802, 'mrpc_test_adapter_eval_acc_and_f1': 0.7430510665804784, 'mrpc_dev_eval_loss': 1.610818862915039, 'mrpc_dev_eval_acc': 0.75, 'mrpc_dev_eval_f1': 0.75, 'mrpc_dev_eval_acc_and_f1': 0.75, 'mrpc_test_eval_loss': 1.4536207914352417, 'mrpc_test_eval_acc': 0.7058823529411765, 'mrpc_test_eval_f1': 0.7802197802197802, 'mrpc_test_eval_acc_and_f1': 0.7430510665804784, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--100-roberta-large-21137', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_05-17-52_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--100-roberta-large-21137', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_adapter_eval_loss': 1.5102335214614868, 'cola_dev_adapter_eval_mcc': 0.4383570037596047, 'cola_test_adapter_eval_loss': 2.2560293674468994, 'cola_test_adapter_eval_mcc': 0.0986614229218339, 'cola_dev_eval_loss': 1.5102335214614868, 'cola_dev_eval_mcc': 0.4383570037596047, 'cola_test_eval_loss': 2.2560293674468994, 'cola_test_eval_mcc': 0.0986614229218339, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--100-roberta-large-4843', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_05-22-04_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-4843', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_adapter_eval_loss': 0.9172309637069702, 'sst-2_dev_adapter_eval_acc': 0.90625, 'sst-2_test_adapter_eval_loss': 1.2412246465682983, 'sst-2_test_adapter_eval_acc': 0.9243119266055045, 'sst-2_dev_eval_loss': 0.9172309637069702, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 1.2412246465682983, 'sst-2_test_eval_acc': 0.9243119266055045, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--42-roberta-large-27788', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_05-17-25_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--42-roberta-large-27788', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,bias,adapter_eval_loss': 2.7965128421783447, 'qqp_dev_prompt,bias,adapter_eval_acc': 0.75, 'qqp_dev_prompt,bias,adapter_eval_f1': 0.7777777777777777, 'qqp_dev_prompt,bias,adapter_eval_acc_and_f1': 0.7638888888888888, 'qqp_test_prompt,bias,adapter_eval_loss': 2.9550974369049072, 'qqp_test_prompt,bias,adapter_eval_acc': 0.6762057877813504, 'qqp_test_prompt,bias,adapter_eval_f1': 0.6372176804766524, 'qqp_test_prompt,bias,adapter_eval_acc_and_f1': 0.6567117341290014, 'qqp_dev_eval_loss': 2.7965128421783447, 'qqp_dev_eval_acc': 0.75, 'qqp_dev_eval_f1': 0.7777777777777777, 'qqp_dev_eval_acc_and_f1': 0.7638888888888888, 'qqp_test_eval_loss': 2.9550974369049072, 'qqp_test_eval_acc': 0.6762057877813504, 'qqp_test_eval_f1': 0.6372176804766524, 'qqp_test_eval_acc_and_f1': 0.6567117341290014, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16-prompt-13-roberta-large-6077', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_04-58-14_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-13-roberta-large-6077', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias_eval_loss': 2.188688278198242, 'sts-b_dev_prompt,bias_eval_pearson': 0.7924752505225232, 'sts-b_dev_prompt,bias_eval_spearmanr': 0.7756773915196977, 'sts-b_dev_prompt,bias_eval_corr': 0.7840763210211105, 'sts-b_test_prompt,bias_eval_loss': 2.188117265701294, 'sts-b_test_prompt,bias_eval_pearson': 0.5590440434093112, 'sts-b_test_prompt,bias_eval_spearmanr': 0.5381491704489298, 'sts-b_test_prompt,bias_eval_corr': 0.5485966069291206, 'sts-b_dev_eval_loss': 2.188688278198242, 'sts-b_dev_eval_pearson': 0.7924752505225232, 'sts-b_dev_eval_spearmanr': 0.7756773915196977, 'sts-b_dev_eval_corr': 0.7840763210211105, 'sts-b_test_eval_loss': 2.188117265701294, 'sts-b_test_eval_pearson': 0.5590440434093112, 'sts-b_test_eval_spearmanr': 0.5381491704489298, 'sts-b_test_eval_corr': 0.5485966069291206, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-13-roberta-large-19281', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_05-15-29_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-13-roberta-large-19281', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,adapter_eval_loss': 2.9451546669006348, 'mrpc_dev_prompt,adapter_eval_acc': 0.78125, 'mrpc_dev_prompt,adapter_eval_f1': 0.8108108108108109, 'mrpc_dev_prompt,adapter_eval_acc_and_f1': 0.7960304054054055, 'mrpc_test_prompt,adapter_eval_loss': 3.5487282276153564, 'mrpc_test_prompt,adapter_eval_acc': 0.7426470588235294, 'mrpc_test_prompt,adapter_eval_f1': 0.8223350253807107, 'mrpc_test_prompt,adapter_eval_acc_and_f1': 0.7824910421021201, 'mrpc_dev_eval_loss': 2.9451546669006348, 'mrpc_dev_eval_acc': 0.78125, 'mrpc_dev_eval_f1': 0.8108108108108109, 'mrpc_dev_eval_acc_and_f1': 0.7960304054054055, 'mrpc_test_eval_loss': 3.5487282276153564, 'mrpc_test_eval_acc': 0.7426470588235294, 'mrpc_test_eval_f1': 0.8223350253807107, 'mrpc_test_eval_acc_and_f1': 0.7824910421021201, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-42-roberta-large-21751', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_05-30-31_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-42-roberta-large-21751', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_adapter_eval_loss': 2.535098075866699, 'rte_dev_adapter_eval_acc': 0.65625, 'rte_test_adapter_eval_loss': 1.9220545291900635, 'rte_test_adapter_eval_acc': 0.6606498194945848, 'rte_dev_eval_loss': 2.535098075866699, 'rte_dev_eval_acc': 0.65625, 'rte_test_eval_loss': 1.9220545291900635, 'rte_test_eval_acc': 0.6606498194945848, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--42-roberta-large-8625', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_05-28-35_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--42-roberta-large-8625', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias_eval_loss': 0.8037757277488708, 'qnli_dev_prompt,bias_eval_acc': 0.78125, 'qnli_test_prompt,bias_eval_loss': 1.252604365348816, 'qnli_test_prompt,bias_eval_acc': 0.6659344682408933, 'qnli_dev_eval_loss': 0.8037757277488708, 'qnli_dev_eval_acc': 0.78125, 'qnli_test_eval_loss': 1.252604365348816, 'qnli_test_eval_acc': 0.6659344682408933, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-13-roberta-large-15124', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_05-28-04_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-13-roberta-large-15124', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,adapter_eval_loss': 0.7055742144584656, 'cola_dev_prompt,adapter_eval_mcc': 0.0, 'cola_test_prompt,adapter_eval_loss': 0.7660331726074219, 'cola_test_prompt,adapter_eval_mcc': 0.0, 'cola_dev_eval_loss': 0.7055742144584656, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.7660331726074219, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-8262', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_05-35-00_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-8262', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,adapter_eval_loss': 0.975387692451477, 'mrpc_dev_prompt,adapter_eval_acc': 0.8125, 'mrpc_dev_prompt,adapter_eval_f1': 0.8125, 'mrpc_dev_prompt,adapter_eval_acc_and_f1': 0.8125, 'mrpc_test_prompt,adapter_eval_loss': 2.4458813667297363, 'mrpc_test_prompt,adapter_eval_acc': 0.7132352941176471, 'mrpc_test_prompt,adapter_eval_f1': 0.782122905027933, 'mrpc_test_prompt,adapter_eval_acc_and_f1': 0.74767909957279, 'mrpc_dev_eval_loss': 0.975387692451477, 'mrpc_dev_eval_acc': 0.8125, 'mrpc_dev_eval_f1': 0.8125, 'mrpc_dev_eval_acc_and_f1': 0.8125, 'mrpc_test_eval_loss': 2.4458813667297363, 'mrpc_test_eval_acc': 0.7132352941176471, 'mrpc_test_eval_f1': 0.782122905027933, 'mrpc_test_eval_acc_and_f1': 0.74767909957279, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-42-roberta-large-17753', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_05-43-22_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-42-roberta-large-17753', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_adapter_eval_loss': 0.38281312584877014, 'sst-2_dev_adapter_eval_acc': 0.9375, 'sst-2_test_adapter_eval_loss': 0.7655892372131348, 'sst-2_test_adapter_eval_acc': 0.9346330275229358, 'sst-2_dev_eval_loss': 0.38281312584877014, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.7655892372131348, 'sst-2_test_eval_acc': 0.9346330275229358, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--42-roberta-large-11137', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_05-37-46_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--42-roberta-large-11137', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_adapter_eval_loss': 2.175689220428467, 'rte_dev_adapter_eval_acc': 0.65625, 'rte_test_adapter_eval_loss': 2.514397144317627, 'rte_test_adapter_eval_acc': 0.7184115523465704, 'rte_dev_eval_loss': 2.175689220428467, 'rte_dev_eval_acc': 0.65625, 'rte_test_eval_loss': 2.514397144317627, 'rte_test_eval_acc': 0.7184115523465704, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--100-roberta-large-20663', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_05-43-36_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--100-roberta-large-20663', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,adapter_eval_loss': 2.4923362731933594, 'cola_dev_prompt,adapter_eval_mcc': 0.5039526306789696, 'cola_test_prompt,adapter_eval_loss': 3.93684983253479, 'cola_test_prompt,adapter_eval_mcc': 0.09644884849592326, 'cola_dev_eval_loss': 2.4923362731933594, 'cola_dev_eval_mcc': 0.5039526306789696, 'cola_test_eval_loss': 3.93684983253479, 'cola_test_eval_mcc': 0.09644884849592326, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-17530', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_05-47-46_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-17530', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias,adapter_eval_loss': 1.0059608221054077, 'qnli_dev_bias,adapter_eval_acc': 0.875, 'qnli_test_bias,adapter_eval_loss': 2.573603868484497, 'qnli_test_bias,adapter_eval_acc': 0.728171334431631, 'qnli_dev_eval_loss': 1.0059608221054077, 'qnli_dev_eval_acc': 0.875, 'qnli_test_eval_loss': 2.573603868484497, 'qnli_test_eval_acc': 0.728171334431631, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--13-roberta-large-2320', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_05-44-42_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--13-roberta-large-2320', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,adapter_eval_loss': 1.4585317373275757, 'mrpc_dev_prompt,adapter_eval_acc': 0.875, 'mrpc_dev_prompt,adapter_eval_f1': 0.8666666666666666, 'mrpc_dev_prompt,adapter_eval_acc_and_f1': 0.8708333333333333, 'mrpc_test_prompt,adapter_eval_loss': 2.669218063354492, 'mrpc_test_prompt,adapter_eval_acc': 0.6887254901960784, 'mrpc_test_prompt,adapter_eval_f1': 0.7392197125256674, 'mrpc_test_prompt,adapter_eval_acc_and_f1': 0.7139726013608729, 'mrpc_dev_eval_loss': 1.4585317373275757, 'mrpc_dev_eval_acc': 0.875, 'mrpc_dev_eval_f1': 0.8666666666666666, 'mrpc_dev_eval_acc_and_f1': 0.8708333333333333, 'mrpc_test_eval_loss': 2.669218063354492, 'mrpc_test_eval_acc': 0.6887254901960784, 'mrpc_test_eval_f1': 0.7392197125256674, 'mrpc_test_eval_acc_and_f1': 0.7139726013608729, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-42-roberta-large-13579', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_05-55-57_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-42-roberta-large-13579', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias_eval_loss': 2.198772430419922, 'sts-b_dev_prompt,bias_eval_pearson': 0.730758254674064, 'sts-b_dev_prompt,bias_eval_spearmanr': 0.7189070660863518, 'sts-b_dev_prompt,bias_eval_corr': 0.7248326603802079, 'sts-b_test_prompt,bias_eval_loss': 2.203195095062256, 'sts-b_test_prompt,bias_eval_pearson': 0.4433429346359531, 'sts-b_test_prompt,bias_eval_spearmanr': 0.43395565778194994, 'sts-b_test_prompt,bias_eval_corr': 0.43864929620895154, 'sts-b_dev_eval_loss': 2.198772430419922, 'sts-b_dev_eval_pearson': 0.730758254674064, 'sts-b_dev_eval_spearmanr': 0.7189070660863518, 'sts-b_dev_eval_corr': 0.7248326603802079, 'sts-b_test_eval_loss': 2.203195095062256, 'sts-b_test_eval_pearson': 0.4433429346359531, 'sts-b_test_eval_spearmanr': 0.43395565778194994, 'sts-b_test_eval_corr': 0.43864929620895154, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-13-roberta-large-29652', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_05-42-35_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-13-roberta-large-29652', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias_eval_loss': 1.3146404027938843, 'mnli_dev_bias_eval_mnli/acc': 0.3541666666666667, 'mnli_test_bias_eval_loss': 1.3042323589324951, 'mnli_test_bias_eval_mnli/acc': 0.3261334691798268, 'mnli-mm_test_bias_eval_loss': 1.307273507118225, 'mnli-mm_test_bias_eval_mnli-mm/acc': 0.3256712774613507, 'mnli_dev_eval_loss': 1.3146404027938843, 'mnli_dev_eval_mnli/acc': 0.3541666666666667, 'mnli_test_eval_loss': 1.3042323589324951, 'mnli_test_eval_mnli/acc': 0.3261334691798268, 'mnli-mm_test_eval_loss': 1.307273507118225, 'mnli-mm_test_eval_mnli-mm/acc': 0.3256712774613507, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--42-roberta-large-15345', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_05-29-24_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--42-roberta-large-15345', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,adapter_eval_loss': 1.7760310173034668, 'cola_dev_prompt,adapter_eval_mcc': 0.4383570037596047, 'cola_test_prompt,adapter_eval_loss': 2.6650025844573975, 'cola_test_prompt,adapter_eval_mcc': 0.052627404272026584, 'cola_dev_eval_loss': 1.7760310173034668, 'cola_dev_eval_mcc': 0.4383570037596047, 'cola_test_eval_loss': 2.6650025844573975, 'cola_test_eval_mcc': 0.052627404272026584, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-28122', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_06-00-50_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-28122', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_adapter_eval_loss': 1.2826848030090332, 'rte_dev_adapter_eval_acc': 0.84375, 'rte_test_adapter_eval_loss': 2.4422452449798584, 'rte_test_adapter_eval_acc': 0.7003610108303249, 'rte_dev_eval_loss': 1.2826848030090332, 'rte_dev_eval_acc': 0.84375, 'rte_test_eval_loss': 2.4422452449798584, 'rte_test_eval_acc': 0.7003610108303249, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--100-roberta-large-2785', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_05-58-39_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--100-roberta-large-2785', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_adapter_eval_loss': 0.5178725719451904, 'sst-2_dev_adapter_eval_acc': 0.96875, 'sst-2_test_adapter_eval_loss': 0.7048046588897705, 'sst-2_test_adapter_eval_acc': 0.926605504587156, 'sst-2_dev_eval_loss': 0.5178725719451904, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.7048046588897705, 'sst-2_test_eval_acc': 0.926605504587156, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--42-roberta-large-4795', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_05-56-56_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--42-roberta-large-4795', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,bias,adapter_eval_loss': 1.089277982711792, 'qqp_dev_prompt,bias,adapter_eval_acc': 0.75, 'qqp_dev_prompt,bias,adapter_eval_f1': 0.7777777777777777, 'qqp_dev_prompt,bias,adapter_eval_acc_and_f1': 0.7638888888888888, 'qqp_test_prompt,bias,adapter_eval_loss': 1.1440976858139038, 'qqp_test_prompt,bias,adapter_eval_acc': 0.6979470690081623, 'qqp_test_prompt,bias,adapter_eval_f1': 0.6611166611166611, 'qqp_test_prompt,bias,adapter_eval_acc_and_f1': 0.6795318650624117, 'qqp_dev_eval_loss': 1.089277982711792, 'qqp_dev_eval_acc': 0.75, 'qqp_dev_eval_f1': 0.7777777777777777, 'qqp_dev_eval_acc_and_f1': 0.7638888888888888, 'qqp_test_eval_loss': 1.1440976858139038, 'qqp_test_eval_acc': 0.6979470690081623, 'qqp_test_eval_f1': 0.6611166611166611, 'qqp_test_eval_acc_and_f1': 0.6795318650624117, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16-prompt-13-roberta-large-26275', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_05-40-38_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-13-roberta-large-26275', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,adapter_eval_loss': 1.5115318298339844, 'mrpc_dev_prompt,adapter_eval_acc': 0.78125, 'mrpc_dev_prompt,adapter_eval_f1': 0.787878787878788, 'mrpc_dev_prompt,adapter_eval_acc_and_f1': 0.784564393939394, 'mrpc_test_prompt,adapter_eval_loss': 2.1009137630462646, 'mrpc_test_prompt,adapter_eval_acc': 0.7083333333333334, 'mrpc_test_prompt,adapter_eval_f1': 0.7724665391969407, 'mrpc_test_prompt,adapter_eval_acc_and_f1': 0.740399936265137, 'mrpc_dev_eval_loss': 1.5115318298339844, 'mrpc_dev_eval_acc': 0.78125, 'mrpc_dev_eval_f1': 0.787878787878788, 'mrpc_dev_eval_acc_and_f1': 0.784564393939394, 'mrpc_test_eval_loss': 2.1009137630462646, 'mrpc_test_eval_acc': 0.7083333333333334, 'mrpc_test_eval_f1': 0.7724665391969407, 'mrpc_test_eval_acc_and_f1': 0.740399936265137, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-42-roberta-large-11593', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_06-08-40_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-42-roberta-large-11593', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias,adapter_eval_loss': 3.4327597618103027, 'qnli_dev_bias,adapter_eval_acc': 0.6875, 'qnli_test_bias,adapter_eval_loss': 4.501773357391357, 'qnli_test_bias,adapter_eval_acc': 0.6333516382939777, 'qnli_dev_eval_loss': 3.4327597618103027, 'qnli_dev_eval_acc': 0.6875, 'qnli_test_eval_loss': 4.501773357391357, 'qnli_test_eval_acc': 0.6333516382939777, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--13-roberta-large-3482', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_06-04-11_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--13-roberta-large-3482', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,adapter_eval_loss': 1.9903571605682373, 'cola_dev_prompt,adapter_eval_mcc': 0.31814238148788887, 'cola_test_prompt,adapter_eval_loss': 2.570380449295044, 'cola_test_prompt,adapter_eval_mcc': 0.07376853015034376, 'cola_dev_eval_loss': 1.9903571605682373, 'cola_dev_eval_mcc': 0.31814238148788887, 'cola_test_eval_loss': 2.570380449295044, 'cola_test_eval_mcc': 0.07376853015034376, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-12629', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_06-13-46_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-12629', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_adapter_eval_loss': 1.6034671068191528, 'rte_dev_adapter_eval_acc': 0.78125, 'rte_test_adapter_eval_loss': 2.4442594051361084, 'rte_test_adapter_eval_acc': 0.740072202166065, 'rte_dev_eval_loss': 1.6034671068191528, 'rte_dev_eval_acc': 0.78125, 'rte_test_eval_loss': 2.4442594051361084, 'rte_test_eval_acc': 0.740072202166065, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--100-roberta-large-31338', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_06-13-52_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--100-roberta-large-31338', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_eval_loss': 0.9632952213287354, 'qqp_dev_eval_acc': 0.46875, 'qqp_dev_eval_f1': 0.0, 'qqp_dev_eval_acc_and_f1': 0.234375, 'qqp_test_eval_loss': 0.7350690960884094, 'qqp_test_eval_acc': 0.6221122928518427, 'qqp_test_eval_f1': 0.06350373911977442, 'qqp_test_eval_acc_and_f1': 0.34280801598580857, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16--13-roberta-large-598', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_06-21-33_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--13-roberta-large-598', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': None, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,adapter_eval_loss': 2.8399150371551514, 'mrpc_dev_prompt,adapter_eval_acc': 0.625, 'mrpc_dev_prompt,adapter_eval_f1': 0.5384615384615384, 'mrpc_dev_prompt,adapter_eval_acc_and_f1': 0.5817307692307692, 'mrpc_test_prompt,adapter_eval_loss': 2.87893009185791, 'mrpc_test_prompt,adapter_eval_acc': 0.5686274509803921, 'mrpc_test_prompt,adapter_eval_f1': 0.6018099547511312, 'mrpc_test_prompt,adapter_eval_acc_and_f1': 0.5852187028657616, 'mrpc_dev_eval_loss': 2.8399150371551514, 'mrpc_dev_eval_acc': 0.625, 'mrpc_dev_eval_f1': 0.5384615384615384, 'mrpc_dev_eval_acc_and_f1': 0.5817307692307692, 'mrpc_test_eval_loss': 2.87893009185791, 'mrpc_test_eval_acc': 0.5686274509803921, 'mrpc_test_eval_f1': 0.6018099547511312, 'mrpc_test_eval_acc_and_f1': 0.5852187028657616, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-100-roberta-large-14282', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_06-21-49_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-100-roberta-large-14282', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_adapter_eval_loss': 0.5882811546325684, 'sst-2_dev_adapter_eval_acc': 0.90625, 'sst-2_test_adapter_eval_loss': 0.36738795042037964, 'sst-2_test_adapter_eval_acc': 0.9334862385321101, 'sst-2_dev_eval_loss': 0.5882811546325684, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 0.36738795042037964, 'sst-2_test_eval_acc': 0.9334862385321101, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--42-roberta-large-20475', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_06-17-11_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--42-roberta-large-20475', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,adapter_eval_loss': 0.7261126041412354, 'cola_dev_prompt,adapter_eval_mcc': 0.0, 'cola_test_prompt,adapter_eval_loss': 0.824863076210022, 'cola_test_prompt,adapter_eval_mcc': 0.0, 'cola_dev_eval_loss': 0.7261126041412354, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.824863076210022, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-2415', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_06-26-50_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-2415', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias,adapter_eval_loss': 2.2433700561523438, 'sts-b_dev_bias,adapter_eval_pearson': 0.3162744498912861, 'sts-b_dev_bias,adapter_eval_spearmanr': 0.20301603432361584, 'sts-b_dev_bias,adapter_eval_corr': 0.259645242107451, 'sts-b_test_bias,adapter_eval_loss': 2.2146377563476562, 'sts-b_test_bias,adapter_eval_pearson': 0.006198979456131238, 'sts-b_test_bias,adapter_eval_spearmanr': 0.003566895031058013, 'sts-b_test_bias,adapter_eval_corr': 0.004882937243594626, 'sts-b_dev_eval_loss': 2.2433700561523438, 'sts-b_dev_eval_pearson': 0.3162744498912861, 'sts-b_dev_eval_spearmanr': 0.20301603432361584, 'sts-b_dev_eval_corr': 0.259645242107451, 'sts-b_test_eval_loss': 2.2146377563476562, 'sts-b_test_eval_pearson': 0.006198979456131238, 'sts-b_test_eval_spearmanr': 0.003566895031058013, 'sts-b_test_eval_corr': 0.004882937243594626, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--13-roberta-large-13136', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_06-09-17_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--13-roberta-large-13136', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias,adapter_eval_loss': 3.089081287384033, 'qnli_dev_bias,adapter_eval_acc': 0.65625, 'qnli_test_bias,adapter_eval_loss': 3.095451831817627, 'qnli_test_bias,adapter_eval_acc': 0.6205381658429434, 'qnli_dev_eval_loss': 3.089081287384033, 'qnli_dev_eval_acc': 0.65625, 'qnli_test_eval_loss': 3.095451831817627, 'qnli_test_eval_acc': 0.6205381658429434, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--13-roberta-large-8286', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_06-23-53_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--13-roberta-large-8286', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_adapter_eval_loss': 1.6308772563934326, 'rte_dev_adapter_eval_acc': 0.71875, 'rte_test_adapter_eval_loss': 2.156334161758423, 'rte_test_adapter_eval_acc': 0.6787003610108303, 'rte_dev_eval_loss': 1.6308772563934326, 'rte_dev_eval_acc': 0.71875, 'rte_test_eval_loss': 2.156334161758423, 'rte_test_eval_acc': 0.6787003610108303, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--100-roberta-large-4386', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_06-29-22_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--100-roberta-large-4386', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,adapter_eval_loss': 3.1102092266082764, 'mrpc_dev_prompt,adapter_eval_acc': 0.5625, 'mrpc_dev_prompt,adapter_eval_f1': 0.5882352941176471, 'mrpc_dev_prompt,adapter_eval_acc_and_f1': 0.5753676470588236, 'mrpc_test_prompt,adapter_eval_loss': 2.099419116973877, 'mrpc_test_prompt,adapter_eval_acc': 0.6985294117647058, 'mrpc_test_prompt,adapter_eval_f1': 0.7717996289424861, 'mrpc_test_prompt,adapter_eval_acc_and_f1': 0.7351645203535959, 'mrpc_dev_eval_loss': 3.1102092266082764, 'mrpc_dev_eval_acc': 0.5625, 'mrpc_dev_eval_f1': 0.5882352941176471, 'mrpc_dev_eval_acc_and_f1': 0.5753676470588236, 'mrpc_test_eval_loss': 2.099419116973877, 'mrpc_test_eval_acc': 0.6985294117647058, 'mrpc_test_eval_f1': 0.7717996289424861, 'mrpc_test_eval_acc_and_f1': 0.7351645203535959, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-100-roberta-large-136', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_06-34-36_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-100-roberta-large-136', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,adapter_eval_loss': 3.4416565895080566, 'cola_dev_prompt,adapter_eval_mcc': 0.40451991747794525, 'cola_test_prompt,adapter_eval_loss': 3.498950481414795, 'cola_test_prompt,adapter_eval_mcc': 0.1565274057585286, 'cola_dev_eval_loss': 3.4416565895080566, 'cola_dev_eval_mcc': 0.40451991747794525, 'cola_test_eval_loss': 3.498950481414795, 'cola_test_eval_mcc': 0.1565274057585286, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-14888', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_06-39-43_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-14888', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_adapter_eval_loss': 0.12435735762119293, 'sst-2_dev_adapter_eval_acc': 0.96875, 'sst-2_test_adapter_eval_loss': 0.5278980135917664, 'sst-2_test_adapter_eval_acc': 0.9185779816513762, 'sst-2_dev_eval_loss': 0.12435735762119293, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.5278980135917664, 'sst-2_test_eval_acc': 0.9185779816513762, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--100-roberta-large-6587', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_06-37-02_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--100-roberta-large-6587', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias_eval_loss': 4.293923854827881, 'mnli_dev_bias_eval_mnli/acc': 0.6666666666666666, 'mnli_test_bias_eval_loss': 4.4213457107543945, 'mnli_test_bias_eval_mnli/acc': 0.6479877738155884, 'mnli-mm_test_bias_eval_loss': 4.131800174713135, 'mnli-mm_test_bias_eval_mnli-mm/acc': 0.6747355573637104, 'mnli_dev_eval_loss': 4.293923854827881, 'mnli_dev_eval_mnli/acc': 0.6666666666666666, 'mnli_test_eval_loss': 4.4213457107543945, 'mnli_test_eval_mnli/acc': 0.6479877738155884, 'mnli-mm_test_eval_loss': 4.131800174713135, 'mnli-mm_test_eval_mnli-mm/acc': 0.6747355573637104, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--42-roberta-large-15394', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_06-13-24_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--42-roberta-large-15394', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,adapter_eval_loss': 2.950713872909546, 'mrpc_dev_prompt,adapter_eval_acc': 0.625, 'mrpc_dev_prompt,adapter_eval_f1': 0.6470588235294118, 'mrpc_dev_prompt,adapter_eval_acc_and_f1': 0.6360294117647058, 'mrpc_test_prompt,adapter_eval_loss': 2.170074224472046, 'mrpc_test_prompt,adapter_eval_acc': 0.7205882352941176, 'mrpc_test_prompt,adapter_eval_f1': 0.7934782608695653, 'mrpc_test_prompt,adapter_eval_acc_and_f1': 0.7570332480818415, 'mrpc_dev_eval_loss': 2.950713872909546, 'mrpc_dev_eval_acc': 0.625, 'mrpc_dev_eval_f1': 0.6470588235294118, 'mrpc_dev_eval_acc_and_f1': 0.6360294117647058, 'mrpc_test_eval_loss': 2.170074224472046, 'mrpc_test_eval_acc': 0.7205882352941176, 'mrpc_test_eval_f1': 0.7934782608695653, 'mrpc_test_eval_acc_and_f1': 0.7570332480818415, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-100-roberta-large-1230', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_06-47-36_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-100-roberta-large-1230', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,adapter_eval_loss': 4.652674198150635, 'rte_dev_prompt,adapter_eval_acc': 0.65625, 'rte_test_prompt,adapter_eval_loss': 4.689055442810059, 'rte_test_prompt,adapter_eval_acc': 0.6425992779783394, 'rte_dev_eval_loss': 4.652674198150635, 'rte_dev_eval_acc': 0.65625, 'rte_test_eval_loss': 4.689055442810059, 'rte_test_eval_acc': 0.6425992779783394, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-42-roberta-large-8769', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_06-44-33_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-42-roberta-large-8769', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt_eval_loss': 1.081800937652588, 'qqp_dev_prompt_eval_acc': 0.6875, 'qqp_dev_prompt_eval_f1': 0.75, 'qqp_dev_prompt_eval_acc_and_f1': 0.71875, 'qqp_test_prompt_eval_loss': 1.486814022064209, 'qqp_test_prompt_eval_acc': 0.4841701706653475, 'qqp_test_prompt_eval_f1': 0.5153493992702936, 'qqp_test_prompt_eval_acc_and_f1': 0.49975978496782053, 'qqp_dev_eval_loss': 1.081800937652588, 'qqp_dev_eval_acc': 0.6875, 'qqp_dev_eval_f1': 0.75, 'qqp_dev_eval_acc_and_f1': 0.71875, 'qqp_test_eval_loss': 1.486814022064209, 'qqp_test_eval_acc': 0.4841701706653475, 'qqp_test_eval_f1': 0.5153493992702936, 'qqp_test_eval_acc_and_f1': 0.49975978496782053, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-13-roberta-large-11764', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_06-30-05_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-13-roberta-large-11764', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias,adapter_eval_loss': 2.7740468978881836, 'qnli_dev_bias,adapter_eval_acc': 0.65625, 'qnli_test_bias,adapter_eval_loss': 2.548410177230835, 'qnli_test_bias,adapter_eval_acc': 0.6262127036426872, 'qnli_dev_eval_loss': 2.7740468978881836, 'qnli_dev_eval_acc': 0.65625, 'qnli_test_eval_loss': 2.548410177230835, 'qnli_test_eval_acc': 0.6262127036426872, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--13-roberta-large-2448', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_06-43-53_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--13-roberta-large-2448', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,adapter_eval_loss': 4.92687463760376, 'cola_dev_prompt,adapter_eval_mcc': 0.375, 'cola_test_prompt,adapter_eval_loss': 5.2543745040893555, 'cola_test_prompt,adapter_eval_mcc': 0.16473420885657822, 'cola_dev_eval_loss': 4.92687463760376, 'cola_dev_eval_mcc': 0.375, 'cola_test_eval_loss': 5.2543745040893555, 'cola_test_eval_mcc': 0.16473420885657822, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-21356', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_06-52-38_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-21356', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias,adapter_eval_loss': 2.1923670768737793, 'sts-b_dev_bias,adapter_eval_pearson': 0.8364893417009636, 'sts-b_dev_bias,adapter_eval_spearmanr': 0.8284058167603783, 'sts-b_dev_bias,adapter_eval_corr': 0.8324475792306709, 'sts-b_test_bias,adapter_eval_loss': 2.1778459548950195, 'sts-b_test_bias,adapter_eval_pearson': 0.6888139895009224, 'sts-b_test_bias,adapter_eval_spearmanr': 0.6886404945335539, 'sts-b_test_bias,adapter_eval_corr': 0.6887272420172381, 'sts-b_dev_eval_loss': 2.1923670768737793, 'sts-b_dev_eval_pearson': 0.8364893417009636, 'sts-b_dev_eval_spearmanr': 0.8284058167603783, 'sts-b_dev_eval_corr': 0.8324475792306709, 'sts-b_test_eval_loss': 2.1778459548950195, 'sts-b_test_eval_pearson': 0.6888139895009224, 'sts-b_test_eval_spearmanr': 0.6886404945335539, 'sts-b_test_eval_corr': 0.6887272420172381, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--13-roberta-large-27544', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_06-40-42_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--13-roberta-large-27544', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,adapter_eval_loss': 1.5394806861877441, 'mrpc_dev_prompt,adapter_eval_acc': 0.6875, 'mrpc_dev_prompt,adapter_eval_f1': 0.7222222222222223, 'mrpc_dev_prompt,adapter_eval_acc_and_f1': 0.7048611111111112, 'mrpc_test_prompt,adapter_eval_loss': 1.3357561826705933, 'mrpc_test_prompt,adapter_eval_acc': 0.7132352941176471, 'mrpc_test_prompt,adapter_eval_f1': 0.7891891891891891, 'mrpc_test_prompt,adapter_eval_acc_and_f1': 0.7512122416534182, 'mrpc_dev_eval_loss': 1.5394806861877441, 'mrpc_dev_eval_acc': 0.6875, 'mrpc_dev_eval_f1': 0.7222222222222223, 'mrpc_dev_eval_acc_and_f1': 0.7048611111111112, 'mrpc_test_eval_loss': 1.3357561826705933, 'mrpc_test_eval_acc': 0.7132352941176471, 'mrpc_test_eval_f1': 0.7891891891891891, 'mrpc_test_eval_acc_and_f1': 0.7512122416534182, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-100-roberta-large-15644', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_07-00-22_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-100-roberta-large-15644', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_adapter_eval_loss': 0.013884690590202808, 'sst-2_dev_adapter_eval_acc': 1.0, 'sst-2_test_adapter_eval_loss': 0.6547368168830872, 'sst-2_test_adapter_eval_acc': 0.9288990825688074, 'sst-2_dev_eval_loss': 0.013884690590202808, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.6547368168830872, 'sst-2_test_eval_acc': 0.9288990825688074, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--100-roberta-large-22056', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_06-57-07_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--100-roberta-large-22056', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,adapter_eval_loss': 2.1620354652404785, 'rte_dev_prompt,adapter_eval_acc': 0.6875, 'rte_test_prompt,adapter_eval_loss': 2.2732298374176025, 'rte_test_prompt,adapter_eval_acc': 0.7256317689530686, 'rte_dev_eval_loss': 2.1620354652404785, 'rte_dev_eval_acc': 0.6875, 'rte_test_eval_loss': 2.2732298374176025, 'rte_test_eval_acc': 0.7256317689530686, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-42-roberta-large-6435', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_07-00-49_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-42-roberta-large-6435', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,adapter_eval_loss': 1.0474557876586914, 'cola_dev_prompt,adapter_eval_mcc': 0.2519763153394848, 'cola_test_prompt,adapter_eval_loss': 1.1958585977554321, 'cola_test_prompt,adapter_eval_mcc': 0.07836645140359805, 'cola_dev_eval_loss': 1.0474557876586914, 'cola_dev_eval_mcc': 0.2519763153394848, 'cola_test_eval_loss': 1.1958585977554321, 'cola_test_eval_mcc': 0.07836645140359805, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-22594', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_07-06-00_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-22594', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias_eval_loss': 2.5886242389678955, 'mrpc_dev_prompt,bias_eval_acc': 0.78125, 'mrpc_dev_prompt,bias_eval_f1': 0.8205128205128205, 'mrpc_dev_prompt,bias_eval_acc_and_f1': 0.8008814102564102, 'mrpc_test_prompt,bias_eval_loss': 3.585362434387207, 'mrpc_test_prompt,bias_eval_acc': 0.7230392156862745, 'mrpc_test_prompt,bias_eval_f1': 0.7963963963963964, 'mrpc_test_prompt,bias_eval_acc_and_f1': 0.7597178060413354, 'mrpc_dev_eval_loss': 2.5886242389678955, 'mrpc_dev_eval_acc': 0.78125, 'mrpc_dev_eval_f1': 0.8205128205128205, 'mrpc_dev_eval_acc_and_f1': 0.8008814102564102, 'mrpc_test_eval_loss': 3.585362434387207, 'mrpc_test_eval_acc': 0.7230392156862745, 'mrpc_test_eval_f1': 0.7963963963963964, 'mrpc_test_eval_acc_and_f1': 0.7597178060413354, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-42-roberta-large-20939', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_07-13-55_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-42-roberta-large-20939', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias,adapter_eval_loss': 0.7000097632408142, 'qnli_dev_prompt,bias,adapter_eval_acc': 0.5, 'qnli_test_prompt,bias,adapter_eval_loss': 0.6987605690956116, 'qnli_test_prompt,bias,adapter_eval_acc': 0.5053999633900788, 'qnli_dev_eval_loss': 0.7000097632408142, 'qnli_dev_eval_acc': 0.5, 'qnli_test_eval_loss': 0.6987605690956116, 'qnli_test_eval_acc': 0.5053999633900788, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-13-roberta-large-2060', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_07-03-42_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-13-roberta-large-2060', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias_eval_loss': 3.4522547721862793, 'cola_dev_prompt,bias_eval_mcc': 0.31814238148788887, 'cola_test_prompt,bias_eval_loss': 4.5849199295043945, 'cola_test_prompt,bias_eval_mcc': 0.08630405854100369, 'cola_dev_eval_loss': 3.4522547721862793, 'cola_dev_eval_mcc': 0.31814238148788887, 'cola_test_eval_loss': 4.5849199295043945, 'cola_test_eval_mcc': 0.08630405854100369, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-17426', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_07-18-44_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-17426', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt_eval_loss': 0.6375844478607178, 'qqp_dev_prompt_eval_acc': 0.75, 'qqp_dev_prompt_eval_f1': 0.7647058823529411, 'qqp_dev_prompt_eval_acc_and_f1': 0.7573529411764706, 'qqp_test_prompt_eval_loss': 0.6709862947463989, 'qqp_test_prompt_eval_acc': 0.6133811526094485, 'qqp_test_prompt_eval_f1': 0.485331401666063, 'qqp_test_prompt_eval_acc_and_f1': 0.5493562771377557, 'qqp_dev_eval_loss': 0.6375844478607178, 'qqp_dev_eval_acc': 0.75, 'qqp_dev_eval_f1': 0.7647058823529411, 'qqp_dev_eval_acc_and_f1': 0.7573529411764706, 'qqp_test_eval_loss': 0.6709862947463989, 'qqp_test_eval_acc': 0.6133811526094485, 'qqp_test_eval_f1': 0.485331401666063, 'qqp_test_eval_acc_and_f1': 0.5493562771377557, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-13-roberta-large-17868', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_07-00-57_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-13-roberta-large-17868', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,adapter_eval_loss': 2.272379159927368, 'rte_dev_prompt,adapter_eval_acc': 0.71875, 'rte_test_prompt,adapter_eval_loss': 2.4060401916503906, 'rte_test_prompt,adapter_eval_acc': 0.7220216606498195, 'rte_dev_eval_loss': 2.272379159927368, 'rte_dev_eval_acc': 0.71875, 'rte_test_eval_loss': 2.4060401916503906, 'rte_test_eval_acc': 0.7220216606498195, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-42-roberta-large-8351', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_07-17-24_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-42-roberta-large-8351', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias_eval_loss': 0.905920684337616, 'mrpc_dev_prompt,bias_eval_acc': 0.75, 'mrpc_dev_prompt,bias_eval_f1': 0.7777777777777777, 'mrpc_dev_prompt,bias_eval_acc_and_f1': 0.7638888888888888, 'mrpc_test_prompt,bias_eval_loss': 1.9160922765731812, 'mrpc_test_prompt,bias_eval_acc': 0.6862745098039216, 'mrpc_test_prompt,bias_eval_f1': 0.7611940298507461, 'mrpc_test_prompt,bias_eval_acc_and_f1': 0.7237342698273339, 'mrpc_dev_eval_loss': 0.905920684337616, 'mrpc_dev_eval_acc': 0.75, 'mrpc_dev_eval_f1': 0.7777777777777777, 'mrpc_dev_eval_acc_and_f1': 0.7638888888888888, 'mrpc_test_eval_loss': 1.9160922765731812, 'mrpc_test_eval_acc': 0.6862745098039216, 'mrpc_test_eval_f1': 0.7611940298507461, 'mrpc_test_eval_acc_and_f1': 0.7237342698273339, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-42-roberta-large-27870', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_07-24-30_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-42-roberta-large-27870', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_adapter_eval_loss': 0.005615028087049723, 'sst-2_dev_adapter_eval_acc': 1.0, 'sst-2_test_adapter_eval_loss': 0.5036115050315857, 'sst-2_test_adapter_eval_acc': 0.9243119266055045, 'sst-2_dev_eval_loss': 0.005615028087049723, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.5036115050315857, 'sst-2_test_eval_acc': 0.9243119266055045, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--100-roberta-large-27810', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_07-16-45_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--100-roberta-large-27810', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias_eval_loss': 1.744868278503418, 'cola_dev_prompt,bias_eval_mcc': 0.5, 'cola_test_prompt,bias_eval_loss': 3.2195093631744385, 'cola_test_prompt,bias_eval_mcc': 0.017258471076539668, 'cola_dev_eval_loss': 1.744868278503418, 'cola_dev_eval_mcc': 0.5, 'cola_test_eval_loss': 3.2195093631744385, 'cola_test_eval_mcc': 0.017258471076539668, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-32250', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_07-29-21_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-32250', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias,adapter_eval_loss': 2.1797738075256348, 'sts-b_dev_bias,adapter_eval_pearson': 0.8723482099676851, 'sts-b_dev_bias,adapter_eval_spearmanr': 0.863313136606125, 'sts-b_dev_bias,adapter_eval_corr': 0.867830673286905, 'sts-b_test_bias,adapter_eval_loss': 2.1777892112731934, 'sts-b_test_bias,adapter_eval_pearson': 0.6690124980176695, 'sts-b_test_bias,adapter_eval_spearmanr': 0.6625336971217343, 'sts-b_test_bias,adapter_eval_corr': 0.6657730975697018, 'sts-b_dev_eval_loss': 2.1797738075256348, 'sts-b_dev_eval_pearson': 0.8723482099676851, 'sts-b_dev_eval_spearmanr': 0.863313136606125, 'sts-b_dev_eval_corr': 0.867830673286905, 'sts-b_test_eval_loss': 2.1777892112731934, 'sts-b_test_eval_pearson': 0.6690124980176695, 'sts-b_test_eval_spearmanr': 0.6625336971217343, 'sts-b_test_eval_corr': 0.6657730975697018, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--13-roberta-large-30069', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_07-12-08_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--13-roberta-large-30069', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias_eval_loss': 0.8311781883239746, 'mrpc_dev_prompt,bias_eval_acc': 0.78125, 'mrpc_dev_prompt,bias_eval_f1': 0.7999999999999999, 'mrpc_dev_prompt,bias_eval_acc_and_f1': 0.7906249999999999, 'mrpc_test_prompt,bias_eval_loss': 1.5614261627197266, 'mrpc_test_prompt,bias_eval_acc': 0.7009803921568627, 'mrpc_test_prompt,bias_eval_f1': 0.7781818181818182, 'mrpc_test_prompt,bias_eval_acc_and_f1': 0.7395811051693404, 'mrpc_dev_eval_loss': 0.8311781883239746, 'mrpc_dev_eval_acc': 0.78125, 'mrpc_dev_eval_f1': 0.7999999999999999, 'mrpc_dev_eval_acc_and_f1': 0.7906249999999999, 'mrpc_test_eval_loss': 1.5614261627197266, 'mrpc_test_eval_acc': 0.7009803921568627, 'mrpc_test_eval_f1': 0.7781818181818182, 'mrpc_test_eval_acc_and_f1': 0.7395811051693404, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-42-roberta-large-2758', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_07-34-44_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-42-roberta-large-2758', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias_eval_loss': 2.7614736557006836, 'mnli_dev_bias_eval_mnli/acc': 0.7083333333333334, 'mnli_test_bias_eval_loss': 2.7787258625030518, 'mnli_test_bias_eval_mnli/acc': 0.6567498726439124, 'mnli-mm_test_bias_eval_loss': 2.5265114307403564, 'mnli-mm_test_bias_eval_mnli-mm/acc': 0.6697518307567127, 'mnli_dev_eval_loss': 2.7614736557006836, 'mnli_dev_eval_mnli/acc': 0.7083333333333334, 'mnli_test_eval_loss': 2.7787258625030518, 'mnli_test_eval_mnli/acc': 0.6567498726439124, 'mnli-mm_test_eval_loss': 2.5265114307403564, 'mnli-mm_test_eval_mnli-mm/acc': 0.6697518307567127, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--42-roberta-large-8276', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_06-59-47_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--42-roberta-large-8276', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias,adapter_eval_loss': 3.7384932041168213, 'qnli_dev_prompt,bias,adapter_eval_acc': 0.75, 'qnli_test_prompt,bias,adapter_eval_loss': 3.886017322540283, 'qnli_test_prompt,bias,adapter_eval_acc': 0.6507413509060955, 'qnli_dev_eval_loss': 3.7384932041168213, 'qnli_dev_eval_acc': 0.75, 'qnli_test_eval_loss': 3.886017322540283, 'qnli_test_eval_acc': 0.6507413509060955, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-13-roberta-large-28768', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_07-25-53_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-13-roberta-large-28768', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,adapter_eval_loss': 2.30804181098938, 'rte_dev_prompt,adapter_eval_acc': 0.65625, 'rte_test_prompt,adapter_eval_loss': 1.8218728303909302, 'rte_test_prompt,adapter_eval_acc': 0.6823104693140795, 'rte_dev_eval_loss': 2.30804181098938, 'rte_dev_eval_acc': 0.65625, 'rte_test_eval_loss': 1.8218728303909302, 'rte_test_eval_acc': 0.6823104693140795, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-42-roberta-large-29117', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_07-33-22_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-42-roberta-large-29117', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias_eval_loss': 3.0061488151550293, 'cola_dev_prompt,bias_eval_mcc': 0.31814238148788887, 'cola_test_prompt,bias_eval_loss': 4.141242980957031, 'cola_test_prompt,bias_eval_mcc': -0.005110605851005528, 'cola_dev_eval_loss': 3.0061488151550293, 'cola_dev_eval_mcc': 0.31814238148788887, 'cola_test_eval_loss': 4.141242980957031, 'cola_test_eval_mcc': -0.005110605851005528, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-16655', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_07-39-41_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-16655', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias_eval_loss': 0.7749174237251282, 'mrpc_dev_prompt,bias_eval_acc': 0.75, 'mrpc_dev_prompt,bias_eval_f1': 0.7777777777777777, 'mrpc_dev_prompt,bias_eval_acc_and_f1': 0.7638888888888888, 'mrpc_test_prompt,bias_eval_loss': 1.023889183998108, 'mrpc_test_prompt,bias_eval_acc': 0.7132352941176471, 'mrpc_test_prompt,bias_eval_f1': 0.7950963222416813, 'mrpc_test_prompt,bias_eval_acc_and_f1': 0.7541658081796642, 'mrpc_dev_eval_loss': 0.7749174237251282, 'mrpc_dev_eval_acc': 0.75, 'mrpc_dev_eval_f1': 0.7777777777777777, 'mrpc_dev_eval_acc_and_f1': 0.7638888888888888, 'mrpc_test_eval_loss': 1.023889183998108, 'mrpc_test_eval_acc': 0.7132352941176471, 'mrpc_test_eval_f1': 0.7950963222416813, 'mrpc_test_eval_acc_and_f1': 0.7541658081796642, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-42-roberta-large-20530', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_07-45-31_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-42-roberta-large-20530', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_adapter_eval_loss': 0.005824219901114702, 'sst-2_dev_adapter_eval_acc': 1.0, 'sst-2_test_adapter_eval_loss': 0.40630829334259033, 'sst-2_test_adapter_eval_acc': 0.9220183486238532, 'sst-2_dev_eval_loss': 0.005824219901114702, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.40630829334259033, 'sst-2_test_eval_acc': 0.9220183486238532, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--100-roberta-large-32765', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_07-37-40_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--100-roberta-large-32765', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias_eval_loss': 1.7615180015563965, 'cola_dev_prompt,bias_eval_mcc': 0.31814238148788887, 'cola_test_prompt,bias_eval_loss': 2.8047549724578857, 'cola_test_prompt,bias_eval_mcc': 0.02512527421286872, 'cola_dev_eval_loss': 1.7615180015563965, 'cola_dev_eval_mcc': 0.31814238148788887, 'cola_test_eval_loss': 2.8047549724578857, 'cola_test_eval_mcc': 0.02512527421286872, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-18320', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_07-50-41_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-18320', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt_eval_loss': 0.6834865808486938, 'qqp_dev_prompt_eval_acc': 0.65625, 'qqp_dev_prompt_eval_f1': 0.7317073170731707, 'qqp_dev_prompt_eval_acc_and_f1': 0.6939786585365854, 'qqp_test_prompt_eval_loss': 0.8111069798469543, 'qqp_test_prompt_eval_acc': 0.4891169923324264, 'qqp_test_prompt_eval_f1': 0.5254887546233545, 'qqp_test_prompt_eval_acc_and_f1': 0.5073028734778905, 'qqp_dev_eval_loss': 0.6834865808486938, 'qqp_dev_eval_acc': 0.65625, 'qqp_dev_eval_f1': 0.7317073170731707, 'qqp_dev_eval_acc_and_f1': 0.6939786585365854, 'qqp_test_eval_loss': 0.8111069798469543, 'qqp_test_eval_acc': 0.4891169923324264, 'qqp_test_eval_f1': 0.5254887546233545, 'qqp_test_eval_acc_and_f1': 0.5073028734778905, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-13-roberta-large-19116', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_07-32-49_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-13-roberta-large-19116', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,adapter_eval_loss': 2.5450198650360107, 'rte_dev_prompt,adapter_eval_acc': 0.78125, 'rte_test_prompt,adapter_eval_loss': 2.767514228820801, 'rte_test_prompt,adapter_eval_acc': 0.7364620938628159, 'rte_dev_eval_loss': 2.5450198650360107, 'rte_dev_eval_acc': 0.78125, 'rte_test_eval_loss': 2.767514228820801, 'rte_test_eval_acc': 0.7364620938628159, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-100-roberta-large-31854', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_07-49-37_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-100-roberta-large-31854', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias_eval_loss': 2.7562005519866943, 'mrpc_dev_prompt,bias_eval_acc': 0.71875, 'mrpc_dev_prompt,bias_eval_f1': 0.742857142857143, 'mrpc_dev_prompt,bias_eval_acc_and_f1': 0.7308035714285714, 'mrpc_test_prompt,bias_eval_loss': 2.8678362369537354, 'mrpc_test_prompt,bias_eval_acc': 0.6544117647058824, 'mrpc_test_prompt,bias_eval_f1': 0.7304015296367112, 'mrpc_test_prompt,bias_eval_acc_and_f1': 0.6924066471712969, 'mrpc_dev_eval_loss': 2.7562005519866943, 'mrpc_dev_eval_acc': 0.71875, 'mrpc_dev_eval_f1': 0.742857142857143, 'mrpc_dev_eval_acc_and_f1': 0.7308035714285714, 'mrpc_test_eval_loss': 2.8678362369537354, 'mrpc_test_eval_acc': 0.6544117647058824, 'mrpc_test_eval_f1': 0.7304015296367112, 'mrpc_test_eval_acc_and_f1': 0.6924066471712969, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-100-roberta-large-6652', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_07-56-38_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-100-roberta-large-6652', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias,adapter_eval_loss': 2.516714096069336, 'qnli_dev_prompt,bias,adapter_eval_acc': 0.71875, 'qnli_test_prompt,bias,adapter_eval_loss': 2.537200450897217, 'qnli_test_prompt,bias,adapter_eval_acc': 0.71499176276771, 'qnli_dev_eval_loss': 2.516714096069336, 'qnli_dev_eval_acc': 0.71875, 'qnli_test_eval_loss': 2.537200450897217, 'qnli_test_eval_acc': 0.71499176276771, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-13-roberta-large-8005', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_07-47-59_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-13-roberta-large-8005', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias_eval_loss': 3.027583599090576, 'cola_dev_prompt,bias_eval_mcc': 0.2519763153394848, 'cola_test_prompt,bias_eval_loss': 3.8511600494384766, 'cola_test_prompt,bias_eval_mcc': 0.0647553232440163, 'cola_dev_eval_loss': 3.027583599090576, 'cola_dev_eval_mcc': 0.2519763153394848, 'cola_test_eval_loss': 3.8511600494384766, 'cola_test_eval_mcc': 0.0647553232440163, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-20193', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_08-01-28_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-20193', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias,adapter_eval_loss': 2.1833479404449463, 'sts-b_dev_bias,adapter_eval_pearson': 0.840635257532893, 'sts-b_dev_bias,adapter_eval_spearmanr': 0.8331826078971647, 'sts-b_dev_bias,adapter_eval_corr': 0.8369089327150289, 'sts-b_test_bias,adapter_eval_loss': 2.1823573112487793, 'sts-b_test_bias,adapter_eval_pearson': 0.6195476538302378, 'sts-b_test_bias,adapter_eval_spearmanr': 0.6077638811681133, 'sts-b_test_bias,adapter_eval_corr': 0.6136557674991756, 'sts-b_dev_eval_loss': 2.1833479404449463, 'sts-b_dev_eval_pearson': 0.840635257532893, 'sts-b_dev_eval_spearmanr': 0.8331826078971647, 'sts-b_dev_eval_corr': 0.8369089327150289, 'sts-b_test_eval_loss': 2.1823573112487793, 'sts-b_test_eval_pearson': 0.6195476538302378, 'sts-b_test_eval_spearmanr': 0.6077638811681133, 'sts-b_test_eval_corr': 0.6136557674991756, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--13-roberta-large-29485', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_07-43-45_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--13-roberta-large-29485', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias_eval_loss': 2.1737570762634277, 'mrpc_dev_prompt,bias_eval_acc': 0.65625, 'mrpc_dev_prompt,bias_eval_f1': 0.6666666666666667, 'mrpc_dev_prompt,bias_eval_acc_and_f1': 0.6614583333333334, 'mrpc_test_prompt,bias_eval_loss': 1.616147756576538, 'mrpc_test_prompt,bias_eval_acc': 0.6838235294117647, 'mrpc_test_prompt,bias_eval_f1': 0.7606679035250464, 'mrpc_test_prompt,bias_eval_acc_and_f1': 0.7222457164684055, 'mrpc_dev_eval_loss': 2.1737570762634277, 'mrpc_dev_eval_acc': 0.65625, 'mrpc_dev_eval_f1': 0.6666666666666667, 'mrpc_dev_eval_acc_and_f1': 0.6614583333333334, 'mrpc_test_eval_loss': 1.616147756576538, 'mrpc_test_eval_acc': 0.6838235294117647, 'mrpc_test_eval_f1': 0.7606679035250464, 'mrpc_test_eval_acc_and_f1': 0.7222457164684055, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-100-roberta-large-11397', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_08-07-22_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-100-roberta-large-11397', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,adapter_eval_loss': 1.4633811712265015, 'sst-2_dev_prompt,adapter_eval_acc': 0.875, 'sst-2_test_prompt,adapter_eval_loss': 1.007481575012207, 'sst-2_test_prompt,adapter_eval_acc': 0.8967889908256881, 'sst-2_dev_eval_loss': 1.4633811712265015, 'sst-2_dev_eval_acc': 0.875, 'sst-2_test_eval_loss': 1.007481575012207, 'sst-2_test_eval_acc': 0.8967889908256881, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-10578', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_07-58-05_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-10578', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias_eval_loss': 4.4898834228515625, 'cola_dev_prompt,bias_eval_mcc': 0.26967994498529685, 'cola_test_prompt,bias_eval_loss': 5.148508071899414, 'cola_test_prompt,bias_eval_mcc': 0.05177190093403012, 'cola_dev_eval_loss': 4.4898834228515625, 'cola_dev_eval_mcc': 0.26967994498529685, 'cola_test_eval_loss': 5.148508071899414, 'cola_test_eval_mcc': 0.05177190093403012, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-10077', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_08-11-49_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-10077', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,adapter_eval_loss': 2.80668568611145, 'rte_dev_prompt,adapter_eval_acc': 0.75, 'rte_test_prompt,adapter_eval_loss': 3.180340528488159, 'rte_test_prompt,adapter_eval_acc': 0.7148014440433214, 'rte_dev_eval_loss': 2.80668568611145, 'rte_dev_eval_acc': 0.75, 'rte_test_eval_loss': 3.180340528488159, 'rte_test_eval_acc': 0.7148014440433214, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-100-roberta-large-2448', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_08-05-59_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-100-roberta-large-2448', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias_eval_loss': 1.3982083797454834, 'mrpc_dev_prompt,bias_eval_acc': 0.6875, 'mrpc_dev_prompt,bias_eval_f1': 0.6875, 'mrpc_dev_prompt,bias_eval_acc_and_f1': 0.6875, 'mrpc_test_prompt,bias_eval_loss': 1.3381341695785522, 'mrpc_test_prompt,bias_eval_acc': 0.6568627450980392, 'mrpc_test_prompt,bias_eval_f1': 0.7265625, 'mrpc_test_prompt,bias_eval_acc_and_f1': 0.6917126225490196, 'mrpc_dev_eval_loss': 1.3982083797454834, 'mrpc_dev_eval_acc': 0.6875, 'mrpc_dev_eval_f1': 0.6875, 'mrpc_dev_eval_acc_and_f1': 0.6875, 'mrpc_test_eval_loss': 1.3381341695785522, 'mrpc_test_eval_acc': 0.6568627450980392, 'mrpc_test_eval_f1': 0.7265625, 'mrpc_test_eval_acc_and_f1': 0.6917126225490196, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-100-roberta-large-19516', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_08-17-51_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-100-roberta-large-19516', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias,adapter_eval_loss': 3.0664820671081543, 'qnli_dev_prompt,bias,adapter_eval_acc': 0.6875, 'qnli_test_prompt,bias,adapter_eval_loss': 3.0123977661132812, 'qnli_test_prompt,bias,adapter_eval_acc': 0.671609006040637, 'qnli_dev_eval_loss': 3.0664820671081543, 'qnli_dev_eval_acc': 0.6875, 'qnli_test_eval_loss': 3.0123977661132812, 'qnli_test_eval_acc': 0.671609006040637, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-13-roberta-large-8231', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_08-09-49_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-13-roberta-large-8231', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias_eval_loss': 1.270367980003357, 'mnli_dev_bias_eval_mnli/acc': 0.6458333333333334, 'mnli_test_bias_eval_loss': 1.4040089845657349, 'mnli_test_bias_eval_mnli/acc': 0.6198675496688741, 'mnli-mm_test_bias_eval_loss': 1.3464566469192505, 'mnli-mm_test_bias_eval_mnli-mm/acc': 0.6282546786004882, 'mnli_dev_eval_loss': 1.270367980003357, 'mnli_dev_eval_mnli/acc': 0.6458333333333334, 'mnli_test_eval_loss': 1.4040089845657349, 'mnli_test_eval_mnli/acc': 0.6198675496688741, 'mnli-mm_test_eval_loss': 1.3464566469192505, 'mnli-mm_test_eval_mnli-mm/acc': 0.6282546786004882, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--42-roberta-large-10827', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_07-46-00_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--42-roberta-large-10827', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias_eval_loss': 0.9852031469345093, 'cola_dev_prompt,bias_eval_mcc': 0.3872983346207417, 'cola_test_prompt,bias_eval_loss': 1.2959644794464111, 'cola_test_prompt,bias_eval_mcc': 0.05169878132883272, 'cola_dev_eval_loss': 0.9852031469345093, 'cola_dev_eval_mcc': 0.3872983346207417, 'cola_test_eval_loss': 1.2959644794464111, 'cola_test_eval_mcc': 0.05169878132883272, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-17011', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_08-22-07_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-17011', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt_eval_loss': 0.6998336315155029, 'qqp_dev_prompt_eval_acc': 0.65625, 'qqp_dev_prompt_eval_f1': 0.7027027027027026, 'qqp_dev_prompt_eval_acc_and_f1': 0.6794763513513513, 'qqp_test_prompt_eval_loss': 0.756781280040741, 'qqp_test_prompt_eval_acc': 0.5464259213455355, 'qqp_test_prompt_eval_f1': 0.5440803540351051, 'qqp_test_prompt_eval_acc_and_f1': 0.5452531376903202, 'qqp_dev_eval_loss': 0.6998336315155029, 'qqp_dev_eval_acc': 0.65625, 'qqp_dev_eval_f1': 0.7027027027027026, 'qqp_dev_eval_acc_and_f1': 0.6794763513513513, 'qqp_test_eval_loss': 0.756781280040741, 'qqp_test_eval_acc': 0.5464259213455355, 'qqp_test_eval_f1': 0.5440803540351051, 'qqp_test_eval_acc_and_f1': 0.5452531376903202, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-13-roberta-large-8139', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_08-04-29_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-13-roberta-large-8139', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,adapter_eval_loss': 1.0825508832931519, 'rte_dev_prompt,adapter_eval_acc': 0.75, 'rte_test_prompt,adapter_eval_loss': 1.3775278329849243, 'rte_test_prompt,adapter_eval_acc': 0.7075812274368231, 'rte_dev_eval_loss': 1.0825508832931519, 'rte_dev_eval_acc': 0.75, 'rte_test_eval_loss': 1.3775278329849243, 'rte_test_eval_acc': 0.7075812274368231, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-100-roberta-large-9353', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_08-22-27_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-100-roberta-large-9353', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias_eval_loss': 1.2573459148406982, 'mrpc_dev_prompt,bias_eval_acc': 0.6875, 'mrpc_dev_prompt,bias_eval_f1': 0.6875, 'mrpc_dev_prompt,bias_eval_acc_and_f1': 0.6875, 'mrpc_test_prompt,bias_eval_loss': 1.1896463632583618, 'mrpc_test_prompt,bias_eval_acc': 0.6715686274509803, 'mrpc_test_prompt,bias_eval_f1': 0.7462121212121212, 'mrpc_test_prompt,bias_eval_acc_and_f1': 0.7088903743315508, 'mrpc_dev_eval_loss': 1.2573459148406982, 'mrpc_dev_eval_acc': 0.6875, 'mrpc_dev_eval_f1': 0.6875, 'mrpc_dev_eval_acc_and_f1': 0.6875, 'mrpc_test_eval_loss': 1.1896463632583618, 'mrpc_test_eval_acc': 0.6715686274509803, 'mrpc_test_eval_f1': 0.7462121212121212, 'mrpc_test_eval_acc_and_f1': 0.7088903743315508, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-100-roberta-large-6732', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_08-28-24_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-100-roberta-large-6732', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias_eval_loss': 0.8021862506866455, 'cola_dev_prompt,bias_eval_mcc': 0.5163977794943222, 'cola_test_prompt,bias_eval_loss': 1.0487045049667358, 'cola_test_prompt,bias_eval_mcc': 0.03795334512627249, 'cola_dev_eval_loss': 0.8021862506866455, 'cola_dev_eval_mcc': 0.5163977794943222, 'cola_test_eval_loss': 1.0487045049667358, 'cola_test_eval_mcc': 0.03795334512627249, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-3791', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_08-32-44_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-3791', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,adapter_eval_loss': 0.022712890058755875, 'sst-2_dev_prompt,adapter_eval_acc': 1.0, 'sst-2_test_prompt,adapter_eval_loss': 0.8753615617752075, 'sst-2_test_prompt,adapter_eval_acc': 0.930045871559633, 'sst-2_dev_eval_loss': 0.022712890058755875, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.8753615617752075, 'sst-2_test_eval_acc': 0.930045871559633, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-1316', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_08-20-39_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-1316', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias,adapter_eval_loss': 2.241487979888916, 'sts-b_dev_prompt,bias,adapter_eval_pearson': 0.25171668474136516, 'sts-b_dev_prompt,bias,adapter_eval_spearmanr': 0.23655448585158698, 'sts-b_dev_prompt,bias,adapter_eval_corr': 0.24413558529647605, 'sts-b_test_prompt,bias,adapter_eval_loss': 2.212935209274292, 'sts-b_test_prompt,bias,adapter_eval_pearson': -0.003909856111205273, 'sts-b_test_prompt,bias,adapter_eval_spearmanr': 0.0023750477448189642, 'sts-b_test_prompt,bias,adapter_eval_corr': -0.0007674041831931544, 'sts-b_dev_eval_loss': 2.241487979888916, 'sts-b_dev_eval_pearson': 0.25171668474136516, 'sts-b_dev_eval_spearmanr': 0.23655448585158698, 'sts-b_dev_eval_corr': 0.24413558529647605, 'sts-b_test_eval_loss': 2.212935209274292, 'sts-b_test_eval_pearson': -0.003909856111205273, 'sts-b_test_eval_spearmanr': 0.0023750477448189642, 'sts-b_test_eval_corr': -0.0007674041831931544, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-13-roberta-large-25119', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_08-14-31_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-13-roberta-large-25119', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,adapter_eval_loss': 1.4724828004837036, 'rte_dev_prompt,adapter_eval_acc': 0.71875, 'rte_test_prompt,adapter_eval_loss': 2.0858545303344727, 'rte_test_prompt,adapter_eval_acc': 0.6714801444043321, 'rte_dev_eval_loss': 1.4724828004837036, 'rte_dev_eval_acc': 0.71875, 'rte_test_eval_loss': 2.0858545303344727, 'rte_test_eval_acc': 0.6714801444043321, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-100-roberta-large-27017', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_08-38-34_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-100-roberta-large-27017', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias,adapter_eval_loss': 0.693177342414856, 'mrpc_dev_bias,adapter_eval_acc': 0.5, 'mrpc_dev_bias,adapter_eval_f1': 0.6666666666666666, 'mrpc_dev_bias,adapter_eval_acc_and_f1': 0.5833333333333333, 'mrpc_test_bias,adapter_eval_loss': 0.6918856501579285, 'mrpc_test_bias,adapter_eval_acc': 0.6838235294117647, 'mrpc_test_bias,adapter_eval_f1': 0.8122270742358079, 'mrpc_test_bias,adapter_eval_acc_and_f1': 0.7480253018237863, 'mrpc_dev_eval_loss': 0.693177342414856, 'mrpc_dev_eval_acc': 0.5, 'mrpc_dev_eval_f1': 0.6666666666666666, 'mrpc_dev_eval_acc_and_f1': 0.5833333333333333, 'mrpc_test_eval_loss': 0.6918856501579285, 'mrpc_test_eval_acc': 0.6838235294117647, 'mrpc_test_eval_f1': 0.8122270742358079, 'mrpc_test_eval_acc_and_f1': 0.7480253018237863, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--42-roberta-large-31153', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_08-39-14_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--42-roberta-large-31153', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias,adapter_eval_loss': 4.4160895347595215, 'cola_dev_bias,adapter_eval_mcc': 0.22677868380553634, 'cola_test_bias,adapter_eval_loss': 2.941634178161621, 'cola_test_bias,adapter_eval_mcc': 0.24545439131070698, 'cola_dev_eval_loss': 4.4160895347595215, 'cola_dev_eval_mcc': 0.22677868380553634, 'cola_test_eval_loss': 2.941634178161621, 'cola_test_eval_mcc': 0.24545439131070698, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--42-roberta-large-24596', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_08-43-21_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-24596', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,adapter_eval_loss': 0.21049591898918152, 'sst-2_dev_prompt,adapter_eval_acc': 0.96875, 'sst-2_test_prompt,adapter_eval_loss': 0.7057647705078125, 'sst-2_test_prompt,adapter_eval_acc': 0.9197247706422018, 'sst-2_dev_eval_loss': 0.21049591898918152, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.7057647705078125, 'sst-2_test_eval_acc': 0.9197247706422018, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-18842', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_08-44-05_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-18842', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias_eval_loss': 0.6995078325271606, 'qqp_dev_bias_eval_acc': 0.5, 'qqp_dev_bias_eval_f1': 0.6666666666666666, 'qqp_dev_bias_eval_acc_and_f1': 0.5833333333333333, 'qqp_test_bias_eval_loss': 0.7293131351470947, 'qqp_test_bias_eval_acc': 0.36816720257234725, 'qqp_test_bias_eval_f1': 0.5381903642773208, 'qqp_test_bias_eval_acc_and_f1': 0.45317878342483403, 'qqp_dev_eval_loss': 0.6995078325271606, 'qqp_dev_eval_acc': 0.5, 'qqp_dev_eval_f1': 0.6666666666666666, 'qqp_dev_eval_acc_and_f1': 0.5833333333333333, 'qqp_test_eval_loss': 0.7293131351470947, 'qqp_test_eval_acc': 0.36816720257234725, 'qqp_test_eval_f1': 0.5381903642773208, 'qqp_test_eval_acc_and_f1': 0.45317878342483403, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16--13-roberta-large-14950', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_08-36-23_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--13-roberta-large-14950', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias_eval_loss': 2.9183406829833984, 'rte_dev_prompt,bias_eval_acc': 0.78125, 'rte_test_prompt,bias_eval_loss': 3.9431161880493164, 'rte_test_prompt,bias_eval_acc': 0.6787003610108303, 'rte_dev_eval_loss': 2.9183406829833984, 'rte_dev_eval_acc': 0.78125, 'rte_test_eval_loss': 3.9431161880493164, 'rte_test_eval_acc': 0.6787003610108303, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-42-roberta-large-10397', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_08-54-35_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-42-roberta-large-10397', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias,adapter_eval_loss': 3.705249786376953, 'mrpc_dev_bias,adapter_eval_acc': 0.78125, 'mrpc_dev_bias,adapter_eval_f1': 0.8205128205128205, 'mrpc_dev_bias,adapter_eval_acc_and_f1': 0.8008814102564102, 'mrpc_test_bias,adapter_eval_loss': 3.745072364807129, 'mrpc_test_bias,adapter_eval_acc': 0.7156862745098039, 'mrpc_test_bias,adapter_eval_f1': 0.8047138047138047, 'mrpc_test_bias,adapter_eval_acc_and_f1': 0.7602000396118043, 'mrpc_dev_eval_loss': 3.705249786376953, 'mrpc_dev_eval_acc': 0.78125, 'mrpc_dev_eval_f1': 0.8205128205128205, 'mrpc_dev_eval_acc_and_f1': 0.8008814102564102, 'mrpc_test_eval_loss': 3.745072364807129, 'mrpc_test_eval_acc': 0.7156862745098039, 'mrpc_test_eval_f1': 0.8047138047138047, 'mrpc_test_eval_acc_and_f1': 0.7602000396118043, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--42-roberta-large-9433', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_08-55-30_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--42-roberta-large-9433', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias_eval_loss': 7.087846279144287, 'mnli_dev_bias_eval_mnli/acc': 0.5833333333333334, 'mnli_test_bias_eval_loss': 6.629271030426025, 'mnli_test_bias_eval_mnli/acc': 0.5938869077941925, 'mnli-mm_test_bias_eval_loss': 5.938827991485596, 'mnli-mm_test_bias_eval_mnli-mm/acc': 0.6304922701383239, 'mnli_dev_eval_loss': 7.087846279144287, 'mnli_dev_eval_mnli/acc': 0.5833333333333334, 'mnli_test_eval_loss': 6.629271030426025, 'mnli_test_eval_mnli/acc': 0.5938869077941925, 'mnli-mm_test_eval_loss': 5.938827991485596, 'mnli-mm_test_eval_mnli-mm/acc': 0.6304922701383239, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--100-roberta-large-13341', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_08-31-32_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--100-roberta-large-13341', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias,adapter_eval_loss': 2.307736873626709, 'cola_dev_bias,adapter_eval_mcc': 0.5, 'cola_test_bias,adapter_eval_loss': 3.1234772205352783, 'cola_test_bias,adapter_eval_mcc': 0.1108941087965775, 'cola_dev_eval_loss': 2.307736873626709, 'cola_dev_eval_mcc': 0.5, 'cola_test_eval_loss': 3.1234772205352783, 'cola_test_eval_mcc': 0.1108941087965775, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--42-roberta-large-9628', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_08-59-43_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-9628', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias,adapter_eval_loss': 2.1838748455047607, 'sts-b_dev_prompt,bias,adapter_eval_pearson': 0.8684564371882513, 'sts-b_dev_prompt,bias,adapter_eval_spearmanr': 0.8616596319818529, 'sts-b_dev_prompt,bias,adapter_eval_corr': 0.865058034585052, 'sts-b_test_prompt,bias,adapter_eval_loss': 2.1759414672851562, 'sts-b_test_prompt,bias,adapter_eval_pearson': 0.6886167501936642, 'sts-b_test_prompt,bias,adapter_eval_spearmanr': 0.6888781984921105, 'sts-b_test_prompt,bias,adapter_eval_corr': 0.6887474743428874, 'sts-b_dev_eval_loss': 2.1838748455047607, 'sts-b_dev_eval_pearson': 0.8684564371882513, 'sts-b_dev_eval_spearmanr': 0.8616596319818529, 'sts-b_dev_eval_corr': 0.865058034585052, 'sts-b_test_eval_loss': 2.1759414672851562, 'sts-b_test_eval_pearson': 0.6886167501936642, 'sts-b_test_eval_spearmanr': 0.6888781984921105, 'sts-b_test_eval_corr': 0.6887474743428874, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-13-roberta-large-4416', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_08-48-12_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-13-roberta-large-4416', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias_eval_loss': 2.1131815910339355, 'rte_dev_prompt,bias_eval_acc': 0.71875, 'rte_test_prompt,bias_eval_loss': 2.215113639831543, 'rte_test_prompt,bias_eval_acc': 0.7003610108303249, 'rte_dev_eval_loss': 2.1131815910339355, 'rte_dev_eval_acc': 0.71875, 'rte_test_eval_loss': 2.215113639831543, 'rte_test_eval_acc': 0.7003610108303249, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-42-roberta-large-4196', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_09-10-07_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-42-roberta-large-4196', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias,adapter_eval_loss': 2.3124663829803467, 'mrpc_dev_bias,adapter_eval_acc': 0.71875, 'mrpc_dev_bias,adapter_eval_f1': 0.7692307692307693, 'mrpc_dev_bias,adapter_eval_acc_and_f1': 0.7439903846153846, 'mrpc_test_bias,adapter_eval_loss': 2.0375776290893555, 'mrpc_test_bias,adapter_eval_acc': 0.6715686274509803, 'mrpc_test_bias,adapter_eval_f1': 0.7624113475177305, 'mrpc_test_bias,adapter_eval_acc_and_f1': 0.7169899874843555, 'mrpc_dev_eval_loss': 2.3124663829803467, 'mrpc_dev_eval_acc': 0.71875, 'mrpc_dev_eval_f1': 0.7692307692307693, 'mrpc_dev_eval_acc_and_f1': 0.7439903846153846, 'mrpc_test_eval_loss': 2.0375776290893555, 'mrpc_test_eval_acc': 0.6715686274509803, 'mrpc_test_eval_f1': 0.7624113475177305, 'mrpc_test_eval_acc_and_f1': 0.7169899874843555, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--42-roberta-large-25793', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_09-11-50_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--42-roberta-large-25793', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,adapter_eval_loss': 0.18182054162025452, 'sst-2_dev_prompt,adapter_eval_acc': 0.96875, 'sst-2_test_prompt,adapter_eval_loss': 0.43302515149116516, 'sst-2_test_prompt,adapter_eval_acc': 0.9243119266055045, 'sst-2_dev_eval_loss': 0.18182054162025452, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.43302515149116516, 'sst-2_test_eval_acc': 0.9243119266055045, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-31887', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_09-08-22_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-31887', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias,adapter_eval_loss': 3.10984206199646, 'cola_dev_bias,adapter_eval_mcc': 0.31814238148788887, 'cola_test_bias,adapter_eval_loss': 4.916022777557373, 'cola_test_bias,adapter_eval_mcc': 0.08318501850513103, 'cola_dev_eval_loss': 3.10984206199646, 'cola_dev_eval_mcc': 0.31814238148788887, 'cola_test_eval_loss': 4.916022777557373, 'cola_test_eval_mcc': 0.08318501850513103, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--42-roberta-large-20610', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_09-16-02_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-20610', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias_eval_loss': 1.9129496812820435, 'rte_dev_prompt,bias_eval_acc': 0.625, 'rte_test_prompt,bias_eval_loss': 1.5899477005004883, 'rte_test_prompt,bias_eval_acc': 0.7220216606498195, 'rte_dev_eval_loss': 1.9129496812820435, 'rte_dev_eval_acc': 0.625, 'rte_test_eval_loss': 1.5899477005004883, 'rte_test_eval_acc': 0.7220216606498195, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-42-roberta-large-24974', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_09-25-34_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-42-roberta-large-24974', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias_eval_loss': 5.738094806671143, 'qqp_dev_bias_eval_acc': 0.65625, 'qqp_dev_bias_eval_f1': 0.717948717948718, 'qqp_dev_bias_eval_acc_and_f1': 0.687099358974359, 'qqp_test_bias_eval_loss': 5.849292278289795, 'qqp_test_bias_eval_acc': 0.5719515211476627, 'qqp_test_bias_eval_f1': 0.6014829825450191, 'qqp_test_bias_eval_acc_and_f1': 0.5867172518463408, 'qqp_dev_eval_loss': 5.738094806671143, 'qqp_dev_eval_acc': 0.65625, 'qqp_dev_eval_f1': 0.717948717948718, 'qqp_dev_eval_acc_and_f1': 0.687099358974359, 'qqp_test_eval_loss': 5.849292278289795, 'qqp_test_eval_acc': 0.5719515211476627, 'qqp_test_eval_f1': 0.6014829825450191, 'qqp_test_eval_acc_and_f1': 0.5867172518463408, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16--13-roberta-large-21951', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_09-08-54_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--13-roberta-large-21951', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias,adapter_eval_loss': 1.4267463684082031, 'mrpc_dev_bias,adapter_eval_acc': 0.6875, 'mrpc_dev_bias,adapter_eval_f1': 0.7368421052631579, 'mrpc_dev_bias,adapter_eval_acc_and_f1': 0.712171052631579, 'mrpc_test_bias,adapter_eval_loss': 1.3627465963363647, 'mrpc_test_bias,adapter_eval_acc': 0.6691176470588235, 'mrpc_test_bias,adapter_eval_f1': 0.7610619469026548, 'mrpc_test_bias,adapter_eval_acc_and_f1': 0.7150897969807392, 'mrpc_dev_eval_loss': 1.4267463684082031, 'mrpc_dev_eval_acc': 0.6875, 'mrpc_dev_eval_f1': 0.7368421052631579, 'mrpc_dev_eval_acc_and_f1': 0.712171052631579, 'mrpc_test_eval_loss': 1.3627465963363647, 'mrpc_test_eval_acc': 0.6691176470588235, 'mrpc_test_eval_f1': 0.7610619469026548, 'mrpc_test_eval_acc_and_f1': 0.7150897969807392, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--42-roberta-large-1538', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_09-27-50_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--42-roberta-large-1538', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias,adapter_eval_loss': 2.802344560623169, 'cola_dev_bias,adapter_eval_mcc': 0.2519763153394848, 'cola_test_bias,adapter_eval_loss': 3.220113754272461, 'cola_test_bias,adapter_eval_mcc': 0.04307401391674944, 'cola_dev_eval_loss': 2.802344560623169, 'cola_dev_eval_mcc': 0.2519763153394848, 'cola_test_eval_loss': 3.220113754272461, 'cola_test_eval_mcc': 0.04307401391674944, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--42-roberta-large-12372', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_09-32-40_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-12372', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,adapter_eval_loss': 1.400667667388916, 'sst-2_dev_prompt,adapter_eval_acc': 0.90625, 'sst-2_test_prompt,adapter_eval_loss': 1.8015698194503784, 'sst-2_test_prompt,adapter_eval_acc': 0.8612385321100917, 'sst-2_dev_eval_loss': 1.400667667388916, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 1.8015698194503784, 'sst-2_test_eval_acc': 0.8612385321100917, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-8569', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_09-30-55_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-8569', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias_eval_loss': 2.2844550609588623, 'rte_dev_prompt,bias_eval_acc': 0.53125, 'rte_test_prompt,bias_eval_loss': 1.507800579071045, 'rte_test_prompt,bias_eval_acc': 0.6750902527075813, 'rte_dev_eval_loss': 2.2844550609588623, 'rte_dev_eval_acc': 0.53125, 'rte_test_eval_loss': 1.507800579071045, 'rte_test_eval_acc': 0.6750902527075813, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-42-roberta-large-26374', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_09-40-50_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-42-roberta-large-26374', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias,adapter_eval_loss': 2.1860902309417725, 'sts-b_dev_prompt,bias,adapter_eval_pearson': 0.8440308358874461, 'sts-b_dev_prompt,bias,adapter_eval_spearmanr': 0.8359384489376185, 'sts-b_dev_prompt,bias,adapter_eval_corr': 0.8399846424125323, 'sts-b_test_prompt,bias,adapter_eval_loss': 2.1830615997314453, 'sts-b_test_prompt,bias,adapter_eval_pearson': 0.619029775747992, 'sts-b_test_prompt,bias,adapter_eval_spearmanr': 0.6038084957069781, 'sts-b_test_prompt,bias,adapter_eval_corr': 0.6114191357274851, 'sts-b_dev_eval_loss': 2.1860902309417725, 'sts-b_dev_eval_pearson': 0.8440308358874461, 'sts-b_dev_eval_spearmanr': 0.8359384489376185, 'sts-b_dev_eval_corr': 0.8399846424125323, 'sts-b_test_eval_loss': 2.1830615997314453, 'sts-b_test_eval_pearson': 0.619029775747992, 'sts-b_test_eval_spearmanr': 0.6038084957069781, 'sts-b_test_eval_corr': 0.6114191357274851, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-13-roberta-large-19452', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_09-23-50_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-13-roberta-large-19452', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias,adapter_eval_loss': 0.7254684567451477, 'mrpc_dev_bias,adapter_eval_acc': 0.5, 'mrpc_dev_bias,adapter_eval_f1': 0.6666666666666666, 'mrpc_dev_bias,adapter_eval_acc_and_f1': 0.5833333333333333, 'mrpc_test_bias,adapter_eval_loss': 0.6314773559570312, 'mrpc_test_bias,adapter_eval_acc': 0.6838235294117647, 'mrpc_test_bias,adapter_eval_f1': 0.8122270742358079, 'mrpc_test_bias,adapter_eval_acc_and_f1': 0.7480253018237863, 'mrpc_dev_eval_loss': 0.7254684567451477, 'mrpc_dev_eval_acc': 0.5, 'mrpc_dev_eval_f1': 0.6666666666666666, 'mrpc_dev_eval_acc_and_f1': 0.5833333333333333, 'mrpc_test_eval_loss': 0.6314773559570312, 'mrpc_test_eval_acc': 0.6838235294117647, 'mrpc_test_eval_f1': 0.8122270742358079, 'mrpc_test_eval_acc_and_f1': 0.7480253018237863, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--100-roberta-large-1185', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_09-43-54_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--100-roberta-large-1185', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias_eval_loss': 3.25571346282959, 'mnli_dev_bias_eval_mnli/acc': 0.7916666666666666, 'mnli_test_bias_eval_loss': 3.549346446990967, 'mnli_test_bias_eval_mnli/acc': 0.7224656138563423, 'mnli-mm_test_bias_eval_loss': 3.2834036350250244, 'mnli-mm_test_bias_eval_mnli-mm/acc': 0.7403376729048007, 'mnli_dev_eval_loss': 3.25571346282959, 'mnli_dev_eval_mnli/acc': 0.7916666666666666, 'mnli_test_eval_loss': 3.549346446990967, 'mnli_test_eval_mnli/acc': 0.7224656138563423, 'mnli-mm_test_eval_loss': 3.2834036350250244, 'mnli-mm_test_eval_mnli-mm/acc': 0.7403376729048007, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--100-roberta-large-14171', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_09-15-34_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--100-roberta-large-14171', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias,adapter_eval_loss': 0.7221612930297852, 'cola_dev_bias,adapter_eval_mcc': 0.0, 'cola_test_bias,adapter_eval_loss': 0.8147040605545044, 'cola_test_bias,adapter_eval_mcc': 0.0, 'cola_dev_eval_loss': 0.7221612930297852, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.8147040605545044, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--100-roberta-large-3559', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_09-48-25_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-3559', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias_eval_loss': 1.8535226583480835, 'rte_dev_prompt,bias_eval_acc': 0.84375, 'rte_test_prompt,bias_eval_loss': 3.5913116931915283, 'rte_test_prompt,bias_eval_acc': 0.740072202166065, 'rte_dev_eval_loss': 1.8535226583480835, 'rte_dev_eval_acc': 0.84375, 'rte_test_eval_loss': 3.5913116931915283, 'rte_test_eval_acc': 0.740072202166065, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-100-roberta-large-10918', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_09-55-45_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-100-roberta-large-10918', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias_eval_loss': 2.154200315475464, 'qqp_dev_bias_eval_acc': 0.6875, 'qqp_dev_bias_eval_f1': 0.7368421052631579, 'qqp_dev_bias_eval_acc_and_f1': 0.712171052631579, 'qqp_test_bias_eval_loss': 2.4482104778289795, 'qqp_test_bias_eval_acc': 0.5936928023744744, 'qqp_test_bias_eval_f1': 0.589006480022017, 'qqp_test_bias_eval_acc_and_f1': 0.5913496411982457, 'qqp_dev_eval_loss': 2.154200315475464, 'qqp_dev_eval_acc': 0.6875, 'qqp_dev_eval_f1': 0.7368421052631579, 'qqp_dev_eval_acc_and_f1': 0.712171052631579, 'qqp_test_eval_loss': 2.4482104778289795, 'qqp_test_eval_acc': 0.5936928023744744, 'qqp_test_eval_f1': 0.589006480022017, 'qqp_test_eval_acc_and_f1': 0.5913496411982457, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16--13-roberta-large-13182', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_09-41-39_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--13-roberta-large-13182', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias,adapter_eval_loss': 3.1378231048583984, 'mrpc_dev_bias,adapter_eval_acc': 0.625, 'mrpc_dev_bias,adapter_eval_f1': 0.6470588235294118, 'mrpc_dev_bias,adapter_eval_acc_and_f1': 0.6360294117647058, 'mrpc_test_bias,adapter_eval_loss': 1.7865207195281982, 'mrpc_test_bias,adapter_eval_acc': 0.7230392156862745, 'mrpc_test_bias,adapter_eval_f1': 0.8014059753954308, 'mrpc_test_bias,adapter_eval_acc_and_f1': 0.7622225955408526, 'mrpc_dev_eval_loss': 3.1378231048583984, 'mrpc_dev_eval_acc': 0.625, 'mrpc_dev_eval_f1': 0.6470588235294118, 'mrpc_dev_eval_acc_and_f1': 0.6360294117647058, 'mrpc_test_eval_loss': 1.7865207195281982, 'mrpc_test_eval_acc': 0.7230392156862745, 'mrpc_test_eval_f1': 0.8014059753954308, 'mrpc_test_eval_acc_and_f1': 0.7622225955408526, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--100-roberta-large-1877', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_10-00-04_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--100-roberta-large-1877', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,adapter_eval_loss': 0.026810258626937866, 'sst-2_dev_prompt,adapter_eval_acc': 1.0, 'sst-2_test_prompt,adapter_eval_loss': 0.7151551842689514, 'sst-2_test_prompt,adapter_eval_acc': 0.8990825688073395, 'sst-2_dev_eval_loss': 0.026810258626937866, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.7151551842689514, 'sst-2_test_eval_acc': 0.8990825688073395, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-3849', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_09-54-12_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-3849', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias,adapter_eval_loss': 4.214142799377441, 'cola_dev_bias,adapter_eval_mcc': 0.34752402342845795, 'cola_test_bias,adapter_eval_loss': 4.632090091705322, 'cola_test_bias,adapter_eval_mcc': 0.2061669630812856, 'cola_dev_eval_loss': 4.214142799377441, 'cola_dev_eval_mcc': 0.34752402342845795, 'cola_test_eval_loss': 4.632090091705322, 'cola_test_eval_mcc': 0.2061669630812856, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--100-roberta-large-13058', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_10-04-58_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-13058', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias_eval_loss': 1.527756929397583, 'rte_dev_prompt,bias_eval_acc': 0.6875, 'rte_test_prompt,bias_eval_loss': 2.077955722808838, 'rte_test_prompt,bias_eval_acc': 0.6823104693140795, 'rte_dev_eval_loss': 1.527756929397583, 'rte_dev_eval_acc': 0.6875, 'rte_test_eval_loss': 2.077955722808838, 'rte_test_eval_acc': 0.6823104693140795, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-100-roberta-large-1231', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_10-11-08_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-100-roberta-large-1231', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias,adapter_eval_loss': 2.7815651893615723, 'mrpc_dev_bias,adapter_eval_acc': 0.75, 'mrpc_dev_bias,adapter_eval_f1': 0.7333333333333334, 'mrpc_dev_bias,adapter_eval_acc_and_f1': 0.7416666666666667, 'mrpc_test_bias,adapter_eval_loss': 2.495412588119507, 'mrpc_test_bias,adapter_eval_acc': 0.6838235294117647, 'mrpc_test_bias,adapter_eval_f1': 0.7425149700598802, 'mrpc_test_bias,adapter_eval_acc_and_f1': 0.7131692497358224, 'mrpc_dev_eval_loss': 2.7815651893615723, 'mrpc_dev_eval_acc': 0.75, 'mrpc_dev_eval_f1': 0.7333333333333334, 'mrpc_dev_eval_acc_and_f1': 0.7416666666666667, 'mrpc_test_eval_loss': 2.495412588119507, 'mrpc_test_eval_acc': 0.6838235294117647, 'mrpc_test_eval_f1': 0.7425149700598802, 'mrpc_test_eval_acc_and_f1': 0.7131692497358224, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--100-roberta-large-27626', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_10-15-46_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--100-roberta-large-27626', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias,adapter_eval_loss': 2.192262649536133, 'sts-b_dev_prompt,bias,adapter_eval_pearson': 0.7740816719992341, 'sts-b_dev_prompt,bias,adapter_eval_spearmanr': 0.7760448369917583, 'sts-b_dev_prompt,bias,adapter_eval_corr': 0.7750632544954962, 'sts-b_test_prompt,bias,adapter_eval_loss': 2.1868298053741455, 'sts-b_test_prompt,bias,adapter_eval_pearson': 0.5712854803319135, 'sts-b_test_prompt,bias,adapter_eval_spearmanr': 0.5574262673493942, 'sts-b_test_prompt,bias,adapter_eval_corr': 0.5643558738406538, 'sts-b_dev_eval_loss': 2.192262649536133, 'sts-b_dev_eval_pearson': 0.7740816719992341, 'sts-b_dev_eval_spearmanr': 0.7760448369917583, 'sts-b_dev_eval_corr': 0.7750632544954962, 'sts-b_test_eval_loss': 2.1868298053741455, 'sts-b_test_eval_pearson': 0.5712854803319135, 'sts-b_test_eval_spearmanr': 0.5574262673493942, 'sts-b_test_eval_corr': 0.5643558738406538, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-13-roberta-large-4287', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_09-58-19_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-13-roberta-large-4287', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias,adapter_eval_loss': 3.947361469268799, 'cola_dev_bias,adapter_eval_mcc': 0.40451991747794525, 'cola_test_bias,adapter_eval_loss': 4.959153652191162, 'cola_test_bias,adapter_eval_mcc': 0.1327665813876745, 'cola_dev_eval_loss': 3.947361469268799, 'cola_dev_eval_mcc': 0.40451991747794525, 'cola_test_eval_loss': 4.959153652191162, 'cola_test_eval_mcc': 0.1327665813876745, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--100-roberta-large-8901', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_10-21-06_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-8901', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,adapter_eval_loss': 0.0010015369625762105, 'sst-2_dev_prompt,adapter_eval_acc': 1.0, 'sst-2_test_prompt,adapter_eval_loss': 0.6491047739982605, 'sst-2_test_prompt,adapter_eval_acc': 0.9174311926605505, 'sst-2_dev_eval_loss': 0.0010015369625762105, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.6491047739982605, 'sst-2_test_eval_acc': 0.9174311926605505, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-13654', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_10-16-06_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-13654', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias_eval_loss': 2.069098949432373, 'mnli_dev_bias_eval_mnli/acc': 0.7291666666666666, 'mnli_test_bias_eval_loss': 2.2512173652648926, 'mnli_test_bias_eval_mnli/acc': 0.682730514518594, 'mnli-mm_test_bias_eval_loss': 2.0983545780181885, 'mnli-mm_test_bias_eval_mnli-mm/acc': 0.7020951993490643, 'mnli_dev_eval_loss': 2.069098949432373, 'mnli_dev_eval_mnli/acc': 0.7291666666666666, 'mnli_test_eval_loss': 2.2512173652648926, 'mnli_test_eval_mnli/acc': 0.682730514518594, 'mnli-mm_test_eval_loss': 2.0983545780181885, 'mnli-mm_test_eval_mnli-mm/acc': 0.7020951993490643, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--100-roberta-large-4840', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_10-00-10_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--100-roberta-large-4840', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias_eval_loss': 1.0988726615905762, 'rte_dev_prompt,bias_eval_acc': 0.65625, 'rte_test_prompt,bias_eval_loss': 1.1314611434936523, 'rte_test_prompt,bias_eval_acc': 0.6462093862815884, 'rte_dev_eval_loss': 1.0988726615905762, 'rte_dev_eval_acc': 0.65625, 'rte_test_eval_loss': 1.1314611434936523, 'rte_test_eval_acc': 0.6462093862815884, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-100-roberta-large-7203', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_10-26-33_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-100-roberta-large-7203', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias_eval_loss': 2.081150770187378, 'qqp_dev_bias_eval_acc': 0.65625, 'qqp_dev_bias_eval_f1': 0.7027027027027026, 'qqp_dev_bias_eval_acc_and_f1': 0.6794763513513513, 'qqp_test_bias_eval_loss': 2.33065128326416, 'qqp_test_bias_eval_acc': 0.5874103388572842, 'qqp_test_bias_eval_f1': 0.5690888894629433, 'qqp_test_bias_eval_acc_and_f1': 0.5782496141601138, 'qqp_dev_eval_loss': 2.081150770187378, 'qqp_dev_eval_acc': 0.65625, 'qqp_dev_eval_f1': 0.7027027027027026, 'qqp_dev_eval_acc_and_f1': 0.6794763513513513, 'qqp_test_eval_loss': 2.33065128326416, 'qqp_test_eval_acc': 0.5874103388572842, 'qqp_test_eval_f1': 0.5690888894629433, 'qqp_test_eval_acc_and_f1': 0.5782496141601138, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16--13-roberta-large-27394', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_10-12-47_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--13-roberta-large-27394', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias,adapter_eval_loss': 1.6786222457885742, 'mrpc_dev_bias,adapter_eval_acc': 0.75, 'mrpc_dev_bias,adapter_eval_f1': 0.75, 'mrpc_dev_bias,adapter_eval_acc_and_f1': 0.75, 'mrpc_test_bias,adapter_eval_loss': 1.40534508228302, 'mrpc_test_bias,adapter_eval_acc': 0.6911764705882353, 'mrpc_test_bias,adapter_eval_f1': 0.7692307692307693, 'mrpc_test_bias,adapter_eval_acc_and_f1': 0.7302036199095023, 'mrpc_dev_eval_loss': 1.6786222457885742, 'mrpc_dev_eval_acc': 0.75, 'mrpc_dev_eval_f1': 0.75, 'mrpc_dev_eval_acc_and_f1': 0.75, 'mrpc_test_eval_loss': 1.40534508228302, 'mrpc_test_eval_acc': 0.6911764705882353, 'mrpc_test_eval_f1': 0.7692307692307693, 'mrpc_test_eval_acc_and_f1': 0.7302036199095023, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--100-roberta-large-22751', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_10-31-44_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--100-roberta-large-22751', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias,adapter_eval_loss': 1.4605647325515747, 'cola_dev_bias,adapter_eval_mcc': 0.3289758474798845, 'cola_test_bias,adapter_eval_loss': 2.070462703704834, 'cola_test_bias,adapter_eval_mcc': 0.07422835429456205, 'cola_dev_eval_loss': 1.4605647325515747, 'cola_dev_eval_mcc': 0.3289758474798845, 'cola_test_eval_loss': 2.070462703704834, 'cola_test_eval_mcc': 0.07422835429456205, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--100-roberta-large-18195', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_10-36-42_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-18195', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias_eval_loss': 0.818871021270752, 'rte_dev_prompt,bias_eval_acc': 0.65625, 'rte_test_prompt,bias_eval_loss': 0.75641268491745, 'rte_test_prompt,bias_eval_acc': 0.6353790613718412, 'rte_dev_eval_loss': 0.818871021270752, 'rte_dev_eval_acc': 0.65625, 'rte_test_eval_loss': 0.75641268491745, 'rte_test_eval_acc': 0.6353790613718412, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-100-roberta-large-14251', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_10-41-53_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-100-roberta-large-14251', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,adapter_eval_loss': 0.002873087301850319, 'sst-2_dev_prompt,adapter_eval_acc': 1.0, 'sst-2_test_prompt,adapter_eval_loss': 0.5094651579856873, 'sst-2_test_prompt,adapter_eval_acc': 0.9139908256880734, 'sst-2_dev_eval_loss': 0.002873087301850319, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.5094651579856873, 'sst-2_test_eval_acc': 0.9139908256880734, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-12499', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_10-39-27_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-12499', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias,adapter_eval_loss': 0.7455265522003174, 'mrpc_dev_prompt,bias,adapter_eval_acc': 0.5, 'mrpc_dev_prompt,bias,adapter_eval_f1': 0.6666666666666666, 'mrpc_dev_prompt,bias,adapter_eval_acc_and_f1': 0.5833333333333333, 'mrpc_test_prompt,bias,adapter_eval_loss': 0.6254903078079224, 'mrpc_test_prompt,bias,adapter_eval_acc': 0.6838235294117647, 'mrpc_test_prompt,bias,adapter_eval_f1': 0.8122270742358079, 'mrpc_test_prompt,bias,adapter_eval_acc_and_f1': 0.7480253018237863, 'mrpc_dev_eval_loss': 0.7455265522003174, 'mrpc_dev_eval_acc': 0.5, 'mrpc_dev_eval_f1': 0.6666666666666666, 'mrpc_dev_eval_acc_and_f1': 0.5833333333333333, 'mrpc_test_eval_loss': 0.6254903078079224, 'mrpc_test_eval_acc': 0.6838235294117647, 'mrpc_test_eval_f1': 0.8122270742358079, 'mrpc_test_eval_acc_and_f1': 0.7480253018237863, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-42-roberta-large-27295', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_10-47-41_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-42-roberta-large-27295', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias,adapter_eval_loss': 0.6997421979904175, 'cola_dev_prompt,bias,adapter_eval_mcc': 0.0, 'cola_test_prompt,bias,adapter_eval_loss': 0.7437357902526855, 'cola_test_prompt,bias,adapter_eval_mcc': 0.0, 'cola_dev_eval_loss': 0.6997421979904175, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.7437357902526855, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-23867', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_10-53-08_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-23867', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias,adapter_eval_loss': 4.237665176391602, 'rte_dev_bias,adapter_eval_acc': 0.65625, 'rte_test_bias,adapter_eval_loss': 4.832911014556885, 'rte_test_bias,adapter_eval_acc': 0.6173285198555957, 'rte_dev_eval_loss': 4.237665176391602, 'rte_dev_eval_acc': 0.65625, 'rte_test_eval_loss': 4.832911014556885, 'rte_test_eval_acc': 0.6173285198555957, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--42-roberta-large-9699', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_10-57-04_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--42-roberta-large-9699', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias_eval_loss': 2.2196366786956787, 'mnli_dev_bias_eval_mnli/acc': 0.6458333333333334, 'mnli_test_bias_eval_loss': 2.101734161376953, 'mnli_test_bias_eval_mnli/acc': 0.6704024452368823, 'mnli-mm_test_bias_eval_loss': 2.0476768016815186, 'mnli-mm_test_bias_eval_mnli-mm/acc': 0.6790073230268511, 'mnli_dev_eval_loss': 2.2196366786956787, 'mnli_dev_eval_mnli/acc': 0.6458333333333334, 'mnli_test_eval_loss': 2.101734161376953, 'mnli_test_eval_mnli/acc': 0.6704024452368823, 'mnli-mm_test_eval_loss': 2.0476768016815186, 'mnli-mm_test_eval_mnli-mm/acc': 0.6790073230268511, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--100-roberta-large-9738', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_10-41-10_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--100-roberta-large-9738', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_adapter_eval_loss': 0.7085025310516357, 'qqp_dev_adapter_eval_acc': 0.5, 'qqp_dev_adapter_eval_f1': 0.6666666666666666, 'qqp_dev_adapter_eval_acc_and_f1': 0.5833333333333333, 'qqp_test_adapter_eval_loss': 0.7548291683197021, 'qqp_test_adapter_eval_acc': 0.36816720257234725, 'qqp_test_adapter_eval_f1': 0.5381903642773208, 'qqp_test_adapter_eval_acc_and_f1': 0.45317878342483403, 'qqp_dev_eval_loss': 0.7085025310516357, 'qqp_dev_eval_acc': 0.5, 'qqp_dev_eval_f1': 0.6666666666666666, 'qqp_dev_eval_acc_and_f1': 0.5833333333333333, 'qqp_test_eval_loss': 0.7548291683197021, 'qqp_test_eval_acc': 0.36816720257234725, 'qqp_test_eval_f1': 0.5381903642773208, 'qqp_test_eval_acc_and_f1': 0.45317878342483403, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16--13-roberta-large-27024', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_10-43-51_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--13-roberta-large-27024', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias,adapter_eval_loss': 1.9728460311889648, 'mrpc_dev_prompt,bias,adapter_eval_acc': 0.78125, 'mrpc_dev_prompt,bias,adapter_eval_f1': 0.8108108108108109, 'mrpc_dev_prompt,bias,adapter_eval_acc_and_f1': 0.7960304054054055, 'mrpc_test_prompt,bias,adapter_eval_loss': 3.020904541015625, 'mrpc_test_prompt,bias,adapter_eval_acc': 0.7009803921568627, 'mrpc_test_prompt,bias,adapter_eval_f1': 0.779783393501805, 'mrpc_test_prompt,bias,adapter_eval_acc_and_f1': 0.7403818928293339, 'mrpc_dev_eval_loss': 1.9728460311889648, 'mrpc_dev_eval_acc': 0.78125, 'mrpc_dev_eval_f1': 0.8108108108108109, 'mrpc_dev_eval_acc_and_f1': 0.7960304054054055, 'mrpc_test_eval_loss': 3.020904541015625, 'mrpc_test_eval_acc': 0.7009803921568627, 'mrpc_test_eval_f1': 0.779783393501805, 'mrpc_test_eval_acc_and_f1': 0.7403818928293339, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-42-roberta-large-32339', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_11-04-00_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-42-roberta-large-32339', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias_eval_loss': 0.1942920982837677, 'sst-2_dev_prompt,bias_eval_acc': 0.96875, 'sst-2_test_prompt,bias_eval_loss': 0.7277214527130127, 'sst-2_test_prompt,bias_eval_acc': 0.9197247706422018, 'sst-2_dev_eval_loss': 0.1942920982837677, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.7277214527130127, 'sst-2_test_eval_acc': 0.9197247706422018, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-18966', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_11-02-12_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-18966', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias,adapter_eval_loss': 3.8987631797790527, 'cola_dev_prompt,bias,adapter_eval_mcc': 0.18786728732554486, 'cola_test_prompt,bias,adapter_eval_loss': 4.293982028961182, 'cola_test_prompt,bias,adapter_eval_mcc': 0.07250677273346826, 'cola_dev_eval_loss': 3.8987631797790527, 'cola_dev_eval_mcc': 0.18786728732554486, 'cola_test_eval_loss': 4.293982028961182, 'cola_test_eval_mcc': 0.07250677273346826, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-16303', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_11-09-47_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-16303', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias,adapter_eval_loss': 2.8095335960388184, 'rte_dev_bias,adapter_eval_acc': 0.71875, 'rte_test_bias,adapter_eval_loss': 2.533527374267578, 'rte_test_bias,adapter_eval_acc': 0.7148014440433214, 'rte_dev_eval_loss': 2.8095335960388184, 'rte_dev_eval_acc': 0.71875, 'rte_test_eval_loss': 2.533527374267578, 'rte_test_eval_acc': 0.7148014440433214, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--42-roberta-large-29010', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_11-15-18_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--42-roberta-large-29010', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias,adapter_eval_loss': 2.338495969772339, 'mrpc_dev_prompt,bias,adapter_eval_acc': 0.8125, 'mrpc_dev_prompt,bias,adapter_eval_f1': 0.8421052631578948, 'mrpc_dev_prompt,bias,adapter_eval_acc_and_f1': 0.8273026315789473, 'mrpc_test_prompt,bias,adapter_eval_loss': 2.8449885845184326, 'mrpc_test_prompt,bias,adapter_eval_acc': 0.7279411764705882, 'mrpc_test_prompt,bias,adapter_eval_f1': 0.8042328042328043, 'mrpc_test_prompt,bias,adapter_eval_acc_and_f1': 0.7660869903516963, 'mrpc_dev_eval_loss': 2.338495969772339, 'mrpc_dev_eval_acc': 0.8125, 'mrpc_dev_eval_f1': 0.8421052631578948, 'mrpc_dev_eval_acc_and_f1': 0.8273026315789473, 'mrpc_test_eval_loss': 2.8449885845184326, 'mrpc_test_eval_acc': 0.7279411764705882, 'mrpc_test_eval_f1': 0.8042328042328043, 'mrpc_test_eval_acc_and_f1': 0.7660869903516963, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-42-roberta-large-5078', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_11-20-25_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-42-roberta-large-5078', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias,adapter_eval_loss': 1.8494775295257568, 'cola_dev_prompt,bias,adapter_eval_mcc': 0.4383570037596047, 'cola_test_prompt,bias,adapter_eval_loss': 2.864316940307617, 'cola_test_prompt,bias,adapter_eval_mcc': 0.060664372256199174, 'cola_dev_eval_loss': 1.8494775295257568, 'cola_dev_eval_mcc': 0.4383570037596047, 'cola_test_eval_loss': 2.864316940307617, 'cola_test_eval_mcc': 0.060664372256199174, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-24564', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_11-26-02_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-24564', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias_eval_loss': 0.24231001734733582, 'sst-2_dev_prompt,bias_eval_acc': 0.96875, 'sst-2_test_prompt,bias_eval_loss': 0.5356482267379761, 'sst-2_test_prompt,bias_eval_acc': 0.9243119266055045, 'sst-2_dev_eval_loss': 0.24231001734733582, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.5356482267379761, 'sst-2_test_eval_acc': 0.9243119266055045, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-202', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_11-23-42_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-202', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias,adapter_eval_loss': 2.198971748352051, 'rte_dev_bias,adapter_eval_acc': 0.59375, 'rte_test_bias,adapter_eval_loss': 1.6488808393478394, 'rte_test_bias,adapter_eval_acc': 0.6534296028880866, 'rte_dev_eval_loss': 2.198971748352051, 'rte_dev_eval_acc': 0.59375, 'rte_test_eval_loss': 1.6488808393478394, 'rte_test_eval_acc': 0.6534296028880866, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--42-roberta-large-11432', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_11-33-41_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--42-roberta-large-11432', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias,adapter_eval_loss': 1.344712734222412, 'mrpc_dev_prompt,bias,adapter_eval_acc': 0.84375, 'mrpc_dev_prompt,bias,adapter_eval_f1': 0.8387096774193549, 'mrpc_dev_prompt,bias,adapter_eval_acc_and_f1': 0.8412298387096775, 'mrpc_test_prompt,bias,adapter_eval_loss': 2.568629741668701, 'mrpc_test_prompt,bias,adapter_eval_acc': 0.6887254901960784, 'mrpc_test_prompt,bias,adapter_eval_f1': 0.7465069860279441, 'mrpc_test_prompt,bias,adapter_eval_acc_and_f1': 0.7176162381120113, 'mrpc_dev_eval_loss': 1.344712734222412, 'mrpc_dev_eval_acc': 0.84375, 'mrpc_dev_eval_f1': 0.8387096774193549, 'mrpc_dev_eval_acc_and_f1': 0.8412298387096775, 'mrpc_test_eval_loss': 2.568629741668701, 'mrpc_test_eval_acc': 0.6887254901960784, 'mrpc_test_eval_f1': 0.7465069860279441, 'mrpc_test_eval_acc_and_f1': 0.7176162381120113, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-42-roberta-large-21176', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_11-36-45_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-42-roberta-large-21176', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_adapter_eval_loss': 3.8922319412231445, 'qqp_dev_adapter_eval_acc': 0.59375, 'qqp_dev_adapter_eval_f1': 0.6829268292682927, 'qqp_dev_adapter_eval_acc_and_f1': 0.6383384146341464, 'qqp_test_adapter_eval_loss': 5.345162868499756, 'qqp_test_adapter_eval_acc': 0.5266386346772199, 'qqp_test_adapter_eval_f1': 0.5598233589401537, 'qqp_test_adapter_eval_acc_and_f1': 0.5432309968086868, 'qqp_dev_eval_loss': 3.8922319412231445, 'qqp_dev_eval_acc': 0.59375, 'qqp_dev_eval_f1': 0.6829268292682927, 'qqp_dev_eval_acc_and_f1': 0.6383384146341464, 'qqp_test_eval_loss': 5.345162868499756, 'qqp_test_eval_acc': 0.5266386346772199, 'qqp_test_eval_f1': 0.5598233589401537, 'qqp_test_eval_acc_and_f1': 0.5432309968086868, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16--13-roberta-large-20835', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_11-19-14_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--13-roberta-large-20835', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_adapter_eval_loss': 4.787420749664307, 'mnli_dev_adapter_eval_mnli/acc': 0.625, 'mnli_test_adapter_eval_loss': 4.500794887542725, 'mnli_test_adapter_eval_mnli/acc': 0.6266938359653591, 'mnli-mm_test_adapter_eval_loss': 4.298470973968506, 'mnli-mm_test_adapter_eval_mnli-mm/acc': 0.6497152156224573, 'mnli_dev_eval_loss': 4.787420749664307, 'mnli_dev_eval_mnli/acc': 0.625, 'mnli_test_eval_loss': 4.500794887542725, 'mnli_test_eval_mnli/acc': 0.6266938359653591, 'mnli-mm_test_eval_loss': 4.298470973968506, 'mnli-mm_test_eval_mnli-mm/acc': 0.6497152156224573, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--42-roberta-large-802', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_11-17-19_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--42-roberta-large-802', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias,adapter_eval_loss': 2.906308889389038, 'cola_dev_prompt,bias,adapter_eval_mcc': 0.31814238148788887, 'cola_test_prompt,bias,adapter_eval_loss': 3.768798589706421, 'cola_test_prompt,bias,adapter_eval_mcc': 0.052501036176700044, 'cola_dev_eval_loss': 2.906308889389038, 'cola_dev_eval_mcc': 0.31814238148788887, 'cola_test_eval_loss': 3.768798589706421, 'cola_test_eval_mcc': 0.052501036176700044, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-22429', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_11-42-11_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-22429', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias_eval_loss': 0.18375813961029053, 'sst-2_dev_prompt,bias_eval_acc': 0.96875, 'sst-2_test_prompt,bias_eval_loss': 0.5048587918281555, 'sst-2_test_prompt,bias_eval_acc': 0.9220183486238532, 'sst-2_dev_eval_loss': 0.18375813961029053, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.5048587918281555, 'sst-2_test_eval_acc': 0.9220183486238532, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-21337', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_11-44-20_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-21337', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt_eval_loss': 0.714008092880249, 'qnli_dev_prompt_eval_acc': 0.59375, 'qnli_test_prompt_eval_loss': 0.7790549993515015, 'qnli_test_prompt_eval_acc': 0.5165659893831228, 'qnli_dev_eval_loss': 0.714008092880249, 'qnli_dev_eval_acc': 0.59375, 'qnli_test_eval_loss': 0.7790549993515015, 'qnli_test_eval_acc': 0.5165659893831228, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-42-roberta-large-23956', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_11-51-50_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-42-roberta-large-23956', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias,adapter_eval_loss': 0.7452418208122253, 'mrpc_dev_prompt,bias,adapter_eval_acc': 0.5, 'mrpc_dev_prompt,bias,adapter_eval_f1': 0.6666666666666666, 'mrpc_dev_prompt,bias,adapter_eval_acc_and_f1': 0.5833333333333333, 'mrpc_test_prompt,bias,adapter_eval_loss': 0.6255484819412231, 'mrpc_test_prompt,bias,adapter_eval_acc': 0.6838235294117647, 'mrpc_test_prompt,bias,adapter_eval_f1': 0.8122270742358079, 'mrpc_test_prompt,bias,adapter_eval_acc_and_f1': 0.7480253018237863, 'mrpc_dev_eval_loss': 0.7452418208122253, 'mrpc_dev_eval_acc': 0.5, 'mrpc_dev_eval_f1': 0.6666666666666666, 'mrpc_dev_eval_acc_and_f1': 0.5833333333333333, 'mrpc_test_eval_loss': 0.6255484819412231, 'mrpc_test_eval_acc': 0.6838235294117647, 'mrpc_test_eval_f1': 0.8122270742358079, 'mrpc_test_eval_acc_and_f1': 0.7480253018237863, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-100-roberta-large-30614', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_11-53-06_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-100-roberta-large-30614', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias,adapter_eval_loss': 2.773036479949951, 'rte_dev_bias,adapter_eval_acc': 0.59375, 'rte_test_bias,adapter_eval_loss': 2.1490607261657715, 'rte_test_bias,adapter_eval_acc': 0.6462093862815884, 'rte_dev_eval_loss': 2.773036479949951, 'rte_dev_eval_acc': 0.59375, 'rte_test_eval_loss': 2.1490607261657715, 'rte_test_eval_acc': 0.6462093862815884, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--42-roberta-large-9653', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_11-52-10_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--42-roberta-large-9653', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias,adapter_eval_loss': 0.7312649488449097, 'cola_dev_prompt,bias,adapter_eval_mcc': 0.0, 'cola_test_prompt,bias,adapter_eval_loss': 0.8375557661056519, 'cola_test_prompt,bias,adapter_eval_mcc': 0.0, 'cola_dev_eval_loss': 0.7312649488449097, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.8375557661056519, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-16540', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_11-58-08_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-16540', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt_eval_loss': 3.0497193336486816, 'qnli_dev_prompt_eval_acc': 0.59375, 'qnli_test_prompt_eval_loss': 3.423197031021118, 'qnli_test_prompt_eval_acc': 0.4836170602233205, 'qnli_dev_eval_loss': 3.0497193336486816, 'qnli_dev_eval_acc': 0.59375, 'qnli_test_eval_loss': 3.423197031021118, 'qnli_test_eval_acc': 0.4836170602233205, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-42-roberta-large-25779', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_12-05-44_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-42-roberta-large-25779', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.4036788940429688, 'sts-b_dev_prompt_eval_pearson': 0.2533263257125345, 'sts-b_dev_prompt_eval_spearmanr': 0.26501431489559285, 'sts-b_dev_prompt_eval_corr': 0.2591703203040637, 'sts-b_test_prompt_eval_loss': 2.515767812728882, 'sts-b_test_prompt_eval_pearson': 0.045631021783080365, 'sts-b_test_prompt_eval_spearmanr': 0.060863883639826366, 'sts-b_test_prompt_eval_corr': 0.05324745271145337, 'sts-b_dev_eval_loss': 2.4036788940429688, 'sts-b_dev_eval_pearson': 0.2533263257125345, 'sts-b_dev_eval_spearmanr': 0.26501431489559285, 'sts-b_dev_eval_corr': 0.2591703203040637, 'sts-b_test_eval_loss': 2.515767812728882, 'sts-b_test_eval_pearson': 0.045631021783080365, 'sts-b_test_eval_spearmanr': 0.060863883639826366, 'sts-b_test_eval_corr': 0.05324745271145337, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-42-roberta-large-12354', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_12-03-12_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-42-roberta-large-12354', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias,adapter_eval_loss': 2.065715789794922, 'mrpc_dev_prompt,bias,adapter_eval_acc': 0.65625, 'mrpc_dev_prompt,bias,adapter_eval_f1': 0.6451612903225806, 'mrpc_dev_prompt,bias,adapter_eval_acc_and_f1': 0.6507056451612903, 'mrpc_test_prompt,bias,adapter_eval_loss': 1.9113401174545288, 'mrpc_test_prompt,bias,adapter_eval_acc': 0.6372549019607843, 'mrpc_test_prompt,bias,adapter_eval_f1': 0.7016129032258064, 'mrpc_test_prompt,bias,adapter_eval_acc_and_f1': 0.6694339025932954, 'mrpc_dev_eval_loss': 2.065715789794922, 'mrpc_dev_eval_acc': 0.65625, 'mrpc_dev_eval_f1': 0.6451612903225806, 'mrpc_dev_eval_acc_and_f1': 0.6507056451612903, 'mrpc_test_eval_loss': 1.9113401174545288, 'mrpc_test_eval_acc': 0.6372549019607843, 'mrpc_test_eval_f1': 0.7016129032258064, 'mrpc_test_eval_acc_and_f1': 0.6694339025932954, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-100-roberta-large-20210', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_12-09-33_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-100-roberta-large-20210', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias_eval_loss': 0.13553495705127716, 'sst-2_dev_prompt,bias_eval_acc': 0.96875, 'sst-2_test_prompt,bias_eval_loss': 0.3880784511566162, 'sst-2_test_prompt,bias_eval_acc': 0.9231651376146789, 'sst-2_dev_eval_loss': 0.13553495705127716, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.3880784511566162, 'sst-2_test_eval_acc': 0.9231651376146789, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-28241', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_12-05-43_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-28241', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias,adapter_eval_loss': 0.7395051717758179, 'rte_dev_bias,adapter_eval_acc': 0.5, 'rte_test_bias,adapter_eval_loss': 0.7228642106056213, 'rte_test_bias,adapter_eval_acc': 0.5270758122743683, 'rte_dev_eval_loss': 0.7395051717758179, 'rte_dev_eval_acc': 0.5, 'rte_test_eval_loss': 0.7228642106056213, 'rte_test_eval_acc': 0.5270758122743683, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--100-roberta-large-24479', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_12-10-36_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--100-roberta-large-24479', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias,adapter_eval_loss': 3.2828688621520996, 'cola_dev_prompt,bias,adapter_eval_mcc': 0.19738550848793068, 'cola_test_prompt,bias,adapter_eval_loss': 3.5784475803375244, 'cola_test_prompt,bias,adapter_eval_mcc': 0.07507488611496207, 'cola_dev_eval_loss': 3.2828688621520996, 'cola_dev_eval_mcc': 0.19738550848793068, 'cola_test_eval_loss': 3.5784475803375244, 'cola_test_eval_mcc': 0.07507488611496207, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-9460', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_12-14-15_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-9460', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_adapter_eval_loss': 2.2998299598693848, 'qqp_dev_adapter_eval_acc': 0.6875, 'qqp_dev_adapter_eval_f1': 0.761904761904762, 'qqp_dev_adapter_eval_acc_and_f1': 0.7247023809523809, 'qqp_test_adapter_eval_loss': 2.8130035400390625, 'qqp_test_adapter_eval_acc': 0.5841701706653475, 'qqp_test_adapter_eval_f1': 0.6043676754365322, 'qqp_test_adapter_eval_acc_and_f1': 0.5942689230509399, 'qqp_dev_eval_loss': 2.2998299598693848, 'qqp_dev_eval_acc': 0.6875, 'qqp_dev_eval_f1': 0.761904761904762, 'qqp_dev_eval_acc_and_f1': 0.7247023809523809, 'qqp_test_eval_loss': 2.8130035400390625, 'qqp_test_eval_acc': 0.5841701706653475, 'qqp_test_eval_f1': 0.6043676754365322, 'qqp_test_eval_acc_and_f1': 0.5942689230509399, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16--13-roberta-large-28781', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_11-55-03_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--13-roberta-large-28781', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt_eval_loss': 0.7464724779129028, 'qnli_dev_prompt_eval_acc': 0.59375, 'qnli_test_prompt_eval_loss': 0.7418191432952881, 'qnli_test_prompt_eval_acc': 0.5096101043382757, 'qnli_dev_eval_loss': 0.7464724779129028, 'qnli_dev_eval_acc': 0.59375, 'qnli_test_eval_loss': 0.7418191432952881, 'qnli_test_eval_acc': 0.5096101043382757, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-42-roberta-large-15228', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_12-19-36_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-42-roberta-large-15228', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias,adapter_eval_loss': 2.0745131969451904, 'mrpc_dev_prompt,bias,adapter_eval_acc': 0.625, 'mrpc_dev_prompt,bias,adapter_eval_f1': 0.6470588235294118, 'mrpc_dev_prompt,bias,adapter_eval_acc_and_f1': 0.6360294117647058, 'mrpc_test_prompt,bias,adapter_eval_loss': 1.5826963186264038, 'mrpc_test_prompt,bias,adapter_eval_acc': 0.7181372549019608, 'mrpc_test_prompt,bias,adapter_eval_f1': 0.7957371225577266, 'mrpc_test_prompt,bias,adapter_eval_acc_and_f1': 0.7569371887298437, 'mrpc_dev_eval_loss': 2.0745131969451904, 'mrpc_dev_eval_acc': 0.625, 'mrpc_dev_eval_f1': 0.6470588235294118, 'mrpc_dev_eval_acc_and_f1': 0.6360294117647058, 'mrpc_test_eval_loss': 1.5826963186264038, 'mrpc_test_eval_acc': 0.7181372549019608, 'mrpc_test_eval_f1': 0.7957371225577266, 'mrpc_test_eval_acc_and_f1': 0.7569371887298437, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-100-roberta-large-5866', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_12-25-18_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-100-roberta-large-5866', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_adapter_eval_loss': 3.3468267917633057, 'mnli_dev_adapter_eval_mnli/acc': 0.75, 'mnli_test_adapter_eval_loss': 5.070642948150635, 'mnli_test_adapter_eval_mnli/acc': 0.6623535404992359, 'mnli-mm_test_adapter_eval_loss': 4.623894214630127, 'mnli-mm_test_adapter_eval_mnli-mm/acc': 0.6930431244914564, 'mnli_dev_eval_loss': 3.3468267917633057, 'mnli_dev_eval_mnli/acc': 0.75, 'mnli_test_eval_loss': 5.070642948150635, 'mnli_test_eval_mnli/acc': 0.6623535404992359, 'mnli-mm_test_eval_loss': 4.623894214630127, 'mnli-mm_test_eval_mnli-mm/acc': 0.6930431244914564, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--42-roberta-large-11674', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_11-56-27_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--42-roberta-large-11674', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.1693978309631348, 'sts-b_dev_prompt_eval_pearson': 0.392260230811027, 'sts-b_dev_prompt_eval_spearmanr': 0.45675024334396347, 'sts-b_dev_prompt_eval_corr': 0.4245052370774952, 'sts-b_test_prompt_eval_loss': 2.3926007747650146, 'sts-b_test_prompt_eval_pearson': 0.09951451251951826, 'sts-b_test_prompt_eval_spearmanr': 0.11573327570118012, 'sts-b_test_prompt_eval_corr': 0.1076238941103492, 'sts-b_dev_eval_loss': 2.1693978309631348, 'sts-b_dev_eval_pearson': 0.392260230811027, 'sts-b_dev_eval_spearmanr': 0.45675024334396347, 'sts-b_dev_eval_corr': 0.4245052370774952, 'sts-b_test_eval_loss': 2.3926007747650146, 'sts-b_test_eval_pearson': 0.09951451251951826, 'sts-b_test_eval_spearmanr': 0.11573327570118012, 'sts-b_test_eval_corr': 0.1076238941103492, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-42-roberta-large-24134', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_12-22-57_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-42-roberta-large-24134', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias,adapter_eval_loss': 4.857457637786865, 'cola_dev_prompt,bias,adapter_eval_mcc': 0.3872983346207417, 'cola_test_prompt,bias,adapter_eval_loss': 5.5133795738220215, 'cola_test_prompt,bias,adapter_eval_mcc': 0.12570342380352245, 'cola_dev_eval_loss': 4.857457637786865, 'cola_dev_eval_mcc': 0.3872983346207417, 'cola_test_eval_loss': 5.5133795738220215, 'cola_test_eval_mcc': 0.12570342380352245, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-13600', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_12-30-12_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-13600', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt_eval_loss': 0.6932764053344727, 'qnli_dev_prompt_eval_acc': 0.5625, 'qnli_test_prompt_eval_loss': 0.7237076163291931, 'qnli_test_prompt_eval_acc': 0.5141863444993593, 'qnli_dev_eval_loss': 0.6932764053344727, 'qnli_dev_eval_acc': 0.5625, 'qnli_test_eval_loss': 0.7237076163291931, 'qnli_test_eval_acc': 0.5141863444993593, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-42-roberta-large-31389', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_12-33-13_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-42-roberta-large-31389', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias_eval_loss': 0.003218557685613632, 'sst-2_dev_prompt,bias_eval_acc': 1.0, 'sst-2_test_prompt,bias_eval_loss': 0.6115346550941467, 'sst-2_test_prompt,bias_eval_acc': 0.9208715596330275, 'sst-2_dev_eval_loss': 0.003218557685613632, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.6115346550941467, 'sst-2_test_eval_acc': 0.9208715596330275, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-4791', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_12-27-02_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-4791', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias,adapter_eval_loss': 1.2356549501419067, 'rte_dev_bias,adapter_eval_acc': 0.875, 'rte_test_bias,adapter_eval_loss': 2.974724292755127, 'rte_test_bias,adapter_eval_acc': 0.7581227436823105, 'rte_dev_eval_loss': 1.2356549501419067, 'rte_dev_eval_acc': 0.875, 'rte_test_eval_loss': 2.974724292755127, 'rte_test_eval_acc': 0.7581227436823105, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--100-roberta-large-7870', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_12-29-31_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--100-roberta-large-7870', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias,adapter_eval_loss': 1.9236396551132202, 'mrpc_dev_prompt,bias,adapter_eval_acc': 0.6875, 'mrpc_dev_prompt,bias,adapter_eval_f1': 0.7222222222222223, 'mrpc_dev_prompt,bias,adapter_eval_acc_and_f1': 0.7048611111111112, 'mrpc_test_prompt,bias,adapter_eval_loss': 1.5043119192123413, 'mrpc_test_prompt,bias,adapter_eval_acc': 0.7230392156862745, 'mrpc_test_prompt,bias,adapter_eval_f1': 0.7999999999999999, 'mrpc_test_prompt,bias,adapter_eval_acc_and_f1': 0.7615196078431372, 'mrpc_dev_eval_loss': 1.9236396551132202, 'mrpc_dev_eval_acc': 0.6875, 'mrpc_dev_eval_f1': 0.7222222222222223, 'mrpc_dev_eval_acc_and_f1': 0.7048611111111112, 'mrpc_test_eval_loss': 1.5043119192123413, 'mrpc_test_eval_acc': 0.7230392156862745, 'mrpc_test_eval_f1': 0.7999999999999999, 'mrpc_test_eval_acc_and_f1': 0.7615196078431372, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-100-roberta-large-23996', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_12-41-06_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-100-roberta-large-23996', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt_eval_loss': 0.6059290766716003, 'qnli_dev_prompt_eval_acc': 0.6875, 'qnli_test_prompt_eval_loss': 0.7758882641792297, 'qnli_test_prompt_eval_acc': 0.5253523704924035, 'qnli_dev_eval_loss': 0.6059290766716003, 'qnli_dev_eval_acc': 0.6875, 'qnli_test_eval_loss': 0.7758882641792297, 'qnli_test_eval_acc': 0.5253523704924035, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-100-roberta-large-19544', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_12-46-37_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-100-roberta-large-19544', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.227126359939575, 'sts-b_dev_prompt_eval_pearson': 0.35098981085348013, 'sts-b_dev_prompt_eval_spearmanr': 0.3625351750546779, 'sts-b_dev_prompt_eval_corr': 0.356762492954079, 'sts-b_test_prompt_eval_loss': 2.4854133129119873, 'sts-b_test_prompt_eval_pearson': 0.16265907010391228, 'sts-b_test_prompt_eval_spearmanr': 0.16862653629979807, 'sts-b_test_prompt_eval_corr': 0.16564280320185518, 'sts-b_dev_eval_loss': 2.227126359939575, 'sts-b_dev_eval_pearson': 0.35098981085348013, 'sts-b_dev_eval_spearmanr': 0.3625351750546779, 'sts-b_dev_eval_corr': 0.356762492954079, 'sts-b_test_eval_loss': 2.4854133129119873, 'sts-b_test_eval_pearson': 0.16265907010391228, 'sts-b_test_eval_spearmanr': 0.16862653629979807, 'sts-b_test_eval_corr': 0.16564280320185518, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-42-roberta-large-7789', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_12-43-46_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-42-roberta-large-7789', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias,adapter_eval_loss': 1.3390276432037354, 'cola_dev_prompt,bias,adapter_eval_mcc': 0.2581988897471611, 'cola_test_prompt,bias,adapter_eval_loss': 1.4446392059326172, 'cola_test_prompt,bias,adapter_eval_mcc': 0.06890247929394343, 'cola_dev_eval_loss': 1.3390276432037354, 'cola_dev_eval_mcc': 0.2581988897471611, 'cola_test_eval_loss': 1.4446392059326172, 'cola_test_eval_mcc': 0.06890247929394343, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-25688', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_12-46-33_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-25688', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_This_is*mask*.*sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt_eval_loss': 0.7190757393836975, 'mrpc_dev_prompt_eval_acc': 0.71875, 'mrpc_dev_prompt_eval_f1': 0.742857142857143, 'mrpc_dev_prompt_eval_acc_and_f1': 0.7308035714285714, 'mrpc_test_prompt_eval_loss': 0.7945647239685059, 'mrpc_test_prompt_eval_acc': 0.5661764705882353, 'mrpc_test_prompt_eval_f1': 0.6641366223908919, 'mrpc_test_prompt_eval_acc_and_f1': 0.6151565464895636, 'mrpc_dev_eval_loss': 0.7190757393836975, 'mrpc_dev_eval_acc': 0.71875, 'mrpc_dev_eval_f1': 0.742857142857143, 'mrpc_dev_eval_acc_and_f1': 0.7308035714285714, 'mrpc_test_eval_loss': 0.7945647239685059, 'mrpc_test_eval_acc': 0.5661764705882353, 'mrpc_test_eval_f1': 0.6641366223908919, 'mrpc_test_eval_acc_and_f1': 0.6151565464895636, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-42-roberta-large-10627', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_12-57-14_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-42-roberta-large-10627', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias,adapter_eval_loss': 1.8040176630020142, 'rte_dev_bias,adapter_eval_acc': 0.8125, 'rte_test_bias,adapter_eval_loss': 2.626235246658325, 'rte_test_bias,adapter_eval_acc': 0.6967509025270758, 'rte_dev_eval_loss': 1.8040176630020142, 'rte_dev_eval_acc': 0.8125, 'rte_test_eval_loss': 2.626235246658325, 'rte_test_eval_acc': 0.6967509025270758, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--100-roberta-large-8217', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_12-47-59_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--100-roberta-large-8217', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_adapter_eval_loss': 2.6965227127075195, 'qqp_dev_adapter_eval_acc': 0.625, 'qqp_dev_adapter_eval_f1': 0.6666666666666665, 'qqp_dev_adapter_eval_acc_and_f1': 0.6458333333333333, 'qqp_test_adapter_eval_loss': 2.858236074447632, 'qqp_test_adapter_eval_acc': 0.6182290378431857, 'qqp_test_adapter_eval_f1': 0.5915910353769216, 'qqp_test_adapter_eval_acc_and_f1': 0.6049100366100537, 'qqp_dev_eval_loss': 2.6965227127075195, 'qqp_dev_eval_acc': 0.625, 'qqp_dev_eval_f1': 0.6666666666666665, 'qqp_dev_eval_acc_and_f1': 0.6458333333333333, 'qqp_test_eval_loss': 2.858236074447632, 'qqp_test_eval_acc': 0.6182290378431857, 'qqp_test_eval_f1': 0.5915910353769216, 'qqp_test_eval_acc_and_f1': 0.6049100366100537, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16--13-roberta-large-26135', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_12-31-13_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--13-roberta-large-26135', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias_eval_loss': 0.02015133574604988, 'sst-2_dev_prompt,bias_eval_acc': 1.0, 'sst-2_test_prompt,bias_eval_loss': 0.6981799006462097, 'sst-2_test_prompt,bias_eval_acc': 0.9151376146788991, 'sst-2_dev_eval_loss': 0.02015133574604988, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.6981799006462097, 'sst-2_test_eval_acc': 0.9151376146788991, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-19218', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_12-47-38_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-19218', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt_eval_loss': 4.767697334289551, 'cola_dev_prompt_eval_mcc': 0.16012815380508713, 'cola_test_prompt_eval_loss': 3.6250739097595215, 'cola_test_prompt_eval_mcc': 0.0073122733627396285, 'cola_dev_eval_loss': 4.767697334289551, 'cola_dev_eval_mcc': 0.16012815380508713, 'cola_test_eval_loss': 3.6250739097595215, 'cola_test_eval_mcc': 0.0073122733627396285, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-719', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_13-02-52_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-719', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt_eval_loss': 3.18886661529541, 'mrpc_dev_prompt_eval_acc': 0.78125, 'mrpc_dev_prompt_eval_f1': 0.7999999999999999, 'mrpc_dev_prompt_eval_acc_and_f1': 0.7906249999999999, 'mrpc_test_prompt_eval_loss': 4.40266227722168, 'mrpc_test_prompt_eval_acc': 0.6274509803921569, 'mrpc_test_prompt_eval_f1': 0.7226277372262774, 'mrpc_test_prompt_eval_acc_and_f1': 0.6750393588092172, 'mrpc_dev_eval_loss': 3.18886661529541, 'mrpc_dev_eval_acc': 0.78125, 'mrpc_dev_eval_f1': 0.7999999999999999, 'mrpc_dev_eval_acc_and_f1': 0.7906249999999999, 'mrpc_test_eval_loss': 4.40266227722168, 'mrpc_test_eval_acc': 0.6274509803921569, 'mrpc_test_eval_f1': 0.7226277372262774, 'mrpc_test_eval_acc_and_f1': 0.6750393588092172, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-42-roberta-large-11230', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_13-04-36_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-42-roberta-large-11230', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt_eval_loss': 2.3386893272399902, 'qnli_dev_prompt_eval_acc': 0.6875, 'qnli_test_prompt_eval_loss': 4.121875286102295, 'qnli_test_prompt_eval_acc': 0.5026542192934286, 'qnli_dev_eval_loss': 2.3386893272399902, 'qnli_dev_eval_acc': 0.6875, 'qnli_test_eval_loss': 4.121875286102295, 'qnli_test_eval_acc': 0.5026542192934286, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-100-roberta-large-17167', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_13-00-10_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-100-roberta-large-17167', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.2132580280303955, 'sts-b_dev_prompt_eval_pearson': 0.3932686231667152, 'sts-b_dev_prompt_eval_spearmanr': 0.4890735416264475, 'sts-b_dev_prompt_eval_corr': 0.4411710823965813, 'sts-b_test_prompt_eval_loss': 2.5149333477020264, 'sts-b_test_prompt_eval_pearson': 0.11466573763146232, 'sts-b_test_prompt_eval_spearmanr': 0.13028574815876512, 'sts-b_test_prompt_eval_corr': 0.12247574289511372, 'sts-b_dev_eval_loss': 2.2132580280303955, 'sts-b_dev_eval_pearson': 0.3932686231667152, 'sts-b_dev_eval_spearmanr': 0.4890735416264475, 'sts-b_dev_eval_corr': 0.4411710823965813, 'sts-b_test_eval_loss': 2.5149333477020264, 'sts-b_test_eval_pearson': 0.11466573763146232, 'sts-b_test_eval_spearmanr': 0.13028574815876512, 'sts-b_test_eval_corr': 0.12247574289511372, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-42-roberta-large-3680', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_13-02-28_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-42-roberta-large-3680', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt_eval_loss': 0.7122360467910767, 'cola_dev_prompt_eval_mcc': 0.18786728732554486, 'cola_test_prompt_eval_loss': 0.7442725896835327, 'cola_test_prompt_eval_mcc': 0.04311644874381675, 'cola_dev_eval_loss': 0.7122360467910767, 'cola_dev_eval_mcc': 0.18786728732554486, 'cola_test_eval_loss': 0.7442725896835327, 'cola_test_eval_mcc': 0.04311644874381675, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-24331', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_13-10-33_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-24331', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt_eval_loss': 3.605881452560425, 'mrpc_dev_prompt_eval_acc': 0.6875, 'mrpc_dev_prompt_eval_f1': 0.7222222222222223, 'mrpc_dev_prompt_eval_acc_and_f1': 0.7048611111111112, 'mrpc_test_prompt_eval_loss': 3.8779170513153076, 'mrpc_test_prompt_eval_acc': 0.571078431372549, 'mrpc_test_prompt_eval_f1': 0.6628131021194605, 'mrpc_test_prompt_eval_acc_and_f1': 0.6169457667460048, 'mrpc_dev_eval_loss': 3.605881452560425, 'mrpc_dev_eval_acc': 0.6875, 'mrpc_dev_eval_f1': 0.7222222222222223, 'mrpc_dev_eval_acc_and_f1': 0.7048611111111112, 'mrpc_test_eval_loss': 3.8779170513153076, 'mrpc_test_eval_acc': 0.571078431372549, 'mrpc_test_eval_f1': 0.6628131021194605, 'mrpc_test_eval_acc_and_f1': 0.6169457667460048, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-42-roberta-large-15964', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_13-12-24_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-42-roberta-large-15964', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_adapter_eval_loss': 2.2405989170074463, 'mnli_dev_adapter_eval_mnli/acc': 0.6875, 'mnli_test_adapter_eval_loss': 2.256018877029419, 'mnli_test_adapter_eval_mnli/acc': 0.6478858889454916, 'mnli-mm_test_adapter_eval_loss': 2.0045254230499268, 'mnli-mm_test_adapter_eval_mnli-mm/acc': 0.6740235964198535, 'mnli_dev_eval_loss': 2.2405989170074463, 'mnli_dev_eval_mnli/acc': 0.6875, 'mnli_test_eval_loss': 2.256018877029419, 'mnli_test_eval_mnli/acc': 0.6478858889454916, 'mnli-mm_test_eval_loss': 2.0045254230499268, 'mnli-mm_test_eval_mnli-mm/acc': 0.6740235964198535, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--42-roberta-large-19745', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_12-43-30_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--42-roberta-large-19745', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias,adapter_eval_loss': 2.036667585372925, 'rte_dev_bias,adapter_eval_acc': 0.71875, 'rte_test_bias,adapter_eval_loss': 2.589073896408081, 'rte_test_bias,adapter_eval_acc': 0.6570397111913358, 'rte_dev_eval_loss': 2.036667585372925, 'rte_dev_eval_acc': 0.71875, 'rte_test_eval_loss': 2.589073896408081, 'rte_test_eval_acc': 0.6570397111913358, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--100-roberta-large-9469', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_13-05-57_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--100-roberta-large-9469', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt_eval_loss': 0.8765617609024048, 'cola_dev_prompt_eval_mcc': 0.1259881576697424, 'cola_test_prompt_eval_loss': 0.7907168865203857, 'cola_test_prompt_eval_mcc': 0.05475178595697109, 'cola_dev_eval_loss': 0.8765617609024048, 'cola_dev_eval_mcc': 0.1259881576697424, 'cola_test_eval_loss': 0.7907168865203857, 'cola_test_eval_mcc': 0.05475178595697109, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-21327', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_13-18-08_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-21327', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt_eval_loss': 1.2580058574676514, 'qnli_dev_prompt_eval_acc': 0.65625, 'qnli_test_prompt_eval_loss': 1.5202748775482178, 'qnli_test_prompt_eval_acc': 0.48325096101043385, 'qnli_dev_eval_loss': 1.2580058574676514, 'qnli_dev_eval_acc': 0.65625, 'qnli_test_eval_loss': 1.5202748775482178, 'qnli_test_eval_acc': 0.48325096101043385, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-100-roberta-large-29449', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_13-13-55_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-100-roberta-large-29449', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt_eval_loss': 1.8671190738677979, 'mrpc_dev_prompt_eval_acc': 0.6875, 'mrpc_dev_prompt_eval_f1': 0.7222222222222223, 'mrpc_dev_prompt_eval_acc_and_f1': 0.7048611111111112, 'mrpc_test_prompt_eval_loss': 1.899491310119629, 'mrpc_test_prompt_eval_acc': 0.5857843137254902, 'mrpc_test_prompt_eval_f1': 0.6743737957610791, 'mrpc_test_prompt_eval_acc_and_f1': 0.6300790547432846, 'mrpc_dev_eval_loss': 1.8671190738677979, 'mrpc_dev_eval_acc': 0.6875, 'mrpc_dev_eval_f1': 0.7222222222222223, 'mrpc_dev_eval_acc_and_f1': 0.7048611111111112, 'mrpc_test_eval_loss': 1.899491310119629, 'mrpc_test_eval_acc': 0.5857843137254902, 'mrpc_test_eval_f1': 0.6743737957610791, 'mrpc_test_eval_acc_and_f1': 0.6300790547432846, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-42-roberta-large-9519', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_13-19-59_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-42-roberta-large-9519', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.1151599884033203, 'sts-b_dev_prompt_eval_pearson': 0.5598198938981284, 'sts-b_dev_prompt_eval_spearmanr': 0.5348570455180769, 'sts-b_dev_prompt_eval_corr': 0.5473384697081026, 'sts-b_test_prompt_eval_loss': 2.2875537872314453, 'sts-b_test_prompt_eval_pearson': 0.0015161670912646756, 'sts-b_test_prompt_eval_spearmanr': -0.004889451781531729, 'sts-b_test_prompt_eval_corr': -0.0016866423451335265, 'sts-b_dev_eval_loss': 2.1151599884033203, 'sts-b_dev_eval_pearson': 0.5598198938981284, 'sts-b_dev_eval_spearmanr': 0.5348570455180769, 'sts-b_dev_eval_corr': 0.5473384697081026, 'sts-b_test_eval_loss': 2.2875537872314453, 'sts-b_test_eval_pearson': 0.0015161670912646756, 'sts-b_test_eval_spearmanr': -0.004889451781531729, 'sts-b_test_eval_corr': -0.0016866423451335265, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-100-roberta-large-2156', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_13-16-28_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-100-roberta-large-2156', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias_eval_loss': 0.004271989688277245, 'sst-2_dev_prompt,bias_eval_acc': 1.0, 'sst-2_test_prompt,bias_eval_loss': 0.5288965702056885, 'sst-2_test_prompt,bias_eval_acc': 0.9048165137614679, 'sst-2_dev_eval_loss': 0.004271989688277245, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.5288965702056885, 'sst-2_test_eval_acc': 0.9048165137614679, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-5812', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_13-09-16_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-5812', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt_eval_loss': 0.7102854251861572, 'cola_dev_prompt_eval_mcc': 0.2581988897471611, 'cola_test_prompt_eval_loss': 0.7280816435813904, 'cola_test_prompt_eval_mcc': 0.07225727412156455, 'cola_dev_eval_loss': 0.7102854251861572, 'cola_dev_eval_mcc': 0.2581988897471611, 'cola_test_eval_loss': 0.7280816435813904, 'cola_test_eval_mcc': 0.07225727412156455, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-21984', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_13-25-49_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-21984', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt_eval_loss': 0.8124870657920837, 'mrpc_dev_prompt_eval_acc': 0.71875, 'mrpc_dev_prompt_eval_f1': 0.742857142857143, 'mrpc_dev_prompt_eval_acc_and_f1': 0.7308035714285714, 'mrpc_test_prompt_eval_loss': 1.345463752746582, 'mrpc_test_prompt_eval_acc': 0.5269607843137255, 'mrpc_test_prompt_eval_f1': 0.6295585412667946, 'mrpc_test_prompt_eval_acc_and_f1': 0.5782596627902601, 'mrpc_dev_eval_loss': 0.8124870657920837, 'mrpc_dev_eval_acc': 0.71875, 'mrpc_dev_eval_f1': 0.742857142857143, 'mrpc_dev_eval_acc_and_f1': 0.7308035714285714, 'mrpc_test_eval_loss': 1.345463752746582, 'mrpc_test_eval_acc': 0.5269607843137255, 'mrpc_test_eval_f1': 0.6295585412667946, 'mrpc_test_eval_acc_and_f1': 0.5782596627902601, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-100-roberta-large-9097', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_13-27-40_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-100-roberta-large-9097', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt_eval_loss': 1.2973096370697021, 'qnli_dev_prompt_eval_acc': 0.65625, 'qnli_test_prompt_eval_loss': 1.8734755516052246, 'qnli_test_prompt_eval_acc': 0.5083287570931723, 'qnli_dev_eval_loss': 1.2973096370697021, 'qnli_dev_eval_acc': 0.65625, 'qnli_test_eval_loss': 1.8734755516052246, 'qnli_test_eval_acc': 0.5083287570931723, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-100-roberta-large-20164', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_13-27-33_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-100-roberta-large-20164', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt_eval_loss': 1.834855318069458, 'cola_dev_prompt_eval_mcc': 0.3289758474798845, 'cola_test_prompt_eval_loss': 2.886094331741333, 'cola_test_prompt_eval_mcc': -0.010075353387426414, 'cola_dev_eval_loss': 1.834855318069458, 'cola_dev_eval_mcc': 0.3289758474798845, 'cola_test_eval_loss': 2.886094331741333, 'cola_test_eval_mcc': -0.010075353387426414, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-29808', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_13-33-32_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-29808', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.23464035987854, 'sts-b_dev_prompt_eval_pearson': 0.3510427102645882, 'sts-b_dev_prompt_eval_spearmanr': 0.33971147285828335, 'sts-b_dev_prompt_eval_corr': 0.3453770915614358, 'sts-b_test_prompt_eval_loss': 2.4456429481506348, 'sts-b_test_prompt_eval_pearson': -0.015535336524338026, 'sts-b_test_prompt_eval_spearmanr': -0.011688056998437222, 'sts-b_test_prompt_eval_corr': -0.013611696761387624, 'sts-b_dev_eval_loss': 2.23464035987854, 'sts-b_dev_eval_pearson': 0.3510427102645882, 'sts-b_dev_eval_spearmanr': 0.33971147285828335, 'sts-b_dev_eval_corr': 0.3453770915614358, 'sts-b_test_eval_loss': 2.4456429481506348, 'sts-b_test_eval_pearson': -0.015535336524338026, 'sts-b_test_eval_spearmanr': -0.011688056998437222, 'sts-b_test_eval_corr': -0.013611696761387624, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-100-roberta-large-31774', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_13-28-59_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-100-roberta-large-31774', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt_eval_loss': 0.8461794853210449, 'mrpc_dev_prompt_eval_acc': 0.625, 'mrpc_dev_prompt_eval_f1': 0.5384615384615384, 'mrpc_dev_prompt_eval_acc_and_f1': 0.5817307692307692, 'mrpc_test_prompt_eval_loss': 0.9793647527694702, 'mrpc_test_prompt_eval_acc': 0.5, 'mrpc_test_prompt_eval_f1': 0.5342465753424658, 'mrpc_test_prompt_eval_acc_and_f1': 0.5171232876712328, 'mrpc_dev_eval_loss': 0.8461794853210449, 'mrpc_dev_eval_acc': 0.625, 'mrpc_dev_eval_f1': 0.5384615384615384, 'mrpc_dev_eval_acc_and_f1': 0.5817307692307692, 'mrpc_test_eval_loss': 0.9793647527694702, 'mrpc_test_eval_acc': 0.5, 'mrpc_test_eval_f1': 0.5342465753424658, 'mrpc_test_eval_acc_and_f1': 0.5171232876712328, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-100-roberta-large-342', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_13-35-12_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-100-roberta-large-342', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias,adapter_eval_loss': 8.198143005371094, 'rte_dev_prompt,bias,adapter_eval_acc': 0.5625, 'rte_test_prompt,bias,adapter_eval_loss': 6.65500545501709, 'rte_test_prompt,bias,adapter_eval_acc': 0.6064981949458483, 'rte_dev_eval_loss': 8.198143005371094, 'rte_dev_eval_acc': 0.5625, 'rte_test_eval_loss': 6.65500545501709, 'rte_test_eval_acc': 0.6064981949458483, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-42-roberta-large-7556', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_13-24-23_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-42-roberta-large-7556', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,adapter_eval_loss': 0.7157025337219238, 'qqp_dev_prompt,adapter_eval_acc': 0.5, 'qqp_dev_prompt,adapter_eval_f1': 0.6666666666666666, 'qqp_dev_prompt,adapter_eval_acc_and_f1': 0.5833333333333333, 'qqp_test_prompt,adapter_eval_loss': 0.7718566060066223, 'qqp_test_prompt,adapter_eval_acc': 0.36816720257234725, 'qqp_test_prompt,adapter_eval_f1': 0.5381903642773208, 'qqp_test_prompt,adapter_eval_acc_and_f1': 0.45317878342483403, 'qqp_dev_eval_loss': 0.7157025337219238, 'qqp_dev_eval_acc': 0.5, 'qqp_dev_eval_f1': 0.6666666666666666, 'qqp_dev_eval_acc_and_f1': 0.5833333333333333, 'qqp_test_eval_loss': 0.7718566060066223, 'qqp_test_eval_acc': 0.36816720257234725, 'qqp_test_eval_f1': 0.5381903642773208, 'qqp_test_eval_acc_and_f1': 0.45317878342483403, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16-prompt-13-roberta-large-19838', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_13-07-36_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-13-roberta-large-19838', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt_eval_loss': 2.8933496475219727, 'cola_dev_prompt_eval_mcc': 0.3872983346207417, 'cola_test_prompt_eval_loss': 4.000270366668701, 'cola_test_prompt_eval_mcc': 0.030176338733705566, 'cola_dev_eval_loss': 2.8933496475219727, 'cola_dev_eval_mcc': 0.3872983346207417, 'cola_test_eval_loss': 4.000270366668701, 'cola_test_eval_mcc': 0.030176338733705566, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-12006', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_13-41-13_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-12006', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt_eval_loss': 1.6599775552749634, 'mrpc_dev_prompt_eval_acc': 0.625, 'mrpc_dev_prompt_eval_f1': 0.5714285714285715, 'mrpc_dev_prompt_eval_acc_and_f1': 0.5982142857142858, 'mrpc_test_prompt_eval_loss': 2.1803393363952637, 'mrpc_test_prompt_eval_acc': 0.49754901960784315, 'mrpc_test_prompt_eval_f1': 0.5514223194748359, 'mrpc_test_prompt_eval_acc_and_f1': 0.5244856695413396, 'mrpc_dev_eval_loss': 1.6599775552749634, 'mrpc_dev_eval_acc': 0.625, 'mrpc_dev_eval_f1': 0.5714285714285715, 'mrpc_dev_eval_acc_and_f1': 0.5982142857142858, 'mrpc_test_eval_loss': 2.1803393363952637, 'mrpc_test_eval_acc': 0.49754901960784315, 'mrpc_test_eval_f1': 0.5514223194748359, 'mrpc_test_eval_acc_and_f1': 0.5244856695413396, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-100-roberta-large-5379', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_13-42-49_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-100-roberta-large-5379', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias_eval_loss': 0.02885889634490013, 'sst-2_dev_prompt,bias_eval_acc': 1.0, 'sst-2_test_prompt,bias_eval_loss': 0.3200029730796814, 'sst-2_test_prompt,bias_eval_acc': 0.908256880733945, 'sst-2_dev_eval_loss': 0.02885889634490013, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.3200029730796814, 'sst-2_test_eval_acc': 0.908256880733945, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-24653', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_13-29-41_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-24653', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_adapter_eval_loss': 1.6461490392684937, 'mnli_dev_adapter_eval_mnli/acc': 0.6458333333333334, 'mnli_test_adapter_eval_loss': 1.6654521226882935, 'mnli_test_adapter_eval_mnli/acc': 0.6346408558329089, 'mnli-mm_test_adapter_eval_loss': 1.5381062030792236, 'mnli-mm_test_adapter_eval_mnli-mm/acc': 0.6497152156224573, 'mnli_dev_eval_loss': 1.6461490392684937, 'mnli_dev_eval_mnli/acc': 0.6458333333333334, 'mnli_test_eval_loss': 1.6654521226882935, 'mnli_test_eval_mnli/acc': 0.6346408558329089, 'mnli-mm_test_eval_loss': 1.5381062030792236, 'mnli-mm_test_eval_mnli-mm/acc': 0.6497152156224573, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--42-roberta-large-23694', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_13-21-27_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--42-roberta-large-23694', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.2216522693634033, 'sts-b_dev_prompt_eval_pearson': 0.40823999017602075, 'sts-b_dev_prompt_eval_spearmanr': 0.4371922961473414, 'sts-b_dev_prompt_eval_corr': 0.42271614316168105, 'sts-b_test_prompt_eval_loss': 2.592183828353882, 'sts-b_test_prompt_eval_pearson': 0.07090406888385474, 'sts-b_test_prompt_eval_spearmanr': 0.07842851504816205, 'sts-b_test_prompt_eval_corr': 0.0746662919660084, 'sts-b_dev_eval_loss': 2.2216522693634033, 'sts-b_dev_eval_pearson': 0.40823999017602075, 'sts-b_dev_eval_spearmanr': 0.4371922961473414, 'sts-b_dev_eval_corr': 0.42271614316168105, 'sts-b_test_eval_loss': 2.592183828353882, 'sts-b_test_eval_pearson': 0.07090406888385474, 'sts-b_test_eval_spearmanr': 0.07842851504816205, 'sts-b_test_eval_corr': 0.0746662919660084, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-100-roberta-large-23777', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_13-41-26_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-100-roberta-large-23777', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt_eval_loss': 1.1430150270462036, 'cola_dev_prompt_eval_mcc': 0.34752402342845795, 'cola_test_prompt_eval_loss': 2.063523292541504, 'cola_test_prompt_eval_mcc': 0.028114327667141524, 'cola_dev_eval_loss': 1.1430150270462036, 'cola_dev_eval_mcc': 0.34752402342845795, 'cola_test_eval_loss': 2.063523292541504, 'cola_test_eval_mcc': 0.028114327667141524, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-28254', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_13-48-56_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-28254', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias_eval_loss': 4.161930084228516, 'qnli_dev_bias_eval_acc': 0.53125, 'qnli_test_bias_eval_loss': 3.8544046878814697, 'qnli_test_bias_eval_acc': 0.5028372688998719, 'qnli_dev_eval_loss': 4.161930084228516, 'qnli_dev_eval_acc': 0.53125, 'qnli_test_eval_loss': 3.8544046878814697, 'qnli_test_eval_acc': 0.5028372688998719, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16--42-roberta-large-27367', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_13-41-06_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--42-roberta-large-27367', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt_eval_loss': 0.9525458812713623, 'mrpc_dev_prompt_eval_acc': 0.5625, 'mrpc_dev_prompt_eval_f1': 0.4166666666666667, 'mrpc_dev_prompt_eval_acc_and_f1': 0.48958333333333337, 'mrpc_test_prompt_eval_loss': 1.2469404935836792, 'mrpc_test_prompt_eval_acc': 0.3799019607843137, 'mrpc_test_prompt_eval_f1': 0.34285714285714286, 'mrpc_test_prompt_eval_acc_and_f1': 0.3613795518207283, 'mrpc_dev_eval_loss': 0.9525458812713623, 'mrpc_dev_eval_acc': 0.5625, 'mrpc_dev_eval_f1': 0.4166666666666667, 'mrpc_dev_eval_acc_and_f1': 0.48958333333333337, 'mrpc_test_eval_loss': 1.2469404935836792, 'mrpc_test_eval_acc': 0.3799019607843137, 'mrpc_test_eval_f1': 0.34285714285714286, 'mrpc_test_eval_acc_and_f1': 0.3613795518207283, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-100-roberta-large-5394', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_13-50-41_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-100-roberta-large-5394', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias,adapter_eval_loss': 3.9463515281677246, 'rte_dev_prompt,bias,adapter_eval_acc': 0.75, 'rte_test_prompt,bias,adapter_eval_loss': 5.069697380065918, 'rte_test_prompt,bias,adapter_eval_acc': 0.6931407942238267, 'rte_dev_eval_loss': 3.9463515281677246, 'rte_dev_eval_acc': 0.75, 'rte_test_eval_loss': 5.069697380065918, 'rte_test_eval_acc': 0.6931407942238267, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-42-roberta-large-31751', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_13-44-19_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-42-roberta-large-31751', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt_eval_loss': 0.9842805862426758, 'cola_dev_prompt_eval_mcc': 0.22677868380553634, 'cola_test_prompt_eval_loss': 1.2837027311325073, 'cola_test_prompt_eval_mcc': -0.014991236837800905, 'cola_dev_eval_loss': 0.9842805862426758, 'cola_dev_eval_mcc': 0.22677868380553634, 'cola_test_eval_loss': 1.2837027311325073, 'cola_test_eval_mcc': -0.014991236837800905, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-6163', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_13-56-31_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-6163', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.1896908283233643, 'sts-b_dev_prompt_eval_pearson': 0.3741542708026251, 'sts-b_dev_prompt_eval_spearmanr': 0.43296199626875964, 'sts-b_dev_prompt_eval_corr': 0.40355813353569236, 'sts-b_test_prompt_eval_loss': 2.407641649246216, 'sts-b_test_prompt_eval_pearson': 0.009950323644377574, 'sts-b_test_prompt_eval_spearmanr': 0.009332600738281554, 'sts-b_test_prompt_eval_corr': 0.009641462191329563, 'sts-b_dev_eval_loss': 2.1896908283233643, 'sts-b_dev_eval_pearson': 0.3741542708026251, 'sts-b_dev_eval_spearmanr': 0.43296199626875964, 'sts-b_dev_eval_corr': 0.40355813353569236, 'sts-b_test_eval_loss': 2.407641649246216, 'sts-b_test_eval_pearson': 0.009950323644377574, 'sts-b_test_eval_spearmanr': 0.009332600738281554, 'sts-b_test_eval_corr': 0.009641462191329563, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-100-roberta-large-4747', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_13-54-45_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-100-roberta-large-4747', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias_eval_loss': 1.4917494058609009, 'mrpc_dev_bias_eval_acc': 0.8125, 'mrpc_dev_bias_eval_f1': 0.823529411764706, 'mrpc_dev_bias_eval_acc_and_f1': 0.818014705882353, 'mrpc_test_bias_eval_loss': 2.9543941020965576, 'mrpc_test_bias_eval_acc': 0.6495098039215687, 'mrpc_test_bias_eval_f1': 0.7276190476190475, 'mrpc_test_bias_eval_acc_and_f1': 0.6885644257703081, 'mrpc_dev_eval_loss': 1.4917494058609009, 'mrpc_dev_eval_acc': 0.8125, 'mrpc_dev_eval_f1': 0.823529411764706, 'mrpc_dev_eval_acc_and_f1': 0.818014705882353, 'mrpc_test_eval_loss': 2.9543941020965576, 'mrpc_test_eval_acc': 0.6495098039215687, 'mrpc_test_eval_f1': 0.7276190476190475, 'mrpc_test_eval_acc_and_f1': 0.6885644257703081, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16--42-roberta-large-6950', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_13-58-31_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--42-roberta-large-6950', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias_eval_loss': 3.641019821166992, 'qnli_dev_bias_eval_acc': 0.625, 'qnli_test_bias_eval_loss': 3.82725191116333, 'qnli_test_bias_eval_acc': 0.5756910122643236, 'qnli_dev_eval_loss': 3.641019821166992, 'qnli_dev_eval_acc': 0.625, 'qnli_test_eval_loss': 3.82725191116333, 'qnli_test_eval_acc': 0.5756910122643236, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16--42-roberta-large-30106', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_13-56-39_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--42-roberta-large-30106', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias_eval_loss': 0.6928278803825378, 'cola_dev_bias_eval_mcc': 0.19088542889273333, 'cola_test_bias_eval_loss': 0.6935805678367615, 'cola_test_bias_eval_mcc': 0.009371138937516269, 'cola_dev_eval_loss': 0.6928278803825378, 'cola_dev_eval_mcc': 0.19088542889273333, 'cola_test_eval_loss': 0.6935805678367615, 'cola_test_eval_mcc': 0.009371138937516269, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--42-roberta-large-30419', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_14-04-13_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-30419', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias,adapter_eval_loss': 1.5990549325942993, 'sst-2_dev_bias,adapter_eval_acc': 0.75, 'sst-2_test_bias,adapter_eval_loss': 1.539109230041504, 'sst-2_test_bias,adapter_eval_acc': 0.7305045871559633, 'sst-2_dev_eval_loss': 1.5990549325942993, 'sst-2_dev_eval_acc': 0.75, 'sst-2_test_eval_loss': 1.539109230041504, 'sst-2_test_eval_acc': 0.7305045871559633, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--42-roberta-large-13642', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_13-51-41_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--42-roberta-large-13642', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias_eval_loss': 2.426356315612793, 'mrpc_dev_bias_eval_acc': 0.6875, 'mrpc_dev_bias_eval_f1': 0.7368421052631579, 'mrpc_dev_bias_eval_acc_and_f1': 0.712171052631579, 'mrpc_test_bias_eval_loss': 3.692638635635376, 'mrpc_test_bias_eval_acc': 0.6225490196078431, 'mrpc_test_bias_eval_f1': 0.7105263157894737, 'mrpc_test_bias_eval_acc_and_f1': 0.6665376676986584, 'mrpc_dev_eval_loss': 2.426356315612793, 'mrpc_dev_eval_acc': 0.6875, 'mrpc_dev_eval_f1': 0.7368421052631579, 'mrpc_dev_eval_acc_and_f1': 0.712171052631579, 'mrpc_test_eval_loss': 3.692638635635376, 'mrpc_test_eval_acc': 0.6225490196078431, 'mrpc_test_eval_f1': 0.7105263157894737, 'mrpc_test_eval_acc_and_f1': 0.6665376676986584, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16--42-roberta-large-28042', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_14-09-08_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--42-roberta-large-28042', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias_eval_loss': 2.1185474395751953, 'sts-b_dev_bias_eval_pearson': 0.8419823232959283, 'sts-b_dev_bias_eval_spearmanr': 0.8275498980731402, 'sts-b_dev_bias_eval_corr': 0.8347661106845342, 'sts-b_test_bias_eval_loss': 2.178230047225952, 'sts-b_test_bias_eval_pearson': 0.7545376787984166, 'sts-b_test_bias_eval_spearmanr': 0.7596446000760622, 'sts-b_test_bias_eval_corr': 0.7570911394372394, 'sts-b_dev_eval_loss': 2.1185474395751953, 'sts-b_dev_eval_pearson': 0.8419823232959283, 'sts-b_dev_eval_spearmanr': 0.8275498980731402, 'sts-b_dev_eval_corr': 0.8347661106845342, 'sts-b_test_eval_loss': 2.178230047225952, 'sts-b_test_eval_pearson': 0.7545376787984166, 'sts-b_test_eval_spearmanr': 0.7596446000760622, 'sts-b_test_eval_corr': 0.7570911394372394, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16--42-roberta-large-10324', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_14-07-39_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--42-roberta-large-10324', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias,adapter_eval_loss': 1.2340967655181885, 'rte_dev_prompt,bias,adapter_eval_acc': 0.75, 'rte_test_prompt,bias,adapter_eval_loss': 2.164475917816162, 'rte_test_prompt,bias,adapter_eval_acc': 0.7111913357400722, 'rte_dev_eval_loss': 1.2340967655181885, 'rte_dev_eval_acc': 0.75, 'rte_test_eval_loss': 2.164475917816162, 'rte_test_eval_acc': 0.7111913357400722, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-42-roberta-large-9128', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_14-04-03_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-42-roberta-large-9128', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,adapter_eval_loss': 3.1586856842041016, 'qqp_dev_prompt,adapter_eval_acc': 0.71875, 'qqp_dev_prompt,adapter_eval_f1': 0.742857142857143, 'qqp_dev_prompt,adapter_eval_acc_and_f1': 0.7308035714285714, 'qqp_test_prompt,adapter_eval_loss': 4.444452285766602, 'qqp_test_prompt,adapter_eval_acc': 0.6380163245115014, 'qqp_test_prompt,adapter_eval_f1': 0.6371637535639023, 'qqp_test_prompt,adapter_eval_acc_and_f1': 0.6375900390377018, 'qqp_dev_eval_loss': 3.1586856842041016, 'qqp_dev_eval_acc': 0.71875, 'qqp_dev_eval_f1': 0.742857142857143, 'qqp_dev_eval_acc_and_f1': 0.7308035714285714, 'qqp_test_eval_loss': 4.444452285766602, 'qqp_test_eval_acc': 0.6380163245115014, 'qqp_test_eval_f1': 0.6371637535639023, 'qqp_test_eval_acc_and_f1': 0.6375900390377018, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16-prompt-13-roberta-large-27982', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_13-46-08_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-13-roberta-large-27982', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias_eval_loss': 3.2365241050720215, 'cola_dev_bias_eval_mcc': 0.26967994498529685, 'cola_test_bias_eval_loss': 3.056067705154419, 'cola_test_bias_eval_mcc': 0.03345488255537799, 'cola_dev_eval_loss': 3.2365241050720215, 'cola_dev_eval_mcc': 0.26967994498529685, 'cola_test_eval_loss': 3.056067705154419, 'cola_test_eval_mcc': 0.03345488255537799, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--42-roberta-large-13045', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_14-15-02_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-13045', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_adapter_eval_loss': 2.8381030559539795, 'mnli_dev_adapter_eval_mnli/acc': 0.6666666666666666, 'mnli_test_adapter_eval_loss': 3.289194345474243, 'mnli_test_adapter_eval_mnli/acc': 0.6530820173204279, 'mnli-mm_test_adapter_eval_loss': 2.895493507385254, 'mnli-mm_test_adapter_eval_mnli-mm/acc': 0.6827705451586655, 'mnli_dev_eval_loss': 2.8381030559539795, 'mnli_dev_eval_mnli/acc': 0.6666666666666666, 'mnli_test_eval_loss': 3.289194345474243, 'mnli_test_eval_mnli/acc': 0.6530820173204279, 'mnli-mm_test_eval_loss': 2.895493507385254, 'mnli-mm_test_eval_mnli-mm/acc': 0.6827705451586655, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--100-roberta-large-14781', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_13-53-09_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--100-roberta-large-14781', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias_eval_loss': 1.8988707065582275, 'qnli_dev_bias_eval_acc': 0.65625, 'qnli_test_bias_eval_loss': 2.0482711791992188, 'qnli_test_bias_eval_acc': 0.5698334248581366, 'qnli_dev_eval_loss': 1.8988707065582275, 'qnli_dev_eval_acc': 0.65625, 'qnli_test_eval_loss': 2.0482711791992188, 'qnli_test_eval_acc': 0.5698334248581366, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16--42-roberta-large-21679', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_14-12-07_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--42-roberta-large-21679', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias_eval_loss': 2.006331443786621, 'mrpc_dev_bias_eval_acc': 0.59375, 'mrpc_dev_bias_eval_f1': 0.6666666666666667, 'mrpc_dev_bias_eval_acc_and_f1': 0.6302083333333334, 'mrpc_test_bias_eval_loss': 2.142378330230713, 'mrpc_test_bias_eval_acc': 0.6421568627450981, 'mrpc_test_bias_eval_f1': 0.7402135231316725, 'mrpc_test_bias_eval_acc_and_f1': 0.6911851929383853, 'mrpc_dev_eval_loss': 2.006331443786621, 'mrpc_dev_eval_acc': 0.59375, 'mrpc_dev_eval_f1': 0.6666666666666667, 'mrpc_dev_eval_acc_and_f1': 0.6302083333333334, 'mrpc_test_eval_loss': 2.142378330230713, 'mrpc_test_eval_acc': 0.6421568627450981, 'mrpc_test_eval_f1': 0.7402135231316725, 'mrpc_test_eval_acc_and_f1': 0.6911851929383853, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16--42-roberta-large-9455', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_14-19-54_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--42-roberta-large-9455', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias_eval_loss': 2.9166183471679688, 'cola_dev_bias_eval_mcc': 0.2519763153394848, 'cola_test_bias_eval_loss': 3.2895212173461914, 'cola_test_bias_eval_mcc': 0.02113826437948577, 'cola_dev_eval_loss': 2.9166183471679688, 'cola_dev_eval_mcc': 0.2519763153394848, 'cola_test_eval_loss': 3.2895212173461914, 'cola_test_eval_mcc': 0.02113826437948577, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--42-roberta-large-23834', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_14-25-31_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-23834', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias_eval_loss': 2.1289989948272705, 'sts-b_dev_bias_eval_pearson': 0.7585382923638793, 'sts-b_dev_bias_eval_spearmanr': 0.7682292995206271, 'sts-b_dev_bias_eval_corr': 0.7633837959422531, 'sts-b_test_bias_eval_loss': 2.202402114868164, 'sts-b_test_bias_eval_pearson': 0.6394810269182658, 'sts-b_test_bias_eval_spearmanr': 0.6460748408809368, 'sts-b_test_bias_eval_corr': 0.6427779338996014, 'sts-b_dev_eval_loss': 2.1289989948272705, 'sts-b_dev_eval_pearson': 0.7585382923638793, 'sts-b_dev_eval_spearmanr': 0.7682292995206271, 'sts-b_dev_eval_corr': 0.7633837959422531, 'sts-b_test_eval_loss': 2.202402114868164, 'sts-b_test_eval_pearson': 0.6394810269182658, 'sts-b_test_eval_spearmanr': 0.6460748408809368, 'sts-b_test_eval_corr': 0.6427779338996014, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16--42-roberta-large-22542', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_14-22-42_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--42-roberta-large-22542', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias,adapter_eval_loss': 0.22075039148330688, 'sst-2_dev_bias,adapter_eval_acc': 0.96875, 'sst-2_test_bias,adapter_eval_loss': 0.8928088545799255, 'sst-2_test_bias,adapter_eval_acc': 0.9254587155963303, 'sst-2_dev_eval_loss': 0.22075039148330688, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.8928088545799255, 'sst-2_test_eval_acc': 0.9254587155963303, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--42-roberta-large-18758', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_14-15-52_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--42-roberta-large-18758', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias_eval_loss': 1.2262827157974243, 'mrpc_dev_bias_eval_acc': 0.75, 'mrpc_dev_bias_eval_f1': 0.7777777777777777, 'mrpc_dev_bias_eval_acc_and_f1': 0.7638888888888888, 'mrpc_test_bias_eval_loss': 1.750745415687561, 'mrpc_test_bias_eval_acc': 0.5906862745098039, 'mrpc_test_bias_eval_f1': 0.6719056974459725, 'mrpc_test_bias_eval_acc_and_f1': 0.6312959859778882, 'mrpc_dev_eval_loss': 1.2262827157974243, 'mrpc_dev_eval_acc': 0.75, 'mrpc_dev_eval_f1': 0.7777777777777777, 'mrpc_dev_eval_acc_and_f1': 0.7638888888888888, 'mrpc_test_eval_loss': 1.750745415687561, 'mrpc_test_eval_acc': 0.5906862745098039, 'mrpc_test_eval_f1': 0.6719056974459725, 'mrpc_test_eval_acc_and_f1': 0.6312959859778882, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16--42-roberta-large-1735', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_14-30-41_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--42-roberta-large-1735', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias_eval_loss': 2.0577306747436523, 'qnli_dev_bias_eval_acc': 0.59375, 'qnli_test_bias_eval_loss': 2.010023832321167, 'qnli_test_bias_eval_acc': 0.5907010799926781, 'qnli_dev_eval_loss': 2.0577306747436523, 'qnli_dev_eval_acc': 0.59375, 'qnli_test_eval_loss': 2.010023832321167, 'qnli_test_eval_acc': 0.5907010799926781, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16--42-roberta-large-2871', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_14-27-38_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--42-roberta-large-2871', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias,adapter_eval_loss': 1.8920047283172607, 'rte_dev_prompt,bias,adapter_eval_acc': 0.65625, 'rte_test_prompt,bias,adapter_eval_loss': 1.5160282850265503, 'rte_test_prompt,bias,adapter_eval_acc': 0.6931407942238267, 'rte_dev_eval_loss': 1.8920047283172607, 'rte_dev_eval_acc': 0.65625, 'rte_test_eval_loss': 1.5160282850265503, 'rte_test_eval_acc': 0.6931407942238267, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-42-roberta-large-27490', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_14-23-41_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-42-roberta-large-27490', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias_eval_loss': 3.184450626373291, 'cola_dev_bias_eval_mcc': 0.44539933408304444, 'cola_test_bias_eval_loss': 3.5071122646331787, 'cola_test_bias_eval_mcc': 0.06344830284099495, 'cola_dev_eval_loss': 3.184450626373291, 'cola_dev_eval_mcc': 0.44539933408304444, 'cola_test_eval_loss': 3.5071122646331787, 'cola_test_eval_mcc': 0.06344830284099495, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--42-roberta-large-20201', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_14-35-57_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-20201', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias_eval_loss': 1.8517956733703613, 'mrpc_dev_bias_eval_acc': 0.6875, 'mrpc_dev_bias_eval_f1': 0.7058823529411765, 'mrpc_dev_bias_eval_acc_and_f1': 0.6966911764705883, 'mrpc_test_bias_eval_loss': 2.53393816947937, 'mrpc_test_bias_eval_acc': 0.5196078431372549, 'mrpc_test_bias_eval_f1': 0.608, 'mrpc_test_bias_eval_acc_and_f1': 0.5638039215686275, 'mrpc_dev_eval_loss': 1.8517956733703613, 'mrpc_dev_eval_acc': 0.6875, 'mrpc_dev_eval_f1': 0.7058823529411765, 'mrpc_dev_eval_acc_and_f1': 0.6966911764705883, 'mrpc_test_eval_loss': 2.53393816947937, 'mrpc_test_eval_acc': 0.5196078431372549, 'mrpc_test_eval_f1': 0.608, 'mrpc_test_eval_acc_and_f1': 0.5638039215686275, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16--100-roberta-large-3176', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_14-41-23_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--100-roberta-large-3176', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias_eval_loss': 2.1219985485076904, 'sts-b_dev_bias_eval_pearson': 0.7325453959539647, 'sts-b_dev_bias_eval_spearmanr': 0.7256213154209892, 'sts-b_dev_bias_eval_corr': 0.729083355687477, 'sts-b_test_bias_eval_loss': 2.1872401237487793, 'sts-b_test_bias_eval_pearson': 0.6295540309746738, 'sts-b_test_bias_eval_spearmanr': 0.633284293943373, 'sts-b_test_bias_eval_corr': 0.6314191624590234, 'sts-b_dev_eval_loss': 2.1219985485076904, 'sts-b_dev_eval_pearson': 0.7325453959539647, 'sts-b_dev_eval_spearmanr': 0.7256213154209892, 'sts-b_dev_eval_corr': 0.729083355687477, 'sts-b_test_eval_loss': 2.1872401237487793, 'sts-b_test_eval_pearson': 0.6295540309746738, 'sts-b_test_eval_spearmanr': 0.633284293943373, 'sts-b_test_eval_corr': 0.6314191624590234, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16--42-roberta-large-32534', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_14-37-14_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--42-roberta-large-32534', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_adapter_eval_loss': 1.7389847040176392, 'mnli_dev_adapter_eval_mnli/acc': 0.7291666666666666, 'mnli_test_adapter_eval_loss': 2.226872444152832, 'mnli_test_adapter_eval_mnli/acc': 0.6803871625063678, 'mnli-mm_test_adapter_eval_loss': 2.027035713195801, 'mnli-mm_test_adapter_eval_mnli-mm/acc': 0.7022986167615948, 'mnli_dev_eval_loss': 1.7389847040176392, 'mnli_dev_eval_mnli/acc': 0.7291666666666666, 'mnli_test_eval_loss': 2.226872444152832, 'mnli_test_eval_mnli/acc': 0.6803871625063678, 'mnli-mm_test_eval_loss': 2.027035713195801, 'mnli-mm_test_eval_mnli-mm/acc': 0.7022986167615948, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--100-roberta-large-8180', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_14-25-34_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--100-roberta-large-8180', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias_eval_loss': 0.7923223376274109, 'cola_dev_bias_eval_mcc': 0.0, 'cola_test_bias_eval_loss': 0.9656208157539368, 'cola_test_bias_eval_mcc': 0.0, 'cola_dev_eval_loss': 0.7923223376274109, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.9656208157539368, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--100-roberta-large-17499', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_14-46-24_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-17499', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias_eval_loss': 0.7542219758033752, 'qnli_dev_bias_eval_acc': 0.5, 'qnli_test_bias_eval_loss': 0.7504256963729858, 'qnli_test_bias_eval_acc': 0.5053999633900788, 'qnli_dev_eval_loss': 0.7542219758033752, 'qnli_dev_eval_acc': 0.5, 'qnli_test_eval_loss': 0.7504256963729858, 'qnli_test_eval_acc': 0.5053999633900788, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16--100-roberta-large-5878', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_14-43-19_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--100-roberta-large-5878', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,adapter_eval_loss': 2.5785000324249268, 'qqp_dev_prompt,adapter_eval_acc': 0.59375, 'qqp_dev_prompt,adapter_eval_f1': 0.6829268292682927, 'qqp_dev_prompt,adapter_eval_acc_and_f1': 0.6383384146341464, 'qqp_test_prompt,adapter_eval_loss': 3.3609049320220947, 'qqp_test_prompt,adapter_eval_acc': 0.540811278753401, 'qqp_test_prompt,adapter_eval_f1': 0.5731693298080239, 'qqp_test_prompt,adapter_eval_acc_and_f1': 0.5569903042807125, 'qqp_dev_eval_loss': 2.5785000324249268, 'qqp_dev_eval_acc': 0.59375, 'qqp_dev_eval_f1': 0.6829268292682927, 'qqp_dev_eval_acc_and_f1': 0.6383384146341464, 'qqp_test_eval_loss': 3.3609049320220947, 'qqp_test_eval_acc': 0.540811278753401, 'qqp_test_eval_f1': 0.5731693298080239, 'qqp_test_eval_acc_and_f1': 0.5569903042807125, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16-prompt-13-roberta-large-1367', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_14-25-20_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-13-roberta-large-1367', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias,adapter_eval_loss': 0.4156382083892822, 'sst-2_dev_bias,adapter_eval_acc': 0.96875, 'sst-2_test_bias,adapter_eval_loss': 0.7208071351051331, 'sst-2_test_bias,adapter_eval_acc': 0.9197247706422018, 'sst-2_dev_eval_loss': 0.4156382083892822, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.7208071351051331, 'sst-2_test_eval_acc': 0.9197247706422018, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--42-roberta-large-12700', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_14-38-52_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--42-roberta-large-12700', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias,adapter_eval_loss': 4.355386734008789, 'rte_dev_prompt,bias,adapter_eval_acc': 0.625, 'rte_test_prompt,bias,adapter_eval_loss': 3.6332736015319824, 'rte_test_prompt,bias,adapter_eval_acc': 0.6678700361010831, 'rte_dev_eval_loss': 4.355386734008789, 'rte_dev_eval_acc': 0.625, 'rte_test_eval_loss': 3.6332736015319824, 'rte_test_eval_acc': 0.6678700361010831, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-100-roberta-large-13026', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_14-43-30_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-100-roberta-large-13026', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias_eval_loss': 1.9676445722579956, 'mrpc_dev_bias_eval_acc': 0.65625, 'mrpc_dev_bias_eval_f1': 0.6451612903225806, 'mrpc_dev_bias_eval_acc_and_f1': 0.6507056451612903, 'mrpc_test_bias_eval_loss': 2.871922016143799, 'mrpc_test_bias_eval_acc': 0.6078431372549019, 'mrpc_test_bias_eval_f1': 0.6761133603238866, 'mrpc_test_bias_eval_acc_and_f1': 0.6419782487893942, 'mrpc_dev_eval_loss': 1.9676445722579956, 'mrpc_dev_eval_acc': 0.65625, 'mrpc_dev_eval_f1': 0.6451612903225806, 'mrpc_dev_eval_acc_and_f1': 0.6507056451612903, 'mrpc_test_eval_loss': 2.871922016143799, 'mrpc_test_eval_acc': 0.6078431372549019, 'mrpc_test_eval_f1': 0.6761133603238866, 'mrpc_test_eval_acc_and_f1': 0.6419782487893942, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16--100-roberta-large-18938', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_14-52-05_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--100-roberta-large-18938', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias_eval_loss': 2.1299655437469482, 'sts-b_dev_bias_eval_pearson': 0.6626193496952271, 'sts-b_dev_bias_eval_spearmanr': 0.6358139696247695, 'sts-b_dev_bias_eval_corr': 0.6492166596599983, 'sts-b_test_bias_eval_loss': 2.2092981338500977, 'sts-b_test_bias_eval_pearson': 0.5340982766175906, 'sts-b_test_bias_eval_spearmanr': 0.5375312766500212, 'sts-b_test_bias_eval_corr': 0.535814776633806, 'sts-b_dev_eval_loss': 2.1299655437469482, 'sts-b_dev_eval_pearson': 0.6626193496952271, 'sts-b_dev_eval_spearmanr': 0.6358139696247695, 'sts-b_dev_eval_corr': 0.6492166596599983, 'sts-b_test_eval_loss': 2.2092981338500977, 'sts-b_test_eval_pearson': 0.5340982766175906, 'sts-b_test_eval_spearmanr': 0.5375312766500212, 'sts-b_test_eval_corr': 0.535814776633806, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16--42-roberta-large-13000', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_14-52-06_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--42-roberta-large-13000', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias_eval_loss': 1.3105792999267578, 'cola_dev_bias_eval_mcc': 0.6999132392733555, 'cola_test_bias_eval_loss': 2.669483184814453, 'cola_test_bias_eval_mcc': 0.3909413637126314, 'cola_dev_eval_loss': 1.3105792999267578, 'cola_dev_eval_mcc': 0.6999132392733555, 'cola_test_eval_loss': 2.669483184814453, 'cola_test_eval_mcc': 0.3909413637126314, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--100-roberta-large-18005', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_14-58-45_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-18005', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias_eval_loss': 1.2876081466674805, 'qnli_dev_bias_eval_acc': 0.71875, 'qnli_test_bias_eval_loss': 1.8579272031784058, 'qnli_test_bias_eval_acc': 0.5583012996522058, 'qnli_dev_eval_loss': 1.2876081466674805, 'qnli_dev_eval_acc': 0.71875, 'qnli_test_eval_loss': 1.8579272031784058, 'qnli_test_eval_acc': 0.5583012996522058, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16--100-roberta-large-1762', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_14-59-09_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--100-roberta-large-1762', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias_eval_loss': 2.73701548576355, 'mrpc_dev_bias_eval_acc': 0.6875, 'mrpc_dev_bias_eval_f1': 0.6666666666666666, 'mrpc_dev_bias_eval_acc_and_f1': 0.6770833333333333, 'mrpc_test_bias_eval_loss': 2.3954882621765137, 'mrpc_test_bias_eval_acc': 0.6740196078431373, 'mrpc_test_bias_eval_f1': 0.7523277467411544, 'mrpc_test_bias_eval_acc_and_f1': 0.7131736772921459, 'mrpc_dev_eval_loss': 2.73701548576355, 'mrpc_dev_eval_acc': 0.6875, 'mrpc_dev_eval_f1': 0.6666666666666666, 'mrpc_dev_eval_acc_and_f1': 0.6770833333333333, 'mrpc_test_eval_loss': 2.3954882621765137, 'mrpc_test_eval_acc': 0.6740196078431373, 'mrpc_test_eval_f1': 0.7523277467411544, 'mrpc_test_eval_acc_and_f1': 0.7131736772921459, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16--100-roberta-large-17571', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_15-05-49_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--100-roberta-large-17571', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias,adapter_eval_loss': 1.4523271322250366, 'rte_dev_prompt,bias,adapter_eval_acc': 0.78125, 'rte_test_prompt,bias,adapter_eval_loss': 2.0650949478149414, 'rte_test_prompt,bias,adapter_eval_acc': 0.7617328519855595, 'rte_dev_eval_loss': 1.4523271322250366, 'rte_dev_eval_acc': 0.78125, 'rte_test_eval_loss': 2.0650949478149414, 'rte_test_eval_acc': 0.7617328519855595, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-100-roberta-large-29724', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_15-03-23_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-100-roberta-large-29724', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias,adapter_eval_loss': 0.5772653222084045, 'sst-2_dev_bias,adapter_eval_acc': 0.9375, 'sst-2_test_bias,adapter_eval_loss': 0.6604824662208557, 'sst-2_test_bias,adapter_eval_acc': 0.9231651376146789, 'sst-2_dev_eval_loss': 0.5772653222084045, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.6604824662208557, 'sst-2_test_eval_acc': 0.9231651376146789, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--42-roberta-large-24409', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_15-02-59_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--42-roberta-large-24409', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias_eval_loss': 2.204887628555298, 'cola_dev_bias_eval_mcc': 0.592156525463792, 'cola_test_bias_eval_loss': 2.39447021484375, 'cola_test_bias_eval_mcc': 0.22119770027667435, 'cola_dev_eval_loss': 2.204887628555298, 'cola_dev_eval_mcc': 0.592156525463792, 'cola_test_eval_loss': 2.39447021484375, 'cola_test_eval_mcc': 0.22119770027667435, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--100-roberta-large-23812', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_15-12-44_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-23812', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias_eval_loss': 1.6541531085968018, 'qnli_dev_bias_eval_acc': 0.71875, 'qnli_test_bias_eval_loss': 2.6342740058898926, 'qnli_test_bias_eval_acc': 0.6108365367014461, 'qnli_dev_eval_loss': 1.6541531085968018, 'qnli_dev_eval_acc': 0.71875, 'qnli_test_eval_loss': 2.6342740058898926, 'qnli_test_eval_acc': 0.6108365367014461, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16--100-roberta-large-31501', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_15-14-33_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--100-roberta-large-31501', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias_eval_loss': 2.134559154510498, 'sts-b_dev_bias_eval_pearson': 0.435936705561057, 'sts-b_dev_bias_eval_spearmanr': 0.3693235720083557, 'sts-b_dev_bias_eval_corr': 0.4026301387847063, 'sts-b_test_bias_eval_loss': 2.2689309120178223, 'sts-b_test_bias_eval_pearson': 0.003907841792078051, 'sts-b_test_bias_eval_spearmanr': 0.01624975695350705, 'sts-b_test_bias_eval_corr': 0.010078799372792551, 'sts-b_dev_eval_loss': 2.134559154510498, 'sts-b_dev_eval_pearson': 0.435936705561057, 'sts-b_dev_eval_spearmanr': 0.3693235720083557, 'sts-b_dev_eval_corr': 0.4026301387847063, 'sts-b_test_eval_loss': 2.2689309120178223, 'sts-b_test_eval_pearson': 0.003907841792078051, 'sts-b_test_eval_spearmanr': 0.01624975695350705, 'sts-b_test_eval_corr': 0.010078799372792551, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16--100-roberta-large-27947', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_15-10-03_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--100-roberta-large-27947', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias_eval_loss': 2.076054096221924, 'mrpc_dev_bias_eval_acc': 0.625, 'mrpc_dev_bias_eval_f1': 0.625, 'mrpc_dev_bias_eval_acc_and_f1': 0.625, 'mrpc_test_bias_eval_loss': 1.8003133535385132, 'mrpc_test_bias_eval_acc': 0.6127450980392157, 'mrpc_test_bias_eval_f1': 0.7063197026022305, 'mrpc_test_bias_eval_acc_and_f1': 0.6595324003207231, 'mrpc_dev_eval_loss': 2.076054096221924, 'mrpc_dev_eval_acc': 0.625, 'mrpc_dev_eval_f1': 0.625, 'mrpc_dev_eval_acc_and_f1': 0.625, 'mrpc_test_eval_loss': 1.8003133535385132, 'mrpc_test_eval_acc': 0.6127450980392157, 'mrpc_test_eval_f1': 0.7063197026022305, 'mrpc_test_eval_acc_and_f1': 0.6595324003207231, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16--100-roberta-large-18406', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_15-19-45_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--100-roberta-large-18406', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias_eval_loss': 2.079206943511963, 'cola_dev_bias_eval_mcc': 0.5163977794943222, 'cola_test_bias_eval_loss': 2.255718946456909, 'cola_test_bias_eval_mcc': 0.2170111141051537, 'cola_dev_eval_loss': 2.079206943511963, 'cola_dev_eval_mcc': 0.5163977794943222, 'cola_test_eval_loss': 2.255718946456909, 'cola_test_eval_mcc': 0.2170111141051537, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16--100-roberta-large-30986', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_15-26-47_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-30986', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_adapter_eval_loss': 1.5810996294021606, 'mnli_dev_adapter_eval_mnli/acc': 0.6666666666666666, 'mnli_test_adapter_eval_loss': 1.601684808731079, 'mnli_test_adapter_eval_mnli/acc': 0.6732552215995925, 'mnli-mm_test_adapter_eval_loss': 1.5877346992492676, 'mnli-mm_test_adapter_eval_mnli-mm/acc': 0.6789056143205858, 'mnli_dev_eval_loss': 1.5810996294021606, 'mnli_dev_eval_mnli/acc': 0.6666666666666666, 'mnli_test_eval_loss': 1.601684808731079, 'mnli_test_eval_mnli/acc': 0.6732552215995925, 'mnli-mm_test_eval_loss': 1.5877346992492676, 'mnli-mm_test_eval_mnli-mm/acc': 0.6789056143205858, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--100-roberta-large-18183', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_14-57-52_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--100-roberta-large-18183', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias,adapter_eval_loss': 1.638965129852295, 'rte_dev_prompt,bias,adapter_eval_acc': 0.78125, 'rte_test_prompt,bias,adapter_eval_loss': 2.548337697982788, 'rte_test_prompt,bias,adapter_eval_acc': 0.7075812274368231, 'rte_dev_eval_loss': 1.638965129852295, 'rte_dev_eval_acc': 0.78125, 'rte_test_eval_loss': 2.548337697982788, 'rte_test_eval_acc': 0.7075812274368231, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-100-roberta-large-30736', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_15-22-55_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-100-roberta-large-30736', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,adapter_eval_loss': 3.2138373851776123, 'qqp_dev_prompt,adapter_eval_acc': 0.59375, 'qqp_dev_prompt,adapter_eval_f1': 0.6060606060606061, 'qqp_dev_prompt,adapter_eval_acc_and_f1': 0.599905303030303, 'qqp_test_prompt,adapter_eval_loss': 2.548157215118408, 'qqp_test_prompt,adapter_eval_acc': 0.5852832055404402, 'qqp_test_prompt,adapter_eval_f1': 0.5007889957424003, 'qqp_test_prompt,adapter_eval_acc_and_f1': 0.5430361006414203, 'qqp_dev_eval_loss': 3.2138373851776123, 'qqp_dev_eval_acc': 0.59375, 'qqp_dev_eval_f1': 0.6060606060606061, 'qqp_dev_eval_acc_and_f1': 0.599905303030303, 'qqp_test_eval_loss': 2.548157215118408, 'qqp_test_eval_acc': 0.5852832055404402, 'qqp_test_eval_f1': 0.5007889957424003, 'qqp_test_eval_acc_and_f1': 0.5430361006414203, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16-prompt-13-roberta-large-25765', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_15-02-54_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-13-roberta-large-25765', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias_eval_loss': 1.4521937370300293, 'qnli_dev_bias_eval_acc': 0.65625, 'qnli_test_bias_eval_loss': 1.6836309432983398, 'qnli_test_bias_eval_acc': 0.5841112941607176, 'qnli_dev_eval_loss': 1.4521937370300293, 'qnli_dev_eval_acc': 0.65625, 'qnli_test_eval_loss': 1.6836309432983398, 'qnli_test_eval_acc': 0.5841112941607176, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16--100-roberta-large-8676', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_15-30-19_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--100-roberta-large-8676', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_adapter_eval_loss': 0.7216836810112, 'mrpc_dev_adapter_eval_acc': 0.5, 'mrpc_dev_adapter_eval_f1': 0.6666666666666666, 'mrpc_dev_adapter_eval_acc_and_f1': 0.5833333333333333, 'mrpc_test_adapter_eval_loss': 0.633434534072876, 'mrpc_test_adapter_eval_acc': 0.6838235294117647, 'mrpc_test_adapter_eval_f1': 0.8122270742358079, 'mrpc_test_adapter_eval_acc_and_f1': 0.7480253018237863, 'mrpc_dev_eval_loss': 0.7216836810112, 'mrpc_dev_eval_acc': 0.5, 'mrpc_dev_eval_f1': 0.6666666666666666, 'mrpc_dev_eval_acc_and_f1': 0.5833333333333333, 'mrpc_test_eval_loss': 0.633434534072876, 'mrpc_test_eval_acc': 0.6838235294117647, 'mrpc_test_eval_f1': 0.8122270742358079, 'mrpc_test_eval_acc_and_f1': 0.7480253018237863, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--42-roberta-large-24483', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_15-33-37_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--42-roberta-large-24483', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias,adapter_eval_loss': 0.722244381904602, 'sst-2_dev_bias,adapter_eval_acc': 0.5, 'sst-2_test_bias,adapter_eval_loss': 0.7178113460540771, 'sst-2_test_bias,adapter_eval_acc': 0.5091743119266054, 'sst-2_dev_eval_loss': 0.722244381904602, 'sst-2_dev_eval_acc': 0.5, 'sst-2_test_eval_loss': 0.7178113460540771, 'sst-2_test_eval_acc': 0.5091743119266054, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--100-roberta-large-7079', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_15-26-09_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--100-roberta-large-7079', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias_eval_loss': 2.111783027648926, 'sts-b_dev_bias_eval_pearson': 0.7695808801018392, 'sts-b_dev_bias_eval_spearmanr': 0.7483952263456172, 'sts-b_dev_bias_eval_corr': 0.7589880532237282, 'sts-b_test_bias_eval_loss': 2.206455707550049, 'sts-b_test_bias_eval_pearson': 0.6627650564004495, 'sts-b_test_bias_eval_spearmanr': 0.6786945066610426, 'sts-b_test_bias_eval_corr': 0.670729781530746, 'sts-b_dev_eval_loss': 2.111783027648926, 'sts-b_dev_eval_pearson': 0.7695808801018392, 'sts-b_dev_eval_spearmanr': 0.7483952263456172, 'sts-b_dev_eval_corr': 0.7589880532237282, 'sts-b_test_eval_loss': 2.206455707550049, 'sts-b_test_eval_pearson': 0.6627650564004495, 'sts-b_test_eval_spearmanr': 0.6786945066610426, 'sts-b_test_eval_corr': 0.670729781530746, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16--100-roberta-large-2720', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_15-31-30_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--100-roberta-large-2720', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_adapter_eval_loss': 4.5582146644592285, 'cola_dev_adapter_eval_mcc': 0.44539933408304444, 'cola_test_adapter_eval_loss': 3.54695463180542, 'cola_test_adapter_eval_mcc': 0.23802762601120525, 'cola_dev_eval_loss': 4.5582146644592285, 'cola_dev_eval_mcc': 0.44539933408304444, 'cola_test_eval_loss': 3.54695463180542, 'cola_test_eval_mcc': 0.23802762601120525, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--42-roberta-large-16507', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_15-40-48_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-16507', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias,adapter_eval_loss': 1.1870768070220947, 'rte_dev_prompt,bias,adapter_eval_acc': 0.65625, 'rte_test_prompt,bias,adapter_eval_loss': 1.2451210021972656, 'rte_test_prompt,bias,adapter_eval_acc': 0.6642599277978339, 'rte_dev_eval_loss': 1.1870768070220947, 'rte_dev_eval_acc': 0.65625, 'rte_test_eval_loss': 1.2451210021972656, 'rte_test_eval_acc': 0.6642599277978339, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-100-roberta-large-27677', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_15-42-13_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-100-roberta-large-27677', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_adapter_eval_loss': 0.6237376928329468, 'qnli_dev_adapter_eval_acc': 0.53125, 'qnli_test_adapter_eval_loss': 0.7427153587341309, 'qnli_test_adapter_eval_acc': 0.4834340106168772, 'qnli_dev_eval_loss': 0.6237376928329468, 'qnli_dev_eval_acc': 0.53125, 'qnli_test_eval_loss': 0.7427153587341309, 'qnli_test_eval_acc': 0.4834340106168772, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--42-roberta-large-3702', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_15-46-05_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--42-roberta-large-3702', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_adapter_eval_loss': 1.0908533334732056, 'mrpc_dev_adapter_eval_acc': 0.84375, 'mrpc_dev_adapter_eval_f1': 0.8484848484848485, 'mrpc_dev_adapter_eval_acc_and_f1': 0.8461174242424243, 'mrpc_test_adapter_eval_loss': 2.893657684326172, 'mrpc_test_adapter_eval_acc': 0.6936274509803921, 'mrpc_test_adapter_eval_f1': 0.7637051039697542, 'mrpc_test_adapter_eval_acc_and_f1': 0.7286662774750732, 'mrpc_dev_eval_loss': 1.0908533334732056, 'mrpc_dev_eval_acc': 0.84375, 'mrpc_dev_eval_f1': 0.8484848484848485, 'mrpc_dev_eval_acc_and_f1': 0.8461174242424243, 'mrpc_test_eval_loss': 2.893657684326172, 'mrpc_test_eval_acc': 0.6936274509803921, 'mrpc_test_eval_f1': 0.7637051039697542, 'mrpc_test_eval_acc_and_f1': 0.7286662774750732, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--42-roberta-large-15146', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_15-49-23_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--42-roberta-large-15146', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_adapter_eval_loss': 3.927482843399048, 'cola_dev_adapter_eval_mcc': 0.31814238148788887, 'cola_test_adapter_eval_loss': 4.850147724151611, 'cola_test_adapter_eval_mcc': 0.1343726413653728, 'cola_dev_eval_loss': 3.927482843399048, 'cola_dev_eval_mcc': 0.31814238148788887, 'cola_test_eval_loss': 4.850147724151611, 'cola_test_eval_mcc': 0.1343726413653728, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--42-roberta-large-30039', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_15-56-46_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-30039', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt_eval_loss': 0.6139754056930542, 'rte_dev_prompt_eval_acc': 0.65625, 'rte_test_prompt_eval_loss': 0.8637508153915405, 'rte_test_prompt_eval_acc': 0.5090252707581228, 'rte_dev_eval_loss': 0.6139754056930542, 'rte_dev_eval_acc': 0.65625, 'rte_test_eval_loss': 0.8637508153915405, 'rte_test_eval_acc': 0.5090252707581228, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-42-roberta-large-15049', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_16-02-02_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-42-roberta-large-15049', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias,adapter_eval_loss': 0.00737561471760273, 'sst-2_dev_bias,adapter_eval_acc': 1.0, 'sst-2_test_bias,adapter_eval_loss': 0.8482334017753601, 'sst-2_test_bias,adapter_eval_acc': 0.9139908256880734, 'sst-2_dev_eval_loss': 0.00737561471760273, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.8482334017753601, 'sst-2_test_eval_acc': 0.9139908256880734, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--100-roberta-large-31285', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_15-51-20_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--100-roberta-large-31285', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,bias_eval_loss': 3.983706474304199, 'qqp_dev_prompt,bias_eval_acc': 0.65625, 'qqp_dev_prompt,bias_eval_f1': 0.6666666666666667, 'qqp_dev_prompt,bias_eval_acc_and_f1': 0.6614583333333334, 'qqp_test_prompt,bias_eval_loss': 4.298111438751221, 'qqp_test_prompt,bias_eval_acc': 0.6215186742517932, 'qqp_test_prompt,bias_eval_f1': 0.6162219101123596, 'qqp_test_prompt,bias_eval_acc_and_f1': 0.6188702921820763, 'qqp_dev_eval_loss': 3.983706474304199, 'qqp_dev_eval_acc': 0.65625, 'qqp_dev_eval_f1': 0.6666666666666667, 'qqp_dev_eval_acc_and_f1': 0.6614583333333334, 'qqp_test_eval_loss': 4.298111438751221, 'qqp_test_eval_acc': 0.6215186742517932, 'qqp_test_eval_f1': 0.6162219101123596, 'qqp_test_eval_acc_and_f1': 0.6188702921820763, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-13-roberta-large-10232', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_15-42-30_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-13-roberta-large-10232', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias_eval_loss': 2.0956249237060547, 'sts-b_dev_bias_eval_pearson': 0.7306345274103239, 'sts-b_dev_bias_eval_spearmanr': 0.6908263627805697, 'sts-b_dev_bias_eval_corr': 0.7107304450954468, 'sts-b_test_bias_eval_loss': 2.1970889568328857, 'sts-b_test_bias_eval_pearson': 0.636986856713495, 'sts-b_test_bias_eval_spearmanr': 0.6501623489942545, 'sts-b_test_bias_eval_corr': 0.6435746028538747, 'sts-b_dev_eval_loss': 2.0956249237060547, 'sts-b_dev_eval_pearson': 0.7306345274103239, 'sts-b_dev_eval_spearmanr': 0.6908263627805697, 'sts-b_dev_eval_corr': 0.7107304450954468, 'sts-b_test_eval_loss': 2.1970889568328857, 'sts-b_test_eval_pearson': 0.636986856713495, 'sts-b_test_eval_spearmanr': 0.6501623489942545, 'sts-b_test_eval_corr': 0.6435746028538747, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16--100-roberta-large-11228', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_15-54-25_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--100-roberta-large-11228', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_adapter_eval_loss': 3.1518468856811523, 'qnli_dev_adapter_eval_acc': 0.6875, 'qnli_test_adapter_eval_loss': 4.101814270019531, 'qnli_test_adapter_eval_acc': 0.5528098114589054, 'qnli_dev_eval_loss': 3.1518468856811523, 'qnli_dev_eval_acc': 0.6875, 'qnli_test_eval_loss': 4.101814270019531, 'qnli_test_eval_acc': 0.5528098114589054, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--42-roberta-large-17511', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_16-02-35_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--42-roberta-large-17511', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_adapter_eval_loss': 1.1912431716918945, 'mrpc_dev_adapter_eval_acc': 0.8125, 'mrpc_dev_adapter_eval_f1': 0.823529411764706, 'mrpc_dev_adapter_eval_acc_and_f1': 0.818014705882353, 'mrpc_test_adapter_eval_loss': 2.995619297027588, 'mrpc_test_adapter_eval_acc': 0.6642156862745098, 'mrpc_test_adapter_eval_f1': 0.7458256029684601, 'mrpc_test_adapter_eval_acc_and_f1': 0.705020644621485, 'mrpc_dev_eval_loss': 1.1912431716918945, 'mrpc_dev_eval_acc': 0.8125, 'mrpc_dev_eval_f1': 0.823529411764706, 'mrpc_dev_eval_acc_and_f1': 0.818014705882353, 'mrpc_test_eval_loss': 2.995619297027588, 'mrpc_test_eval_acc': 0.6642156862745098, 'mrpc_test_eval_f1': 0.7458256029684601, 'mrpc_test_eval_acc_and_f1': 0.705020644621485, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--42-roberta-large-6706', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_16-05-01_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--42-roberta-large-6706', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt_eval_loss': 1.3698828220367432, 'rte_dev_prompt_eval_acc': 0.5, 'rte_test_prompt_eval_loss': 1.2760463953018188, 'rte_test_prompt_eval_acc': 0.4693140794223827, 'rte_dev_eval_loss': 1.3698828220367432, 'rte_dev_eval_acc': 0.5, 'rte_test_eval_loss': 1.2760463953018188, 'rte_test_eval_acc': 0.4693140794223827, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-42-roberta-large-19423', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_16-13-54_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-42-roberta-large-19423', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_adapter_eval_loss': 3.4399521350860596, 'cola_dev_adapter_eval_mcc': 0.31311214554257477, 'cola_test_adapter_eval_loss': 4.351705551147461, 'cola_test_adapter_eval_mcc': 0.09422678483718287, 'cola_dev_eval_loss': 3.4399521350860596, 'cola_dev_eval_mcc': 0.31311214554257477, 'cola_test_eval_loss': 4.351705551147461, 'cola_test_eval_mcc': 0.09422678483718287, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--42-roberta-large-13815', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_16-12-36_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-13815', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_adapter_eval_loss': 1.9047669172286987, 'mnli_dev_adapter_eval_mnli/acc': 0.6875, 'mnli_test_adapter_eval_loss': 1.8382346630096436, 'mnli_test_adapter_eval_mnli/acc': 0.6780438104941416, 'mnli-mm_test_adapter_eval_loss': 1.8176982402801514, 'mnli-mm_test_adapter_eval_mnli-mm/acc': 0.6858218063466233, 'mnli_dev_eval_loss': 1.9047669172286987, 'mnli_dev_eval_mnli/acc': 0.6875, 'mnli_test_eval_loss': 1.8382346630096436, 'mnli_test_eval_mnli/acc': 0.6780438104941416, 'mnli-mm_test_eval_loss': 1.8176982402801514, 'mnli-mm_test_eval_mnli-mm/acc': 0.6858218063466233, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--100-roberta-large-12399', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_15-41-43_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--100-roberta-large-12399', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_adapter_eval_loss': 2.651355266571045, 'qnli_dev_adapter_eval_acc': 0.6875, 'qnli_test_adapter_eval_loss': 3.1193740367889404, 'qnli_test_adapter_eval_acc': 0.5712978217096834, 'qnli_dev_eval_loss': 2.651355266571045, 'qnli_dev_eval_acc': 0.6875, 'qnli_test_eval_loss': 3.1193740367889404, 'qnli_test_eval_acc': 0.5712978217096834, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--42-roberta-large-15388', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_16-19-25_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--42-roberta-large-15388', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_adapter_eval_loss': 1.0201776027679443, 'mrpc_dev_adapter_eval_acc': 0.75, 'mrpc_dev_adapter_eval_f1': 0.75, 'mrpc_dev_adapter_eval_acc_and_f1': 0.75, 'mrpc_test_adapter_eval_loss': 2.3500144481658936, 'mrpc_test_adapter_eval_acc': 0.6029411764705882, 'mrpc_test_adapter_eval_f1': 0.6707317073170732, 'mrpc_test_adapter_eval_acc_and_f1': 0.6368364418938307, 'mrpc_dev_eval_loss': 1.0201776027679443, 'mrpc_dev_eval_acc': 0.75, 'mrpc_dev_eval_f1': 0.75, 'mrpc_dev_eval_acc_and_f1': 0.75, 'mrpc_test_eval_loss': 2.3500144481658936, 'mrpc_test_eval_acc': 0.6029411764705882, 'mrpc_test_eval_f1': 0.6707317073170732, 'mrpc_test_eval_acc_and_f1': 0.6368364418938307, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--42-roberta-large-11297', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_16-20-52_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--42-roberta-large-11297', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt_eval_loss': 5.20909309387207, 'rte_dev_prompt_eval_acc': 0.5625, 'rte_test_prompt_eval_loss': 5.134777069091797, 'rte_test_prompt_eval_acc': 0.49458483754512633, 'rte_dev_eval_loss': 5.20909309387207, 'rte_dev_eval_acc': 0.5625, 'rte_test_eval_loss': 5.134777069091797, 'rte_test_eval_acc': 0.49458483754512633, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-42-roberta-large-8014', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_16-25-55_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-42-roberta-large-8014', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias,adapter_eval_loss': 0.0159315075725317, 'sst-2_dev_bias,adapter_eval_acc': 1.0, 'sst-2_test_bias,adapter_eval_loss': 0.5469250679016113, 'sst-2_test_bias,adapter_eval_acc': 0.9231651376146789, 'sst-2_dev_eval_loss': 0.0159315075725317, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.5469250679016113, 'sst-2_test_eval_acc': 0.9231651376146789, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--100-roberta-large-31155', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_16-15-38_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--100-roberta-large-31155', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias_eval_loss': 2.1149239540100098, 'sts-b_dev_bias_eval_pearson': 0.6085598823453164, 'sts-b_dev_bias_eval_spearmanr': 0.5745850791604099, 'sts-b_dev_bias_eval_corr': 0.5915724807528632, 'sts-b_test_bias_eval_loss': 2.219235420227051, 'sts-b_test_bias_eval_pearson': 0.5612182459323056, 'sts-b_test_bias_eval_spearmanr': 0.5653212723093491, 'sts-b_test_bias_eval_corr': 0.5632697591208273, 'sts-b_dev_eval_loss': 2.1149239540100098, 'sts-b_dev_eval_pearson': 0.6085598823453164, 'sts-b_dev_eval_spearmanr': 0.5745850791604099, 'sts-b_dev_eval_corr': 0.5915724807528632, 'sts-b_test_eval_loss': 2.219235420227051, 'sts-b_test_eval_pearson': 0.5612182459323056, 'sts-b_test_eval_spearmanr': 0.5653212723093491, 'sts-b_test_eval_corr': 0.5632697591208273, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16--100-roberta-large-24104', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_16-19-00_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--100-roberta-large-24104', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_adapter_eval_loss': 2.9561450481414795, 'cola_dev_adapter_eval_mcc': 0.31311214554257477, 'cola_test_adapter_eval_loss': 3.2246246337890625, 'cola_test_adapter_eval_mcc': 0.04983034811376369, 'cola_dev_eval_loss': 2.9561450481414795, 'cola_dev_eval_mcc': 0.31311214554257477, 'cola_test_eval_loss': 3.2246246337890625, 'cola_test_eval_mcc': 0.04983034811376369, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--42-roberta-large-5491', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_16-28-34_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-5491', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt_eval_loss': 1.4127048254013062, 'rte_dev_prompt_eval_acc': 0.5, 'rte_test_prompt_eval_loss': 1.151490330696106, 'rte_test_prompt_eval_acc': 0.47653429602888087, 'rte_dev_eval_loss': 1.4127048254013062, 'rte_dev_eval_acc': 0.5, 'rte_test_eval_loss': 1.151490330696106, 'rte_test_eval_acc': 0.47653429602888087, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-42-roberta-large-5678', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_16-37-50_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-42-roberta-large-5678', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_adapter_eval_loss': 0.6965985298156738, 'mrpc_dev_adapter_eval_acc': 0.5, 'mrpc_dev_adapter_eval_f1': 0.6666666666666666, 'mrpc_dev_adapter_eval_acc_and_f1': 0.5833333333333333, 'mrpc_test_adapter_eval_loss': 0.6660134792327881, 'mrpc_test_adapter_eval_acc': 0.6838235294117647, 'mrpc_test_adapter_eval_f1': 0.8122270742358079, 'mrpc_test_adapter_eval_acc_and_f1': 0.7480253018237863, 'mrpc_dev_eval_loss': 0.6965985298156738, 'mrpc_dev_eval_acc': 0.5, 'mrpc_dev_eval_f1': 0.6666666666666666, 'mrpc_dev_eval_acc_and_f1': 0.5833333333333333, 'mrpc_test_eval_loss': 0.6660134792327881, 'mrpc_test_eval_acc': 0.6838235294117647, 'mrpc_test_eval_f1': 0.8122270742358079, 'mrpc_test_eval_acc_and_f1': 0.7480253018237863, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--100-roberta-large-12774', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_16-36-53_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--100-roberta-large-12774', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_adapter_eval_loss': 2.33229398727417, 'qnli_dev_adapter_eval_acc': 0.625, 'qnli_test_adapter_eval_loss': 2.3667213916778564, 'qnli_test_adapter_eval_acc': 0.5879553358960278, 'qnli_dev_eval_loss': 2.33229398727417, 'qnli_dev_eval_acc': 0.625, 'qnli_test_eval_loss': 2.3667213916778564, 'qnli_test_eval_acc': 0.5879553358960278, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--42-roberta-large-19360', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_16-36-40_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--42-roberta-large-19360', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,bias_eval_loss': 2.6765499114990234, 'qqp_dev_prompt,bias_eval_acc': 0.625, 'qqp_dev_prompt,bias_eval_f1': 0.625, 'qqp_dev_prompt,bias_eval_acc_and_f1': 0.625, 'qqp_test_prompt,bias_eval_loss': 2.4018666744232178, 'qqp_test_prompt,bias_eval_acc': 0.5963146178580262, 'qqp_test_prompt,bias_eval_f1': 0.5302633472442079, 'qqp_test_prompt,bias_eval_acc_and_f1': 0.563288982551117, 'qqp_dev_eval_loss': 2.6765499114990234, 'qqp_dev_eval_acc': 0.625, 'qqp_dev_eval_f1': 0.625, 'qqp_dev_eval_acc_and_f1': 0.625, 'qqp_test_eval_loss': 2.4018666744232178, 'qqp_test_eval_acc': 0.5963146178580262, 'qqp_test_eval_f1': 0.5302633472442079, 'qqp_test_eval_acc_and_f1': 0.563288982551117, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-13-roberta-large-17959', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_16-18-13_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-13-roberta-large-17959', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_adapter_eval_loss': 0.7433037757873535, 'cola_dev_adapter_eval_mcc': 0.0, 'cola_test_adapter_eval_loss': 0.8654740452766418, 'cola_test_adapter_eval_mcc': 0.0, 'cola_dev_eval_loss': 0.7433037757873535, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.8654740452766418, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--100-roberta-large-1365', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_16-44-43_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-1365', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt_eval_loss': 0.7328040599822998, 'rte_dev_prompt_eval_acc': 0.59375, 'rte_test_prompt_eval_loss': 0.8175497055053711, 'rte_test_prompt_eval_acc': 0.49097472924187724, 'rte_dev_eval_loss': 0.7328040599822998, 'rte_dev_eval_acc': 0.59375, 'rte_test_eval_loss': 0.8175497055053711, 'rte_test_eval_acc': 0.49097472924187724, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-100-roberta-large-30813', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_16-49-46_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-100-roberta-large-30813', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias,adapter_eval_loss': 0.006026735529303551, 'sst-2_dev_bias,adapter_eval_acc': 1.0, 'sst-2_test_bias,adapter_eval_loss': 0.44788119196891785, 'sst-2_test_bias,adapter_eval_acc': 0.9220183486238532, 'sst-2_dev_eval_loss': 0.006026735529303551, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.44788119196891785, 'sst-2_test_eval_acc': 0.9220183486238532, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--100-roberta-large-20780', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_16-39-22_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--100-roberta-large-20780', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_adapter_eval_loss': 2.1541402339935303, 'sts-b_dev_adapter_eval_pearson': 0.3349532842602569, 'sts-b_dev_adapter_eval_spearmanr': 0.3050152096603851, 'sts-b_dev_adapter_eval_corr': 0.319984246960321, 'sts-b_test_adapter_eval_loss': 2.211038827896118, 'sts-b_test_adapter_eval_pearson': -0.001708185328135639, 'sts-b_test_adapter_eval_spearmanr': 0.0033794387365727514, 'sts-b_test_adapter_eval_corr': 0.0008356267042185562, 'sts-b_dev_eval_loss': 2.1541402339935303, 'sts-b_dev_eval_pearson': 0.3349532842602569, 'sts-b_dev_eval_spearmanr': 0.3050152096603851, 'sts-b_dev_eval_corr': 0.319984246960321, 'sts-b_test_eval_loss': 2.211038827896118, 'sts-b_test_eval_pearson': -0.001708185328135639, 'sts-b_test_eval_spearmanr': 0.0033794387365727514, 'sts-b_test_eval_corr': 0.0008356267042185562, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--42-roberta-large-9873', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_16-42-44_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--42-roberta-large-9873', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_adapter_eval_loss': 3.0832533836364746, 'mrpc_dev_adapter_eval_acc': 0.6875, 'mrpc_dev_adapter_eval_f1': 0.7058823529411765, 'mrpc_dev_adapter_eval_acc_and_f1': 0.6966911764705883, 'mrpc_test_adapter_eval_loss': 2.601802349090576, 'mrpc_test_adapter_eval_acc': 0.7132352941176471, 'mrpc_test_adapter_eval_f1': 0.7929203539823008, 'mrpc_test_adapter_eval_acc_and_f1': 0.7530778240499739, 'mrpc_dev_eval_loss': 3.0832533836364746, 'mrpc_dev_eval_acc': 0.6875, 'mrpc_dev_eval_f1': 0.7058823529411765, 'mrpc_dev_eval_acc_and_f1': 0.6966911764705883, 'mrpc_test_eval_loss': 2.601802349090576, 'mrpc_test_eval_acc': 0.7132352941176471, 'mrpc_test_eval_f1': 0.7929203539823008, 'mrpc_test_eval_acc_and_f1': 0.7530778240499739, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--100-roberta-large-28217', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_16-52-52_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--100-roberta-large-28217', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_adapter_eval_loss': 0.6931543350219727, 'qnli_dev_adapter_eval_acc': 0.5, 'qnli_test_adapter_eval_loss': 0.6931127905845642, 'qnli_test_adapter_eval_acc': 0.5053999633900788, 'qnli_dev_eval_loss': 0.6931543350219727, 'qnli_dev_eval_acc': 0.5, 'qnli_test_eval_loss': 0.6931127905845642, 'qnli_test_eval_acc': 0.5053999633900788, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--100-roberta-large-10860', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_16-53-24_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--100-roberta-large-10860', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt_eval_loss': 0.799582839012146, 'rte_dev_prompt_eval_acc': 0.59375, 'rte_test_prompt_eval_loss': 1.1575640439987183, 'rte_test_prompt_eval_acc': 0.48375451263537905, 'rte_dev_eval_loss': 0.799582839012146, 'rte_dev_eval_acc': 0.59375, 'rte_test_eval_loss': 1.1575640439987183, 'rte_test_eval_acc': 0.48375451263537905, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-100-roberta-large-5757', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_17-01-56_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-100-roberta-large-5757', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_adapter_eval_loss': 2.387895107269287, 'cola_dev_adapter_eval_mcc': 0.6888467201936644, 'cola_test_adapter_eval_loss': 4.509277820587158, 'cola_test_adapter_eval_mcc': 0.3315759885304104, 'cola_dev_eval_loss': 2.387895107269287, 'cola_dev_eval_mcc': 0.6888467201936644, 'cola_test_eval_loss': 4.509277820587158, 'cola_test_eval_mcc': 0.3315759885304104, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--100-roberta-large-927', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_17-00-50_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-927', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,adapter_eval_loss': 5.036375045776367, 'mnli_dev_prompt,adapter_eval_mnli/acc': 0.5833333333333334, 'mnli_test_prompt,adapter_eval_loss': 4.285806179046631, 'mnli_test_prompt,adapter_eval_mnli/acc': 0.6136525725929699, 'mnli-mm_test_prompt,adapter_eval_loss': 3.9311482906341553, 'mnli-mm_test_prompt,adapter_eval_mnli-mm/acc': 0.6440195280716029, 'mnli_dev_eval_loss': 5.036375045776367, 'mnli_dev_eval_mnli/acc': 0.5833333333333334, 'mnli_test_eval_loss': 4.285806179046631, 'mnli_test_eval_mnli/acc': 0.6136525725929699, 'mnli-mm_test_eval_loss': 3.9311482906341553, 'mnli-mm_test_eval_mnli-mm/acc': 0.6440195280716029, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-12216', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_16-30-17_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-12216', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_adapter_eval_loss': 3.093888521194458, 'mrpc_dev_adapter_eval_acc': 0.75, 'mrpc_dev_adapter_eval_f1': 0.7777777777777777, 'mrpc_dev_adapter_eval_acc_and_f1': 0.7638888888888888, 'mrpc_test_adapter_eval_loss': 3.019367218017578, 'mrpc_test_adapter_eval_acc': 0.7230392156862745, 'mrpc_test_adapter_eval_f1': 0.8081494057724957, 'mrpc_test_adapter_eval_acc_and_f1': 0.7655943107293851, 'mrpc_dev_eval_loss': 3.093888521194458, 'mrpc_dev_eval_acc': 0.75, 'mrpc_dev_eval_f1': 0.7777777777777777, 'mrpc_dev_eval_acc_and_f1': 0.7638888888888888, 'mrpc_test_eval_loss': 3.019367218017578, 'mrpc_test_eval_acc': 0.7230392156862745, 'mrpc_test_eval_f1': 0.8081494057724957, 'mrpc_test_eval_acc_and_f1': 0.7655943107293851, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--100-roberta-large-11809', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_17-08-39_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--100-roberta-large-11809', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt_eval_loss': 1.6108534336090088, 'rte_dev_prompt_eval_acc': 0.625, 'rte_test_prompt_eval_loss': 2.0633695125579834, 'rte_test_prompt_eval_acc': 0.47653429602888087, 'rte_dev_eval_loss': 1.6108534336090088, 'rte_dev_eval_acc': 0.625, 'rte_test_eval_loss': 2.0633695125579834, 'rte_test_eval_acc': 0.47653429602888087, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-100-roberta-large-846', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_17-13-47_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-100-roberta-large-846', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_adapter_eval_loss': 1.8131039142608643, 'qnli_dev_adapter_eval_acc': 0.65625, 'qnli_test_adapter_eval_loss': 2.2921154499053955, 'qnli_test_adapter_eval_acc': 0.5482335712978217, 'qnli_dev_eval_loss': 1.8131039142608643, 'qnli_dev_eval_acc': 0.65625, 'qnli_test_eval_loss': 2.2921154499053955, 'qnli_test_eval_acc': 0.5482335712978217, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--100-roberta-large-25301', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_17-09-52_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--100-roberta-large-25301', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,bias_eval_loss': 2.366579532623291, 'qqp_dev_prompt,bias_eval_acc': 0.59375, 'qqp_dev_prompt,bias_eval_f1': 0.6285714285714286, 'qqp_dev_prompt,bias_eval_acc_and_f1': 0.6111607142857143, 'qqp_test_prompt,bias_eval_loss': 2.064889669418335, 'qqp_test_prompt,bias_eval_acc': 0.5886223101657185, 'qqp_test_prompt,bias_eval_f1': 0.5161459242450689, 'qqp_test_prompt,bias_eval_acc_and_f1': 0.5523841172053937, 'qqp_dev_eval_loss': 2.366579532623291, 'qqp_dev_eval_acc': 0.59375, 'qqp_dev_eval_f1': 0.6285714285714286, 'qqp_dev_eval_acc_and_f1': 0.6111607142857143, 'qqp_test_eval_loss': 2.064889669418335, 'qqp_test_eval_acc': 0.5886223101657185, 'qqp_test_eval_f1': 0.5161459242450689, 'qqp_test_eval_acc_and_f1': 0.5523841172053937, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-13-roberta-large-22722', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_16-54-48_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-13-roberta-large-22722', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias,adapter_eval_loss': 1.9690871238708496, 'sst-2_dev_prompt,bias,adapter_eval_acc': 0.84375, 'sst-2_test_prompt,bias,adapter_eval_loss': 2.198472499847412, 'sst-2_test_prompt,bias,adapter_eval_acc': 0.875, 'sst-2_dev_eval_loss': 1.9690871238708496, 'sst-2_dev_eval_acc': 0.84375, 'sst-2_test_eval_loss': 2.198472499847412, 'sst-2_test_eval_acc': 0.875, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-27107', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_17-03-41_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-27107', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_adapter_eval_loss': 2.118455648422241, 'sts-b_dev_adapter_eval_pearson': 0.8322701640950725, 'sts-b_dev_adapter_eval_spearmanr': 0.8370999634747833, 'sts-b_dev_adapter_eval_corr': 0.8346850637849279, 'sts-b_test_adapter_eval_loss': 2.1883738040924072, 'sts-b_test_adapter_eval_pearson': 0.6734752061840483, 'sts-b_test_adapter_eval_spearmanr': 0.6759226025823987, 'sts-b_test_adapter_eval_corr': 0.6746989043832234, 'sts-b_dev_eval_loss': 2.118455648422241, 'sts-b_dev_eval_pearson': 0.8322701640950725, 'sts-b_dev_eval_spearmanr': 0.8370999634747833, 'sts-b_dev_eval_corr': 0.8346850637849279, 'sts-b_test_eval_loss': 2.1883738040924072, 'sts-b_test_eval_pearson': 0.6734752061840483, 'sts-b_test_eval_spearmanr': 0.6759226025823987, 'sts-b_test_eval_corr': 0.6746989043832234, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--42-roberta-large-15011', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_17-07-55_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--42-roberta-large-15011', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_adapter_eval_loss': 2.3171305656433105, 'cola_dev_adapter_eval_mcc': 0.5773502691896258, 'cola_test_adapter_eval_loss': 2.5087974071502686, 'cola_test_adapter_eval_mcc': 0.3160711113507434, 'cola_dev_eval_loss': 2.3171305656433105, 'cola_dev_eval_mcc': 0.5773502691896258, 'cola_test_eval_loss': 2.5087974071502686, 'cola_test_eval_mcc': 0.3160711113507434, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--100-roberta-large-11745', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_17-16-57_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-11745', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt_eval_loss': 1.5402371883392334, 'rte_dev_prompt_eval_acc': 0.59375, 'rte_test_prompt_eval_loss': 1.4960322380065918, 'rte_test_prompt_eval_acc': 0.48375451263537905, 'rte_dev_eval_loss': 1.5402371883392334, 'rte_dev_eval_acc': 0.59375, 'rte_test_eval_loss': 1.4960322380065918, 'rte_test_eval_acc': 0.48375451263537905, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-100-roberta-large-31118', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_17-25-56_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-100-roberta-large-31118', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_adapter_eval_loss': 1.1506047248840332, 'mrpc_dev_adapter_eval_acc': 0.65625, 'mrpc_dev_adapter_eval_f1': 0.7317073170731707, 'mrpc_dev_adapter_eval_acc_and_f1': 0.6939786585365854, 'mrpc_test_adapter_eval_loss': 1.0553802251815796, 'mrpc_test_adapter_eval_acc': 0.6838235294117647, 'mrpc_test_adapter_eval_f1': 0.7915993537964459, 'mrpc_test_adapter_eval_acc_and_f1': 0.7377114416041053, 'mrpc_dev_eval_loss': 1.1506047248840332, 'mrpc_dev_eval_acc': 0.65625, 'mrpc_dev_eval_f1': 0.7317073170731707, 'mrpc_dev_eval_acc_and_f1': 0.6939786585365854, 'mrpc_test_eval_loss': 1.0553802251815796, 'mrpc_test_eval_acc': 0.6838235294117647, 'mrpc_test_eval_f1': 0.7915993537964459, 'mrpc_test_eval_acc_and_f1': 0.7377114416041053, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--100-roberta-large-6179', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_17-24-36_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--100-roberta-large-6179', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_adapter_eval_loss': 2.002666473388672, 'qnli_dev_adapter_eval_acc': 0.6875, 'qnli_test_adapter_eval_loss': 2.2017552852630615, 'qnli_test_adapter_eval_acc': 0.5928976752699981, 'qnli_dev_eval_loss': 2.002666473388672, 'qnli_dev_eval_acc': 0.6875, 'qnli_test_eval_loss': 2.2017552852630615, 'qnli_test_eval_acc': 0.5928976752699981, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--100-roberta-large-4939', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_17-26-12_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--100-roberta-large-4939', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_adapter_eval_loss': 2.852783203125, 'cola_dev_adapter_eval_mcc': 0.4605661864718383, 'cola_test_adapter_eval_loss': 2.9100308418273926, 'cola_test_adapter_eval_mcc': 0.2291333721733502, 'cola_dev_eval_loss': 2.852783203125, 'cola_dev_eval_mcc': 0.4605661864718383, 'cola_test_eval_loss': 2.9100308418273926, 'cola_test_eval_mcc': 0.2291333721733502, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--100-roberta-large-17056', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_17-33-14_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-17056', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias_eval_loss': 4.6605119705200195, 'rte_dev_bias_eval_acc': 0.625, 'rte_test_bias_eval_loss': 5.224368095397949, 'rte_test_bias_eval_acc': 0.5523465703971119, 'rte_dev_eval_loss': 4.6605119705200195, 'rte_dev_eval_acc': 0.625, 'rte_test_eval_loss': 5.224368095397949, 'rte_test_eval_acc': 0.5523465703971119, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16--42-roberta-large-16023', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_17-38-04_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--42-roberta-large-16023', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,adapter_eval_loss': 0.7048819065093994, 'mrpc_dev_prompt,adapter_eval_acc': 0.5, 'mrpc_dev_prompt,adapter_eval_f1': 0.6666666666666666, 'mrpc_dev_prompt,adapter_eval_acc_and_f1': 0.5833333333333333, 'mrpc_test_prompt,adapter_eval_loss': 0.6484199166297913, 'mrpc_test_prompt,adapter_eval_acc': 0.6838235294117647, 'mrpc_test_prompt,adapter_eval_f1': 0.8122270742358079, 'mrpc_test_prompt,adapter_eval_acc_and_f1': 0.7480253018237863, 'mrpc_dev_eval_loss': 0.7048819065093994, 'mrpc_dev_eval_acc': 0.5, 'mrpc_dev_eval_f1': 0.6666666666666666, 'mrpc_dev_eval_acc_and_f1': 0.5833333333333333, 'mrpc_test_eval_loss': 0.6484199166297913, 'mrpc_test_eval_acc': 0.6838235294117647, 'mrpc_test_eval_f1': 0.8122270742358079, 'mrpc_test_eval_acc_and_f1': 0.7480253018237863, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-42-roberta-large-4602', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_17-40-18_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-42-roberta-large-4602', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias,adapter_eval_loss': 0.6223207712173462, 'sst-2_dev_prompt,bias,adapter_eval_acc': 0.9375, 'sst-2_test_prompt,bias,adapter_eval_loss': 0.9538868069648743, 'sst-2_test_prompt,bias,adapter_eval_acc': 0.9162844036697247, 'sst-2_dev_eval_loss': 0.6223207712173462, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.9538868069648743, 'sst-2_test_eval_acc': 0.9162844036697247, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-2580', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_17-31-49_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-2580', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_adapter_eval_loss': 1.6451178789138794, 'qnli_dev_adapter_eval_acc': 0.6875, 'qnli_test_adapter_eval_loss': 2.168748378753662, 'qnli_test_adapter_eval_acc': 0.5623283909939594, 'qnli_dev_eval_loss': 1.6451178789138794, 'qnli_dev_eval_acc': 0.6875, 'qnli_test_eval_loss': 2.168748378753662, 'qnli_test_eval_acc': 0.5623283909939594, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--100-roberta-large-14992', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_17-42-53_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--100-roberta-large-14992', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_adapter_eval_loss': 2.117811441421509, 'sts-b_dev_adapter_eval_pearson': 0.7824465844690258, 'sts-b_dev_adapter_eval_spearmanr': 0.7810851567920696, 'sts-b_dev_adapter_eval_corr': 0.7817658706305477, 'sts-b_test_adapter_eval_loss': 2.185535192489624, 'sts-b_test_adapter_eval_pearson': 0.6375853930303843, 'sts-b_test_adapter_eval_spearmanr': 0.6366952833725319, 'sts-b_test_adapter_eval_corr': 0.6371403382014581, 'sts-b_dev_eval_loss': 2.117811441421509, 'sts-b_dev_eval_pearson': 0.7824465844690258, 'sts-b_dev_eval_spearmanr': 0.7810851567920696, 'sts-b_dev_eval_corr': 0.7817658706305477, 'sts-b_test_eval_loss': 2.185535192489624, 'sts-b_test_eval_pearson': 0.6375853930303843, 'sts-b_test_eval_spearmanr': 0.6366952833725319, 'sts-b_test_eval_corr': 0.6371403382014581, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--42-roberta-large-32533', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_17-32-35_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--42-roberta-large-32533', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,adapter_eval_loss': 0.7179829478263855, 'cola_dev_prompt,adapter_eval_mcc': 0.0, 'cola_test_prompt,adapter_eval_loss': 0.8034902215003967, 'cola_test_prompt,adapter_eval_mcc': 0.0, 'cola_dev_eval_loss': 0.7179829478263855, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.8034902215003967, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-30787', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_17-49-21_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-30787', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,bias_eval_loss': 2.196338653564453, 'qqp_dev_prompt,bias_eval_acc': 0.5625, 'qqp_dev_prompt,bias_eval_f1': 0.6111111111111112, 'qqp_dev_prompt,bias_eval_acc_and_f1': 0.5868055555555556, 'qqp_test_prompt,bias_eval_loss': 1.9588793516159058, 'qqp_test_prompt,bias_eval_acc': 0.583823893148652, 'qqp_test_prompt,bias_eval_f1': 0.523882286361064, 'qqp_test_prompt,bias_eval_acc_and_f1': 0.553853089754858, 'qqp_dev_eval_loss': 2.196338653564453, 'qqp_dev_eval_acc': 0.5625, 'qqp_dev_eval_f1': 0.6111111111111112, 'qqp_dev_eval_acc_and_f1': 0.5868055555555556, 'qqp_test_eval_loss': 1.9588793516159058, 'qqp_test_eval_acc': 0.583823893148652, 'qqp_test_eval_f1': 0.523882286361064, 'qqp_test_eval_acc_and_f1': 0.553853089754858, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-13-roberta-large-5530', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_17-31-32_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-13-roberta-large-5530', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias_eval_loss': 4.464351654052734, 'rte_dev_bias_eval_acc': 0.46875, 'rte_test_bias_eval_loss': 3.0817694664001465, 'rte_test_bias_eval_acc': 0.555956678700361, 'rte_dev_eval_loss': 4.464351654052734, 'rte_dev_eval_acc': 0.46875, 'rte_test_eval_loss': 3.0817694664001465, 'rte_test_eval_acc': 0.555956678700361, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16--42-roberta-large-3161', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_17-52-14_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--42-roberta-large-3161', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,adapter_eval_loss': 3.4866294860839844, 'mnli_dev_prompt,adapter_eval_mnli/acc': 0.6666666666666666, 'mnli_test_prompt,adapter_eval_loss': 2.909005641937256, 'mnli_test_prompt,adapter_eval_mnli/acc': 0.65206316861946, 'mnli-mm_test_prompt,adapter_eval_loss': 2.6844289302825928, 'mnli-mm_test_prompt,adapter_eval_mnli-mm/acc': 0.68053295362083, 'mnli_dev_eval_loss': 3.4866294860839844, 'mnli_dev_eval_mnli/acc': 0.6666666666666666, 'mnli_test_eval_loss': 2.909005641937256, 'mnli_test_eval_mnli/acc': 0.65206316861946, 'mnli-mm_test_eval_loss': 2.6844289302825928, 'mnli-mm_test_eval_mnli-mm/acc': 0.68053295362083, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-3473', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_17-22-45_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-3473', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,adapter_eval_loss': 1.4447321891784668, 'mrpc_dev_prompt,adapter_eval_acc': 0.8125, 'mrpc_dev_prompt,adapter_eval_f1': 0.8125, 'mrpc_dev_prompt,adapter_eval_acc_and_f1': 0.8125, 'mrpc_test_prompt,adapter_eval_loss': 3.2558064460754395, 'mrpc_test_prompt,adapter_eval_acc': 0.6200980392156863, 'mrpc_test_prompt,adapter_eval_f1': 0.6954813359528487, 'mrpc_test_prompt,adapter_eval_acc_and_f1': 0.6577896875842675, 'mrpc_dev_eval_loss': 1.4447321891784668, 'mrpc_dev_eval_acc': 0.8125, 'mrpc_dev_eval_f1': 0.8125, 'mrpc_dev_eval_acc_and_f1': 0.8125, 'mrpc_test_eval_loss': 3.2558064460754395, 'mrpc_test_eval_acc': 0.6200980392156863, 'mrpc_test_eval_f1': 0.6954813359528487, 'mrpc_test_eval_acc_and_f1': 0.6577896875842675, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-42-roberta-large-32378', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_17-57-43_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-42-roberta-large-32378', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,adapter_eval_loss': 2.8324661254882812, 'qnli_dev_prompt,adapter_eval_acc': 0.5625, 'qnli_test_prompt,adapter_eval_loss': 2.9540960788726807, 'qnli_test_prompt,adapter_eval_acc': 0.52242357678931, 'qnli_dev_eval_loss': 2.8324661254882812, 'qnli_dev_eval_acc': 0.5625, 'qnli_test_eval_loss': 2.9540960788726807, 'qnli_test_eval_acc': 0.52242357678931, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-42-roberta-large-26236', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_17-59-55_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-42-roberta-large-26236', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias_eval_loss': 2.3997788429260254, 'rte_dev_bias_eval_acc': 0.375, 'rte_test_bias_eval_loss': 1.934923768043518, 'rte_test_bias_eval_acc': 0.51985559566787, 'rte_dev_eval_loss': 2.3997788429260254, 'rte_dev_eval_acc': 0.375, 'rte_test_eval_loss': 1.934923768043518, 'rte_test_eval_acc': 0.51985559566787, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16--42-roberta-large-12494', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_18-09-43_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--42-roberta-large-12494', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,adapter_eval_loss': 3.6622045040130615, 'cola_dev_prompt,adapter_eval_mcc': 0.40451991747794525, 'cola_test_prompt,adapter_eval_loss': 6.563830375671387, 'cola_test_prompt,adapter_eval_mcc': 0.1478247129894438, 'cola_dev_eval_loss': 3.6622045040130615, 'cola_dev_eval_mcc': 0.40451991747794525, 'cola_test_eval_loss': 6.563830375671387, 'cola_test_eval_mcc': 0.1478247129894438, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-13953', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_18-07-00_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-13953', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias,adapter_eval_loss': 0.2790689766407013, 'sst-2_dev_prompt,bias,adapter_eval_acc': 0.96875, 'sst-2_test_prompt,bias,adapter_eval_loss': 0.5816494822502136, 'sst-2_test_prompt,bias,adapter_eval_acc': 0.930045871559633, 'sst-2_dev_eval_loss': 0.2790689766407013, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.5816494822502136, 'sst-2_test_eval_acc': 0.930045871559633, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-30735', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_17-59-29_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-30735', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_adapter_eval_loss': 2.124054431915283, 'sts-b_dev_adapter_eval_pearson': 0.7141826903224433, 'sts-b_dev_adapter_eval_spearmanr': 0.7333348297838547, 'sts-b_dev_adapter_eval_corr': 0.723758760053149, 'sts-b_test_adapter_eval_loss': 2.2040858268737793, 'sts-b_test_adapter_eval_pearson': 0.5309952744230072, 'sts-b_test_adapter_eval_spearmanr': 0.5341070808713747, 'sts-b_test_adapter_eval_corr': 0.532551177647191, 'sts-b_dev_eval_loss': 2.124054431915283, 'sts-b_dev_eval_pearson': 0.7141826903224433, 'sts-b_dev_eval_spearmanr': 0.7333348297838547, 'sts-b_dev_eval_corr': 0.723758760053149, 'sts-b_test_eval_loss': 2.2040858268737793, 'sts-b_test_eval_pearson': 0.5309952744230072, 'sts-b_test_eval_spearmanr': 0.5341070808713747, 'sts-b_test_eval_corr': 0.532551177647191, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--42-roberta-large-14220', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_18-00-13_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--42-roberta-large-14220', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,adapter_eval_loss': 1.5066471099853516, 'mrpc_dev_prompt,adapter_eval_acc': 0.75, 'mrpc_dev_prompt,adapter_eval_f1': 0.7333333333333334, 'mrpc_dev_prompt,adapter_eval_acc_and_f1': 0.7416666666666667, 'mrpc_test_prompt,adapter_eval_loss': 3.9713308811187744, 'mrpc_test_prompt,adapter_eval_acc': 0.5563725490196079, 'mrpc_test_prompt,adapter_eval_f1': 0.5839080459770115, 'mrpc_test_prompt,adapter_eval_acc_and_f1': 0.5701402974983096, 'mrpc_dev_eval_loss': 1.5066471099853516, 'mrpc_dev_eval_acc': 0.75, 'mrpc_dev_eval_f1': 0.7333333333333334, 'mrpc_dev_eval_acc_and_f1': 0.7416666666666667, 'mrpc_test_eval_loss': 3.9713308811187744, 'mrpc_test_eval_acc': 0.5563725490196079, 'mrpc_test_eval_f1': 0.5839080459770115, 'mrpc_test_eval_acc_and_f1': 0.5701402974983096, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-42-roberta-large-4141', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_18-15-25_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-42-roberta-large-4141', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,adapter_eval_loss': 5.448956489562988, 'qnli_dev_prompt,adapter_eval_acc': 0.65625, 'qnli_test_prompt,adapter_eval_loss': 6.458499431610107, 'qnli_test_prompt,adapter_eval_acc': 0.5255354200988468, 'qnli_dev_eval_loss': 5.448956489562988, 'qnli_dev_eval_acc': 0.65625, 'qnli_test_eval_loss': 6.458499431610107, 'qnli_test_eval_acc': 0.5255354200988468, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-42-roberta-large-18621', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_18-17-57_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-42-roberta-large-18621', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias_eval_loss': 4.4931111335754395, 'rte_dev_bias_eval_acc': 0.375, 'rte_test_bias_eval_loss': 3.129223346710205, 'rte_test_bias_eval_acc': 0.5523465703971119, 'rte_dev_eval_loss': 4.4931111335754395, 'rte_dev_eval_acc': 0.375, 'rte_test_eval_loss': 3.129223346710205, 'rte_test_eval_acc': 0.5523465703971119, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16--42-roberta-large-13318', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_18-23-38_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--42-roberta-large-13318', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,adapter_eval_loss': 2.7655625343322754, 'cola_dev_prompt,adapter_eval_mcc': 0.5726562866782, 'cola_test_prompt,adapter_eval_loss': 3.5781948566436768, 'cola_test_prompt,adapter_eval_mcc': 0.18053041311772142, 'cola_dev_eval_loss': 2.7655625343322754, 'cola_dev_eval_mcc': 0.5726562866782, 'cola_test_eval_loss': 3.5781948566436768, 'cola_test_eval_mcc': 0.18053041311772142, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-10146', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_18-24-27_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-10146', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias,adapter_eval_loss': 0.6989870071411133, 'qqp_dev_bias,adapter_eval_acc': 0.5, 'qqp_dev_bias,adapter_eval_f1': 0.6666666666666666, 'qqp_dev_bias,adapter_eval_acc_and_f1': 0.5833333333333333, 'qqp_test_bias,adapter_eval_loss': 0.7275052070617676, 'qqp_test_bias,adapter_eval_acc': 0.36816720257234725, 'qqp_test_bias,adapter_eval_f1': 0.5381903642773208, 'qqp_test_bias,adapter_eval_acc_and_f1': 0.45317878342483403, 'qqp_dev_eval_loss': 0.6989870071411133, 'qqp_dev_eval_acc': 0.5, 'qqp_dev_eval_f1': 0.6666666666666666, 'qqp_dev_eval_acc_and_f1': 0.5833333333333333, 'qqp_test_eval_loss': 0.7275052070617676, 'qqp_test_eval_acc': 0.36816720257234725, 'qqp_test_eval_f1': 0.5381903642773208, 'qqp_test_eval_acc_and_f1': 0.45317878342483403, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16--13-roberta-large-1367', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_18-08-22_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--13-roberta-large-1367', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,adapter_eval_loss': 1.5967200994491577, 'mrpc_dev_prompt,adapter_eval_acc': 0.65625, 'mrpc_dev_prompt,adapter_eval_f1': 0.6666666666666667, 'mrpc_dev_prompt,adapter_eval_acc_and_f1': 0.6614583333333334, 'mrpc_test_prompt,adapter_eval_loss': 3.0680367946624756, 'mrpc_test_prompt,adapter_eval_acc': 0.625, 'mrpc_test_prompt,adapter_eval_f1': 0.6871165644171778, 'mrpc_test_prompt,adapter_eval_acc_and_f1': 0.656058282208589, 'mrpc_dev_eval_loss': 1.5967200994491577, 'mrpc_dev_eval_acc': 0.65625, 'mrpc_dev_eval_f1': 0.6666666666666667, 'mrpc_dev_eval_acc_and_f1': 0.6614583333333334, 'mrpc_test_eval_loss': 3.0680367946624756, 'mrpc_test_eval_acc': 0.625, 'mrpc_test_eval_f1': 0.6871165644171778, 'mrpc_test_eval_acc_and_f1': 0.656058282208589, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-42-roberta-large-26216', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_18-32-50_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-42-roberta-large-26216', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias_eval_loss': 1.3930730819702148, 'rte_dev_bias_eval_acc': 0.5625, 'rte_test_bias_eval_loss': 1.6271778345108032, 'rte_test_bias_eval_acc': 0.5054151624548736, 'rte_dev_eval_loss': 1.3930730819702148, 'rte_dev_eval_acc': 0.5625, 'rte_test_eval_loss': 1.6271778345108032, 'rte_test_eval_acc': 0.5054151624548736, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16--100-roberta-large-7724', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_18-37-42_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--100-roberta-large-7724', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_adapter_eval_loss': 2.113232135772705, 'sts-b_dev_adapter_eval_pearson': 0.33182986849573254, 'sts-b_dev_adapter_eval_spearmanr': 0.3305130263858601, 'sts-b_dev_adapter_eval_corr': 0.3311714474407963, 'sts-b_test_adapter_eval_loss': 2.211745023727417, 'sts-b_test_adapter_eval_pearson': -0.003279552972141291, 'sts-b_test_adapter_eval_spearmanr': 0.00492571273262117, 'sts-b_test_adapter_eval_corr': 0.0008230798802399395, 'sts-b_dev_eval_loss': 2.113232135772705, 'sts-b_dev_eval_pearson': 0.33182986849573254, 'sts-b_dev_eval_spearmanr': 0.3305130263858601, 'sts-b_dev_eval_corr': 0.3311714474407963, 'sts-b_test_eval_loss': 2.211745023727417, 'sts-b_test_eval_pearson': -0.003279552972141291, 'sts-b_test_eval_spearmanr': 0.00492571273262117, 'sts-b_test_eval_corr': 0.0008230798802399395, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--100-roberta-large-25223', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_18-27-18_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--100-roberta-large-25223', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias,adapter_eval_loss': 0.18774226307868958, 'sst-2_dev_prompt,bias,adapter_eval_acc': 0.96875, 'sst-2_test_prompt,bias,adapter_eval_loss': 0.46964550018310547, 'sst-2_test_prompt,bias,adapter_eval_acc': 0.9220183486238532, 'sst-2_dev_eval_loss': 0.18774226307868958, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.46964550018310547, 'sst-2_test_eval_acc': 0.9220183486238532, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-32633', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_18-26-31_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-32633', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,adapter_eval_loss': 1.8641812801361084, 'qnli_dev_prompt,adapter_eval_acc': 0.65625, 'qnli_test_prompt,adapter_eval_loss': 2.5831298828125, 'qnli_test_prompt,adapter_eval_acc': 0.6071755445725792, 'qnli_dev_eval_loss': 1.8641812801361084, 'qnli_dev_eval_acc': 0.65625, 'qnli_test_eval_loss': 2.5831298828125, 'qnli_test_eval_acc': 0.6071755445725792, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-42-roberta-large-26938', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_18-35-55_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-42-roberta-large-26938', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,adapter_eval_loss': 3.423358917236328, 'mnli_dev_prompt,adapter_eval_mnli/acc': 0.7083333333333334, 'mnli_test_prompt,adapter_eval_loss': 3.0630154609680176, 'mnli_test_prompt,adapter_eval_mnli/acc': 0.6556291390728477, 'mnli-mm_test_prompt,adapter_eval_loss': 2.86702299118042, 'mnli-mm_test_prompt,adapter_eval_mnli-mm/acc': 0.6819568755085436, 'mnli_dev_eval_loss': 3.423358917236328, 'mnli_dev_eval_mnli/acc': 0.7083333333333334, 'mnli_test_eval_loss': 3.0630154609680176, 'mnli_test_eval_mnli/acc': 0.6556291390728477, 'mnli-mm_test_eval_loss': 2.86702299118042, 'mnli-mm_test_eval_mnli-mm/acc': 0.6819568755085436, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-4156', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_18-11-01_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-4156', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,adapter_eval_loss': 2.3483810424804688, 'cola_dev_prompt,adapter_eval_mcc': 0.5726562866782, 'cola_test_prompt,adapter_eval_loss': 3.884159803390503, 'cola_test_prompt,adapter_eval_mcc': 0.15201050714532235, 'cola_dev_eval_loss': 2.3483810424804688, 'cola_dev_eval_mcc': 0.5726562866782, 'cola_test_eval_loss': 3.884159803390503, 'cola_test_eval_mcc': 0.15201050714532235, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-26448', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_18-42-21_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-26448', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias_eval_loss': 2.2694153785705566, 'rte_dev_bias_eval_acc': 0.65625, 'rte_test_bias_eval_loss': 2.073646068572998, 'rte_test_bias_eval_acc': 0.592057761732852, 'rte_dev_eval_loss': 2.2694153785705566, 'rte_dev_eval_acc': 0.65625, 'rte_test_eval_loss': 2.073646068572998, 'rte_test_eval_acc': 0.592057761732852, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16--100-roberta-large-4859', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_18-51-47_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--100-roberta-large-4859', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,adapter_eval_loss': 4.208739757537842, 'mrpc_dev_prompt,adapter_eval_acc': 0.59375, 'mrpc_dev_prompt,adapter_eval_f1': 0.6486486486486486, 'mrpc_dev_prompt,adapter_eval_acc_and_f1': 0.6211993243243243, 'mrpc_test_prompt,adapter_eval_loss': 2.2626538276672363, 'mrpc_test_prompt,adapter_eval_acc': 0.6887254901960784, 'mrpc_test_prompt,adapter_eval_f1': 0.7791304347826087, 'mrpc_test_prompt,adapter_eval_acc_and_f1': 0.7339279624893436, 'mrpc_dev_eval_loss': 4.208739757537842, 'mrpc_dev_eval_acc': 0.59375, 'mrpc_dev_eval_f1': 0.6486486486486486, 'mrpc_dev_eval_acc_and_f1': 0.6211993243243243, 'mrpc_test_eval_loss': 2.2626538276672363, 'mrpc_test_eval_acc': 0.6887254901960784, 'mrpc_test_eval_f1': 0.7791304347826087, 'mrpc_test_eval_acc_and_f1': 0.7339279624893436, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-100-roberta-large-12948', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_18-50-23_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-100-roberta-large-12948', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,adapter_eval_loss': 3.0936663150787354, 'qnli_dev_prompt,adapter_eval_acc': 0.625, 'qnli_test_prompt,adapter_eval_loss': 3.1481332778930664, 'qnli_test_prompt,adapter_eval_acc': 0.5817316492769541, 'qnli_dev_eval_loss': 3.0936663150787354, 'qnli_dev_eval_acc': 0.625, 'qnli_test_eval_loss': 3.1481332778930664, 'qnli_test_eval_acc': 0.5817316492769541, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-42-roberta-large-15463', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_18-53-49_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-42-roberta-large-15463', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,adapter_eval_loss': 3.026118040084839, 'cola_dev_prompt,adapter_eval_mcc': 0.0, 'cola_test_prompt,adapter_eval_loss': 2.1171443462371826, 'cola_test_prompt,adapter_eval_mcc': 0.18372979704922268, 'cola_dev_eval_loss': 3.026118040084839, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 2.1171443462371826, 'cola_test_eval_mcc': 0.18372979704922268, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-23911', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_18-59-57_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-23911', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_adapter_eval_loss': 2.0854594707489014, 'sts-b_dev_adapter_eval_pearson': 0.7818091110566511, 'sts-b_dev_adapter_eval_spearmanr': 0.7811340688842066, 'sts-b_dev_adapter_eval_corr': 0.7814715899704288, 'sts-b_test_adapter_eval_loss': 2.1932156085968018, 'sts-b_test_adapter_eval_pearson': 0.5945676885010011, 'sts-b_test_adapter_eval_spearmanr': 0.6222764757029825, 'sts-b_test_adapter_eval_corr': 0.6084220821019918, 'sts-b_dev_eval_loss': 2.0854594707489014, 'sts-b_dev_eval_pearson': 0.7818091110566511, 'sts-b_dev_eval_spearmanr': 0.7811340688842066, 'sts-b_dev_eval_corr': 0.7814715899704288, 'sts-b_test_eval_loss': 2.1932156085968018, 'sts-b_test_eval_pearson': 0.5945676885010011, 'sts-b_test_eval_spearmanr': 0.6222764757029825, 'sts-b_test_eval_corr': 0.6084220821019918, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--100-roberta-large-17735', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_18-52-41_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--100-roberta-large-17735', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias_eval_loss': 1.6222728490829468, 'rte_dev_bias_eval_acc': 0.6875, 'rte_test_bias_eval_loss': 1.7876009941101074, 'rte_test_bias_eval_acc': 0.5740072202166066, 'rte_dev_eval_loss': 1.6222728490829468, 'rte_dev_eval_acc': 0.6875, 'rte_test_eval_loss': 1.7876009941101074, 'rte_test_eval_acc': 0.5740072202166066, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16--100-roberta-large-23831', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_19-05-39_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--100-roberta-large-23831', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias,adapter_eval_loss': 0.4986189901828766, 'sst-2_dev_prompt,bias,adapter_eval_acc': 0.9375, 'sst-2_test_prompt,bias,adapter_eval_loss': 1.3770893812179565, 'sst-2_test_prompt,bias,adapter_eval_acc': 0.8428899082568807, 'sst-2_dev_eval_loss': 0.4986189901828766, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 1.3770893812179565, 'sst-2_test_eval_acc': 0.8428899082568807, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-41', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_18-53-28_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-41', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,adapter_eval_loss': 1.918628454208374, 'mrpc_dev_prompt,adapter_eval_acc': 0.71875, 'mrpc_dev_prompt,adapter_eval_f1': 0.742857142857143, 'mrpc_dev_prompt,adapter_eval_acc_and_f1': 0.7308035714285714, 'mrpc_test_prompt,adapter_eval_loss': 2.816269874572754, 'mrpc_test_prompt,adapter_eval_acc': 0.6813725490196079, 'mrpc_test_prompt,adapter_eval_f1': 0.7661870503597122, 'mrpc_test_prompt,adapter_eval_acc_and_f1': 0.72377979968966, 'mrpc_dev_eval_loss': 1.918628454208374, 'mrpc_dev_eval_acc': 0.71875, 'mrpc_dev_eval_f1': 0.742857142857143, 'mrpc_dev_eval_acc_and_f1': 0.7308035714285714, 'mrpc_test_eval_loss': 2.816269874572754, 'mrpc_test_eval_acc': 0.6813725490196079, 'mrpc_test_eval_f1': 0.7661870503597122, 'mrpc_test_eval_acc_and_f1': 0.72377979968966, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-100-roberta-large-6565', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_19-07-54_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-100-roberta-large-6565', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias,adapter_eval_loss': 4.793638706207275, 'qqp_dev_bias,adapter_eval_acc': 0.59375, 'qqp_dev_bias,adapter_eval_f1': 0.6486486486486486, 'qqp_dev_bias,adapter_eval_acc_and_f1': 0.6211993243243243, 'qqp_test_bias,adapter_eval_loss': 6.62154483795166, 'qqp_test_bias,adapter_eval_acc': 0.5576304724214692, 'qqp_test_bias,adapter_eval_f1': 0.5387729839853521, 'qqp_test_bias,adapter_eval_acc_and_f1': 0.5482017282034106, 'qqp_dev_eval_loss': 4.793638706207275, 'qqp_dev_eval_acc': 0.59375, 'qqp_dev_eval_f1': 0.6486486486486486, 'qqp_dev_eval_acc_and_f1': 0.6211993243243243, 'qqp_test_eval_loss': 6.62154483795166, 'qqp_test_eval_acc': 0.5576304724214692, 'qqp_test_eval_f1': 0.5387729839853521, 'qqp_test_eval_acc_and_f1': 0.5482017282034106, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16--13-roberta-large-12733', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_18-48-00_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--13-roberta-large-12733', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,adapter_eval_loss': 0.7229676246643066, 'qnli_dev_prompt,adapter_eval_acc': 0.5, 'qnli_test_prompt,adapter_eval_loss': 0.7203251123428345, 'qnli_test_prompt,adapter_eval_acc': 0.5053999633900788, 'qnli_dev_eval_loss': 0.7229676246643066, 'qnli_dev_eval_acc': 0.5, 'qnli_test_eval_loss': 0.7203251123428345, 'qnli_test_eval_acc': 0.5053999633900788, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-100-roberta-large-10800', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_19-11-45_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-100-roberta-large-10800', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias_eval_loss': 1.5720915794372559, 'rte_dev_bias_eval_acc': 0.65625, 'rte_test_bias_eval_loss': 1.875120759010315, 'rte_test_bias_eval_acc': 0.5487364620938628, 'rte_dev_eval_loss': 1.5720915794372559, 'rte_dev_eval_acc': 0.65625, 'rte_test_eval_loss': 1.875120759010315, 'rte_test_eval_acc': 0.5487364620938628, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16--100-roberta-large-13793', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_19-19-27_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--100-roberta-large-13793', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,adapter_eval_loss': 2.0803444385528564, 'cola_dev_prompt,adapter_eval_mcc': 0.6454972243679028, 'cola_test_prompt,adapter_eval_loss': 2.699693441390991, 'cola_test_prompt,adapter_eval_mcc': 0.37516721434782185, 'cola_dev_eval_loss': 2.0803444385528564, 'cola_dev_eval_mcc': 0.6454972243679028, 'cola_test_eval_loss': 2.699693441390991, 'cola_test_eval_mcc': 0.37516721434782185, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-8396', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_19-17-29_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-8396', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_adapter_eval_loss': 2.090534210205078, 'sts-b_dev_adapter_eval_pearson': 0.7720835849446945, 'sts-b_dev_adapter_eval_spearmanr': 0.7469238176921975, 'sts-b_dev_adapter_eval_corr': 0.759503701318446, 'sts-b_test_adapter_eval_loss': 2.2032253742218018, 'sts-b_test_adapter_eval_pearson': 0.5660942352846908, 'sts-b_test_adapter_eval_spearmanr': 0.5836441492203377, 'sts-b_test_adapter_eval_corr': 0.5748691922525142, 'sts-b_dev_eval_loss': 2.090534210205078, 'sts-b_dev_eval_pearson': 0.7720835849446945, 'sts-b_dev_eval_spearmanr': 0.7469238176921975, 'sts-b_dev_eval_corr': 0.759503701318446, 'sts-b_test_eval_loss': 2.2032253742218018, 'sts-b_test_eval_pearson': 0.5660942352846908, 'sts-b_test_eval_spearmanr': 0.5836441492203377, 'sts-b_test_eval_corr': 0.5748691922525142, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--100-roberta-large-19913', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_19-18-14_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--100-roberta-large-19913', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,adapter_eval_loss': 3.0232458114624023, 'mrpc_dev_prompt,adapter_eval_acc': 0.65625, 'mrpc_dev_prompt,adapter_eval_f1': 0.6206896551724138, 'mrpc_dev_prompt,adapter_eval_acc_and_f1': 0.6384698275862069, 'mrpc_test_prompt,adapter_eval_loss': 2.859093427658081, 'mrpc_test_prompt,adapter_eval_acc': 0.6029411764705882, 'mrpc_test_prompt,adapter_eval_f1': 0.6610878661087867, 'mrpc_test_prompt,adapter_eval_acc_and_f1': 0.6320145212896875, 'mrpc_dev_eval_loss': 3.0232458114624023, 'mrpc_dev_eval_acc': 0.65625, 'mrpc_dev_eval_f1': 0.6206896551724138, 'mrpc_dev_eval_acc_and_f1': 0.6384698275862069, 'mrpc_test_eval_loss': 2.859093427658081, 'mrpc_test_eval_acc': 0.6029411764705882, 'mrpc_test_eval_f1': 0.6610878661087867, 'mrpc_test_eval_acc_and_f1': 0.6320145212896875, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-100-roberta-large-8662', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_19-25-29_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-100-roberta-large-8662', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,adapter_eval_loss': 2.063051223754883, 'qnli_dev_prompt,adapter_eval_acc': 0.65625, 'qnli_test_prompt,adapter_eval_loss': 2.7101378440856934, 'qnli_test_prompt,adapter_eval_acc': 0.5667215815485996, 'qnli_dev_eval_loss': 2.063051223754883, 'qnli_dev_eval_acc': 0.65625, 'qnli_test_eval_loss': 2.7101378440856934, 'qnli_test_eval_acc': 0.5667215815485996, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-100-roberta-large-24389', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_19-29-31_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-100-roberta-large-24389', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias,adapter_eval_loss': 0.0066703567281365395, 'sst-2_dev_prompt,bias,adapter_eval_acc': 1.0, 'sst-2_test_prompt,bias,adapter_eval_loss': 0.6365349292755127, 'sst-2_test_prompt,bias,adapter_eval_acc': 0.9277522935779816, 'sst-2_dev_eval_loss': 0.0066703567281365395, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.6365349292755127, 'sst-2_test_eval_acc': 0.9277522935779816, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-266', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_19-21-17_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-266', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_adapter_eval_loss': 3.359170436859131, 'rte_dev_adapter_eval_acc': 0.5, 'rte_test_adapter_eval_loss': 3.356551170349121, 'rte_test_adapter_eval_acc': 0.5234657039711191, 'rte_dev_eval_loss': 3.359170436859131, 'rte_dev_eval_acc': 0.5, 'rte_test_eval_loss': 3.356551170349121, 'rte_test_eval_acc': 0.5234657039711191, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--42-roberta-large-26202', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_19-33-27_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--42-roberta-large-26202', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,adapter_eval_loss': 2.972352981567383, 'mnli_dev_prompt,adapter_eval_mnli/acc': 0.6875, 'mnli_test_prompt,adapter_eval_loss': 2.9064462184906006, 'mnli_test_prompt,adapter_eval_mnli/acc': 0.6358634742740703, 'mnli-mm_test_prompt,adapter_eval_loss': 2.748323678970337, 'mnli-mm_test_prompt,adapter_eval_mnli-mm/acc': 0.6501220504475184, 'mnli_dev_eval_loss': 2.972352981567383, 'mnli_dev_eval_mnli/acc': 0.6875, 'mnli_test_eval_loss': 2.9064462184906006, 'mnli_test_eval_mnli/acc': 0.6358634742740703, 'mnli-mm_test_eval_loss': 2.748323678970337, 'mnli-mm_test_eval_mnli-mm/acc': 0.6501220504475184, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-23066', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_18-59-05_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-23066', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,adapter_eval_loss': 3.42157244682312, 'cola_dev_prompt,adapter_eval_mcc': 0.5393598899705937, 'cola_test_prompt,adapter_eval_loss': 2.631559371948242, 'cola_test_prompt,adapter_eval_mcc': 0.3449629338788743, 'cola_dev_eval_loss': 3.42157244682312, 'cola_dev_eval_mcc': 0.5393598899705937, 'cola_test_eval_loss': 2.631559371948242, 'cola_test_eval_mcc': 0.3449629338788743, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-19084', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_19-35-07_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-19084', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,adapter_eval_loss': 4.043846130371094, 'mrpc_dev_prompt,adapter_eval_acc': 0.59375, 'mrpc_dev_prompt,adapter_eval_f1': 0.6666666666666667, 'mrpc_dev_prompt,adapter_eval_acc_and_f1': 0.6302083333333334, 'mrpc_test_prompt,adapter_eval_loss': 2.803985595703125, 'mrpc_test_prompt,adapter_eval_acc': 0.6887254901960784, 'mrpc_test_prompt,adapter_eval_f1': 0.7806563039723661, 'mrpc_test_prompt,adapter_eval_acc_and_f1': 0.7346908970842223, 'mrpc_dev_eval_loss': 4.043846130371094, 'mrpc_dev_eval_acc': 0.59375, 'mrpc_dev_eval_f1': 0.6666666666666667, 'mrpc_dev_eval_acc_and_f1': 0.6302083333333334, 'mrpc_test_eval_loss': 2.803985595703125, 'mrpc_test_eval_acc': 0.6887254901960784, 'mrpc_test_eval_f1': 0.7806563039723661, 'mrpc_test_eval_acc_and_f1': 0.7346908970842223, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-100-roberta-large-299', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_19-42-59_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-100-roberta-large-299', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_adapter_eval_loss': 4.700531959533691, 'rte_dev_adapter_eval_acc': 0.40625, 'rte_test_adapter_eval_loss': 3.6812217235565186, 'rte_test_adapter_eval_acc': 0.5306859205776173, 'rte_dev_eval_loss': 4.700531959533691, 'rte_dev_eval_acc': 0.40625, 'rte_test_eval_loss': 3.6812217235565186, 'rte_test_eval_acc': 0.5306859205776173, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--42-roberta-large-25285', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_19-48-05_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--42-roberta-large-25285', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,adapter_eval_loss': 2.9446144104003906, 'qnli_dev_prompt,adapter_eval_acc': 0.65625, 'qnli_test_prompt,adapter_eval_loss': 3.3005335330963135, 'qnli_test_prompt,adapter_eval_acc': 0.5403624382207578, 'qnli_dev_eval_loss': 2.9446144104003906, 'qnli_dev_eval_acc': 0.65625, 'qnli_test_eval_loss': 3.3005335330963135, 'qnli_test_eval_acc': 0.5403624382207578, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-100-roberta-large-10234', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_19-47-17_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-100-roberta-large-10234', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_adapter_eval_loss': 2.0977509021759033, 'sts-b_dev_adapter_eval_pearson': 0.7128392679110964, 'sts-b_dev_adapter_eval_spearmanr': 0.6555125550984959, 'sts-b_dev_adapter_eval_corr': 0.6841759115047962, 'sts-b_test_adapter_eval_loss': 2.220913887023926, 'sts-b_test_adapter_eval_pearson': 0.5256796589046189, 'sts-b_test_adapter_eval_spearmanr': 0.5203062878945452, 'sts-b_test_adapter_eval_corr': 0.5229929733995821, 'sts-b_dev_eval_loss': 2.0977509021759033, 'sts-b_dev_eval_pearson': 0.7128392679110964, 'sts-b_dev_eval_spearmanr': 0.6555125550984959, 'sts-b_dev_eval_corr': 0.6841759115047962, 'sts-b_test_eval_loss': 2.220913887023926, 'sts-b_test_eval_pearson': 0.5256796589046189, 'sts-b_test_eval_spearmanr': 0.5203062878945452, 'sts-b_test_eval_corr': 0.5229929733995821, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--100-roberta-large-31452', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_19-42-44_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--100-roberta-large-31452', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias,adapter_eval_loss': 2.723680019378662, 'qqp_dev_bias,adapter_eval_acc': 0.6875, 'qqp_dev_bias,adapter_eval_f1': 0.761904761904762, 'qqp_dev_bias,adapter_eval_acc_and_f1': 0.7247023809523809, 'qqp_test_bias,adapter_eval_loss': 3.3650569915771484, 'qqp_test_bias,adapter_eval_acc': 0.5649270343804106, 'qqp_test_bias,adapter_eval_f1': 0.5886727153680666, 'qqp_test_bias,adapter_eval_acc_and_f1': 0.5767998748742387, 'qqp_dev_eval_loss': 2.723680019378662, 'qqp_dev_eval_acc': 0.6875, 'qqp_dev_eval_f1': 0.761904761904762, 'qqp_dev_eval_acc_and_f1': 0.7247023809523809, 'qqp_test_eval_loss': 3.3650569915771484, 'qqp_test_eval_acc': 0.5649270343804106, 'qqp_test_eval_f1': 0.5886727153680666, 'qqp_test_eval_acc_and_f1': 0.5767998748742387, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16--13-roberta-large-10762', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_19-27-23_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--13-roberta-large-10762', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,adapter_eval_loss': 3.6160435676574707, 'cola_dev_prompt,adapter_eval_mcc': 0.4865336327998411, 'cola_test_prompt,adapter_eval_loss': 2.8338429927825928, 'cola_test_prompt,adapter_eval_mcc': 0.3180514157072531, 'cola_dev_eval_loss': 3.6160435676574707, 'cola_dev_eval_mcc': 0.4865336327998411, 'cola_test_eval_loss': 2.8338429927825928, 'cola_test_eval_mcc': 0.3180514157072531, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-4305', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_19-52-53_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-4305', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias,adapter_eval_loss': 0.0009578949538990855, 'sst-2_dev_prompt,bias,adapter_eval_acc': 1.0, 'sst-2_test_prompt,bias,adapter_eval_loss': 0.7750974893569946, 'sst-2_test_prompt,bias,adapter_eval_acc': 0.9197247706422018, 'sst-2_dev_eval_loss': 0.0009578949538990855, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.7750974893569946, 'sst-2_test_eval_acc': 0.9197247706422018, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-19929', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_19-48-00_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-19929', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias_eval_loss': 1.4713362455368042, 'mrpc_dev_prompt,bias_eval_acc': 0.6875, 'mrpc_dev_prompt,bias_eval_f1': 0.6875, 'mrpc_dev_prompt,bias_eval_acc_and_f1': 0.6875, 'mrpc_test_prompt,bias_eval_loss': 1.794757604598999, 'mrpc_test_prompt,bias_eval_acc': 0.6568627450980392, 'mrpc_test_prompt,bias_eval_f1': 0.7378277153558052, 'mrpc_test_prompt,bias_eval_acc_and_f1': 0.6973452302269222, 'mrpc_dev_eval_loss': 1.4713362455368042, 'mrpc_dev_eval_acc': 0.6875, 'mrpc_dev_eval_f1': 0.6875, 'mrpc_dev_eval_acc_and_f1': 0.6875, 'mrpc_test_eval_loss': 1.794757604598999, 'mrpc_test_eval_acc': 0.6568627450980392, 'mrpc_test_eval_f1': 0.7378277153558052, 'mrpc_test_eval_acc_and_f1': 0.6973452302269222, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-42-roberta-large-29662', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_20-00-43_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-42-roberta-large-29662', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_adapter_eval_loss': 3.7240142822265625, 'rte_dev_adapter_eval_acc': 0.40625, 'rte_test_adapter_eval_loss': 2.6699013710021973, 'rte_test_adapter_eval_acc': 0.5270758122743683, 'rte_dev_eval_loss': 3.7240142822265625, 'rte_dev_eval_acc': 0.40625, 'rte_test_eval_loss': 2.6699013710021973, 'rte_test_eval_acc': 0.5270758122743683, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--42-roberta-large-23677', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_20-03-20_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--42-roberta-large-23677', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,adapter_eval_loss': 3.8602752685546875, 'qnli_dev_prompt,adapter_eval_acc': 0.6875, 'qnli_test_prompt,adapter_eval_loss': 3.851425886154175, 'qnli_test_prompt,adapter_eval_acc': 0.5409115870400879, 'qnli_dev_eval_loss': 3.8602752685546875, 'qnli_dev_eval_acc': 0.6875, 'qnli_test_eval_loss': 3.851425886154175, 'qnli_test_eval_acc': 0.5409115870400879, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-100-roberta-large-30373', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_20-05-05_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-100-roberta-large-30373', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias_eval_loss': 2.3205959796905518, 'cola_dev_prompt,bias_eval_mcc': 0.44539933408304444, 'cola_test_prompt,bias_eval_loss': 2.8507981300354004, 'cola_test_prompt,bias_eval_mcc': 0.15848090877479157, 'cola_dev_eval_loss': 2.3205959796905518, 'cola_dev_eval_mcc': 0.44539933408304444, 'cola_test_eval_loss': 2.8507981300354004, 'cola_test_eval_mcc': 0.15848090877479157, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-15330', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_20-10-32_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-15330', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias_eval_loss': 1.9368129968643188, 'mrpc_dev_prompt,bias_eval_acc': 0.6875, 'mrpc_dev_prompt,bias_eval_f1': 0.7222222222222223, 'mrpc_dev_prompt,bias_eval_acc_and_f1': 0.7048611111111112, 'mrpc_test_prompt,bias_eval_loss': 2.5212557315826416, 'mrpc_test_prompt,bias_eval_acc': 0.6200980392156863, 'mrpc_test_prompt,bias_eval_f1': 0.7013487475915221, 'mrpc_test_prompt,bias_eval_acc_and_f1': 0.6607233934036042, 'mrpc_dev_eval_loss': 1.9368129968643188, 'mrpc_dev_eval_acc': 0.6875, 'mrpc_dev_eval_f1': 0.7222222222222223, 'mrpc_dev_eval_acc_and_f1': 0.7048611111111112, 'mrpc_test_eval_loss': 2.5212557315826416, 'mrpc_test_eval_acc': 0.6200980392156863, 'mrpc_test_eval_f1': 0.7013487475915221, 'mrpc_test_eval_acc_and_f1': 0.6607233934036042, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-42-roberta-large-6521', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_20-16-04_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-42-roberta-large-6521', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_adapter_eval_loss': 3.5286202430725098, 'rte_dev_adapter_eval_acc': 0.40625, 'rte_test_adapter_eval_loss': 2.418916702270508, 'rte_test_adapter_eval_acc': 0.51985559566787, 'rte_dev_eval_loss': 3.5286202430725098, 'rte_dev_eval_acc': 0.40625, 'rte_test_eval_loss': 2.418916702270508, 'rte_test_eval_acc': 0.51985559566787, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--42-roberta-large-2412', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_20-18-20_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--42-roberta-large-2412', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,adapter_eval_loss': 2.152560234069824, 'sts-b_dev_prompt,adapter_eval_pearson': 0.33843235509953545, 'sts-b_dev_prompt,adapter_eval_spearmanr': 0.49894289397727426, 'sts-b_dev_prompt,adapter_eval_corr': 0.41868762453840486, 'sts-b_test_prompt,adapter_eval_loss': 2.2122371196746826, 'sts-b_test_prompt,adapter_eval_pearson': -0.032284235239674275, 'sts-b_test_prompt,adapter_eval_spearmanr': -0.02041895986046283, 'sts-b_test_prompt,adapter_eval_corr': -0.02635159755006855, 'sts-b_dev_eval_loss': 2.152560234069824, 'sts-b_dev_eval_pearson': 0.33843235509953545, 'sts-b_dev_eval_spearmanr': 0.49894289397727426, 'sts-b_dev_eval_corr': 0.41868762453840486, 'sts-b_test_eval_loss': 2.2122371196746826, 'sts-b_test_eval_pearson': -0.032284235239674275, 'sts-b_test_eval_spearmanr': -0.02041895986046283, 'sts-b_test_eval_corr': -0.02635159755006855, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-42-roberta-large-24702', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_20-08-34_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-42-roberta-large-24702', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias_eval_loss': 3.0392796993255615, 'qnli_dev_prompt,bias_eval_acc': 0.53125, 'qnli_test_prompt,bias_eval_loss': 2.5276455879211426, 'qnli_test_prompt,bias_eval_acc': 0.509793153944719, 'qnli_dev_eval_loss': 3.0392796993255615, 'qnli_dev_eval_acc': 0.53125, 'qnli_test_eval_loss': 2.5276455879211426, 'qnli_test_eval_acc': 0.509793153944719, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-42-roberta-large-19471', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_20-23-22_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-42-roberta-large-19471', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,adapter_eval_loss': 3.067230463027954, 'mnli_dev_prompt,adapter_eval_mnli/acc': 0.5833333333333334, 'mnli_test_prompt,adapter_eval_loss': 3.3188161849975586, 'mnli_test_prompt,adapter_eval_mnli/acc': 0.6576668364747835, 'mnli-mm_test_prompt,adapter_eval_loss': 3.2384145259857178, 'mnli-mm_test_prompt,adapter_eval_mnli-mm/acc': 0.6717860048820179, 'mnli_dev_eval_loss': 3.067230463027954, 'mnli_dev_eval_mnli/acc': 0.5833333333333334, 'mnli_test_eval_loss': 3.3188161849975586, 'mnli_test_eval_mnli/acc': 0.6576668364747835, 'mnli-mm_test_eval_loss': 3.2384145259857178, 'mnli-mm_test_eval_mnli-mm/acc': 0.6717860048820179, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-29696', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_19-50-26_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-29696', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias_eval_loss': 2.210278272628784, 'cola_dev_prompt,bias_eval_mcc': 0.5, 'cola_test_prompt,bias_eval_loss': 3.563992500305176, 'cola_test_prompt,bias_eval_mcc': 0.11594855342654903, 'cola_dev_eval_loss': 2.210278272628784, 'cola_dev_eval_mcc': 0.5, 'cola_test_eval_loss': 3.563992500305176, 'cola_test_eval_mcc': 0.11594855342654903, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-24862', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_20-26-02_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-24862', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias,adapter_eval_loss': 0.0027894217055290937, 'sst-2_dev_prompt,bias,adapter_eval_acc': 1.0, 'sst-2_test_prompt,bias,adapter_eval_loss': 0.5574890375137329, 'sst-2_test_prompt,bias,adapter_eval_acc': 0.9151376146788991, 'sst-2_dev_eval_loss': 0.0027894217055290937, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.5574890375137329, 'sst-2_test_eval_acc': 0.9151376146788991, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-24801', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_20-15-48_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-24801', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias_eval_loss': 1.6454942226409912, 'mrpc_dev_prompt,bias_eval_acc': 0.65625, 'mrpc_dev_prompt,bias_eval_f1': 0.6666666666666667, 'mrpc_dev_prompt,bias_eval_acc_and_f1': 0.6614583333333334, 'mrpc_test_prompt,bias_eval_loss': 1.9988818168640137, 'mrpc_test_prompt,bias_eval_acc': 0.553921568627451, 'mrpc_test_prompt,bias_eval_f1': 0.6270491803278689, 'mrpc_test_prompt,bias_eval_acc_and_f1': 0.5904853744776599, 'mrpc_dev_eval_loss': 1.6454942226409912, 'mrpc_dev_eval_acc': 0.65625, 'mrpc_dev_eval_f1': 0.6666666666666667, 'mrpc_dev_eval_acc_and_f1': 0.6614583333333334, 'mrpc_test_eval_loss': 1.9988818168640137, 'mrpc_test_eval_acc': 0.553921568627451, 'mrpc_test_eval_f1': 0.6270491803278689, 'mrpc_test_eval_acc_and_f1': 0.5904853744776599, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-42-roberta-large-16008', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_20-31-37_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-42-roberta-large-16008', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_adapter_eval_loss': 4.040042877197266, 'rte_dev_adapter_eval_acc': 0.625, 'rte_test_adapter_eval_loss': 5.257647514343262, 'rte_test_adapter_eval_acc': 0.5234657039711191, 'rte_dev_eval_loss': 4.040042877197266, 'rte_dev_eval_acc': 0.625, 'rte_test_eval_loss': 5.257647514343262, 'rte_test_eval_acc': 0.5234657039711191, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--100-roberta-large-20900', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_20-33-21_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--100-roberta-large-20900', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias,adapter_eval_loss': 2.5510103702545166, 'qqp_dev_bias,adapter_eval_acc': 0.59375, 'qqp_dev_bias,adapter_eval_f1': 0.6486486486486486, 'qqp_dev_bias,adapter_eval_acc_and_f1': 0.6211993243243243, 'qqp_test_bias,adapter_eval_loss': 2.5993258953094482, 'qqp_test_bias,adapter_eval_acc': 0.5828592629235716, 'qqp_test_bias,adapter_eval_f1': 0.5754562617998741, 'qqp_test_bias,adapter_eval_acc_and_f1': 0.5791577623617228, 'qqp_dev_eval_loss': 2.5510103702545166, 'qqp_dev_eval_acc': 0.59375, 'qqp_dev_eval_f1': 0.6486486486486486, 'qqp_dev_eval_acc_and_f1': 0.6211993243243243, 'qqp_test_eval_loss': 2.5993258953094482, 'qqp_test_eval_acc': 0.5828592629235716, 'qqp_test_eval_f1': 0.5754562617998741, 'qqp_test_eval_acc_and_f1': 0.5791577623617228, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16--13-roberta-large-22637', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_20-08-36_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--13-roberta-large-22637', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias_eval_loss': 1.8673779964447021, 'qnli_dev_prompt,bias_eval_acc': 0.6875, 'qnli_test_prompt,bias_eval_loss': 2.0335564613342285, 'qnli_test_prompt,bias_eval_acc': 0.5714808713161267, 'qnli_dev_eval_loss': 1.8673779964447021, 'qnli_dev_eval_acc': 0.6875, 'qnli_test_eval_loss': 2.0335564613342285, 'qnli_test_eval_acc': 0.5714808713161267, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-42-roberta-large-4828', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_20-39-56_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-42-roberta-large-4828', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias_eval_loss': 1.9978545904159546, 'cola_dev_prompt,bias_eval_mcc': 0.629940788348712, 'cola_test_prompt,bias_eval_loss': 3.8977296352386475, 'cola_test_prompt,bias_eval_mcc': 0.13366473294911196, 'cola_dev_eval_loss': 1.9978545904159546, 'cola_dev_eval_mcc': 0.629940788348712, 'cola_test_eval_loss': 3.8977296352386475, 'cola_test_eval_mcc': 0.13366473294911196, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-26393', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_20-41-38_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-26393', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt_eval_loss': 0.4244774580001831, 'sst-2_dev_prompt_eval_acc': 0.84375, 'sst-2_test_prompt_eval_loss': 0.43101024627685547, 'sst-2_test_prompt_eval_acc': 0.8600917431192661, 'sst-2_dev_eval_loss': 0.4244774580001831, 'sst-2_dev_eval_acc': 0.84375, 'sst-2_test_eval_loss': 0.43101024627685547, 'sst-2_test_eval_acc': 0.8600917431192661, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-1647', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_20-43-47_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-1647', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_adapter_eval_loss': 2.3588037490844727, 'rte_dev_adapter_eval_acc': 0.59375, 'rte_test_adapter_eval_loss': 2.3934872150421143, 'rte_test_adapter_eval_acc': 0.5487364620938628, 'rte_dev_eval_loss': 2.3588037490844727, 'rte_dev_eval_acc': 0.59375, 'rte_test_eval_loss': 2.3934872150421143, 'rte_test_eval_acc': 0.5487364620938628, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--100-roberta-large-25398', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_20-48-06_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--100-roberta-large-25398', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias_eval_loss': 1.7108904123306274, 'mrpc_dev_prompt,bias_eval_acc': 0.6875, 'mrpc_dev_prompt,bias_eval_f1': 0.7058823529411765, 'mrpc_dev_prompt,bias_eval_acc_and_f1': 0.6966911764705883, 'mrpc_test_prompt,bias_eval_loss': 2.0553905963897705, 'mrpc_test_prompt,bias_eval_acc': 0.5955882352941176, 'mrpc_test_prompt,bias_eval_f1': 0.6719681908548708, 'mrpc_test_prompt,bias_eval_acc_and_f1': 0.6337782130744942, 'mrpc_dev_eval_loss': 1.7108904123306274, 'mrpc_dev_eval_acc': 0.6875, 'mrpc_dev_eval_f1': 0.7058823529411765, 'mrpc_dev_eval_acc_and_f1': 0.6966911764705883, 'mrpc_test_eval_loss': 2.0553905963897705, 'mrpc_test_eval_acc': 0.5955882352941176, 'mrpc_test_eval_f1': 0.6719681908548708, 'mrpc_test_eval_acc_and_f1': 0.6337782130744942, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-42-roberta-large-3599', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_20-47-06_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-42-roberta-large-3599', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,adapter_eval_loss': 2.1279149055480957, 'sts-b_dev_prompt,adapter_eval_pearson': 0.8281890480529521, 'sts-b_dev_prompt,adapter_eval_spearmanr': 0.8492212003307147, 'sts-b_dev_prompt,adapter_eval_corr': 0.8387051241918334, 'sts-b_test_prompt,adapter_eval_loss': 2.1955392360687256, 'sts-b_test_prompt,adapter_eval_pearson': 0.5540177566455567, 'sts-b_test_prompt,adapter_eval_spearmanr': 0.558376242308948, 'sts-b_test_prompt,adapter_eval_corr': 0.5561969994772524, 'sts-b_dev_eval_loss': 2.1279149055480957, 'sts-b_dev_eval_pearson': 0.8281890480529521, 'sts-b_dev_eval_spearmanr': 0.8492212003307147, 'sts-b_dev_eval_corr': 0.8387051241918334, 'sts-b_test_eval_loss': 2.1955392360687256, 'sts-b_test_eval_pearson': 0.5540177566455567, 'sts-b_test_eval_spearmanr': 0.558376242308948, 'sts-b_test_eval_corr': 0.5561969994772524, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-42-roberta-large-31256', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_20-37-03_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-42-roberta-large-31256', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias_eval_loss': 2.64438796043396, 'qnli_dev_prompt,bias_eval_acc': 0.65625, 'qnli_test_prompt,bias_eval_loss': 2.6937828063964844, 'qnli_test_prompt,bias_eval_acc': 0.5809994508511807, 'qnli_dev_eval_loss': 2.64438796043396, 'qnli_dev_eval_acc': 0.65625, 'qnli_test_eval_loss': 2.6937828063964844, 'qnli_test_eval_acc': 0.5809994508511807, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-42-roberta-large-22750', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_20-56-35_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-42-roberta-large-22750', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias_eval_loss': 2.048264980316162, 'cola_dev_prompt,bias_eval_mcc': 0.4605661864718383, 'cola_test_prompt,bias_eval_loss': 1.9179273843765259, 'cola_test_prompt,bias_eval_mcc': 0.17252945151274832, 'cola_dev_eval_loss': 2.048264980316162, 'cola_dev_eval_mcc': 0.4605661864718383, 'cola_test_eval_loss': 1.9179273843765259, 'cola_test_eval_mcc': 0.17252945151274832, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-14207', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_20-57-32_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-14207', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_adapter_eval_loss': 2.2169737815856934, 'rte_dev_adapter_eval_acc': 0.5625, 'rte_test_adapter_eval_loss': 2.290717840194702, 'rte_test_adapter_eval_acc': 0.5270758122743683, 'rte_dev_eval_loss': 2.2169737815856934, 'rte_dev_eval_acc': 0.5625, 'rte_test_eval_loss': 2.290717840194702, 'rte_test_eval_acc': 0.5270758122743683, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--100-roberta-large-9697', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_21-02-53_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--100-roberta-large-9697', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias_eval_loss': 2.741407632827759, 'mrpc_dev_prompt,bias_eval_acc': 0.5625, 'mrpc_dev_prompt,bias_eval_f1': 0.65, 'mrpc_dev_prompt,bias_eval_acc_and_f1': 0.60625, 'mrpc_test_prompt,bias_eval_loss': 2.3140695095062256, 'mrpc_test_prompt,bias_eval_acc': 0.6323529411764706, 'mrpc_test_prompt,bias_eval_f1': 0.7395833333333334, 'mrpc_test_prompt,bias_eval_acc_and_f1': 0.685968137254902, 'mrpc_dev_eval_loss': 2.741407632827759, 'mrpc_dev_eval_acc': 0.5625, 'mrpc_dev_eval_f1': 0.65, 'mrpc_dev_eval_acc_and_f1': 0.60625, 'mrpc_test_eval_loss': 2.3140695095062256, 'mrpc_test_eval_acc': 0.6323529411764706, 'mrpc_test_eval_f1': 0.7395833333333334, 'mrpc_test_eval_acc_and_f1': 0.685968137254902, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-100-roberta-large-29691', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_21-02-53_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-100-roberta-large-29691', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt_eval_loss': 0.8872569799423218, 'sst-2_dev_prompt_eval_acc': 0.8125, 'sst-2_test_prompt_eval_loss': 0.7801305055618286, 'sst-2_test_prompt_eval_acc': 0.8119266055045872, 'sst-2_dev_eval_loss': 0.8872569799423218, 'sst-2_dev_eval_acc': 0.8125, 'sst-2_test_eval_loss': 0.7801305055618286, 'sst-2_test_eval_acc': 0.8119266055045872, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-8003', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_21-01-27_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-8003', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias_eval_loss': 2.5793442726135254, 'cola_dev_prompt,bias_eval_mcc': 0.592156525463792, 'cola_test_prompt,bias_eval_loss': 2.5875446796417236, 'cola_test_prompt,bias_eval_mcc': 0.46957620875830214, 'cola_dev_eval_loss': 2.5793442726135254, 'cola_dev_eval_mcc': 0.592156525463792, 'cola_test_eval_loss': 2.5875446796417236, 'cola_test_eval_mcc': 0.46957620875830214, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-6976', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_21-13-28_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-6976', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias_eval_loss': 1.585181713104248, 'qnli_dev_prompt,bias_eval_acc': 0.625, 'qnli_test_prompt,bias_eval_loss': 2.0255331993103027, 'qnli_test_prompt,bias_eval_acc': 0.5718469705290133, 'qnli_dev_eval_loss': 1.585181713104248, 'qnli_dev_eval_acc': 0.625, 'qnli_test_eval_loss': 2.0255331993103027, 'qnli_test_eval_acc': 0.5718469705290133, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-42-roberta-large-18719', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_21-13-12_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-42-roberta-large-18719', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,bias,adapter_eval_loss': 0.7107622623443604, 'qqp_dev_prompt,bias,adapter_eval_acc': 0.5, 'qqp_dev_prompt,bias,adapter_eval_f1': 0.6666666666666666, 'qqp_dev_prompt,bias,adapter_eval_acc_and_f1': 0.5833333333333333, 'qqp_test_prompt,bias,adapter_eval_loss': 0.7604191303253174, 'qqp_test_prompt,bias,adapter_eval_acc': 0.36816720257234725, 'qqp_test_prompt,bias,adapter_eval_f1': 0.5381903642773208, 'qqp_test_prompt,bias,adapter_eval_acc_and_f1': 0.45317878342483403, 'qqp_dev_eval_loss': 0.7107622623443604, 'qqp_dev_eval_acc': 0.5, 'qqp_dev_eval_f1': 0.6666666666666666, 'qqp_dev_eval_acc_and_f1': 0.5833333333333333, 'qqp_test_eval_loss': 0.7604191303253174, 'qqp_test_eval_acc': 0.36816720257234725, 'qqp_test_eval_f1': 0.5381903642773208, 'qqp_test_eval_acc_and_f1': 0.45317878342483403, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16-prompt-13-roberta-large-26985', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_20-49-07_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-13-roberta-large-26985', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,adapter_eval_loss': 1.8987709283828735, 'mnli_dev_prompt,adapter_eval_mnli/acc': 0.6875, 'mnli_test_prompt,adapter_eval_loss': 1.9339981079101562, 'mnli_test_prompt,adapter_eval_mnli/acc': 0.6922058074375955, 'mnli-mm_test_prompt,adapter_eval_loss': 1.9050817489624023, 'mnli-mm_test_prompt,adapter_eval_mnli-mm/acc': 0.7014849471114727, 'mnli_dev_eval_loss': 1.8987709283828735, 'mnli_dev_eval_mnli/acc': 0.6875, 'mnli_test_eval_loss': 1.9339981079101562, 'mnli_test_eval_mnli/acc': 0.6922058074375955, 'mnli-mm_test_eval_loss': 1.9050817489624023, 'mnli-mm_test_eval_mnli-mm/acc': 0.7014849471114727, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-29384', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_20-40-56_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-29384', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_adapter_eval_loss': 2.242093563079834, 'rte_dev_adapter_eval_acc': 0.625, 'rte_test_adapter_eval_loss': 2.572796583175659, 'rte_test_adapter_eval_acc': 0.555956678700361, 'rte_dev_eval_loss': 2.242093563079834, 'rte_dev_eval_acc': 0.625, 'rte_test_eval_loss': 2.572796583175659, 'rte_test_eval_acc': 0.555956678700361, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--100-roberta-large-29798', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_21-18-03_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--100-roberta-large-29798', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,adapter_eval_loss': 2.1146302223205566, 'sts-b_dev_prompt,adapter_eval_pearson': 0.8284723936676606, 'sts-b_dev_prompt,adapter_eval_spearmanr': 0.8317739654623285, 'sts-b_dev_prompt,adapter_eval_corr': 0.8301231795649946, 'sts-b_test_prompt,adapter_eval_loss': 2.193105459213257, 'sts-b_test_prompt,adapter_eval_pearson': 0.556680956347337, 'sts-b_test_prompt,adapter_eval_spearmanr': 0.5595378761743786, 'sts-b_test_prompt,adapter_eval_corr': 0.5581094162608577, 'sts-b_dev_eval_loss': 2.1146302223205566, 'sts-b_dev_eval_pearson': 0.8284723936676606, 'sts-b_dev_eval_spearmanr': 0.8317739654623285, 'sts-b_dev_eval_corr': 0.8301231795649946, 'sts-b_test_eval_loss': 2.193105459213257, 'sts-b_test_eval_pearson': 0.556680956347337, 'sts-b_test_eval_spearmanr': 0.5595378761743786, 'sts-b_test_eval_corr': 0.5581094162608577, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-42-roberta-large-8096', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_21-05-26_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-42-roberta-large-8096', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias_eval_loss': 2.380918264389038, 'mrpc_dev_prompt,bias_eval_acc': 0.625, 'mrpc_dev_prompt,bias_eval_f1': 0.6000000000000001, 'mrpc_dev_prompt,bias_eval_acc_and_f1': 0.6125, 'mrpc_test_prompt,bias_eval_loss': 2.876239061355591, 'mrpc_test_prompt,bias_eval_acc': 0.5759803921568627, 'mrpc_test_prompt,bias_eval_f1': 0.6802218114602588, 'mrpc_test_prompt,bias_eval_acc_and_f1': 0.6281011018085607, 'mrpc_dev_eval_loss': 2.380918264389038, 'mrpc_dev_eval_acc': 0.625, 'mrpc_dev_eval_f1': 0.6000000000000001, 'mrpc_dev_eval_acc_and_f1': 0.6125, 'mrpc_test_eval_loss': 2.876239061355591, 'mrpc_test_eval_acc': 0.5759803921568627, 'mrpc_test_eval_f1': 0.6802218114602588, 'mrpc_test_eval_acc_and_f1': 0.6281011018085607, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-100-roberta-large-16944', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_21-18-21_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-100-roberta-large-16944', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt_eval_loss': 0.5062870979309082, 'sst-2_dev_prompt_eval_acc': 0.78125, 'sst-2_test_prompt_eval_loss': 0.6384443640708923, 'sst-2_test_prompt_eval_acc': 0.6880733944954128, 'sst-2_dev_eval_loss': 0.5062870979309082, 'sst-2_dev_eval_acc': 0.78125, 'sst-2_test_eval_loss': 0.6384443640708923, 'sst-2_test_eval_acc': 0.6880733944954128, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-27260', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_21-19-11_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-27260', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias_eval_loss': 1.908016324043274, 'cola_dev_prompt,bias_eval_mcc': 0.5726562866782, 'cola_test_prompt,bias_eval_loss': 1.7399101257324219, 'cola_test_prompt,bias_eval_mcc': 0.31700692643351513, 'cola_dev_eval_loss': 1.908016324043274, 'cola_dev_eval_mcc': 0.5726562866782, 'cola_test_eval_loss': 1.7399101257324219, 'cola_test_eval_mcc': 0.31700692643351513, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-4697', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_21-29-11_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-4697', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias_eval_loss': 1.2646396160125732, 'qnli_dev_prompt,bias_eval_acc': 0.84375, 'qnli_test_prompt,bias_eval_loss': 2.4510483741760254, 'qnli_test_prompt,bias_eval_acc': 0.6093721398498994, 'qnli_dev_eval_loss': 1.2646396160125732, 'qnli_dev_eval_acc': 0.84375, 'qnli_test_eval_loss': 2.4510483741760254, 'qnli_test_eval_acc': 0.6093721398498994, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-100-roberta-large-31669', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_21-29-57_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-100-roberta-large-31669', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,adapter_eval_loss': 0.6975136399269104, 'rte_dev_prompt,adapter_eval_acc': 0.5, 'rte_test_prompt,adapter_eval_loss': 0.702562689781189, 'rte_test_prompt,adapter_eval_acc': 0.4729241877256318, 'rte_dev_eval_loss': 0.6975136399269104, 'rte_dev_eval_acc': 0.5, 'rte_test_eval_loss': 0.702562689781189, 'rte_test_eval_acc': 0.4729241877256318, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-42-roberta-large-32704', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_21-32-51_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-42-roberta-large-32704', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias_eval_loss': 1.9624512195587158, 'mrpc_dev_prompt,bias_eval_acc': 0.65625, 'mrpc_dev_prompt,bias_eval_f1': 0.6206896551724138, 'mrpc_dev_prompt,bias_eval_acc_and_f1': 0.6384698275862069, 'mrpc_test_prompt,bias_eval_loss': 2.395456552505493, 'mrpc_test_prompt,bias_eval_acc': 0.5882352941176471, 'mrpc_test_prompt,bias_eval_f1': 0.6705882352941177, 'mrpc_test_prompt,bias_eval_acc_and_f1': 0.6294117647058823, 'mrpc_dev_eval_loss': 1.9624512195587158, 'mrpc_dev_eval_acc': 0.65625, 'mrpc_dev_eval_f1': 0.6206896551724138, 'mrpc_dev_eval_acc_and_f1': 0.6384698275862069, 'mrpc_test_eval_loss': 2.395456552505493, 'mrpc_test_eval_acc': 0.5882352941176471, 'mrpc_test_eval_f1': 0.6705882352941177, 'mrpc_test_eval_acc_and_f1': 0.6294117647058823, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-100-roberta-large-878', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_21-33-51_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-100-roberta-large-878', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt_eval_loss': 0.5410196781158447, 'sst-2_dev_prompt_eval_acc': 0.8125, 'sst-2_test_prompt_eval_loss': 0.5592616200447083, 'sst-2_test_prompt_eval_acc': 0.7408256880733946, 'sst-2_dev_eval_loss': 0.5410196781158447, 'sst-2_dev_eval_acc': 0.8125, 'sst-2_test_eval_loss': 0.5592616200447083, 'sst-2_test_eval_acc': 0.7408256880733946, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-14056', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_21-37-05_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-14056', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias_eval_loss': 2.3931167125701904, 'cola_dev_prompt,bias_eval_mcc': 0.44539933408304444, 'cola_test_prompt,bias_eval_loss': 2.380666732788086, 'cola_test_prompt,bias_eval_mcc': 0.2722723459637005, 'cola_dev_eval_loss': 2.3931167125701904, 'cola_dev_eval_mcc': 0.44539933408304444, 'cola_test_eval_loss': 2.380666732788086, 'cola_test_eval_mcc': 0.2722723459637005, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-23632', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_21-44-43_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-23632', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,adapter_eval_loss': 2.1185028553009033, 'sts-b_dev_prompt,adapter_eval_pearson': 0.7762281728362945, 'sts-b_dev_prompt,adapter_eval_spearmanr': 0.7979814263488225, 'sts-b_dev_prompt,adapter_eval_corr': 0.7871047995925585, 'sts-b_test_prompt,adapter_eval_loss': 2.2017054557800293, 'sts-b_test_prompt,adapter_eval_pearson': 0.5180495684994864, 'sts-b_test_prompt,adapter_eval_spearmanr': 0.520575930002437, 'sts-b_test_prompt,adapter_eval_corr': 0.5193127492509617, 'sts-b_dev_eval_loss': 2.1185028553009033, 'sts-b_dev_eval_pearson': 0.7762281728362945, 'sts-b_dev_eval_spearmanr': 0.7979814263488225, 'sts-b_dev_eval_corr': 0.7871047995925585, 'sts-b_test_eval_loss': 2.2017054557800293, 'sts-b_test_eval_pearson': 0.5180495684994864, 'sts-b_test_eval_spearmanr': 0.520575930002437, 'sts-b_test_eval_corr': 0.5193127492509617, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-42-roberta-large-10750', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_21-33-42_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-42-roberta-large-10750', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias_eval_loss': 2.3166396617889404, 'qnli_dev_prompt,bias_eval_acc': 0.75, 'qnli_test_prompt,bias_eval_loss': 3.6135387420654297, 'qnli_test_prompt,bias_eval_acc': 0.5923485264506682, 'qnli_dev_eval_loss': 2.3166396617889404, 'qnli_dev_eval_acc': 0.75, 'qnli_test_eval_loss': 3.6135387420654297, 'qnli_test_eval_acc': 0.5923485264506682, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-100-roberta-large-2098', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_21-46-38_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-100-roberta-large-2098', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,adapter_eval_loss': 4.625227451324463, 'rte_dev_prompt,adapter_eval_acc': 0.5625, 'rte_test_prompt,adapter_eval_loss': 4.321556091308594, 'rte_test_prompt,adapter_eval_acc': 0.5379061371841155, 'rte_dev_eval_loss': 4.625227451324463, 'rte_dev_eval_acc': 0.5625, 'rte_test_eval_loss': 4.321556091308594, 'rte_test_eval_acc': 0.5379061371841155, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-42-roberta-large-17638', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_21-49-06_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-42-roberta-large-17638', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias_eval_loss': 1.752244234085083, 'mrpc_dev_prompt,bias_eval_acc': 0.5625, 'mrpc_dev_prompt,bias_eval_f1': 0.5333333333333333, 'mrpc_dev_prompt,bias_eval_acc_and_f1': 0.5479166666666666, 'mrpc_test_prompt,bias_eval_loss': 1.8976436853408813, 'mrpc_test_prompt,bias_eval_acc': 0.5857843137254902, 'mrpc_test_prompt,bias_eval_f1': 0.6599597585513078, 'mrpc_test_prompt,bias_eval_acc_and_f1': 0.622872036138399, 'mrpc_dev_eval_loss': 1.752244234085083, 'mrpc_dev_eval_acc': 0.5625, 'mrpc_dev_eval_f1': 0.5333333333333333, 'mrpc_dev_eval_acc_and_f1': 0.5479166666666666, 'mrpc_test_eval_loss': 1.8976436853408813, 'mrpc_test_eval_acc': 0.5857843137254902, 'mrpc_test_eval_f1': 0.6599597585513078, 'mrpc_test_eval_acc_and_f1': 0.622872036138399, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-16-prompt-100-roberta-large-30451', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_21-49-43_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-100-roberta-large-30451', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt_eval_loss': 0.7823799252510071, 'sst-2_dev_prompt_eval_acc': 0.625, 'sst-2_test_prompt_eval_loss': 0.8672601580619812, 'sst-2_test_prompt_eval_acc': 0.5584862385321101, 'sst-2_dev_eval_loss': 0.7823799252510071, 'sst-2_dev_eval_acc': 0.625, 'sst-2_test_eval_loss': 0.8672601580619812, 'sst-2_test_eval_acc': 0.5584862385321101, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-29107', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_21-54-09_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-29107', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,bias,adapter_eval_loss': 3.625638484954834, 'qqp_dev_prompt,bias,adapter_eval_acc': 0.75, 'qqp_dev_prompt,bias,adapter_eval_f1': 0.7777777777777777, 'qqp_dev_prompt,bias,adapter_eval_acc_and_f1': 0.7638888888888888, 'qqp_test_prompt,bias,adapter_eval_loss': 3.9455981254577637, 'qqp_test_prompt,bias,adapter_eval_acc': 0.6845906505070493, 'qqp_test_prompt,bias,adapter_eval_f1': 0.6553699800010812, 'qqp_test_prompt,bias,adapter_eval_acc_and_f1': 0.6699803152540652, 'qqp_dev_eval_loss': 3.625638484954834, 'qqp_dev_eval_acc': 0.75, 'qqp_dev_eval_f1': 0.7777777777777777, 'qqp_dev_eval_acc_and_f1': 0.7638888888888888, 'qqp_test_eval_loss': 3.9455981254577637, 'qqp_test_eval_acc': 0.6845906505070493, 'qqp_test_eval_f1': 0.6553699800010812, 'qqp_test_eval_acc_and_f1': 0.6699803152540652, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16-prompt-13-roberta-large-29926', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_21-32-04_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-13-roberta-large-29926', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias_eval_loss': 2.616469144821167, 'cola_dev_prompt,bias_eval_mcc': 0.2886751345948129, 'cola_test_prompt,bias_eval_loss': 1.9861838817596436, 'cola_test_prompt,bias_eval_mcc': 0.21959434369125658, 'cola_dev_eval_loss': 2.616469144821167, 'cola_dev_eval_mcc': 0.2886751345948129, 'cola_test_eval_loss': 1.9861838817596436, 'cola_test_eval_mcc': 0.21959434369125658, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-2213', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_22-00-35_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-2213', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias_eval_loss': 3.0290307998657227, 'qnli_dev_prompt,bias_eval_acc': 0.6875, 'qnli_test_prompt,bias_eval_loss': 3.797590732574463, 'qnli_test_prompt,bias_eval_acc': 0.5390810909756544, 'qnli_dev_eval_loss': 3.0290307998657227, 'qnli_dev_eval_acc': 0.6875, 'qnli_test_eval_loss': 3.797590732574463, 'qnli_test_eval_acc': 0.5390810909756544, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-100-roberta-large-30583', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_22-03-09_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-100-roberta-large-30583', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,adapter_eval_loss': 3.5462591648101807, 'rte_dev_prompt,adapter_eval_acc': 0.5625, 'rte_test_prompt,adapter_eval_loss': 3.2989397048950195, 'rte_test_prompt,adapter_eval_acc': 0.5703971119133574, 'rte_dev_eval_loss': 3.5462591648101807, 'rte_dev_eval_acc': 0.5625, 'rte_test_eval_loss': 3.2989397048950195, 'rte_test_eval_acc': 0.5703971119133574, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-42-roberta-large-28464', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_22-05-11_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-42-roberta-large-28464', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,adapter_eval_loss': 2.340829610824585, 'mnli_dev_prompt,adapter_eval_mnli/acc': 0.6875, 'mnli_test_prompt,adapter_eval_loss': 2.1590607166290283, 'mnli_test_prompt,adapter_eval_mnli/acc': 0.6959755476311767, 'mnli-mm_test_prompt,adapter_eval_loss': 2.2563328742980957, 'mnli-mm_test_prompt,adapter_eval_mnli-mm/acc': 0.7013832384052074, 'mnli_dev_eval_loss': 2.340829610824585, 'mnli_dev_eval_mnli/acc': 0.6875, 'mnli_test_eval_loss': 2.1590607166290283, 'mnli_test_eval_mnli/acc': 0.6959755476311767, 'mnli-mm_test_eval_loss': 2.2563328742980957, 'mnli-mm_test_eval_mnli-mm/acc': 0.7013832384052074, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-2391', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_21-32-12_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-2391', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias,adapter_eval_loss': 0.6959037184715271, 'mrpc_dev_bias,adapter_eval_acc': 0.5, 'mrpc_dev_bias,adapter_eval_f1': 0.6666666666666666, 'mrpc_dev_bias,adapter_eval_acc_and_f1': 0.5833333333333333, 'mrpc_test_bias,adapter_eval_loss': 0.668579638004303, 'mrpc_test_bias,adapter_eval_acc': 0.6838235294117647, 'mrpc_test_bias,adapter_eval_f1': 0.8122270742358079, 'mrpc_test_bias,adapter_eval_acc_and_f1': 0.7480253018237863, 'mrpc_dev_eval_loss': 0.6959037184715271, 'mrpc_dev_eval_acc': 0.5, 'mrpc_dev_eval_f1': 0.6666666666666666, 'mrpc_dev_eval_acc_and_f1': 0.5833333333333333, 'mrpc_test_eval_loss': 0.668579638004303, 'mrpc_test_eval_acc': 0.6838235294117647, 'mrpc_test_eval_f1': 0.8122270742358079, 'mrpc_test_eval_acc_and_f1': 0.7480253018237863, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--42-roberta-large-2698', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_22-05-29_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--42-roberta-large-2698', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt_eval_loss': 1.8880767822265625, 'sst-2_dev_prompt_eval_acc': 0.65625, 'sst-2_test_prompt_eval_loss': 1.764533281326294, 'sst-2_test_prompt_eval_acc': 0.6227064220183486, 'sst-2_dev_eval_loss': 1.8880767822265625, 'sst-2_dev_eval_acc': 0.65625, 'sst-2_test_eval_loss': 1.764533281326294, 'sst-2_test_eval_acc': 0.6227064220183486, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-7118', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_22-13-07_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-7118', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,adapter_eval_loss': 2.112898588180542, 'sts-b_dev_prompt,adapter_eval_pearson': 0.31358215210780677, 'sts-b_dev_prompt,adapter_eval_spearmanr': 0.3355426783744763, 'sts-b_dev_prompt,adapter_eval_corr': 0.32456241524114154, 'sts-b_test_prompt,adapter_eval_loss': 2.2137632369995117, 'sts-b_test_prompt,adapter_eval_pearson': 0.008661022040931231, 'sts-b_test_prompt,adapter_eval_spearmanr': 0.004516786160665534, 'sts-b_test_prompt,adapter_eval_corr': 0.006588904100798383, 'sts-b_dev_eval_loss': 2.112898588180542, 'sts-b_dev_eval_pearson': 0.31358215210780677, 'sts-b_dev_eval_spearmanr': 0.3355426783744763, 'sts-b_dev_eval_corr': 0.32456241524114154, 'sts-b_test_eval_loss': 2.2137632369995117, 'sts-b_test_eval_pearson': 0.008661022040931231, 'sts-b_test_eval_spearmanr': 0.004516786160665534, 'sts-b_test_eval_corr': 0.006588904100798383, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-100-roberta-large-9178', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_22-02-10_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-100-roberta-large-9178', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias,adapter_eval_loss': 0.6933258771896362, 'cola_dev_bias,adapter_eval_mcc': 0.0, 'cola_test_bias,adapter_eval_loss': 0.7007930874824524, 'cola_test_bias,adapter_eval_mcc': 0.0, 'cola_dev_eval_loss': 0.6933258771896362, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.7007930874824524, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--42-roberta-large-22092', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_22-16-08_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-22092', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias_eval_loss': 2.776113510131836, 'qnli_dev_prompt,bias_eval_acc': 0.625, 'qnli_test_prompt,bias_eval_loss': 3.0690486431121826, 'qnli_test_prompt,bias_eval_acc': 0.5350539996339008, 'qnli_dev_eval_loss': 2.776113510131836, 'qnli_dev_eval_acc': 0.625, 'qnli_test_eval_loss': 3.0690486431121826, 'qnli_test_eval_acc': 0.5350539996339008, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-100-roberta-large-27819', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_22-20-10_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-100-roberta-large-27819', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,adapter_eval_loss': 3.210808038711548, 'rte_dev_prompt,adapter_eval_acc': 0.5, 'rte_test_prompt,adapter_eval_loss': 2.6690514087677, 'rte_test_prompt,adapter_eval_acc': 0.5451263537906137, 'rte_dev_eval_loss': 3.210808038711548, 'rte_dev_eval_acc': 0.5, 'rte_test_eval_loss': 2.6690514087677, 'rte_test_eval_acc': 0.5451263537906137, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-42-roberta-large-1207', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_22-21-43_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-42-roberta-large-1207', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias,adapter_eval_loss': 0.49104905128479004, 'mrpc_dev_bias,adapter_eval_acc': 0.9375, 'mrpc_dev_bias,adapter_eval_f1': 0.9375, 'mrpc_dev_bias,adapter_eval_acc_and_f1': 0.9375, 'mrpc_test_bias,adapter_eval_loss': 1.7684926986694336, 'mrpc_test_bias,adapter_eval_acc': 0.7034313725490197, 'mrpc_test_bias,adapter_eval_f1': 0.781981981981982, 'mrpc_test_bias,adapter_eval_acc_and_f1': 0.7427066772655009, 'mrpc_dev_eval_loss': 0.49104905128479004, 'mrpc_dev_eval_acc': 0.9375, 'mrpc_dev_eval_f1': 0.9375, 'mrpc_dev_eval_acc_and_f1': 0.9375, 'mrpc_test_eval_loss': 1.7684926986694336, 'mrpc_test_eval_acc': 0.7034313725490197, 'mrpc_test_eval_f1': 0.781981981981982, 'mrpc_test_eval_acc_and_f1': 0.7427066772655009, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--42-roberta-large-1089', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_22-24-47_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--42-roberta-large-1089', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt_eval_loss': 0.6733819246292114, 'sst-2_dev_prompt_eval_acc': 0.75, 'sst-2_test_prompt_eval_loss': 0.7591399550437927, 'sst-2_test_prompt_eval_acc': 0.6261467889908257, 'sst-2_dev_eval_loss': 0.6733819246292114, 'sst-2_dev_eval_acc': 0.75, 'sst-2_test_eval_loss': 0.7591399550437927, 'sst-2_test_eval_acc': 0.6261467889908257, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-6273', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_22-28-39_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-6273', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,adapter_eval_loss': 2.8089280128479004, 'rte_dev_prompt,adapter_eval_acc': 0.5625, 'rte_test_prompt,adapter_eval_loss': 2.9367384910583496, 'rte_test_prompt,adapter_eval_acc': 0.5126353790613718, 'rte_dev_eval_loss': 2.8089280128479004, 'rte_dev_eval_acc': 0.5625, 'rte_test_eval_loss': 2.9367384910583496, 'rte_test_eval_acc': 0.5126353790613718, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-100-roberta-large-17444', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_22-37-46_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-100-roberta-large-17444', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias,adapter_eval_loss': 3.4267144203186035, 'cola_dev_bias,adapter_eval_mcc': 0.5039526306789696, 'cola_test_bias,adapter_eval_loss': 5.459599494934082, 'cola_test_bias,adapter_eval_mcc': 0.15806920596528204, 'cola_dev_eval_loss': 3.4267144203186035, 'cola_dev_eval_mcc': 0.5039526306789696, 'cola_test_eval_loss': 5.459599494934082, 'cola_test_eval_mcc': 0.15806920596528204, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--42-roberta-large-31568', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_22-35-20_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-31568', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,bias,adapter_eval_loss': 3.3972809314727783, 'qqp_dev_prompt,bias,adapter_eval_acc': 0.625, 'qqp_dev_prompt,bias,adapter_eval_f1': 0.6470588235294118, 'qqp_dev_prompt,bias,adapter_eval_acc_and_f1': 0.6360294117647058, 'qqp_test_prompt,bias,adapter_eval_loss': 3.698082685470581, 'qqp_test_prompt,bias,adapter_eval_acc': 0.5740786544645066, 'qqp_test_prompt,bias,adapter_eval_f1': 0.5580762716214135, 'qqp_test_prompt,bias,adapter_eval_acc_and_f1': 0.56607746304296, 'qqp_dev_eval_loss': 3.3972809314727783, 'qqp_dev_eval_acc': 0.625, 'qqp_dev_eval_f1': 0.6470588235294118, 'qqp_dev_eval_acc_and_f1': 0.6360294117647058, 'qqp_test_eval_loss': 3.698082685470581, 'qqp_test_eval_acc': 0.5740786544645066, 'qqp_test_eval_f1': 0.5580762716214135, 'qqp_test_eval_acc_and_f1': 0.56607746304296, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16-prompt-13-roberta-large-2089', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_22-15-01_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-13-roberta-large-2089', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,adapter_eval_loss': 2.090094804763794, 'sts-b_dev_prompt,adapter_eval_pearson': 0.7516378161716979, 'sts-b_dev_prompt,adapter_eval_spearmanr': 0.7121617882551561, 'sts-b_dev_prompt,adapter_eval_corr': 0.731899802213427, 'sts-b_test_prompt,adapter_eval_loss': 2.193009853363037, 'sts-b_test_prompt,adapter_eval_pearson': 0.6050243874296867, 'sts-b_test_prompt,adapter_eval_spearmanr': 0.6254989013029946, 'sts-b_test_prompt,adapter_eval_corr': 0.6152616443663406, 'sts-b_dev_eval_loss': 2.090094804763794, 'sts-b_dev_eval_pearson': 0.7516378161716979, 'sts-b_dev_eval_spearmanr': 0.7121617882551561, 'sts-b_dev_eval_corr': 0.731899802213427, 'sts-b_test_eval_loss': 2.193009853363037, 'sts-b_test_eval_pearson': 0.6050243874296867, 'sts-b_test_eval_spearmanr': 0.6254989013029946, 'sts-b_test_eval_corr': 0.6152616443663406, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-100-roberta-large-30043', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_22-29-47_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-100-roberta-large-30043', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias,adapter_eval_loss': 0.6943245530128479, 'qnli_dev_bias,adapter_eval_acc': 0.5, 'qnli_test_bias,adapter_eval_loss': 0.6948670148849487, 'qnli_test_bias,adapter_eval_acc': 0.4946000366099213, 'qnli_dev_eval_loss': 0.6943245530128479, 'qnli_dev_eval_acc': 0.5, 'qnli_test_eval_loss': 0.6948670148849487, 'qnli_test_eval_acc': 0.4946000366099213, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--42-roberta-large-16861', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_22-36-57_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--42-roberta-large-16861', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias,adapter_eval_loss': 0.9796488881111145, 'mrpc_dev_bias,adapter_eval_acc': 0.75, 'mrpc_dev_bias,adapter_eval_f1': 0.7777777777777777, 'mrpc_dev_bias,adapter_eval_acc_and_f1': 0.7638888888888888, 'mrpc_test_bias,adapter_eval_loss': 1.8395227193832397, 'mrpc_test_bias,adapter_eval_acc': 0.6642156862745098, 'mrpc_test_bias,adapter_eval_f1': 0.7467652495378928, 'mrpc_test_bias,adapter_eval_acc_and_f1': 0.7054904679062013, 'mrpc_dev_eval_loss': 0.9796488881111145, 'mrpc_dev_eval_acc': 0.75, 'mrpc_dev_eval_f1': 0.7777777777777777, 'mrpc_dev_eval_acc_and_f1': 0.7638888888888888, 'mrpc_test_eval_loss': 1.8395227193832397, 'mrpc_test_eval_acc': 0.6642156862745098, 'mrpc_test_eval_f1': 0.7467652495378928, 'mrpc_test_eval_acc_and_f1': 0.7054904679062013, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--42-roberta-large-28681', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_22-43-43_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--42-roberta-large-28681', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt_eval_loss': 0.46604788303375244, 'sst-2_dev_prompt_eval_acc': 0.90625, 'sst-2_test_prompt_eval_loss': 0.5291203856468201, 'sst-2_test_prompt_eval_acc': 0.7534403669724771, 'sst-2_dev_eval_loss': 0.46604788303375244, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 0.5291203856468201, 'sst-2_test_eval_acc': 0.7534403669724771, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-2615', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_22-45-46_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-2615', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,adapter_eval_loss': 2.598970651626587, 'rte_dev_prompt,adapter_eval_acc': 0.5625, 'rte_test_prompt,adapter_eval_loss': 2.312457799911499, 'rte_test_prompt,adapter_eval_acc': 0.5992779783393501, 'rte_dev_eval_loss': 2.598970651626587, 'rte_dev_eval_acc': 0.5625, 'rte_test_eval_loss': 2.312457799911499, 'rte_test_eval_acc': 0.5992779783393501, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-100-roberta-large-10840', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_22-53-44_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-100-roberta-large-10840', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,adapter_eval_loss': 2.1386892795562744, 'mnli_dev_prompt,adapter_eval_mnli/acc': 0.7083333333333334, 'mnli_test_prompt,adapter_eval_loss': 1.8361886739730835, 'mnli_test_prompt,adapter_eval_mnli/acc': 0.6900662251655629, 'mnli-mm_test_prompt,adapter_eval_loss': 1.9020155668258667, 'mnli-mm_test_prompt,adapter_eval_mnli-mm/acc': 0.6986371033360456, 'mnli_dev_eval_loss': 2.1386892795562744, 'mnli_dev_eval_mnli/acc': 0.7083333333333334, 'mnli_test_eval_loss': 1.8361886739730835, 'mnli_test_eval_mnli/acc': 0.6900662251655629, 'mnli-mm_test_eval_loss': 1.9020155668258667, 'mnli-mm_test_eval_mnli-mm/acc': 0.6986371033360456, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-16174', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_22-22-03_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-16174', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias,adapter_eval_loss': 2.879084587097168, 'cola_dev_bias,adapter_eval_mcc': 0.5039526306789696, 'cola_test_bias,adapter_eval_loss': 3.825629234313965, 'cola_test_bias,adapter_eval_mcc': 0.07963199797336519, 'cola_dev_eval_loss': 2.879084587097168, 'cola_dev_eval_mcc': 0.5039526306789696, 'cola_test_eval_loss': 3.825629234313965, 'cola_test_eval_mcc': 0.07963199797336519, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--42-roberta-large-30245', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_22-54-38_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-30245', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias,adapter_eval_loss': 2.3993542194366455, 'qnli_dev_bias,adapter_eval_acc': 0.59375, 'qnli_test_bias,adapter_eval_loss': 2.63161039352417, 'qnli_test_bias,adapter_eval_acc': 0.5427420831045213, 'qnli_dev_eval_loss': 2.3993542194366455, 'qnli_dev_eval_acc': 0.59375, 'qnli_test_eval_loss': 2.63161039352417, 'qnli_test_eval_acc': 0.5427420831045213, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--42-roberta-large-10950', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_22-57-26_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--42-roberta-large-10950', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias_eval_loss': 1.111452579498291, 'sst-2_dev_bias_eval_acc': 0.84375, 'sst-2_test_bias_eval_loss': 1.171495795249939, 'sst-2_test_bias_eval_acc': 0.8302752293577982, 'sst-2_dev_eval_loss': 1.111452579498291, 'sst-2_dev_eval_acc': 0.84375, 'sst-2_test_eval_loss': 1.171495795249939, 'sst-2_test_eval_acc': 0.8302752293577982, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--42-roberta-large-2787', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_23-03-07_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--42-roberta-large-2787', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias,adapter_eval_loss': 1.439862608909607, 'mrpc_dev_bias,adapter_eval_acc': 0.6875, 'mrpc_dev_bias,adapter_eval_f1': 0.75, 'mrpc_dev_bias,adapter_eval_acc_and_f1': 0.71875, 'mrpc_test_bias,adapter_eval_loss': 2.1325676441192627, 'mrpc_test_bias,adapter_eval_acc': 0.6813725490196079, 'mrpc_test_bias,adapter_eval_f1': 0.7766323024054983, 'mrpc_test_bias,adapter_eval_acc_and_f1': 0.7290024257125531, 'mrpc_dev_eval_loss': 1.439862608909607, 'mrpc_dev_eval_acc': 0.6875, 'mrpc_dev_eval_f1': 0.75, 'mrpc_dev_eval_acc_and_f1': 0.71875, 'mrpc_test_eval_loss': 2.1325676441192627, 'mrpc_test_eval_acc': 0.6813725490196079, 'mrpc_test_eval_f1': 0.7766323024054983, 'mrpc_test_eval_acc_and_f1': 0.7290024257125531, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--42-roberta-large-4674', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_23-02-38_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--42-roberta-large-4674', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,adapter_eval_loss': 1.6906548738479614, 'rte_dev_prompt,adapter_eval_acc': 0.71875, 'rte_test_prompt,adapter_eval_loss': 2.0885510444641113, 'rte_test_prompt,adapter_eval_acc': 0.6173285198555957, 'rte_dev_eval_loss': 1.6906548738479614, 'rte_dev_eval_acc': 0.71875, 'rte_test_eval_loss': 2.0885510444641113, 'rte_test_eval_acc': 0.6173285198555957, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-100-roberta-large-13914', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_23-09-49_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-100-roberta-large-13914', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,adapter_eval_loss': 2.1021764278411865, 'sts-b_dev_prompt,adapter_eval_pearson': 0.6887127140039434, 'sts-b_dev_prompt,adapter_eval_spearmanr': 0.6295789775819729, 'sts-b_dev_prompt,adapter_eval_corr': 0.6591458457929582, 'sts-b_test_prompt,adapter_eval_loss': 2.2212636470794678, 'sts-b_test_prompt,adapter_eval_pearson': 0.524595538573151, 'sts-b_test_prompt,adapter_eval_spearmanr': 0.5139784806037446, 'sts-b_test_prompt,adapter_eval_corr': 0.5192870095884479, 'sts-b_dev_eval_loss': 2.1021764278411865, 'sts-b_dev_eval_pearson': 0.6887127140039434, 'sts-b_dev_eval_spearmanr': 0.6295789775819729, 'sts-b_dev_eval_corr': 0.6591458457929582, 'sts-b_test_eval_loss': 2.2212636470794678, 'sts-b_test_eval_pearson': 0.524595538573151, 'sts-b_test_eval_spearmanr': 0.5139784806037446, 'sts-b_test_eval_corr': 0.5192870095884479, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-100-roberta-large-26015', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_22-57-12_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-100-roberta-large-26015', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias,adapter_eval_loss': 3.2278218269348145, 'cola_dev_bias,adapter_eval_mcc': 0.31814238148788887, 'cola_test_bias,adapter_eval_loss': 3.8281362056732178, 'cola_test_bias,adapter_eval_mcc': 0.08043839053095042, 'cola_dev_eval_loss': 3.2278218269348145, 'cola_dev_eval_mcc': 0.31814238148788887, 'cola_test_eval_loss': 3.8281362056732178, 'cola_test_eval_mcc': 0.08043839053095042, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--42-roberta-large-12737', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_23-14-00_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--42-roberta-large-12737', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,bias,adapter_eval_loss': 3.5023443698883057, 'qqp_dev_prompt,bias,adapter_eval_acc': 0.625, 'qqp_dev_prompt,bias,adapter_eval_f1': 0.625, 'qqp_dev_prompt,bias,adapter_eval_acc_and_f1': 0.625, 'qqp_test_prompt,bias,adapter_eval_loss': 2.731736898422241, 'qqp_test_prompt,bias,adapter_eval_acc': 0.5907989116992333, 'qqp_test_prompt,bias,adapter_eval_f1': 0.5077948351779127, 'qqp_test_prompt,bias,adapter_eval_acc_and_f1': 0.549296873438573, 'qqp_dev_eval_loss': 3.5023443698883057, 'qqp_dev_eval_acc': 0.625, 'qqp_dev_eval_f1': 0.625, 'qqp_dev_eval_acc_and_f1': 0.625, 'qqp_test_eval_loss': 2.731736898422241, 'qqp_test_eval_acc': 0.5907989116992333, 'qqp_test_eval_f1': 0.5077948351779127, 'qqp_test_eval_acc_and_f1': 0.549296873438573, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16-prompt-13-roberta-large-29135', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_22-56-15_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-13-roberta-large-29135', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-13', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias,adapter_eval_loss': 0.7235243916511536, 'mrpc_dev_bias,adapter_eval_acc': 0.5, 'mrpc_dev_bias,adapter_eval_f1': 0.6666666666666666, 'mrpc_dev_bias,adapter_eval_acc_and_f1': 0.5833333333333333, 'mrpc_test_bias,adapter_eval_loss': 0.6324561834335327, 'mrpc_test_bias,adapter_eval_acc': 0.6838235294117647, 'mrpc_test_bias,adapter_eval_f1': 0.8122270742358079, 'mrpc_test_bias,adapter_eval_acc_and_f1': 0.7480253018237863, 'mrpc_dev_eval_loss': 0.7235243916511536, 'mrpc_dev_eval_acc': 0.5, 'mrpc_dev_eval_f1': 0.6666666666666666, 'mrpc_dev_eval_acc_and_f1': 0.5833333333333333, 'mrpc_test_eval_loss': 0.6324561834335327, 'mrpc_test_eval_acc': 0.6838235294117647, 'mrpc_test_eval_f1': 0.8122270742358079, 'mrpc_test_eval_acc_and_f1': 0.7480253018237863, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--100-roberta-large-28276', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_23-21-21_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--100-roberta-large-28276', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias_eval_loss': 0.4609953463077545, 'sst-2_dev_bias_eval_acc': 0.96875, 'sst-2_test_bias_eval_loss': 1.1284477710723877, 'sst-2_test_bias_eval_acc': 0.9071100917431193, 'sst-2_dev_eval_loss': 0.4609953463077545, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 1.1284477710723877, 'sst-2_test_eval_acc': 0.9071100917431193, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--42-roberta-large-3470', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_23-21-07_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--42-roberta-large-3470', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,adapter_eval_loss': 1.4021849632263184, 'rte_dev_prompt,adapter_eval_acc': 0.6875, 'rte_test_prompt,adapter_eval_loss': 1.6795761585235596, 'rte_test_prompt,adapter_eval_acc': 0.5884476534296029, 'rte_dev_eval_loss': 1.4021849632263184, 'rte_dev_eval_acc': 0.6875, 'rte_test_eval_loss': 1.6795761585235596, 'rte_test_eval_acc': 0.5884476534296029, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-100-roberta-large-28684', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_23-26-19_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-100-roberta-large-28684', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias,adapter_eval_loss': 2.7633392810821533, 'qnli_dev_bias,adapter_eval_acc': 0.71875, 'qnli_test_bias,adapter_eval_loss': 2.850425958633423, 'qnli_test_bias,adapter_eval_acc': 0.5939959729086582, 'qnli_dev_eval_loss': 2.7633392810821533, 'qnli_dev_eval_acc': 0.71875, 'qnli_test_eval_loss': 2.850425958633423, 'qnli_test_eval_acc': 0.5939959729086582, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--42-roberta-large-14674', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_23-18-20_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--42-roberta-large-14674', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias,adapter_eval_loss': 0.732761025428772, 'cola_dev_bias,adapter_eval_mcc': 0.0, 'cola_test_bias,adapter_eval_loss': 0.8412588834762573, 'cola_test_bias,adapter_eval_mcc': 0.0, 'cola_dev_eval_loss': 0.732761025428772, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.8412588834762573, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--100-roberta-large-17161', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_23-33-16_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-17161', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias_eval_loss': 0.23843978345394135, 'sst-2_dev_bias_eval_acc': 0.96875, 'sst-2_test_bias_eval_loss': 0.6437970995903015, 'sst-2_test_bias_eval_acc': 0.9231651376146789, 'sst-2_dev_eval_loss': 0.23843978345394135, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.6437970995903015, 'sst-2_test_eval_acc': 0.9231651376146789, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--42-roberta-large-32241', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_23-40-50_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--42-roberta-large-32241', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,adapter_eval_loss': 2.1027369499206543, 'sts-b_dev_prompt,adapter_eval_pearson': 0.6919610278239713, 'sts-b_dev_prompt,adapter_eval_spearmanr': 0.6332574992155223, 'sts-b_dev_prompt,adapter_eval_corr': 0.6626092635197468, 'sts-b_test_prompt,adapter_eval_loss': 2.213548421859741, 'sts-b_test_prompt,adapter_eval_pearson': 0.5491950234603334, 'sts-b_test_prompt,adapter_eval_spearmanr': 0.5477459941506048, 'sts-b_test_prompt,adapter_eval_corr': 0.5484705088054691, 'sts-b_dev_eval_loss': 2.1027369499206543, 'sts-b_dev_eval_pearson': 0.6919610278239713, 'sts-b_dev_eval_spearmanr': 0.6332574992155223, 'sts-b_dev_eval_corr': 0.6626092635197468, 'sts-b_test_eval_loss': 2.213548421859741, 'sts-b_test_eval_pearson': 0.5491950234603334, 'sts-b_test_eval_spearmanr': 0.5477459941506048, 'sts-b_test_eval_corr': 0.5484705088054691, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-100-roberta-large-30807', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_23-26-21_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-100-roberta-large-30807', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias_eval_loss': 3.397020101547241, 'rte_dev_prompt,bias_eval_acc': 0.4375, 'rte_test_prompt,bias_eval_loss': 2.8967907428741455, 'rte_test_prompt,bias_eval_acc': 0.49458483754512633, 'rte_dev_eval_loss': 3.397020101547241, 'rte_dev_eval_acc': 0.4375, 'rte_test_eval_loss': 2.8967907428741455, 'rte_test_eval_acc': 0.49458483754512633, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-42-roberta-large-533', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_23-42-31_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-42-roberta-large-533', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias_eval_loss': 4.787450790405273, 'mnli_dev_prompt,bias_eval_mnli/acc': 0.6041666666666666, 'mnli_test_prompt,bias_eval_loss': 3.7231462001800537, 'mnli_test_prompt,bias_eval_mnli/acc': 0.6484971981660723, 'mnli-mm_test_prompt,bias_eval_loss': 3.4710400104522705, 'mnli-mm_test_prompt,bias_eval_mnli-mm/acc': 0.6731082180634662, 'mnli_dev_eval_loss': 4.787450790405273, 'mnli_dev_eval_mnli/acc': 0.6041666666666666, 'mnli_test_eval_loss': 3.7231462001800537, 'mnli_test_eval_mnli/acc': 0.6484971981660723, 'mnli-mm_test_eval_loss': 3.4710400104522705, 'mnli-mm_test_eval_mnli-mm/acc': 0.6731082180634662, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-5010', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_23-12-19_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-5010', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias,adapter_eval_loss': 1.7600765228271484, 'mrpc_dev_bias,adapter_eval_acc': 0.71875, 'mrpc_dev_bias,adapter_eval_f1': 0.7272727272727272, 'mrpc_dev_bias,adapter_eval_acc_and_f1': 0.7230113636363635, 'mrpc_test_bias,adapter_eval_loss': 2.0739502906799316, 'mrpc_test_bias,adapter_eval_acc': 0.6764705882352942, 'mrpc_test_bias,adapter_eval_f1': 0.7582417582417582, 'mrpc_test_bias,adapter_eval_acc_and_f1': 0.7173561732385262, 'mrpc_dev_eval_loss': 1.7600765228271484, 'mrpc_dev_eval_acc': 0.71875, 'mrpc_dev_eval_f1': 0.7272727272727272, 'mrpc_dev_eval_acc_and_f1': 0.7230113636363635, 'mrpc_test_eval_loss': 2.0739502906799316, 'mrpc_test_eval_acc': 0.6764705882352942, 'mrpc_test_eval_f1': 0.7582417582417582, 'mrpc_test_eval_acc_and_f1': 0.7173561732385262, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--100-roberta-large-5708', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_23-40-42_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--100-roberta-large-5708', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias,adapter_eval_loss': 1.992173433303833, 'qnli_dev_bias,adapter_eval_acc': 0.625, 'qnli_test_bias,adapter_eval_loss': 1.9267240762710571, 'qnli_test_bias,adapter_eval_acc': 0.5916163280248947, 'qnli_dev_eval_loss': 1.992173433303833, 'qnli_dev_eval_acc': 0.625, 'qnli_test_eval_loss': 1.9267240762710571, 'qnli_test_eval_acc': 0.5916163280248947, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--42-roberta-large-3232', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_23-46-08_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--42-roberta-large-3232', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias_eval_loss': 0.1625799685716629, 'sst-2_dev_bias_eval_acc': 0.96875, 'sst-2_test_bias_eval_loss': 0.42616796493530273, 'sst-2_test_bias_eval_acc': 0.9231651376146789, 'sst-2_dev_eval_loss': 0.1625799685716629, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.42616796493530273, 'sst-2_test_eval_acc': 0.9231651376146789, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--42-roberta-large-28578', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_23-55-03_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--42-roberta-large-28578', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias,adapter_eval_loss': 2.6820285320281982, 'cola_dev_bias,adapter_eval_mcc': 0.625, 'cola_test_bias,adapter_eval_loss': 3.422485113143921, 'cola_test_bias,adapter_eval_mcc': 0.3243158526914306, 'cola_dev_eval_loss': 2.6820285320281982, 'cola_dev_eval_mcc': 0.625, 'cola_test_eval_loss': 3.422485113143921, 'cola_test_eval_mcc': 0.3243158526914306, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--100-roberta-large-5100', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_23-52-33_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-5100', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias_eval_loss': 3.052818536758423, 'rte_dev_prompt,bias_eval_acc': 0.53125, 'rte_test_prompt,bias_eval_loss': 2.809096097946167, 'rte_test_prompt,bias_eval_acc': 0.5631768953068592, 'rte_dev_eval_loss': 3.052818536758423, 'rte_dev_eval_acc': 0.53125, 'rte_test_eval_loss': 2.809096097946167, 'rte_test_eval_acc': 0.5631768953068592, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-42-roberta-large-17497', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_23-57-50_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-42-roberta-large-17497', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias,adapter_eval_loss': 4.073167324066162, 'mrpc_dev_bias,adapter_eval_acc': 0.65625, 'mrpc_dev_bias,adapter_eval_f1': 0.717948717948718, 'mrpc_dev_bias,adapter_eval_acc_and_f1': 0.687099358974359, 'mrpc_test_bias,adapter_eval_loss': 2.8341920375823975, 'mrpc_test_bias,adapter_eval_acc': 0.7156862745098039, 'mrpc_test_bias,adapter_eval_f1': 0.8129032258064517, 'mrpc_test_bias,adapter_eval_acc_and_f1': 0.7642947501581279, 'mrpc_dev_eval_loss': 4.073167324066162, 'mrpc_dev_eval_acc': 0.65625, 'mrpc_dev_eval_f1': 0.717948717948718, 'mrpc_dev_eval_acc_and_f1': 0.687099358974359, 'mrpc_test_eval_loss': 2.8341920375823975, 'mrpc_test_eval_acc': 0.7156862745098039, 'mrpc_test_eval_f1': 0.8129032258064517, 'mrpc_test_eval_acc_and_f1': 0.7642947501581279, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--100-roberta-large-29610', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_23-59-47_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--100-roberta-large-29610', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias_eval_loss': 2.117271661758423, 'sts-b_dev_prompt,bias_eval_pearson': 0.7912093853572673, 'sts-b_dev_prompt,bias_eval_spearmanr': 0.7772283996106367, 'sts-b_dev_prompt,bias_eval_corr': 0.7842188924839519, 'sts-b_test_prompt,bias_eval_loss': 2.1775383949279785, 'sts-b_test_prompt,bias_eval_pearson': 0.6942455187380588, 'sts-b_test_prompt,bias_eval_spearmanr': 0.699626992874321, 'sts-b_test_prompt,bias_eval_corr': 0.6969362558061899, 'sts-b_dev_eval_loss': 2.117271661758423, 'sts-b_dev_eval_pearson': 0.7912093853572673, 'sts-b_dev_eval_spearmanr': 0.7772283996106367, 'sts-b_dev_eval_corr': 0.7842188924839519, 'sts-b_test_eval_loss': 2.1775383949279785, 'sts-b_test_eval_pearson': 0.6942455187380588, 'sts-b_test_eval_spearmanr': 0.699626992874321, 'sts-b_test_eval_corr': 0.6969362558061899, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-42-roberta-large-6577', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_23-56-29_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-42-roberta-large-6577', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias_eval_loss': 0.7648962140083313, 'sst-2_dev_bias_eval_acc': 0.5, 'sst-2_test_bias_eval_loss': 0.7579010725021362, 'sst-2_test_bias_eval_acc': 0.5091743119266054, 'sst-2_dev_eval_loss': 0.7648962140083313, 'sst-2_dev_eval_acc': 0.5, 'sst-2_test_eval_loss': 0.7579010725021362, 'sst-2_test_eval_acc': 0.5091743119266054, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--100-roberta-large-30177', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_00-08-46_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--100-roberta-large-30177', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias,adapter_eval_loss': 3.015638828277588, 'qnli_dev_bias,adapter_eval_acc': 0.75, 'qnli_test_bias,adapter_eval_loss': 4.338083267211914, 'qnli_test_bias,adapter_eval_acc': 0.5063152114222954, 'qnli_dev_eval_loss': 3.015638828277588, 'qnli_dev_eval_acc': 0.75, 'qnli_test_eval_loss': 4.338083267211914, 'qnli_test_eval_acc': 0.5063152114222954, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--100-roberta-large-15722', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_00-06-14_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--100-roberta-large-15722', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias_eval_loss': 1.5724387168884277, 'rte_dev_prompt,bias_eval_acc': 0.46875, 'rte_test_prompt,bias_eval_loss': 1.4916982650756836, 'rte_test_prompt,bias_eval_acc': 0.5306859205776173, 'rte_dev_eval_loss': 1.5724387168884277, 'rte_dev_eval_acc': 0.46875, 'rte_test_eval_loss': 1.4916982650756836, 'rte_test_eval_acc': 0.5306859205776173, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-42-roberta-large-26216', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_00-12-45_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-42-roberta-large-26216', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias,adapter_eval_loss': 2.083855628967285, 'cola_dev_bias,adapter_eval_mcc': 0.6454972243679028, 'cola_test_bias,adapter_eval_loss': 3.442023277282715, 'cola_test_bias,adapter_eval_mcc': 0.29805331896804843, 'cola_dev_eval_loss': 2.083855628967285, 'cola_dev_eval_mcc': 0.6454972243679028, 'cola_test_eval_loss': 3.442023277282715, 'cola_test_eval_mcc': 0.29805331896804843, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--100-roberta-large-31518', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_00-11-48_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-31518', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias_eval_loss': 0.0019123184029012918, 'sst-2_dev_bias_eval_acc': 1.0, 'sst-2_test_bias_eval_loss': 0.8221665024757385, 'sst-2_test_bias_eval_acc': 0.9139908256880734, 'sst-2_dev_eval_loss': 0.0019123184029012918, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.8221665024757385, 'sst-2_test_eval_acc': 0.9139908256880734, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--100-roberta-large-22265', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_00-23-03_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--100-roberta-large-22265', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias_eval_loss': 2.1191844940185547, 'sts-b_dev_prompt,bias_eval_pearson': 0.7678019243292491, 'sts-b_dev_prompt,bias_eval_spearmanr': 0.7682292995206271, 'sts-b_dev_prompt,bias_eval_corr': 0.7680156119249382, 'sts-b_test_prompt,bias_eval_loss': 2.199648857116699, 'sts-b_test_prompt,bias_eval_pearson': 0.5793961491774966, 'sts-b_test_prompt,bias_eval_spearmanr': 0.5860271161673397, 'sts-b_test_prompt,bias_eval_corr': 0.5827116326724182, 'sts-b_dev_eval_loss': 2.1191844940185547, 'sts-b_dev_eval_pearson': 0.7678019243292491, 'sts-b_dev_eval_spearmanr': 0.7682292995206271, 'sts-b_dev_eval_corr': 0.7680156119249382, 'sts-b_test_eval_loss': 2.199648857116699, 'sts-b_test_eval_pearson': 0.5793961491774966, 'sts-b_test_eval_spearmanr': 0.5860271161673397, 'sts-b_test_eval_corr': 0.5827116326724182, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-42-roberta-large-23216', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_00-20-17_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-42-roberta-large-23216', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias_eval_loss': 2.478696584701538, 'mnli_dev_prompt,bias_eval_mnli/acc': 0.75, 'mnli_test_prompt,bias_eval_loss': 2.8384768962860107, 'mnli_test_prompt,bias_eval_mnli/acc': 0.6366785532348447, 'mnli-mm_test_prompt,bias_eval_loss': 2.6524548530578613, 'mnli-mm_test_prompt,bias_eval_mnli-mm/acc': 0.6590724165988608, 'mnli_dev_eval_loss': 2.478696584701538, 'mnli_dev_eval_mnli/acc': 0.75, 'mnli_test_eval_loss': 2.8384768962860107, 'mnli_test_eval_mnli/acc': 0.6366785532348447, 'mnli-mm_test_eval_loss': 2.6524548530578613, 'mnli-mm_test_eval_mnli-mm/acc': 0.6590724165988608, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-19760', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan09_23-59-31_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-19760', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias,adapter_eval_loss': 1.2520904541015625, 'mrpc_dev_bias,adapter_eval_acc': 0.59375, 'mrpc_dev_bias,adapter_eval_f1': 0.6666666666666667, 'mrpc_dev_bias,adapter_eval_acc_and_f1': 0.6302083333333334, 'mrpc_test_bias,adapter_eval_loss': 1.132214069366455, 'mrpc_test_bias,adapter_eval_acc': 0.678921568627451, 'mrpc_test_bias,adapter_eval_f1': 0.7841845140032948, 'mrpc_test_bias,adapter_eval_acc_and_f1': 0.7315530413153729, 'mrpc_dev_eval_loss': 1.2520904541015625, 'mrpc_dev_eval_acc': 0.59375, 'mrpc_dev_eval_f1': 0.6666666666666667, 'mrpc_dev_eval_acc_and_f1': 0.6302083333333334, 'mrpc_test_eval_loss': 1.132214069366455, 'mrpc_test_eval_acc': 0.678921568627451, 'mrpc_test_eval_f1': 0.7841845140032948, 'mrpc_test_eval_acc_and_f1': 0.7315530413153729, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16--100-roberta-large-22695', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_00-18-52_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16--100-roberta-large-22695', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias_eval_loss': 1.7212892770767212, 'rte_dev_prompt,bias_eval_acc': 0.46875, 'rte_test_prompt,bias_eval_loss': 1.7121917009353638, 'rte_test_prompt,bias_eval_acc': 0.5342960288808665, 'rte_dev_eval_loss': 1.7212892770767212, 'rte_dev_eval_acc': 0.46875, 'rte_test_eval_loss': 1.7121917009353638, 'rte_test_eval_acc': 0.5342960288808665, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-42-roberta-large-14008', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_00-27-46_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-42-roberta-large-14008', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias,adapter_eval_loss': 2.019375801086426, 'qnli_dev_bias,adapter_eval_acc': 0.65625, 'qnli_test_bias,adapter_eval_loss': 2.7038955688476562, 'qnli_test_bias,adapter_eval_acc': 0.5584843492586491, 'qnli_dev_eval_loss': 2.019375801086426, 'qnli_dev_eval_acc': 0.65625, 'qnli_test_eval_loss': 2.7038955688476562, 'qnli_test_eval_acc': 0.5584843492586491, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--100-roberta-large-15668', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_00-25-45_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--100-roberta-large-15668', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias_eval_loss': 0.02562076225876808, 'sst-2_dev_bias_eval_acc': 1.0, 'sst-2_test_bias_eval_loss': 0.7920157313346863, 'sst-2_test_bias_eval_acc': 0.9185779816513762, 'sst-2_dev_eval_loss': 0.02562076225876808, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.7920157313346863, 'sst-2_test_eval_acc': 0.9185779816513762, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--100-roberta-large-4810', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_00-36-28_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--100-roberta-large-4810', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_bias,adapter_eval_loss': 2.011498212814331, 'cola_dev_bias,adapter_eval_mcc': 0.4605661864718383, 'cola_test_bias,adapter_eval_loss': 2.3202643394470215, 'cola_test_bias,adapter_eval_mcc': 0.2270564061336542, 'cola_dev_eval_loss': 2.011498212814331, 'cola_dev_eval_mcc': 0.4605661864718383, 'cola_test_eval_loss': 2.3202643394470215, 'cola_test_eval_mcc': 0.2270564061336542, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16--100-roberta-large-12064', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_00-31-03_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16--100-roberta-large-12064', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias_eval_loss': 2.127570867538452, 'sts-b_dev_prompt,bias_eval_pearson': 0.6832834990981831, 'sts-b_dev_prompt,bias_eval_spearmanr': 0.6767690577895077, 'sts-b_dev_prompt,bias_eval_corr': 0.6800262784438453, 'sts-b_test_prompt,bias_eval_loss': 2.208022356033325, 'sts-b_test_prompt,bias_eval_pearson': 0.5275268516786786, 'sts-b_test_prompt,bias_eval_spearmanr': 0.5321617360509284, 'sts-b_test_prompt,bias_eval_corr': 0.5298442938648036, 'sts-b_dev_eval_loss': 2.127570867538452, 'sts-b_dev_eval_pearson': 0.6832834990981831, 'sts-b_dev_eval_spearmanr': 0.6767690577895077, 'sts-b_dev_eval_corr': 0.6800262784438453, 'sts-b_test_eval_loss': 2.208022356033325, 'sts-b_test_eval_pearson': 0.5275268516786786, 'sts-b_test_eval_spearmanr': 0.5321617360509284, 'sts-b_test_eval_corr': 0.5298442938648036, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-42-roberta-large-27400', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_00-36-45_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-42-roberta-large-27400', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias_eval_loss': 2.6861329078674316, 'rte_dev_prompt,bias_eval_acc': 0.4375, 'rte_test_prompt,bias_eval_loss': 1.8414747714996338, 'rte_test_prompt,bias_eval_acc': 0.5342960288808665, 'rte_dev_eval_loss': 2.6861329078674316, 'rte_dev_eval_acc': 0.4375, 'rte_test_eval_loss': 1.8414747714996338, 'rte_test_eval_acc': 0.5342960288808665, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-100-roberta-large-4784', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_00-43-09_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-100-roberta-large-4784', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias,adapter_eval_loss': 0.729813814163208, 'mrpc_dev_prompt,bias,adapter_eval_acc': 0.5, 'mrpc_dev_prompt,bias,adapter_eval_f1': 0.6666666666666666, 'mrpc_dev_prompt,bias,adapter_eval_acc_and_f1': 0.5833333333333333, 'mrpc_test_prompt,bias,adapter_eval_loss': 0.6296389698982239, 'mrpc_test_prompt,bias,adapter_eval_acc': 0.6838235294117647, 'mrpc_test_prompt,bias,adapter_eval_f1': 0.8122270742358079, 'mrpc_test_prompt,bias,adapter_eval_acc_and_f1': 0.7480253018237863, 'mrpc_dev_eval_loss': 0.729813814163208, 'mrpc_dev_eval_acc': 0.5, 'mrpc_dev_eval_f1': 0.6666666666666666, 'mrpc_dev_eval_acc_and_f1': 0.5833333333333333, 'mrpc_test_eval_loss': 0.6296389698982239, 'mrpc_test_eval_acc': 0.6838235294117647, 'mrpc_test_eval_f1': 0.8122270742358079, 'mrpc_test_eval_acc_and_f1': 0.7480253018237863, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-42-roberta-large-25981', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_00-37-50_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-42-roberta-large-25981', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias_eval_loss': 0.009601503610610962, 'sst-2_dev_bias_eval_acc': 1.0, 'sst-2_test_bias_eval_loss': 0.46995100378990173, 'sst-2_test_bias_eval_acc': 0.9220183486238532, 'sst-2_dev_eval_loss': 0.009601503610610962, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.46995100378990173, 'sst-2_test_eval_acc': 0.9220183486238532, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16--100-roberta-large-18594', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_00-49-18_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--100-roberta-large-18594', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias,adapter_eval_loss': 1.9018722772598267, 'qnli_dev_bias,adapter_eval_acc': 0.65625, 'qnli_test_bias,adapter_eval_loss': 2.2967605590820312, 'qnli_test_bias,adapter_eval_acc': 0.5802672524254073, 'qnli_dev_eval_loss': 1.9018722772598267, 'qnli_dev_eval_acc': 0.65625, 'qnli_test_eval_loss': 2.2967605590820312, 'qnli_test_eval_acc': 0.5802672524254073, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--100-roberta-large-13284', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_00-45-19_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--100-roberta-large-13284', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias_eval_loss': 2.3662469387054443, 'mnli_dev_prompt,bias_eval_mnli/acc': 0.6458333333333334, 'mnli_test_prompt,bias_eval_loss': 2.637359142303467, 'mnli_test_prompt,bias_eval_mnli/acc': 0.6101884870096791, 'mnli-mm_test_prompt,bias_eval_loss': 2.5014021396636963, 'mnli-mm_test_prompt,bias_eval_mnli-mm/acc': 0.6264239218877136, 'mnli_dev_eval_loss': 2.3662469387054443, 'mnli_dev_eval_mnli/acc': 0.6458333333333334, 'mnli_test_eval_loss': 2.637359142303467, 'mnli_test_eval_mnli/acc': 0.6101884870096791, 'mnli-mm_test_eval_loss': 2.5014021396636963, 'mnli-mm_test_eval_mnli-mm/acc': 0.6264239218877136, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-32083', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_00-37-07_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-32083', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias_eval_loss': 2.1400957107543945, 'sts-b_dev_prompt,bias_eval_pearson': 0.5933219414779556, 'sts-b_dev_prompt,bias_eval_spearmanr': 0.6580362371939772, 'sts-b_dev_prompt,bias_eval_corr': 0.6256790893359664, 'sts-b_test_prompt,bias_eval_loss': 2.249376058578491, 'sts-b_test_prompt,bias_eval_pearson': 0.3600931813744431, 'sts-b_test_prompt,bias_eval_spearmanr': 0.38118409702793715, 'sts-b_test_prompt,bias_eval_corr': 0.3706386392011901, 'sts-b_dev_eval_loss': 2.1400957107543945, 'sts-b_dev_eval_pearson': 0.5933219414779556, 'sts-b_dev_eval_spearmanr': 0.6580362371939772, 'sts-b_dev_eval_corr': 0.6256790893359664, 'sts-b_test_eval_loss': 2.249376058578491, 'sts-b_test_eval_pearson': 0.3600931813744431, 'sts-b_test_eval_spearmanr': 0.38118409702793715, 'sts-b_test_eval_corr': 0.3706386392011901, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-42-roberta-large-8650', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_00-52-37_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-42-roberta-large-8650', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias,adapter_eval_loss': 0.6946433782577515, 'cola_dev_prompt,bias,adapter_eval_mcc': 0.0, 'cola_test_prompt,bias,adapter_eval_loss': 0.7152383923530579, 'cola_test_prompt,bias,adapter_eval_mcc': 0.0, 'cola_dev_eval_loss': 0.6946433782577515, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.7152383923530579, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-22088', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_00-50-30_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-22088', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias_eval_loss': 1.0827947854995728, 'rte_dev_prompt,bias_eval_acc': 0.78125, 'rte_test_prompt,bias_eval_loss': 1.5953353643417358, 'rte_test_prompt,bias_eval_acc': 0.5631768953068592, 'rte_dev_eval_loss': 1.0827947854995728, 'rte_dev_eval_acc': 0.78125, 'rte_test_eval_loss': 1.5953353643417358, 'rte_test_eval_acc': 0.5631768953068592, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-100-roberta-large-106', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_00-57-54_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-100-roberta-large-106', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_adapter_eval_loss': 0.0002120767894666642, 'sst-2_dev_adapter_eval_acc': 1.0, 'sst-2_test_adapter_eval_loss': 1.0983712673187256, 'sst-2_test_adapter_eval_acc': 0.9139908256880734, 'sst-2_dev_eval_loss': 0.0002120767894666642, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 1.0983712673187256, 'sst-2_test_eval_acc': 0.9139908256880734, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--42-roberta-large-19617', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_01-02-30_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--42-roberta-large-19617', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias,adapter_eval_loss': 1.3818963766098022, 'mrpc_dev_prompt,bias,adapter_eval_acc': 0.71875, 'mrpc_dev_prompt,bias,adapter_eval_f1': 0.7567567567567567, 'mrpc_dev_prompt,bias,adapter_eval_acc_and_f1': 0.7377533783783783, 'mrpc_test_prompt,bias,adapter_eval_loss': 2.384531259536743, 'mrpc_test_prompt,bias,adapter_eval_acc': 0.6911764705882353, 'mrpc_test_prompt,bias,adapter_eval_f1': 0.7649253731343284, 'mrpc_test_prompt,bias,adapter_eval_acc_and_f1': 0.7280509218612818, 'mrpc_dev_eval_loss': 1.3818963766098022, 'mrpc_dev_eval_acc': 0.71875, 'mrpc_dev_eval_f1': 0.7567567567567567, 'mrpc_dev_eval_acc_and_f1': 0.7377533783783783, 'mrpc_test_eval_loss': 2.384531259536743, 'mrpc_test_eval_acc': 0.6911764705882353, 'mrpc_test_eval_f1': 0.7649253731343284, 'mrpc_test_eval_acc_and_f1': 0.7280509218612818, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-42-roberta-large-10322', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_00-58-51_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-42-roberta-large-10322', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias,adapter_eval_loss': 2.2653493881225586, 'qnli_dev_bias,adapter_eval_acc': 0.6875, 'qnli_test_bias,adapter_eval_loss': 3.0425355434417725, 'qnli_test_bias,adapter_eval_acc': 0.5701995240710233, 'qnli_dev_eval_loss': 2.2653493881225586, 'qnli_dev_eval_acc': 0.6875, 'qnli_test_eval_loss': 3.0425355434417725, 'qnli_test_eval_acc': 0.5701995240710233, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--100-roberta-large-841', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_01-04-51_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--100-roberta-large-841', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias_eval_loss': 2.093291997909546, 'sts-b_dev_prompt,bias_eval_pearson': 0.7703482572996234, 'sts-b_dev_prompt,bias_eval_spearmanr': 0.7334972137297424, 'sts-b_dev_prompt,bias_eval_corr': 0.7519227355146829, 'sts-b_test_prompt,bias_eval_loss': 2.1896374225616455, 'sts-b_test_prompt,bias_eval_pearson': 0.6446143485319148, 'sts-b_test_prompt,bias_eval_spearmanr': 0.6824394858002608, 'sts-b_test_prompt,bias_eval_corr': 0.6635269171660878, 'sts-b_dev_eval_loss': 2.093291997909546, 'sts-b_dev_eval_pearson': 0.7703482572996234, 'sts-b_dev_eval_spearmanr': 0.7334972137297424, 'sts-b_dev_eval_corr': 0.7519227355146829, 'sts-b_test_eval_loss': 2.1896374225616455, 'sts-b_test_eval_pearson': 0.6446143485319148, 'sts-b_test_eval_spearmanr': 0.6824394858002608, 'sts-b_test_eval_corr': 0.6635269171660878, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-100-roberta-large-7489', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_01-09-42_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-100-roberta-large-7489', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias_eval_loss': 1.7408148050308228, 'rte_dev_prompt,bias_eval_acc': 0.71875, 'rte_test_prompt,bias_eval_loss': 2.0453853607177734, 'rte_test_prompt,bias_eval_acc': 0.6101083032490975, 'rte_dev_eval_loss': 1.7408148050308228, 'rte_dev_eval_acc': 0.71875, 'rte_test_eval_loss': 2.0453853607177734, 'rte_test_eval_acc': 0.6101083032490975, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-100-roberta-large-10233', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_01-12-51_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-100-roberta-large-10233', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias,adapter_eval_loss': 1.9597883224487305, 'cola_dev_prompt,bias,adapter_eval_mcc': 0.3779644730092272, 'cola_test_prompt,bias,adapter_eval_loss': 2.2708938121795654, 'cola_test_prompt,bias,adapter_eval_mcc': 0.18744195304449005, 'cola_dev_eval_loss': 1.9597883224487305, 'cola_dev_eval_mcc': 0.3779644730092272, 'cola_test_eval_loss': 2.2708938121795654, 'cola_test_eval_mcc': 0.18744195304449005, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-24434', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_01-11-38_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-24434', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_adapter_eval_loss': 0.6114063858985901, 'sst-2_dev_adapter_eval_acc': 0.9375, 'sst-2_test_adapter_eval_loss': 0.7981309294700623, 'sst-2_test_adapter_eval_acc': 0.9139908256880734, 'sst-2_dev_eval_loss': 0.6114063858985901, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.7981309294700623, 'sst-2_test_eval_acc': 0.9139908256880734, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--42-roberta-large-31686', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_01-17-26_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--42-roberta-large-31686', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias_eval_loss': 1.8012422323226929, 'mnli_dev_prompt,bias_eval_mnli/acc': 0.625, 'mnli_test_prompt,bias_eval_loss': 1.8194363117218018, 'mnli_test_prompt,bias_eval_mnli/acc': 0.6152827305145185, 'mnli-mm_test_prompt,bias_eval_loss': 1.7378299236297607, 'mnli-mm_test_prompt,bias_eval_mnli-mm/acc': 0.6277461350691619, 'mnli_dev_eval_loss': 1.8012422323226929, 'mnli_dev_eval_mnli/acc': 0.625, 'mnli_test_eval_loss': 1.8194363117218018, 'mnli_test_eval_mnli/acc': 0.6152827305145185, 'mnli-mm_test_eval_loss': 1.7378299236297607, 'mnli-mm_test_eval_mnli-mm/acc': 0.6277461350691619, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-16561', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_01-08-14_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-16561', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias,adapter_eval_loss': 1.3457521200180054, 'mrpc_dev_prompt,bias,adapter_eval_acc': 0.75, 'mrpc_dev_prompt,bias,adapter_eval_f1': 0.75, 'mrpc_dev_prompt,bias,adapter_eval_acc_and_f1': 0.75, 'mrpc_test_prompt,bias,adapter_eval_loss': 3.335909128189087, 'mrpc_test_prompt,bias,adapter_eval_acc': 0.5759803921568627, 'mrpc_test_prompt,bias,adapter_eval_f1': 0.6197802197802198, 'mrpc_test_prompt,bias,adapter_eval_acc_and_f1': 0.5978803059685412, 'mrpc_dev_eval_loss': 1.3457521200180054, 'mrpc_dev_eval_acc': 0.75, 'mrpc_dev_eval_f1': 0.75, 'mrpc_dev_eval_acc_and_f1': 0.75, 'mrpc_test_eval_loss': 3.335909128189087, 'mrpc_test_eval_acc': 0.5759803921568627, 'mrpc_test_eval_f1': 0.6197802197802198, 'mrpc_test_eval_acc_and_f1': 0.5978803059685412, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-42-roberta-large-21289', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_01-19-15_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-42-roberta-large-21289', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias_eval_loss': 2.100715160369873, 'sts-b_dev_prompt,bias_eval_pearson': 0.7004961841388564, 'sts-b_dev_prompt,bias_eval_spearmanr': 0.6545929246901085, 'sts-b_dev_prompt,bias_eval_corr': 0.6775445544144825, 'sts-b_test_prompt,bias_eval_loss': 2.1983439922332764, 'sts-b_test_prompt,bias_eval_pearson': 0.64049340662504, 'sts-b_test_prompt,bias_eval_spearmanr': 0.6514327395118616, 'sts-b_test_prompt,bias_eval_corr': 0.6459630730684508, 'sts-b_dev_eval_loss': 2.100715160369873, 'sts-b_dev_eval_pearson': 0.7004961841388564, 'sts-b_dev_eval_spearmanr': 0.6545929246901085, 'sts-b_dev_eval_corr': 0.6775445544144825, 'sts-b_test_eval_loss': 2.1983439922332764, 'sts-b_test_eval_pearson': 0.64049340662504, 'sts-b_test_eval_spearmanr': 0.6514327395118616, 'sts-b_test_eval_corr': 0.6459630730684508, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-100-roberta-large-16806', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_01-25-38_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-100-roberta-large-16806', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias_eval_loss': 0.7477954626083374, 'rte_dev_prompt,bias_eval_acc': 0.71875, 'rte_test_prompt,bias_eval_loss': 0.7735958695411682, 'rte_test_prompt,bias_eval_acc': 0.5523465703971119, 'rte_dev_eval_loss': 0.7477954626083374, 'rte_dev_eval_acc': 0.71875, 'rte_test_eval_loss': 0.7735958695411682, 'rte_test_eval_acc': 0.5523465703971119, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-16-prompt-100-roberta-large-308', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_01-27-41_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-100-roberta-large-308', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias,adapter_eval_loss': 7.134557723999023, 'qnli_dev_prompt,bias,adapter_eval_acc': 0.53125, 'qnli_test_prompt,bias,adapter_eval_loss': 7.998316287994385, 'qnli_test_prompt,bias,adapter_eval_acc': 0.5059491122094087, 'qnli_dev_eval_loss': 7.134557723999023, 'qnli_dev_eval_acc': 0.53125, 'qnli_test_eval_loss': 7.998316287994385, 'qnli_test_eval_acc': 0.5059491122094087, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-42-roberta-large-26076', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_01-24-23_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-42-roberta-large-26076', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_adapter_eval_loss': 0.4576609134674072, 'sst-2_dev_adapter_eval_acc': 0.96875, 'sst-2_test_adapter_eval_loss': 0.9733171463012695, 'sst-2_test_adapter_eval_acc': 0.9162844036697247, 'sst-2_dev_eval_loss': 0.4576609134674072, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.9733171463012695, 'sst-2_test_eval_acc': 0.9162844036697247, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--42-roberta-large-28416', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_01-33-04_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--42-roberta-large-28416', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias,adapter_eval_loss': 1.5262624025344849, 'cola_dev_prompt,bias,adapter_eval_mcc': 0.629940788348712, 'cola_test_prompt,bias,adapter_eval_loss': 3.4834582805633545, 'cola_test_prompt,bias,adapter_eval_mcc': 0.18423157358820416, 'cola_dev_eval_loss': 1.5262624025344849, 'cola_dev_eval_mcc': 0.629940788348712, 'cola_test_eval_loss': 3.4834582805633545, 'cola_test_eval_mcc': 0.18423157358820416, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-12074', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_01-32-12_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-12074', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias_eval_loss': 2.1192703247070312, 'sts-b_dev_prompt,bias_eval_pearson': 0.6015764719419809, 'sts-b_dev_prompt,bias_eval_spearmanr': 0.5681476663016986, 'sts-b_dev_prompt,bias_eval_corr': 0.5848620691218398, 'sts-b_test_prompt,bias_eval_loss': 2.218158483505249, 'sts-b_test_prompt,bias_eval_pearson': 0.5760937659331842, 'sts-b_test_prompt,bias_eval_spearmanr': 0.5788498537216499, 'sts-b_test_prompt,bias_eval_corr': 0.577471809827417, 'sts-b_dev_eval_loss': 2.1192703247070312, 'sts-b_dev_eval_pearson': 0.6015764719419809, 'sts-b_dev_eval_spearmanr': 0.5681476663016986, 'sts-b_dev_eval_corr': 0.5848620691218398, 'sts-b_test_eval_loss': 2.218158483505249, 'sts-b_test_eval_pearson': 0.5760937659331842, 'sts-b_test_eval_spearmanr': 0.5788498537216499, 'sts-b_test_eval_corr': 0.577471809827417, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-100-roberta-large-9627', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_01-42-20_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-100-roberta-large-9627', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias,adapter_eval_loss': 1.7511816024780273, 'mrpc_dev_prompt,bias,adapter_eval_acc': 0.6875, 'mrpc_dev_prompt,bias,adapter_eval_f1': 0.6875, 'mrpc_dev_prompt,bias,adapter_eval_acc_and_f1': 0.6875, 'mrpc_test_prompt,bias,adapter_eval_loss': 3.2154295444488525, 'mrpc_test_prompt,bias,adapter_eval_acc': 0.5931372549019608, 'mrpc_test_prompt,bias,adapter_eval_f1': 0.6541666666666667, 'mrpc_test_prompt,bias,adapter_eval_acc_and_f1': 0.6236519607843137, 'mrpc_dev_eval_loss': 1.7511816024780273, 'mrpc_dev_eval_acc': 0.6875, 'mrpc_dev_eval_f1': 0.6875, 'mrpc_dev_eval_acc_and_f1': 0.6875, 'mrpc_test_eval_loss': 3.2154295444488525, 'mrpc_test_eval_acc': 0.5931372549019608, 'mrpc_test_eval_f1': 0.6541666666666667, 'mrpc_test_eval_acc_and_f1': 0.6236519607843137, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-42-roberta-large-5329', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_01-39-55_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-42-roberta-large-5329', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias,adapter_eval_loss': 0.6931380033493042, 'rte_dev_bias,adapter_eval_acc': 0.53125, 'rte_test_bias,adapter_eval_loss': 0.6931219696998596, 'rte_test_bias,adapter_eval_acc': 0.5306859205776173, 'rte_dev_eval_loss': 0.6931380033493042, 'rte_dev_eval_acc': 0.53125, 'rte_test_eval_loss': 0.6931219696998596, 'rte_test_eval_acc': 0.5306859205776173, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--42-roberta-large-3440', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_01-43-01_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--42-roberta-large-3440', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_adapter_eval_loss': 0.28331559896469116, 'sst-2_dev_adapter_eval_acc': 0.9375, 'sst-2_test_adapter_eval_loss': 0.5654487013816833, 'sst-2_test_adapter_eval_acc': 0.9254587155963303, 'sst-2_dev_eval_loss': 0.28331559896469116, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.5654487013816833, 'sst-2_test_eval_acc': 0.9254587155963303, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--42-roberta-large-23275', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_01-48-40_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--42-roberta-large-23275', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias,adapter_eval_loss': 3.0601885318756104, 'qnli_dev_prompt,bias,adapter_eval_acc': 0.53125, 'qnli_test_prompt,bias,adapter_eval_loss': 3.7430057525634766, 'qnli_test_prompt,bias,adapter_eval_acc': 0.5053999633900788, 'qnli_dev_eval_loss': 3.0601885318756104, 'qnli_dev_eval_acc': 0.53125, 'qnli_test_eval_loss': 3.7430057525634766, 'qnli_test_eval_acc': 0.5053999633900788, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-42-roberta-large-7359', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_01-45-38_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-42-roberta-large-7359', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias_eval_loss': 3.9976279735565186, 'mnli_dev_prompt,bias_eval_mnli/acc': 0.7291666666666666, 'mnli_test_prompt,bias_eval_loss': 3.188650608062744, 'mnli_test_prompt,bias_eval_mnli/acc': 0.6970962812022414, 'mnli-mm_test_prompt,bias_eval_loss': 2.974364757537842, 'mnli-mm_test_prompt,bias_eval_mnli-mm/acc': 0.7137917005695688, 'mnli_dev_eval_loss': 3.9976279735565186, 'mnli_dev_eval_mnli/acc': 0.7291666666666666, 'mnli_test_eval_loss': 3.188650608062744, 'mnli_test_eval_mnli/acc': 0.6970962812022414, 'mnli-mm_test_eval_loss': 2.974364757537842, 'mnli-mm_test_eval_mnli-mm/acc': 0.7137917005695688, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-21364', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_01-38-57_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-21364', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias,adapter_eval_loss': 2.597162961959839, 'cola_dev_prompt,bias,adapter_eval_mcc': 0.5726562866782, 'cola_test_prompt,bias,adapter_eval_loss': 3.3809781074523926, 'cola_test_prompt,bias,adapter_eval_mcc': 0.1505144078402748, 'cola_dev_eval_loss': 2.597162961959839, 'cola_dev_eval_mcc': 0.5726562866782, 'cola_test_eval_loss': 3.3809781074523926, 'cola_test_eval_mcc': 0.1505144078402748, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-42-roberta-large-22265', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_01-53-02_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-42-roberta-large-22265', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias_eval_loss': 2.1392738819122314, 'sts-b_dev_prompt,bias_eval_pearson': 0.4852982895630606, 'sts-b_dev_prompt,bias_eval_spearmanr': 0.44050296561753577, 'sts-b_dev_prompt,bias_eval_corr': 0.46290062759029815, 'sts-b_test_prompt,bias_eval_loss': 2.2745888233184814, 'sts-b_test_prompt,bias_eval_pearson': 0.42285324229057625, 'sts-b_test_prompt,bias_eval_spearmanr': 0.42041872963723187, 'sts-b_test_prompt,bias_eval_corr': 0.42163598596390406, 'sts-b_dev_eval_loss': 2.1392738819122314, 'sts-b_dev_eval_pearson': 0.4852982895630606, 'sts-b_dev_eval_spearmanr': 0.44050296561753577, 'sts-b_dev_eval_corr': 0.46290062759029815, 'sts-b_test_eval_loss': 2.2745888233184814, 'sts-b_test_eval_pearson': 0.42285324229057625, 'sts-b_test_eval_spearmanr': 0.42041872963723187, 'sts-b_test_eval_corr': 0.42163598596390406, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-100-roberta-large-14605', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_01-58-30_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-100-roberta-large-14605', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_adapter_eval_loss': 0.6219300031661987, 'sst-2_dev_adapter_eval_acc': 0.9375, 'sst-2_test_adapter_eval_loss': 1.0624665021896362, 'sst-2_test_adapter_eval_acc': 0.9002293577981652, 'sst-2_dev_eval_loss': 0.6219300031661987, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 1.0624665021896362, 'sst-2_test_eval_acc': 0.9002293577981652, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--100-roberta-large-26243', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_02-03-49_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--100-roberta-large-26243', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias,adapter_eval_loss': 4.261385440826416, 'rte_dev_bias,adapter_eval_acc': 0.4375, 'rte_test_bias,adapter_eval_loss': 3.135751724243164, 'rte_test_bias,adapter_eval_acc': 0.51985559566787, 'rte_dev_eval_loss': 4.261385440826416, 'rte_dev_eval_acc': 0.4375, 'rte_test_eval_loss': 3.135751724243164, 'rte_test_eval_acc': 0.51985559566787, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--42-roberta-large-138', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_02-01-20_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--42-roberta-large-138', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias,adapter_eval_loss': 0.7308295965194702, 'mrpc_dev_prompt,bias,adapter_eval_acc': 0.5, 'mrpc_dev_prompt,bias,adapter_eval_f1': 0.6666666666666666, 'mrpc_dev_prompt,bias,adapter_eval_acc_and_f1': 0.5833333333333333, 'mrpc_test_prompt,bias,adapter_eval_loss': 0.6292730569839478, 'mrpc_test_prompt,bias,adapter_eval_acc': 0.6838235294117647, 'mrpc_test_prompt,bias,adapter_eval_f1': 0.8122270742358079, 'mrpc_test_prompt,bias,adapter_eval_acc_and_f1': 0.7480253018237863, 'mrpc_dev_eval_loss': 0.7308295965194702, 'mrpc_dev_eval_acc': 0.5, 'mrpc_dev_eval_f1': 0.6666666666666666, 'mrpc_dev_eval_acc_and_f1': 0.5833333333333333, 'mrpc_test_eval_loss': 0.6292730569839478, 'mrpc_test_eval_acc': 0.6838235294117647, 'mrpc_test_eval_f1': 0.8122270742358079, 'mrpc_test_eval_acc_and_f1': 0.7480253018237863, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-100-roberta-large-27314', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_02-00-32_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-100-roberta-large-27314', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias,adapter_eval_loss': 2.040200710296631, 'qnli_dev_prompt,bias,adapter_eval_acc': 0.625, 'qnli_test_prompt,bias,adapter_eval_loss': 2.207874298095703, 'qnli_test_prompt,bias,adapter_eval_acc': 0.5751418634449936, 'qnli_dev_eval_loss': 2.040200710296631, 'qnli_dev_eval_acc': 0.625, 'qnli_test_eval_loss': 2.207874298095703, 'qnli_test_eval_acc': 0.5751418634449936, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-42-roberta-large-23705', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_02-06-50_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-42-roberta-large-23705', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias,adapter_eval_loss': 0.7390163540840149, 'cola_dev_prompt,bias,adapter_eval_mcc': 0.0, 'cola_test_prompt,bias,adapter_eval_loss': 0.8558188080787659, 'cola_test_prompt,bias,adapter_eval_mcc': 0.0, 'cola_dev_eval_loss': 0.7390163540840149, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.8558188080787659, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-27454', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_02-14-07_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-27454', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_adapter_eval_loss': 0.0001740789011819288, 'sst-2_dev_adapter_eval_acc': 1.0, 'sst-2_test_adapter_eval_loss': 0.8711327910423279, 'sst-2_test_adapter_eval_acc': 0.9071100917431193, 'sst-2_dev_eval_loss': 0.0001740789011819288, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.8711327910423279, 'sst-2_test_eval_acc': 0.9071100917431193, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--100-roberta-large-13727', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_02-19-21_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--100-roberta-large-13727', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias,adapter_eval_loss': 4.29146146774292, 'rte_dev_bias,adapter_eval_acc': 0.40625, 'rte_test_bias,adapter_eval_loss': 3.048557996749878, 'rte_test_bias,adapter_eval_acc': 0.51985559566787, 'rte_dev_eval_loss': 4.29146146774292, 'rte_dev_eval_acc': 0.40625, 'rte_test_eval_loss': 3.048557996749878, 'rte_test_eval_acc': 0.51985559566787, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--42-roberta-large-27506', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_02-19-32_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--42-roberta-large-27506', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias,adapter_eval_loss': 3.6391868591308594, 'mrpc_dev_prompt,bias,adapter_eval_acc': 0.65625, 'mrpc_dev_prompt,bias,adapter_eval_f1': 0.6206896551724138, 'mrpc_dev_prompt,bias,adapter_eval_acc_and_f1': 0.6384698275862069, 'mrpc_test_prompt,bias,adapter_eval_loss': 3.077793836593628, 'mrpc_test_prompt,bias,adapter_eval_acc': 0.5980392156862745, 'mrpc_test_prompt,bias,adapter_eval_f1': 0.6569037656903767, 'mrpc_test_prompt,bias,adapter_eval_acc_and_f1': 0.6274714906883256, 'mrpc_dev_eval_loss': 3.6391868591308594, 'mrpc_dev_eval_acc': 0.65625, 'mrpc_dev_eval_f1': 0.6206896551724138, 'mrpc_dev_eval_acc_and_f1': 0.6384698275862069, 'mrpc_test_eval_loss': 3.077793836593628, 'mrpc_test_eval_acc': 0.5980392156862745, 'mrpc_test_eval_f1': 0.6569037656903767, 'mrpc_test_eval_acc_and_f1': 0.6274714906883256, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-100-roberta-large-26305', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_02-21-23_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-100-roberta-large-26305', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias,adapter_eval_loss': 2.1529197692871094, 'sts-b_dev_bias,adapter_eval_pearson': 0.6509510791212443, 'sts-b_dev_bias,adapter_eval_spearmanr': 0.6460540915564192, 'sts-b_dev_bias,adapter_eval_corr': 0.6485025853388318, 'sts-b_test_bias,adapter_eval_loss': 2.213832139968872, 'sts-b_test_bias,adapter_eval_pearson': -0.01454892238440519, 'sts-b_test_bias,adapter_eval_spearmanr': -0.00923354575858255, 'sts-b_test_bias,adapter_eval_corr': -0.01189123407149387, 'sts-b_dev_eval_loss': 2.1529197692871094, 'sts-b_dev_eval_pearson': 0.6509510791212443, 'sts-b_dev_eval_spearmanr': 0.6460540915564192, 'sts-b_dev_eval_corr': 0.6485025853388318, 'sts-b_test_eval_loss': 2.213832139968872, 'sts-b_test_eval_pearson': -0.01454892238440519, 'sts-b_test_eval_spearmanr': -0.00923354575858255, 'sts-b_test_eval_corr': -0.01189123407149387, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--42-roberta-large-5698', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_02-15-47_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--42-roberta-large-5698', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias_eval_loss': 2.5479753017425537, 'mnli_dev_prompt,bias_eval_mnli/acc': 0.7291666666666666, 'mnli_test_prompt,bias_eval_loss': 2.407015562057495, 'mnli_test_prompt,bias_eval_mnli/acc': 0.6901681100356597, 'mnli-mm_test_prompt,bias_eval_loss': 2.4389700889587402, 'mnli-mm_test_prompt,bias_eval_mnli-mm/acc': 0.7002644426362896, 'mnli_dev_eval_loss': 2.5479753017425537, 'mnli_dev_eval_mnli/acc': 0.7291666666666666, 'mnli_test_eval_loss': 2.407015562057495, 'mnli_test_eval_mnli/acc': 0.6901681100356597, 'mnli-mm_test_eval_loss': 2.4389700889587402, 'mnli-mm_test_eval_mnli-mm/acc': 0.7002644426362896, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-31365', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_02-09-19_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-31365', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias,adapter_eval_loss': 2.5191667079925537, 'qnli_dev_prompt,bias,adapter_eval_acc': 0.65625, 'qnli_test_prompt,bias,adapter_eval_loss': 2.968590259552002, 'qnli_test_prompt,bias,adapter_eval_acc': 0.5914332784184514, 'qnli_dev_eval_loss': 2.5191667079925537, 'qnli_dev_eval_acc': 0.65625, 'qnli_test_eval_loss': 2.968590259552002, 'qnli_test_eval_acc': 0.5914332784184514, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-42-roberta-large-26269', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_02-28-39_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-42-roberta-large-26269', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_adapter_eval_loss': 8.467121006106026e-06, 'sst-2_dev_adapter_eval_acc': 1.0, 'sst-2_test_adapter_eval_loss': 0.9620811939239502, 'sst-2_test_adapter_eval_acc': 0.9151376146788991, 'sst-2_dev_eval_loss': 8.467121006106026e-06, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.9620811939239502, 'sst-2_test_eval_acc': 0.9151376146788991, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--100-roberta-large-4783', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_02-35-20_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--100-roberta-large-4783', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias,adapter_eval_loss': 1.9434741735458374, 'rte_dev_bias,adapter_eval_acc': 0.375, 'rte_test_bias,adapter_eval_loss': 1.3668686151504517, 'rte_test_bias,adapter_eval_acc': 0.5270758122743683, 'rte_dev_eval_loss': 1.9434741735458374, 'rte_dev_eval_acc': 0.375, 'rte_test_eval_loss': 1.3668686151504517, 'rte_test_eval_acc': 0.5270758122743683, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--42-roberta-large-27637', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_02-38-03_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--42-roberta-large-27637', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias,adapter_eval_loss': 0.730402946472168, 'cola_dev_prompt,bias,adapter_eval_mcc': 0.0, 'cola_test_prompt,bias,adapter_eval_loss': 0.6253600120544434, 'cola_test_prompt,bias,adapter_eval_mcc': 0.0, 'cola_dev_eval_loss': 0.730402946472168, 'cola_dev_eval_mcc': 0.0, 'cola_test_eval_loss': 0.6253600120544434, 'cola_test_eval_mcc': 0.0, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-30949', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_02-34-56_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-30949', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias,adapter_eval_loss': 3.2964344024658203, 'mrpc_dev_prompt,bias,adapter_eval_acc': 0.6875, 'mrpc_dev_prompt,bias,adapter_eval_f1': 0.6666666666666666, 'mrpc_dev_prompt,bias,adapter_eval_acc_and_f1': 0.6770833333333333, 'mrpc_test_prompt,bias,adapter_eval_loss': 3.252816677093506, 'mrpc_test_prompt,bias,adapter_eval_acc': 0.6348039215686274, 'mrpc_test_prompt,bias,adapter_eval_f1': 0.7014028056112224, 'mrpc_test_prompt,bias,adapter_eval_acc_and_f1': 0.668103363589925, 'mrpc_dev_eval_loss': 3.2964344024658203, 'mrpc_dev_eval_acc': 0.6875, 'mrpc_dev_eval_f1': 0.6666666666666666, 'mrpc_dev_eval_acc_and_f1': 0.6770833333333333, 'mrpc_test_eval_loss': 3.252816677093506, 'mrpc_test_eval_acc': 0.6348039215686274, 'mrpc_test_eval_f1': 0.7014028056112224, 'mrpc_test_eval_acc_and_f1': 0.668103363589925, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-100-roberta-large-18727', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_02-42-15_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-100-roberta-large-18727', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_adapter_eval_loss': 0.019484519958496094, 'sst-2_dev_adapter_eval_acc': 1.0, 'sst-2_test_adapter_eval_loss': 0.5046485662460327, 'sst-2_test_adapter_eval_acc': 0.9231651376146789, 'sst-2_dev_eval_loss': 0.019484519958496094, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.5046485662460327, 'sst-2_test_eval_acc': 0.9231651376146789, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--100-roberta-large-14250', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_02-50-31_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--100-roberta-large-14250', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias,adapter_eval_loss': 0.7211003303527832, 'qnli_dev_prompt,bias,adapter_eval_acc': 0.5, 'qnli_test_prompt,bias,adapter_eval_loss': 0.7185184359550476, 'qnli_test_prompt,bias,adapter_eval_acc': 0.5053999633900788, 'qnli_dev_eval_loss': 0.7211003303527832, 'qnli_dev_eval_acc': 0.5, 'qnli_test_eval_loss': 0.7185184359550476, 'qnli_test_eval_acc': 0.5053999633900788, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-100-roberta-large-28307', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_02-49-40_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-100-roberta-large-28307', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias,adapter_eval_loss': 4.229010581970215, 'rte_dev_bias,adapter_eval_acc': 0.53125, 'rte_test_bias,adapter_eval_loss': 5.218927383422852, 'rte_test_bias,adapter_eval_acc': 0.4729241877256318, 'rte_dev_eval_loss': 4.229010581970215, 'rte_dev_eval_acc': 0.53125, 'rte_test_eval_loss': 5.218927383422852, 'rte_test_eval_acc': 0.4729241877256318, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--100-roberta-large-2549', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_02-55-48_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--100-roberta-large-2549', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias,adapter_eval_loss': 2.1187429428100586, 'sts-b_dev_bias,adapter_eval_pearson': 0.7949835965204867, 'sts-b_dev_bias,adapter_eval_spearmanr': 0.7854928792851356, 'sts-b_dev_bias,adapter_eval_corr': 0.7902382379028111, 'sts-b_test_bias,adapter_eval_loss': 2.180645704269409, 'sts-b_test_bias,adapter_eval_pearson': 0.693675701077625, 'sts-b_test_bias,adapter_eval_spearmanr': 0.6955070610130256, 'sts-b_test_bias,adapter_eval_corr': 0.6945913810453253, 'sts-b_dev_eval_loss': 2.1187429428100586, 'sts-b_dev_eval_pearson': 0.7949835965204867, 'sts-b_dev_eval_spearmanr': 0.7854928792851356, 'sts-b_dev_eval_corr': 0.7902382379028111, 'sts-b_test_eval_loss': 2.180645704269409, 'sts-b_test_eval_pearson': 0.693675701077625, 'sts-b_test_eval_spearmanr': 0.6955070610130256, 'sts-b_test_eval_corr': 0.6945913810453253, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--42-roberta-large-10662', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_02-43-40_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--42-roberta-large-10662', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias,adapter_eval_loss': 3.581188917160034, 'cola_dev_prompt,bias,adapter_eval_mcc': 0.5773502691896258, 'cola_test_prompt,bias,adapter_eval_loss': 3.1683478355407715, 'cola_test_prompt,bias,adapter_eval_mcc': 0.39213093547272937, 'cola_dev_eval_loss': 3.581188917160034, 'cola_dev_eval_mcc': 0.5773502691896258, 'cola_test_eval_loss': 3.1683478355407715, 'cola_test_eval_mcc': 0.39213093547272937, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-32378', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_02-55-52_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-32378', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,adapter_eval_loss': 1.44680917263031, 'sst-2_dev_prompt,adapter_eval_acc': 0.84375, 'sst-2_test_prompt,adapter_eval_loss': 1.1753846406936646, 'sst-2_test_prompt,adapter_eval_acc': 0.8589449541284404, 'sst-2_dev_eval_loss': 1.44680917263031, 'sst-2_dev_eval_acc': 0.84375, 'sst-2_test_eval_loss': 1.1753846406936646, 'sst-2_test_eval_acc': 0.8589449541284404, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-5348', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_03-06-26_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-5348', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt,bias,adapter_eval_loss': 3.3011693954467773, 'mrpc_dev_prompt,bias,adapter_eval_acc': 0.59375, 'mrpc_dev_prompt,bias,adapter_eval_f1': 0.6486486486486486, 'mrpc_dev_prompt,bias,adapter_eval_acc_and_f1': 0.6211993243243243, 'mrpc_test_prompt,bias,adapter_eval_loss': 2.701953411102295, 'mrpc_test_prompt,bias,adapter_eval_acc': 0.6740196078431373, 'mrpc_test_prompt,bias,adapter_eval_f1': 0.767888307155323, 'mrpc_test_prompt,bias,adapter_eval_acc_and_f1': 0.7209539574992301, 'mrpc_dev_eval_loss': 3.3011693954467773, 'mrpc_dev_eval_acc': 0.59375, 'mrpc_dev_eval_f1': 0.6486486486486486, 'mrpc_dev_eval_acc_and_f1': 0.6211993243243243, 'mrpc_test_eval_loss': 2.701953411102295, 'mrpc_test_eval_acc': 0.6740196078431373, 'mrpc_test_eval_f1': 0.767888307155323, 'mrpc_test_eval_acc_and_f1': 0.7209539574992301, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MRPC-16-prompt-100-roberta-large-27626', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_03-03-20_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-16-prompt-100-roberta-large-27626', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mrpc', 'data_dir': 'data/k-shot/MRPC/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias,adapter_eval_loss': 2.769587516784668, 'rte_dev_bias,adapter_eval_acc': 0.65625, 'rte_test_bias,adapter_eval_loss': 3.059032440185547, 'rte_test_bias,adapter_eval_acc': 0.5740072202166066, 'rte_dev_eval_loss': 2.769587516784668, 'rte_dev_eval_acc': 0.65625, 'rte_test_eval_loss': 3.059032440185547, 'rte_test_eval_acc': 0.5740072202166066, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--100-roberta-large-3304', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_03-14-13_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--100-roberta-large-3304', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias,adapter_eval_loss': 1.3671016693115234, 'qnli_dev_prompt,bias,adapter_eval_acc': 0.6875, 'qnli_test_prompt,bias,adapter_eval_loss': 1.9248894453048706, 'qnli_test_prompt,bias,adapter_eval_acc': 0.6117517847336629, 'qnli_dev_eval_loss': 1.3671016693115234, 'qnli_dev_eval_acc': 0.6875, 'qnli_test_eval_loss': 1.9248894453048706, 'qnli_test_eval_acc': 0.6117517847336629, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-100-roberta-large-2587', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_03-10-56_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-100-roberta-large-2587', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias_eval_loss': 2.194186210632324, 'mnli_dev_prompt,bias_eval_mnli/acc': 0.7083333333333334, 'mnli_test_prompt,bias_eval_loss': 1.8577070236206055, 'mnli_test_prompt,bias_eval_mnli/acc': 0.6893530310748853, 'mnli-mm_test_prompt,bias_eval_loss': 1.9275367259979248, 'mnli-mm_test_prompt,bias_eval_mnli-mm/acc': 0.694060211554109, 'mnli_dev_eval_loss': 2.194186210632324, 'mnli_dev_eval_mnli/acc': 0.7083333333333334, 'mnli_test_eval_loss': 1.8577070236206055, 'mnli_test_eval_mnli/acc': 0.6893530310748853, 'mnli-mm_test_eval_loss': 1.9275367259979248, 'mnli-mm_test_eval_mnli-mm/acc': 0.694060211554109, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-25786', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_02-48-59_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-25786', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'cola_dev_prompt,bias,adapter_eval_loss': 4.058107852935791, 'cola_dev_prompt,bias,adapter_eval_mcc': 0.4865336327998411, 'cola_test_prompt,bias,adapter_eval_loss': 3.0819671154022217, 'cola_test_prompt,bias,adapter_eval_mcc': 0.30981882633606694, 'cola_dev_eval_loss': 4.058107852935791, 'cola_dev_eval_mcc': 0.4865336327998411, 'cola_test_eval_loss': 3.0819671154022217, 'cola_test_eval_mcc': 0.30981882633606694, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/CoLA-16-prompt-100-roberta-large-20634', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_03-16-29_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/CoLA-16-prompt-100-roberta-large-20634', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cola', 'data_dir': 'data/k-shot/CoLA/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'incorrect','1':'correct'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,adapter_eval_loss': 0.28288373351097107, 'sst-2_dev_prompt,adapter_eval_acc': 0.9375, 'sst-2_test_prompt,adapter_eval_loss': 0.6633939146995544, 'sst-2_test_prompt,adapter_eval_acc': 0.908256880733945, 'sst-2_dev_eval_loss': 0.28288373351097107, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.6633939146995544, 'sst-2_test_eval_acc': 0.908256880733945, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-17027', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_03-22-22_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-17027', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias,adapter_eval_loss': 2.118518829345703, 'sts-b_dev_bias,adapter_eval_pearson': 0.7829159004574882, 'sts-b_dev_bias,adapter_eval_spearmanr': 0.7801668812726809, 'sts-b_dev_bias,adapter_eval_corr': 0.7815413908650846, 'sts-b_test_bias,adapter_eval_loss': 2.183767318725586, 'sts-b_test_bias,adapter_eval_pearson': 0.6641002861362327, 'sts-b_test_bias,adapter_eval_spearmanr': 0.6658032329035598, 'sts-b_test_bias,adapter_eval_corr': 0.6649517595198963, 'sts-b_dev_eval_loss': 2.118518829345703, 'sts-b_dev_eval_pearson': 0.7829159004574882, 'sts-b_dev_eval_spearmanr': 0.7801668812726809, 'sts-b_dev_eval_corr': 0.7815413908650846, 'sts-b_test_eval_loss': 2.183767318725586, 'sts-b_test_eval_pearson': 0.6641002861362327, 'sts-b_test_eval_spearmanr': 0.6658032329035598, 'sts-b_test_eval_corr': 0.6649517595198963, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--42-roberta-large-29469', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_03-14-40_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--42-roberta-large-29469', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias,adapter_eval_loss': 2.4685163497924805, 'rte_dev_bias,adapter_eval_acc': 0.6875, 'rte_test_bias,adapter_eval_loss': 2.8349978923797607, 'rte_test_bias,adapter_eval_acc': 0.5884476534296029, 'rte_dev_eval_loss': 2.4685163497924805, 'rte_dev_eval_acc': 0.6875, 'rte_test_eval_loss': 2.8349978923797607, 'rte_test_eval_acc': 0.5884476534296029, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--100-roberta-large-2675', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_03-32-16_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--100-roberta-large-2675', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias,adapter_eval_loss': 2.860903263092041, 'qnli_dev_prompt,bias,adapter_eval_acc': 0.6875, 'qnli_test_prompt,bias,adapter_eval_loss': 3.218906879425049, 'qnli_test_prompt,bias,adapter_eval_acc': 0.5579352004393191, 'qnli_dev_eval_loss': 2.860903263092041, 'qnli_dev_eval_acc': 0.6875, 'qnli_test_eval_loss': 3.218906879425049, 'qnli_test_eval_acc': 0.5579352004393191, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-100-roberta-large-13476', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_03-32-24_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-100-roberta-large-13476', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,adapter_eval_loss': 0.0009337335941381752, 'sst-2_dev_prompt,adapter_eval_acc': 1.0, 'sst-2_test_prompt,adapter_eval_loss': 0.8485007882118225, 'sst-2_test_prompt,adapter_eval_acc': 0.9208715596330275, 'sst-2_dev_eval_loss': 0.0009337335941381752, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.8485007882118225, 'sst-2_test_eval_acc': 0.9208715596330275, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-20941', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_03-38-23_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-20941', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_bias,adapter_eval_loss': 1.533764362335205, 'rte_dev_bias,adapter_eval_acc': 0.59375, 'rte_test_bias,adapter_eval_loss': 1.4263471364974976, 'rte_test_bias,adapter_eval_acc': 0.5523465703971119, 'rte_dev_eval_loss': 1.533764362335205, 'rte_dev_eval_acc': 0.59375, 'rte_test_eval_loss': 1.4263471364974976, 'rte_test_eval_acc': 0.5523465703971119, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16--100-roberta-large-760', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_03-50-28_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16--100-roberta-large-760', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,adapter_eval_loss': 0.018951712176203728, 'sst-2_dev_prompt,adapter_eval_acc': 1.0, 'sst-2_test_prompt,adapter_eval_loss': 0.6839607954025269, 'sst-2_test_prompt,adapter_eval_acc': 0.9277522935779816, 'sst-2_dev_eval_loss': 0.018951712176203728, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.6839607954025269, 'sst-2_test_eval_acc': 0.9277522935779816, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-22378', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_03-55-20_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-22378', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias,adapter_eval_loss': 3.8470828533172607, 'qnli_dev_prompt,bias,adapter_eval_acc': 0.6875, 'qnli_test_prompt,bias,adapter_eval_loss': 3.5633723735809326, 'qnli_test_prompt,bias,adapter_eval_acc': 0.5524437122460186, 'qnli_dev_eval_loss': 3.8470828533172607, 'qnli_dev_eval_acc': 0.6875, 'qnli_test_eval_loss': 3.5633723735809326, 'qnli_test_eval_acc': 0.5524437122460186, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-100-roberta-large-12702', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_03-53-31_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-100-roberta-large-12702', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias,adapter_eval_loss': 2.125077247619629, 'sts-b_dev_bias,adapter_eval_pearson': 0.7089385665862855, 'sts-b_dev_bias,adapter_eval_spearmanr': 0.6914614660997277, 'sts-b_dev_bias,adapter_eval_corr': 0.7002000163430067, 'sts-b_test_bias,adapter_eval_loss': 2.2014060020446777, 'sts-b_test_bias,adapter_eval_pearson': 0.5516928012716256, 'sts-b_test_bias,adapter_eval_spearmanr': 0.5536804280612394, 'sts-b_test_bias,adapter_eval_corr': 0.5526866146664324, 'sts-b_dev_eval_loss': 2.125077247619629, 'sts-b_dev_eval_pearson': 0.7089385665862855, 'sts-b_dev_eval_spearmanr': 0.6914614660997277, 'sts-b_dev_eval_corr': 0.7002000163430067, 'sts-b_test_eval_loss': 2.2014060020446777, 'sts-b_test_eval_pearson': 0.5516928012716256, 'sts-b_test_eval_spearmanr': 0.5536804280612394, 'sts-b_test_eval_corr': 0.5526866146664324, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--42-roberta-large-24841', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_03-46-13_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--42-roberta-large-24841', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias_eval_loss': 1.4931944608688354, 'mnli_dev_prompt,bias_eval_mnli/acc': 0.7083333333333334, 'mnli_test_prompt,bias_eval_loss': 1.3826231956481934, 'mnli_test_prompt,bias_eval_mnli/acc': 0.6619460010188487, 'mnli-mm_test_prompt,bias_eval_loss': 1.4618573188781738, 'mnli-mm_test_prompt,bias_eval_mnli-mm/acc': 0.6627339300244101, 'mnli_dev_eval_loss': 1.4931944608688354, 'mnli_dev_eval_mnli/acc': 0.7083333333333334, 'mnli_test_eval_loss': 1.3826231956481934, 'mnli_test_eval_mnli/acc': 0.6619460010188487, 'mnli-mm_test_eval_loss': 1.4618573188781738, 'mnli-mm_test_eval_mnli-mm/acc': 0.6627339300244101, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-27949', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_03-35-07_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-27949', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias,adapter_eval_loss': 7.147573947906494, 'rte_dev_prompt,bias,adapter_eval_acc': 0.53125, 'rte_test_prompt,bias,adapter_eval_loss': 5.910229682922363, 'rte_test_prompt,bias,adapter_eval_acc': 0.5523465703971119, 'rte_dev_eval_loss': 7.147573947906494, 'rte_dev_eval_acc': 0.53125, 'rte_test_eval_loss': 5.910229682922363, 'rte_test_eval_acc': 0.5523465703971119, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-42-roberta-large-19899', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_04-08-47_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-42-roberta-large-19899', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,adapter_eval_loss': 0.2573174238204956, 'sst-2_dev_prompt,adapter_eval_acc': 0.96875, 'sst-2_test_prompt,adapter_eval_loss': 0.719117283821106, 'sst-2_test_prompt,adapter_eval_acc': 0.8990825688073395, 'sst-2_dev_eval_loss': 0.2573174238204956, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.719117283821106, 'sst-2_test_eval_acc': 0.8990825688073395, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-26147', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_04-11-50_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-26147', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,adapter_eval_loss': 0.0011230941163375974, 'sst-2_dev_prompt,adapter_eval_acc': 1.0, 'sst-2_test_prompt,adapter_eval_loss': 0.8238195180892944, 'sst-2_test_prompt,adapter_eval_acc': 0.9185779816513762, 'sst-2_dev_eval_loss': 0.0011230941163375974, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.8238195180892944, 'sst-2_test_eval_acc': 0.9185779816513762, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-19735', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_04-28-50_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-19735', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias,adapter_eval_loss': 3.159700393676758, 'rte_dev_prompt,bias,adapter_eval_acc': 0.53125, 'rte_test_prompt,bias,adapter_eval_loss': 4.426708221435547, 'rte_test_prompt,bias,adapter_eval_acc': 0.48375451263537905, 'rte_dev_eval_loss': 3.159700393676758, 'rte_dev_eval_acc': 0.53125, 'rte_test_eval_loss': 4.426708221435547, 'rte_test_eval_acc': 0.48375451263537905, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-42-roberta-large-11605', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_04-28-32_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-42-roberta-large-11605', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias,adapter_eval_loss': 2.1126549243927, 'sts-b_dev_bias,adapter_eval_pearson': 0.4804913985680209, 'sts-b_dev_bias,adapter_eval_spearmanr': 0.4423393575297818, 'sts-b_dev_bias,adapter_eval_corr': 0.46141537804890137, 'sts-b_test_bias,adapter_eval_loss': 2.2134146690368652, 'sts-b_test_bias,adapter_eval_pearson': -0.034570533861583104, 'sts-b_test_bias,adapter_eval_spearmanr': -0.03311824454992404, 'sts-b_test_bias,adapter_eval_corr': -0.03384438920575357, 'sts-b_dev_eval_loss': 2.1126549243927, 'sts-b_dev_eval_pearson': 0.4804913985680209, 'sts-b_dev_eval_spearmanr': 0.4423393575297818, 'sts-b_dev_eval_corr': 0.46141537804890137, 'sts-b_test_eval_loss': 2.2134146690368652, 'sts-b_test_eval_pearson': -0.034570533861583104, 'sts-b_test_eval_spearmanr': -0.03311824454992404, 'sts-b_test_eval_corr': -0.03384438920575357, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--100-roberta-large-18172', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_04-18-14_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--100-roberta-large-18172', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,adapter_eval_loss': 0.005314187612384558, 'sst-2_dev_prompt,adapter_eval_acc': 1.0, 'sst-2_test_prompt,adapter_eval_loss': 0.7379448413848877, 'sst-2_test_prompt,adapter_eval_acc': 0.9162844036697247, 'sst-2_dev_eval_loss': 0.005314187612384558, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.7379448413848877, 'sst-2_test_eval_acc': 0.9162844036697247, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-9045', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_04-45-46_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-9045', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias,adapter_eval_loss': 2.9320406913757324, 'rte_dev_prompt,bias,adapter_eval_acc': 0.5625, 'rte_test_prompt,bias,adapter_eval_loss': 2.849658727645874, 'rte_test_prompt,bias,adapter_eval_acc': 0.5812274368231047, 'rte_dev_eval_loss': 2.9320406913757324, 'rte_dev_eval_acc': 0.5625, 'rte_test_eval_loss': 2.849658727645874, 'rte_test_eval_acc': 0.5812274368231047, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-42-roberta-large-17493', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_04-47-44_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-42-roberta-large-17493', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias,adapter_eval_loss': 4.225500106811523, 'mnli_dev_bias,adapter_eval_mnli/acc': 0.4166666666666667, 'mnli_test_bias,adapter_eval_loss': 3.818598747253418, 'mnli_test_bias,adapter_eval_mnli/acc': 0.5422312786551197, 'mnli-mm_test_bias,adapter_eval_loss': 3.561413288116455, 'mnli-mm_test_bias,adapter_eval_mnli-mm/acc': 0.5781122864117169, 'mnli_dev_eval_loss': 4.225500106811523, 'mnli_dev_eval_mnli/acc': 0.4166666666666667, 'mnli_test_eval_loss': 3.818598747253418, 'mnli_test_eval_mnli/acc': 0.5422312786551197, 'mnli-mm_test_eval_loss': 3.561413288116455, 'mnli-mm_test_eval_mnli-mm/acc': 0.5781122864117169, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--42-roberta-large-5432', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_04-22-11_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--42-roberta-large-5432', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias,adapter_eval_loss': 2.0845305919647217, 'sts-b_dev_bias,adapter_eval_pearson': 0.8387532841485968, 'sts-b_dev_bias,adapter_eval_spearmanr': 0.8188389156280874, 'sts-b_dev_bias,adapter_eval_corr': 0.8287960998883421, 'sts-b_test_bias,adapter_eval_loss': 2.184506416320801, 'sts-b_test_bias,adapter_eval_pearson': 0.6692614408698663, 'sts-b_test_bias,adapter_eval_spearmanr': 0.7091294457834931, 'sts-b_test_bias,adapter_eval_corr': 0.6891954433266797, 'sts-b_dev_eval_loss': 2.0845305919647217, 'sts-b_dev_eval_pearson': 0.8387532841485968, 'sts-b_dev_eval_spearmanr': 0.8188389156280874, 'sts-b_dev_eval_corr': 0.8287960998883421, 'sts-b_test_eval_loss': 2.184506416320801, 'sts-b_test_eval_pearson': 0.6692614408698663, 'sts-b_test_eval_spearmanr': 0.7091294457834931, 'sts-b_test_eval_corr': 0.6891954433266797, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--100-roberta-large-32691', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_04-49-08_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--100-roberta-large-32691', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,adapter_eval_loss': 0.13121454417705536, 'sst-2_dev_prompt,adapter_eval_acc': 0.96875, 'sst-2_test_prompt,adapter_eval_loss': 0.4911844730377197, 'sst-2_test_prompt,adapter_eval_acc': 0.9151376146788991, 'sst-2_dev_eval_loss': 0.13121454417705536, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.4911844730377197, 'sst-2_test_eval_acc': 0.9151376146788991, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-24221', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_05-02-33_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-24221', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias,adapter_eval_loss': 2.9627790451049805, 'rte_dev_prompt,bias,adapter_eval_acc': 0.5, 'rte_test_prompt,bias,adapter_eval_loss': 2.7323033809661865, 'rte_test_prompt,bias,adapter_eval_acc': 0.5487364620938628, 'rte_dev_eval_loss': 2.9627790451049805, 'rte_dev_eval_acc': 0.5, 'rte_test_eval_loss': 2.7323033809661865, 'rte_test_eval_acc': 0.5487364620938628, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-42-roberta-large-1148', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_05-06-43_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-42-roberta-large-1148', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias_eval_loss': 0.533728837966919, 'sst-2_dev_prompt,bias_eval_acc': 0.9375, 'sst-2_test_prompt,bias_eval_loss': 0.7167084217071533, 'sst-2_test_prompt,bias_eval_acc': 0.9197247706422018, 'sst-2_dev_eval_loss': 0.533728837966919, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.7167084217071533, 'sst-2_test_eval_acc': 0.9197247706422018, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-9253', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_05-19-21_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-9253', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias,adapter_eval_loss': 0.7402684092521667, 'rte_dev_prompt,bias,adapter_eval_acc': 0.5, 'rte_test_prompt,bias,adapter_eval_loss': 0.7234933376312256, 'rte_test_prompt,bias,adapter_eval_acc': 0.5270758122743683, 'rte_dev_eval_loss': 0.7402684092521667, 'rte_dev_eval_acc': 0.5, 'rte_test_eval_loss': 0.7234933376312256, 'rte_test_eval_acc': 0.5270758122743683, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-100-roberta-large-5351', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_05-25-42_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-100-roberta-large-5351', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias_eval_loss': 0.11616630852222443, 'sst-2_dev_prompt,bias_eval_acc': 0.96875, 'sst-2_test_prompt,bias_eval_loss': 0.7321303486824036, 'sst-2_test_prompt,bias_eval_acc': 0.9059633027522935, 'sst-2_dev_eval_loss': 0.11616630852222443, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.7321303486824036, 'sst-2_test_eval_acc': 0.9059633027522935, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-23478', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_05-33-33_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-23478', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias,adapter_eval_loss': 2.09432053565979, 'sts-b_dev_bias,adapter_eval_pearson': 0.7513455965455689, 'sts-b_dev_bias,adapter_eval_spearmanr': 0.7397507005067763, 'sts-b_dev_bias,adapter_eval_corr': 0.7455481485261726, 'sts-b_test_bias,adapter_eval_loss': 2.199674129486084, 'sts-b_test_bias,adapter_eval_pearson': 0.5837756606815304, 'sts-b_test_bias,adapter_eval_spearmanr': 0.5970265917297255, 'sts-b_test_bias,adapter_eval_corr': 0.5904011262056279, 'sts-b_dev_eval_loss': 2.09432053565979, 'sts-b_dev_eval_pearson': 0.7513455965455689, 'sts-b_dev_eval_spearmanr': 0.7397507005067763, 'sts-b_dev_eval_corr': 0.7455481485261726, 'sts-b_test_eval_loss': 2.199674129486084, 'sts-b_test_eval_pearson': 0.5837756606815304, 'sts-b_test_eval_spearmanr': 0.5970265917297255, 'sts-b_test_eval_corr': 0.5904011262056279, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--100-roberta-large-11833', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_05-18-52_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--100-roberta-large-11833', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias_eval_loss': 0.019552480429410934, 'sst-2_dev_prompt,bias_eval_acc': 1.0, 'sst-2_test_prompt,bias_eval_loss': 0.835828423500061, 'sst-2_test_prompt,bias_eval_acc': 0.9277522935779816, 'sst-2_dev_eval_loss': 0.019552480429410934, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.835828423500061, 'sst-2_test_eval_acc': 0.9277522935779816, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-17347', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_05-47-12_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-17347', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias,adapter_eval_loss': 2.9553298950195312, 'rte_dev_prompt,bias,adapter_eval_acc': 0.625, 'rte_test_prompt,bias,adapter_eval_loss': 3.2304883003234863, 'rte_test_prompt,bias,adapter_eval_acc': 0.5956678700361011, 'rte_dev_eval_loss': 2.9553298950195312, 'rte_dev_eval_acc': 0.625, 'rte_test_eval_loss': 3.2304883003234863, 'rte_test_eval_acc': 0.5956678700361011, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-100-roberta-large-13581', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_05-45-10_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-100-roberta-large-13581', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias,adapter_eval_loss': 3.024752616882324, 'mnli_dev_bias,adapter_eval_mnli/acc': 0.6666666666666666, 'mnli_test_bias,adapter_eval_loss': 3.439161539077759, 'mnli_test_bias,adapter_eval_mnli/acc': 0.687111563932756, 'mnli-mm_test_bias,adapter_eval_loss': 3.036982297897339, 'mnli-mm_test_bias,adapter_eval_mnli-mm/acc': 0.7158258746948739, 'mnli_dev_eval_loss': 3.024752616882324, 'mnli_dev_eval_mnli/acc': 0.6666666666666666, 'mnli_test_eval_loss': 3.439161539077759, 'mnli_test_eval_mnli/acc': 0.687111563932756, 'mnli-mm_test_eval_loss': 3.036982297897339, 'mnli-mm_test_eval_mnli-mm/acc': 0.7158258746948739, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--42-roberta-large-20987', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_05-17-17_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--42-roberta-large-20987', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias_eval_loss': 0.13372550904750824, 'sst-2_dev_prompt,bias_eval_acc': 1.0, 'sst-2_test_prompt,bias_eval_loss': 0.24691027402877808, 'sst-2_test_prompt,bias_eval_acc': 0.9071100917431193, 'sst-2_dev_eval_loss': 0.13372550904750824, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.24691027402877808, 'sst-2_test_eval_acc': 0.9071100917431193, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-3173', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_06-02-11_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-3173', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias,adapter_eval_loss': 2.098156690597534, 'sts-b_dev_bias,adapter_eval_pearson': 0.7099354934047939, 'sts-b_dev_bias,adapter_eval_spearmanr': 0.6785033153081794, 'sts-b_dev_bias,adapter_eval_corr': 0.6942194043564867, 'sts-b_test_bias,adapter_eval_loss': 2.210191488265991, 'sts-b_test_bias,adapter_eval_pearson': 0.5662784838013936, 'sts-b_test_bias,adapter_eval_spearmanr': 0.5693715418894622, 'sts-b_test_bias,adapter_eval_corr': 0.5678250128454279, 'sts-b_dev_eval_loss': 2.098156690597534, 'sts-b_dev_eval_pearson': 0.7099354934047939, 'sts-b_dev_eval_spearmanr': 0.6785033153081794, 'sts-b_dev_eval_corr': 0.6942194043564867, 'sts-b_test_eval_loss': 2.210191488265991, 'sts-b_test_eval_pearson': 0.5662784838013936, 'sts-b_test_eval_spearmanr': 0.5693715418894622, 'sts-b_test_eval_corr': 0.5678250128454279, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--100-roberta-large-1063', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_05-51-08_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--100-roberta-large-1063', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias,adapter_eval_loss': 1.915725588798523, 'rte_dev_prompt,bias,adapter_eval_acc': 0.65625, 'rte_test_prompt,bias,adapter_eval_loss': 1.9193512201309204, 'rte_test_prompt,bias,adapter_eval_acc': 0.631768953068592, 'rte_dev_eval_loss': 1.915725588798523, 'rte_dev_eval_acc': 0.65625, 'rte_test_eval_loss': 1.9193512201309204, 'rte_test_eval_acc': 0.631768953068592, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-100-roberta-large-26863', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_06-04-07_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-100-roberta-large-26863', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias_eval_loss': 0.00012099952436983585, 'sst-2_dev_prompt,bias_eval_acc': 1.0, 'sst-2_test_prompt,bias_eval_loss': 0.721376359462738, 'sst-2_test_prompt,bias_eval_acc': 0.9151376146788991, 'sst-2_dev_eval_loss': 0.00012099952436983585, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.721376359462738, 'sst-2_test_eval_acc': 0.9151376146788991, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-9440', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_06-16-45_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-9440', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt,bias,adapter_eval_loss': 2.351008892059326, 'rte_dev_prompt,bias,adapter_eval_acc': 0.71875, 'rte_test_prompt,bias,adapter_eval_loss': 2.8010618686676025, 'rte_test_prompt,bias,adapter_eval_acc': 0.5812274368231047, 'rte_dev_eval_loss': 2.351008892059326, 'rte_dev_eval_acc': 0.71875, 'rte_test_eval_loss': 2.8010618686676025, 'rte_test_eval_acc': 0.5812274368231047, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/RTE-16-prompt-100-roberta-large-27934', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_06-23-27_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-16-prompt-100-roberta-large-27934', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'rte', 'data_dir': 'data/k-shot/RTE/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias_eval_loss': 0.006914486642926931, 'sst-2_dev_prompt,bias_eval_acc': 1.0, 'sst-2_test_prompt,bias_eval_loss': 0.9007886052131653, 'sst-2_test_prompt,bias_eval_acc': 0.9128440366972477, 'sst-2_dev_eval_loss': 0.006914486642926931, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.9007886052131653, 'sst-2_test_eval_acc': 0.9128440366972477, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-3948', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_06-32-04_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-3948', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias,adapter_eval_loss': 2.1609418392181396, 'sts-b_dev_prompt,bias,adapter_eval_pearson': 0.2578717416554757, 'sts-b_dev_prompt,bias,adapter_eval_spearmanr': 0.24278923507902536, 'sts-b_dev_prompt,bias,adapter_eval_corr': 0.2503304883672505, 'sts-b_test_prompt,bias,adapter_eval_loss': 2.214369535446167, 'sts-b_test_prompt,bias,adapter_eval_pearson': -0.013503710112238282, 'sts-b_test_prompt,bias,adapter_eval_spearmanr': -0.01323609700033004, 'sts-b_test_prompt,bias,adapter_eval_corr': -0.01336990355628416, 'sts-b_dev_eval_loss': 2.1609418392181396, 'sts-b_dev_eval_pearson': 0.2578717416554757, 'sts-b_dev_eval_spearmanr': 0.24278923507902536, 'sts-b_dev_eval_corr': 0.2503304883672505, 'sts-b_test_eval_loss': 2.214369535446167, 'sts-b_test_eval_pearson': -0.013503710112238282, 'sts-b_test_eval_spearmanr': -0.01323609700033004, 'sts-b_test_eval_corr': -0.01336990355628416, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-42-roberta-large-14233', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_06-22-53_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-42-roberta-large-14233', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias_eval_loss': 0.014870572835206985, 'sst-2_dev_prompt,bias_eval_acc': 1.0, 'sst-2_test_prompt,bias_eval_loss': 0.7358916997909546, 'sst-2_test_prompt,bias_eval_acc': 0.9243119266055045, 'sst-2_dev_eval_loss': 0.014870572835206985, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.7358916997909546, 'sst-2_test_eval_acc': 0.9243119266055045, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-22063', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_06-46-59_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-22063', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias,adapter_eval_loss': 1.826372742652893, 'mnli_dev_bias,adapter_eval_mnli/acc': 0.6666666666666666, 'mnli_test_bias,adapter_eval_loss': 2.0360922813415527, 'mnli_test_bias,adapter_eval_mnli/acc': 0.638920020376974, 'mnli-mm_test_bias,adapter_eval_loss': 1.83878755569458, 'mnli-mm_test_bias,adapter_eval_mnli-mm/acc': 0.6602929210740439, 'mnli_dev_eval_loss': 1.826372742652893, 'mnli_dev_eval_mnli/acc': 0.6666666666666666, 'mnli_test_eval_loss': 2.0360922813415527, 'mnli_test_eval_mnli/acc': 0.638920020376974, 'mnli-mm_test_eval_loss': 1.83878755569458, 'mnli-mm_test_eval_mnli-mm/acc': 0.6602929210740439, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--42-roberta-large-31505', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_06-10-36_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--42-roberta-large-31505', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias_eval_loss': 0.06440584361553192, 'sst-2_dev_prompt,bias_eval_acc': 0.96875, 'sst-2_test_prompt,bias_eval_loss': 0.3510344624519348, 'sst-2_test_prompt,bias_eval_acc': 0.911697247706422, 'sst-2_dev_eval_loss': 0.06440584361553192, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.3510344624519348, 'sst-2_test_eval_acc': 0.911697247706422, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-9060', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_07-02-01_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-9060', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias,adapter_eval_loss': 2.1247668266296387, 'sts-b_dev_prompt,bias,adapter_eval_pearson': 0.8253814819504779, 'sts-b_dev_prompt,bias,adapter_eval_spearmanr': 0.8060622509194435, 'sts-b_dev_prompt,bias,adapter_eval_corr': 0.8157218664349607, 'sts-b_test_prompt,bias,adapter_eval_loss': 2.178844451904297, 'sts-b_test_prompt,bias,adapter_eval_pearson': 0.6898352254317749, 'sts-b_test_prompt,bias,adapter_eval_spearmanr': 0.6909842933061426, 'sts-b_test_prompt,bias,adapter_eval_corr': 0.6904097593689588, 'sts-b_dev_eval_loss': 2.1247668266296387, 'sts-b_dev_eval_pearson': 0.8253814819504779, 'sts-b_dev_eval_spearmanr': 0.8060622509194435, 'sts-b_dev_eval_corr': 0.8157218664349607, 'sts-b_test_eval_loss': 2.178844451904297, 'sts-b_test_eval_pearson': 0.6898352254317749, 'sts-b_test_eval_spearmanr': 0.6909842933061426, 'sts-b_test_eval_corr': 0.6904097593689588, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-42-roberta-large-10309', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_06-57-25_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-42-roberta-large-10309', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias,adapter_eval_loss': 0.7078709006309509, 'sst-2_dev_bias,adapter_eval_acc': 0.5, 'sst-2_test_bias,adapter_eval_loss': 0.7046769857406616, 'sst-2_test_bias,adapter_eval_acc': 0.5091743119266054, 'sst-2_dev_eval_loss': 0.7078709006309509, 'sst-2_dev_eval_acc': 0.5, 'sst-2_test_eval_loss': 0.7046769857406616, 'sst-2_test_eval_acc': 0.5091743119266054, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--42-roberta-large-30043', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_07-17-20_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--42-roberta-large-30043', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias,adapter_eval_loss': 0.7154229879379272, 'sst-2_dev_bias,adapter_eval_acc': 0.9375, 'sst-2_test_bias,adapter_eval_loss': 0.9040506482124329, 'sst-2_test_bias,adapter_eval_acc': 0.9208715596330275, 'sst-2_dev_eval_loss': 0.7154229879379272, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.9040506482124329, 'sst-2_test_eval_acc': 0.9208715596330275, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--42-roberta-large-25376', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_07-36-20_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--42-roberta-large-25376', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias,adapter_eval_loss': 2.156749963760376, 'mnli_dev_bias,adapter_eval_mnli/acc': 0.6666666666666666, 'mnli_test_bias,adapter_eval_loss': 2.286269426345825, 'mnli_test_bias,adapter_eval_mnli/acc': 0.6434029546612328, 'mnli-mm_test_bias,adapter_eval_loss': 2.0807511806488037, 'mnli-mm_test_bias,adapter_eval_mnli-mm/acc': 0.6582587469487388, 'mnli_dev_eval_loss': 2.156749963760376, 'mnli_dev_eval_mnli/acc': 0.6666666666666666, 'mnli_test_eval_loss': 2.286269426345825, 'mnli_test_eval_mnli/acc': 0.6434029546612328, 'mnli-mm_test_eval_loss': 2.0807511806488037, 'mnli-mm_test_eval_mnli-mm/acc': 0.6582587469487388, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--42-roberta-large-30448', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_07-04-28_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--42-roberta-large-30448', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias,adapter_eval_loss': 2.1194958686828613, 'sts-b_dev_prompt,bias,adapter_eval_pearson': 0.7620166256983207, 'sts-b_dev_prompt,bias,adapter_eval_spearmanr': 0.7842072935579913, 'sts-b_dev_prompt,bias,adapter_eval_corr': 0.773111959628156, 'sts-b_test_prompt,bias,adapter_eval_loss': 2.181593894958496, 'sts-b_test_prompt,bias,adapter_eval_pearson': 0.6503454720250135, 'sts-b_test_prompt,bias,adapter_eval_spearmanr': 0.6507688378925562, 'sts-b_test_prompt,bias,adapter_eval_corr': 0.6505571549587849, 'sts-b_dev_eval_loss': 2.1194958686828613, 'sts-b_dev_eval_pearson': 0.7620166256983207, 'sts-b_dev_eval_spearmanr': 0.7842072935579913, 'sts-b_dev_eval_corr': 0.773111959628156, 'sts-b_test_eval_loss': 2.181593894958496, 'sts-b_test_eval_pearson': 0.6503454720250135, 'sts-b_test_eval_spearmanr': 0.6507688378925562, 'sts-b_test_eval_corr': 0.6505571549587849, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-42-roberta-large-26466', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_07-30-51_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-42-roberta-large-26466', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias,adapter_eval_loss': 0.2704102396965027, 'sst-2_dev_bias,adapter_eval_acc': 0.96875, 'sst-2_test_bias,adapter_eval_loss': 0.7510839104652405, 'sst-2_test_bias,adapter_eval_acc': 0.9243119266055045, 'sst-2_dev_eval_loss': 0.2704102396965027, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.7510839104652405, 'sst-2_test_eval_acc': 0.9243119266055045, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--42-roberta-large-3631', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_07-55-46_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--42-roberta-large-3631', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias,adapter_eval_loss': 0.3295932710170746, 'sst-2_dev_bias,adapter_eval_acc': 0.9375, 'sst-2_test_bias,adapter_eval_loss': 0.5683894753456116, 'sst-2_test_bias,adapter_eval_acc': 0.9346330275229358, 'sst-2_dev_eval_loss': 0.3295932710170746, 'sst-2_dev_eval_acc': 0.9375, 'sst-2_test_eval_loss': 0.5683894753456116, 'sst-2_test_eval_acc': 0.9346330275229358, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--42-roberta-large-8425', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_08-14-06_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--42-roberta-large-8425', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias,adapter_eval_loss': 2.118086338043213, 'sts-b_dev_prompt,bias,adapter_eval_pearson': 0.778954391321336, 'sts-b_dev_prompt,bias,adapter_eval_spearmanr': 0.8040420447767882, 'sts-b_dev_prompt,bias,adapter_eval_corr': 0.7914982180490622, 'sts-b_test_prompt,bias,adapter_eval_loss': 2.196337938308716, 'sts-b_test_prompt,bias,adapter_eval_pearson': 0.557789751842781, 'sts-b_test_prompt,bias,adapter_eval_spearmanr': 0.5568939336454946, 'sts-b_test_prompt,bias,adapter_eval_corr': 0.5573418427441378, 'sts-b_dev_eval_loss': 2.118086338043213, 'sts-b_dev_eval_pearson': 0.778954391321336, 'sts-b_dev_eval_spearmanr': 0.8040420447767882, 'sts-b_dev_eval_corr': 0.7914982180490622, 'sts-b_test_eval_loss': 2.196337938308716, 'sts-b_test_eval_pearson': 0.557789751842781, 'sts-b_test_eval_spearmanr': 0.5568939336454946, 'sts-b_test_eval_corr': 0.5573418427441378, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-42-roberta-large-4132', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_08-05-43_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-42-roberta-large-4132', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias,adapter_eval_loss': 4.434723377227783, 'mnli_dev_bias,adapter_eval_mnli/acc': 0.5833333333333334, 'mnli_test_bias,adapter_eval_loss': 3.311772584915161, 'mnli_test_bias,adapter_eval_mnli/acc': 0.5987773815588385, 'mnli-mm_test_bias,adapter_eval_loss': 3.2210586071014404, 'mnli-mm_test_bias,adapter_eval_mnli-mm/acc': 0.6069975589910497, 'mnli_dev_eval_loss': 4.434723377227783, 'mnli_dev_eval_mnli/acc': 0.5833333333333334, 'mnli_test_eval_loss': 3.311772584915161, 'mnli_test_eval_mnli/acc': 0.5987773815588385, 'mnli-mm_test_eval_loss': 3.2210586071014404, 'mnli-mm_test_eval_mnli-mm/acc': 0.6069975589910497, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--100-roberta-large-25268', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_07-56-44_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--100-roberta-large-25268', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias,adapter_eval_loss': 0.7378561496734619, 'sst-2_dev_bias,adapter_eval_acc': 0.5, 'sst-2_test_bias,adapter_eval_loss': 0.7323564887046814, 'sst-2_test_bias,adapter_eval_acc': 0.5091743119266054, 'sst-2_dev_eval_loss': 0.7378561496734619, 'sst-2_dev_eval_acc': 0.5, 'sst-2_test_eval_loss': 0.7323564887046814, 'sst-2_test_eval_acc': 0.5091743119266054, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--100-roberta-large-15535', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_08-33-19_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--100-roberta-large-15535', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias,adapter_eval_loss': 0.00037595428875647485, 'sst-2_dev_bias,adapter_eval_acc': 1.0, 'sst-2_test_bias,adapter_eval_loss': 0.8678207397460938, 'sst-2_test_bias,adapter_eval_acc': 0.9220183486238532, 'sst-2_dev_eval_loss': 0.00037595428875647485, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.8678207397460938, 'sst-2_test_eval_acc': 0.9220183486238532, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--100-roberta-large-11663', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_08-52-48_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--100-roberta-large-11663', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias,adapter_eval_loss': 2.117386817932129, 'sts-b_dev_prompt,bias,adapter_eval_pearson': 0.3152959128602588, 'sts-b_dev_prompt,bias,adapter_eval_spearmanr': 0.33817909407011304, 'sts-b_dev_prompt,bias,adapter_eval_corr': 0.32673750346518593, 'sts-b_test_prompt,bias,adapter_eval_loss': 2.2149295806884766, 'sts-b_test_prompt,bias,adapter_eval_pearson': -0.018451718358860062, 'sts-b_test_prompt,bias,adapter_eval_spearmanr': -0.024268624260013364, 'sts-b_test_prompt,bias,adapter_eval_corr': -0.021360171309436713, 'sts-b_dev_eval_loss': 2.117386817932129, 'sts-b_dev_eval_pearson': 0.3152959128602588, 'sts-b_dev_eval_spearmanr': 0.33817909407011304, 'sts-b_dev_eval_corr': 0.32673750346518593, 'sts-b_test_eval_loss': 2.2149295806884766, 'sts-b_test_eval_pearson': -0.018451718358860062, 'sts-b_test_eval_spearmanr': -0.024268624260013364, 'sts-b_test_eval_corr': -0.021360171309436713, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-100-roberta-large-11292', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_08-41-18_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-100-roberta-large-11292', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias,adapter_eval_loss': 8.444527338724583e-05, 'sst-2_dev_bias,adapter_eval_acc': 1.0, 'sst-2_test_bias,adapter_eval_loss': 1.0916507244110107, 'sst-2_test_bias,adapter_eval_acc': 0.9048165137614679, 'sst-2_dev_eval_loss': 8.444527338724583e-05, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 1.0916507244110107, 'sst-2_test_eval_acc': 0.9048165137614679, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--100-roberta-large-22240', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_09-11-20_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--100-roberta-large-22240', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias,adapter_eval_loss': 4.105940341949463, 'mnli_dev_bias,adapter_eval_mnli/acc': 0.6666666666666666, 'mnli_test_bias,adapter_eval_loss': 3.590301752090454, 'mnli_test_bias,adapter_eval_mnli/acc': 0.6936321956189506, 'mnli-mm_test_bias,adapter_eval_loss': 3.445394277572632, 'mnli-mm_test_bias,adapter_eval_mnli-mm/acc': 0.7053498779495525, 'mnli_dev_eval_loss': 4.105940341949463, 'mnli_dev_eval_mnli/acc': 0.6666666666666666, 'mnli_test_eval_loss': 3.590301752090454, 'mnli_test_eval_mnli/acc': 0.6936321956189506, 'mnli-mm_test_eval_loss': 3.445394277572632, 'mnli-mm_test_eval_mnli-mm/acc': 0.7053498779495525, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--100-roberta-large-13362', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_08-49-03_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--100-roberta-large-13362', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias,adapter_eval_loss': 0.015312408097088337, 'sst-2_dev_bias,adapter_eval_acc': 1.0, 'sst-2_test_bias,adapter_eval_loss': 0.5744109749794006, 'sst-2_test_bias,adapter_eval_acc': 0.9220183486238532, 'sst-2_dev_eval_loss': 0.015312408097088337, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.5744109749794006, 'sst-2_test_eval_acc': 0.9220183486238532, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16--100-roberta-large-6429', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_09-29-58_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16--100-roberta-large-6429', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias,adapter_eval_loss': 2.0909271240234375, 'sts-b_dev_prompt,bias,adapter_eval_pearson': 0.7458281261221323, 'sts-b_dev_prompt,bias,adapter_eval_spearmanr': 0.6847568020852134, 'sts-b_dev_prompt,bias,adapter_eval_corr': 0.7152924641036729, 'sts-b_test_prompt,bias,adapter_eval_loss': 2.193458080291748, 'sts-b_test_prompt,bias,adapter_eval_pearson': 0.5835134225465923, 'sts-b_test_prompt,bias,adapter_eval_spearmanr': 0.614790723066106, 'sts-b_test_prompt,bias,adapter_eval_corr': 0.5991520728063492, 'sts-b_dev_eval_loss': 2.0909271240234375, 'sts-b_dev_eval_pearson': 0.7458281261221323, 'sts-b_dev_eval_spearmanr': 0.6847568020852134, 'sts-b_dev_eval_corr': 0.7152924641036729, 'sts-b_test_eval_loss': 2.193458080291748, 'sts-b_test_eval_pearson': 0.5835134225465923, 'sts-b_test_eval_spearmanr': 0.614790723066106, 'sts-b_test_eval_corr': 0.5991520728063492, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-100-roberta-large-894', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_09-14-36_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-100-roberta-large-894', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias,adapter_eval_loss': 5.012695789337158, 'sst-2_dev_prompt,bias,adapter_eval_acc': 0.53125, 'sst-2_test_prompt,bias,adapter_eval_loss': 4.17392110824585, 'sst-2_test_prompt,bias,adapter_eval_acc': 0.6490825688073395, 'sst-2_dev_eval_loss': 5.012695789337158, 'sst-2_dev_eval_acc': 0.53125, 'sst-2_test_eval_loss': 4.17392110824585, 'sst-2_test_eval_acc': 0.6490825688073395, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-25022', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_09-46-37_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-25022', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias,adapter_eval_loss': 1.3042943477630615, 'sst-2_dev_prompt,bias,adapter_eval_acc': 0.90625, 'sst-2_test_prompt,bias,adapter_eval_loss': 1.0425488948822021, 'sst-2_test_prompt,bias,adapter_eval_acc': 0.9025229357798165, 'sst-2_dev_eval_loss': 1.3042943477630615, 'sst-2_dev_eval_acc': 0.90625, 'sst-2_test_eval_loss': 1.0425488948822021, 'sst-2_test_eval_acc': 0.9025229357798165, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-839', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_10-02-50_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-839', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias,adapter_eval_loss': 2.0934975147247314, 'sts-b_dev_prompt,bias,adapter_eval_pearson': 0.7298258668507771, 'sts-b_dev_prompt,bias,adapter_eval_spearmanr': 0.663789228773982, 'sts-b_dev_prompt,bias,adapter_eval_corr': 0.6968075478123796, 'sts-b_test_prompt,bias,adapter_eval_loss': 2.188453197479248, 'sts-b_test_prompt,bias,adapter_eval_pearson': 0.6514172584344083, 'sts-b_test_prompt,bias,adapter_eval_spearmanr': 0.6817702237719648, 'sts-b_test_prompt,bias,adapter_eval_corr': 0.6665937411031866, 'sts-b_dev_eval_loss': 2.0934975147247314, 'sts-b_dev_eval_pearson': 0.7298258668507771, 'sts-b_dev_eval_spearmanr': 0.663789228773982, 'sts-b_dev_eval_corr': 0.6968075478123796, 'sts-b_test_eval_loss': 2.188453197479248, 'sts-b_test_eval_pearson': 0.6514172584344083, 'sts-b_test_eval_spearmanr': 0.6817702237719648, 'sts-b_test_eval_corr': 0.6665937411031866, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-100-roberta-large-6532', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_09-49-17_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-100-roberta-large-6532', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias,adapter_eval_loss': 2.8320882320404053, 'mnli_dev_bias,adapter_eval_mnli/acc': 0.7291666666666666, 'mnli_test_bias,adapter_eval_loss': 2.702122688293457, 'mnli_test_bias,adapter_eval_mnli/acc': 0.6837493632195619, 'mnli-mm_test_bias,adapter_eval_loss': 2.521787643432617, 'mnli-mm_test_bias,adapter_eval_mnli-mm/acc': 0.7006712774613507, 'mnli_dev_eval_loss': 2.8320882320404053, 'mnli_dev_eval_mnli/acc': 0.7291666666666666, 'mnli_test_eval_loss': 2.702122688293457, 'mnli_test_eval_mnli/acc': 0.6837493632195619, 'mnli-mm_test_eval_loss': 2.521787643432617, 'mnli-mm_test_eval_mnli-mm/acc': 0.7006712774613507, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--100-roberta-large-27305', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_09-42-40_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--100-roberta-large-27305', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias,adapter_eval_loss': 0.18108785152435303, 'sst-2_dev_prompt,bias,adapter_eval_acc': 0.96875, 'sst-2_test_prompt,bias,adapter_eval_loss': 0.7347175478935242, 'sst-2_test_prompt,bias,adapter_eval_acc': 0.9185779816513762, 'sst-2_dev_eval_loss': 0.18108785152435303, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.7347175478935242, 'sst-2_test_eval_acc': 0.9185779816513762, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-1199', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_10-18-50_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-1199', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias,adapter_eval_loss': 0.08557305485010147, 'sst-2_dev_prompt,bias,adapter_eval_acc': 0.96875, 'sst-2_test_prompt,bias,adapter_eval_loss': 0.5624229907989502, 'sst-2_test_prompt,bias,adapter_eval_acc': 0.9071100917431193, 'sst-2_dev_eval_loss': 0.08557305485010147, 'sst-2_dev_eval_acc': 0.96875, 'sst-2_test_eval_loss': 0.5624229907989502, 'sst-2_test_eval_acc': 0.9071100917431193, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-42-roberta-large-28577', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_10-35-41_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-42-roberta-large-28577', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias,adapter_eval_loss': 2.102263927459717, 'sts-b_dev_prompt,bias,adapter_eval_pearson': 0.6909100838964185, 'sts-b_dev_prompt,bias,adapter_eval_spearmanr': 0.6308664601537153, 'sts-b_dev_prompt,bias,adapter_eval_corr': 0.6608882720250668, 'sts-b_test_prompt,bias,adapter_eval_loss': 2.208190679550171, 'sts-b_test_prompt,bias,adapter_eval_pearson': 0.5784045043598438, 'sts-b_test_prompt,bias,adapter_eval_spearmanr': 0.583736096421885, 'sts-b_test_prompt,bias,adapter_eval_corr': 0.5810703003908644, 'sts-b_dev_eval_loss': 2.102263927459717, 'sts-b_dev_eval_pearson': 0.6909100838964185, 'sts-b_dev_eval_spearmanr': 0.6308664601537153, 'sts-b_dev_eval_corr': 0.6608882720250668, 'sts-b_test_eval_loss': 2.208190679550171, 'sts-b_test_eval_pearson': 0.5784045043598438, 'sts-b_test_eval_spearmanr': 0.583736096421885, 'sts-b_test_eval_corr': 0.5810703003908644, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-100-roberta-large-31558', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_10-22-31_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-100-roberta-large-31558', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias,adapter_eval_loss': 0.7206303477287292, 'sst-2_dev_prompt,bias,adapter_eval_acc': 0.5, 'sst-2_test_prompt,bias,adapter_eval_loss': 0.7163165807723999, 'sst-2_test_prompt,bias,adapter_eval_acc': 0.5091743119266054, 'sst-2_dev_eval_loss': 0.7206303477287292, 'sst-2_dev_eval_acc': 0.5, 'sst-2_test_eval_loss': 0.7163165807723999, 'sst-2_test_eval_acc': 0.5091743119266054, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-5017', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_10-51-36_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-5017', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.173818588256836, 'sts-b_dev_prompt_eval_pearson': 0.36004949419781496, 'sts-b_dev_prompt_eval_spearmanr': 0.35500531579569017, 'sts-b_dev_prompt_eval_corr': 0.35752740499675256, 'sts-b_test_prompt_eval_loss': 2.2724661827087402, 'sts-b_test_prompt_eval_pearson': 0.020623100391398454, 'sts-b_test_prompt_eval_spearmanr': 0.022733245266236383, 'sts-b_test_prompt_eval_corr': 0.02167817282881742, 'sts-b_dev_eval_loss': 2.173818588256836, 'sts-b_dev_eval_pearson': 0.36004949419781496, 'sts-b_dev_eval_spearmanr': 0.35500531579569017, 'sts-b_dev_eval_corr': 0.35752740499675256, 'sts-b_test_eval_loss': 2.2724661827087402, 'sts-b_test_eval_pearson': 0.020623100391398454, 'sts-b_test_eval_spearmanr': 0.022733245266236383, 'sts-b_test_eval_corr': 0.02167817282881742, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-42-roberta-large-7805', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_10-55-54_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-42-roberta-large-7805', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias,adapter_eval_loss': 5.0581722462084144e-05, 'sst-2_dev_prompt,bias,adapter_eval_acc': 1.0, 'sst-2_test_prompt,bias,adapter_eval_loss': 0.7887147665023804, 'sst-2_test_prompt,bias,adapter_eval_acc': 0.9174311926605505, 'sst-2_dev_eval_loss': 5.0581722462084144e-05, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.7887147665023804, 'sst-2_test_eval_acc': 0.9174311926605505, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-8910', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_11-08-23_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-8910', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias,adapter_eval_loss': 2.1945369243621826, 'mnli_dev_bias,adapter_eval_mnli/acc': 0.6666666666666666, 'mnli_test_bias,adapter_eval_loss': 2.0033793449401855, 'mnli_test_bias,adapter_eval_mnli/acc': 0.6800815078960775, 'mnli-mm_test_bias,adapter_eval_loss': 1.9392045736312866, 'mnli-mm_test_bias,adapter_eval_mnli-mm/acc': 0.6948738812042311, 'mnli_dev_eval_loss': 2.1945369243621826, 'mnli_dev_eval_mnli/acc': 0.6666666666666666, 'mnli_test_eval_loss': 2.0033793449401855, 'mnli_test_eval_mnli/acc': 0.6800815078960775, 'mnli-mm_test_eval_loss': 1.9392045736312866, 'mnli-mm_test_eval_mnli-mm/acc': 0.6948738812042311, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--100-roberta-large-12569', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_10-33-54_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--100-roberta-large-12569', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.1963438987731934, 'sts-b_dev_prompt_eval_pearson': 0.31600377734207713, 'sts-b_dev_prompt_eval_spearmanr': 0.2842981008027566, 'sts-b_dev_prompt_eval_corr': 0.30015093907241686, 'sts-b_test_prompt_eval_loss': 2.3093972206115723, 'sts-b_test_prompt_eval_pearson': 0.045640755014192506, 'sts-b_test_prompt_eval_spearmanr': 0.040330971818861784, 'sts-b_test_prompt_eval_corr': 0.042985863416527145, 'sts-b_dev_eval_loss': 2.1963438987731934, 'sts-b_dev_eval_pearson': 0.31600377734207713, 'sts-b_dev_eval_spearmanr': 0.2842981008027566, 'sts-b_dev_eval_corr': 0.30015093907241686, 'sts-b_test_eval_loss': 2.3093972206115723, 'sts-b_test_eval_pearson': 0.045640755014192506, 'sts-b_test_eval_spearmanr': 0.040330971818861784, 'sts-b_test_eval_corr': 0.042985863416527145, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-42-roberta-large-6534', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_11-15-38_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-42-roberta-large-6534', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias,adapter_eval_loss': 0.0006123905768617988, 'sst-2_dev_prompt,bias,adapter_eval_acc': 1.0, 'sst-2_test_prompt,bias,adapter_eval_loss': 1.0249390602111816, 'sst-2_test_prompt,bias,adapter_eval_acc': 0.9139908256880734, 'sst-2_dev_eval_loss': 0.0006123905768617988, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 1.0249390602111816, 'sst-2_test_eval_acc': 0.9139908256880734, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-15622', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_11-25-02_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-15622', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.1645100116729736, 'sts-b_dev_prompt_eval_pearson': 0.39389927170229416, 'sts-b_dev_prompt_eval_spearmanr': 0.37759489357265347, 'sts-b_dev_prompt_eval_corr': 0.3857470826374738, 'sts-b_test_prompt_eval_loss': 2.291579484939575, 'sts-b_test_prompt_eval_pearson': 0.09323784375273979, 'sts-b_test_prompt_eval_spearmanr': 0.09738272022976562, 'sts-b_test_prompt_eval_corr': 0.0953102819912527, 'sts-b_dev_eval_loss': 2.1645100116729736, 'sts-b_dev_eval_pearson': 0.39389927170229416, 'sts-b_dev_eval_spearmanr': 0.37759489357265347, 'sts-b_dev_eval_corr': 0.3857470826374738, 'sts-b_test_eval_loss': 2.291579484939575, 'sts-b_test_eval_pearson': 0.09323784375273979, 'sts-b_test_eval_spearmanr': 0.09738272022976562, 'sts-b_test_eval_corr': 0.0953102819912527, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-42-roberta-large-16575', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_11-35-46_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-42-roberta-large-16575', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt,bias,adapter_eval_loss': 0.01162530668079853, 'sst-2_dev_prompt,bias,adapter_eval_acc': 1.0, 'sst-2_test_prompt,bias,adapter_eval_loss': 0.8178851008415222, 'sst-2_test_prompt,bias,adapter_eval_acc': 0.9231651376146789, 'sst-2_dev_eval_loss': 0.01162530668079853, 'sst-2_dev_eval_acc': 1.0, 'sst-2_test_eval_loss': 0.8178851008415222, 'sst-2_test_eval_acc': 0.9231651376146789, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/SST-2-16-prompt-100-roberta-large-31205', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_11-41-34_node4', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-16-prompt-100-roberta-large-31205', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sst-2', 'data_dir': 'data/k-shot/SST-2/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**mask**sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.1702706813812256, 'sts-b_dev_prompt_eval_pearson': 0.309797341520237, 'sts-b_dev_prompt_eval_spearmanr': 0.2734624496739693, 'sts-b_dev_prompt_eval_corr': 0.2916298955971032, 'sts-b_test_prompt_eval_loss': 2.25288462638855, 'sts-b_test_prompt_eval_pearson': 0.11413601825731828, 'sts-b_test_prompt_eval_spearmanr': 0.10390142251435883, 'sts-b_test_prompt_eval_corr': 0.10901872038583856, 'sts-b_dev_eval_loss': 2.1702706813812256, 'sts-b_dev_eval_pearson': 0.309797341520237, 'sts-b_dev_eval_spearmanr': 0.2734624496739693, 'sts-b_dev_eval_corr': 0.2916298955971032, 'sts-b_test_eval_loss': 2.25288462638855, 'sts-b_test_eval_pearson': 0.11413601825731828, 'sts-b_test_eval_spearmanr': 0.10390142251435883, 'sts-b_test_eval_corr': 0.10901872038583856, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-42-roberta-large-30095', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_11-47-54_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-42-roberta-large-30095', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias,adapter_eval_loss': 5.831636905670166, 'mnli_dev_prompt,bias,adapter_eval_mnli/acc': 0.5208333333333334, 'mnli_test_prompt,bias,adapter_eval_loss': 5.65595817565918, 'mnli_test_prompt,bias,adapter_eval_mnli/acc': 0.5574121242995416, 'mnli-mm_test_prompt,bias,adapter_eval_loss': 5.038564682006836, 'mnli-mm_test_prompt,bias,adapter_eval_mnli-mm/acc': 0.5907241659886087, 'mnli_dev_eval_loss': 5.831636905670166, 'mnli_dev_eval_mnli/acc': 0.5208333333333334, 'mnli_test_eval_loss': 5.65595817565918, 'mnli_test_eval_mnli/acc': 0.5574121242995416, 'mnli-mm_test_eval_loss': 5.038564682006836, 'mnli-mm_test_eval_mnli-mm/acc': 0.5907241659886087, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-20036', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_11-25-09_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-20036', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.134859561920166, 'sts-b_dev_prompt_eval_pearson': 0.4820134906727261, 'sts-b_dev_prompt_eval_spearmanr': 0.4136497576926255, 'sts-b_dev_prompt_eval_corr': 0.4478316241826758, 'sts-b_test_prompt_eval_loss': 2.3082869052886963, 'sts-b_test_prompt_eval_pearson': 0.06451080991777752, 'sts-b_test_prompt_eval_spearmanr': 0.033790265281869486, 'sts-b_test_prompt_eval_corr': 0.049150537599823504, 'sts-b_dev_eval_loss': 2.134859561920166, 'sts-b_dev_eval_pearson': 0.4820134906727261, 'sts-b_dev_eval_spearmanr': 0.4136497576926255, 'sts-b_dev_eval_corr': 0.4478316241826758, 'sts-b_test_eval_loss': 2.3082869052886963, 'sts-b_test_eval_pearson': 0.06451080991777752, 'sts-b_test_eval_spearmanr': 0.033790265281869486, 'sts-b_test_eval_corr': 0.049150537599823504, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-100-roberta-large-11064', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_12-01-01_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-100-roberta-large-11064', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.405034065246582, 'sts-b_dev_prompt_eval_pearson': 0.2692533288854438, 'sts-b_dev_prompt_eval_spearmanr': 0.25823221867516505, 'sts-b_dev_prompt_eval_corr': 0.2637427737803044, 'sts-b_test_prompt_eval_loss': 2.762157917022705, 'sts-b_test_prompt_eval_pearson': 0.060652099356778136, 'sts-b_test_prompt_eval_spearmanr': 0.06151390988912817, 'sts-b_test_prompt_eval_corr': 0.06108300462295316, 'sts-b_dev_eval_loss': 2.405034065246582, 'sts-b_dev_eval_pearson': 0.2692533288854438, 'sts-b_dev_eval_spearmanr': 0.25823221867516505, 'sts-b_dev_eval_corr': 0.2637427737803044, 'sts-b_test_eval_loss': 2.762157917022705, 'sts-b_test_eval_pearson': 0.060652099356778136, 'sts-b_test_eval_spearmanr': 0.06151390988912817, 'sts-b_test_eval_corr': 0.06108300462295316, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-100-roberta-large-13422', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_12-12-47_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-100-roberta-large-13422', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.127157688140869, 'sts-b_dev_prompt_eval_pearson': 0.5625952090313772, 'sts-b_dev_prompt_eval_spearmanr': 0.5451569060920152, 'sts-b_dev_prompt_eval_corr': 0.5538760575616961, 'sts-b_test_prompt_eval_loss': 2.2979736328125, 'sts-b_test_prompt_eval_pearson': 0.1247270947518181, 'sts-b_test_prompt_eval_spearmanr': 0.12019812832367671, 'sts-b_test_prompt_eval_corr': 0.1224626115377474, 'sts-b_dev_eval_loss': 2.127157688140869, 'sts-b_dev_eval_pearson': 0.5625952090313772, 'sts-b_dev_eval_spearmanr': 0.5451569060920152, 'sts-b_dev_eval_corr': 0.5538760575616961, 'sts-b_test_eval_loss': 2.2979736328125, 'sts-b_test_eval_pearson': 0.1247270947518181, 'sts-b_test_eval_spearmanr': 0.12019812832367671, 'sts-b_test_eval_corr': 0.1224626115377474, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-100-roberta-large-10499', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_12-23-55_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-100-roberta-large-10499', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias,adapter_eval_loss': 4.458666801452637, 'mnli_dev_prompt,bias,adapter_eval_mnli/acc': 0.625, 'mnli_test_prompt,bias,adapter_eval_loss': 3.718452215194702, 'mnli_test_prompt,bias,adapter_eval_mnli/acc': 0.6803871625063678, 'mnli-mm_test_prompt,bias,adapter_eval_loss': 3.447991132736206, 'mnli-mm_test_prompt,bias,adapter_eval_mnli-mm/acc': 0.7061635475996745, 'mnli_dev_eval_loss': 4.458666801452637, 'mnli_dev_eval_mnli/acc': 0.625, 'mnli_test_eval_loss': 3.718452215194702, 'mnli_test_eval_mnli/acc': 0.6803871625063678, 'mnli-mm_test_eval_loss': 3.447991132736206, 'mnli-mm_test_eval_mnli-mm/acc': 0.7061635475996745, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-23367', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_12-05-37_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-23367', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt_eval_loss': 2.129750967025757, 'sts-b_dev_prompt_eval_pearson': 0.5525625558893652, 'sts-b_dev_prompt_eval_spearmanr': 0.5786314529573143, 'sts-b_dev_prompt_eval_corr': 0.5655970044233398, 'sts-b_test_prompt_eval_loss': 2.2791380882263184, 'sts-b_test_prompt_eval_pearson': 0.14525789068413394, 'sts-b_test_prompt_eval_spearmanr': 0.130025294473756, 'sts-b_test_prompt_eval_corr': 0.13764159257894498, 'sts-b_dev_eval_loss': 2.129750967025757, 'sts-b_dev_eval_pearson': 0.5525625558893652, 'sts-b_dev_eval_spearmanr': 0.5786314529573143, 'sts-b_dev_eval_corr': 0.5655970044233398, 'sts-b_test_eval_loss': 2.2791380882263184, 'sts-b_test_eval_pearson': 0.14525789068413394, 'sts-b_test_eval_spearmanr': 0.130025294473756, 'sts-b_test_eval_corr': 0.13764159257894498, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-100-roberta-large-11995', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_12-36-13_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-100-roberta-large-11995', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias_eval_loss': 2.1525774002075195, 'sts-b_dev_bias_eval_pearson': 0.28608487965001167, 'sts-b_dev_bias_eval_spearmanr': 0.2676100118516377, 'sts-b_dev_bias_eval_corr': 0.27684744575082465, 'sts-b_test_bias_eval_loss': 2.212533712387085, 'sts-b_test_bias_eval_pearson': -0.005206589493721291, 'sts-b_test_bias_eval_spearmanr': -0.010041927563666722, 'sts-b_test_bias_eval_corr': -0.007624258528694006, 'sts-b_dev_eval_loss': 2.1525774002075195, 'sts-b_dev_eval_pearson': 0.28608487965001167, 'sts-b_dev_eval_spearmanr': 0.2676100118516377, 'sts-b_dev_eval_corr': 0.27684744575082465, 'sts-b_test_eval_loss': 2.212533712387085, 'sts-b_test_eval_pearson': -0.005206589493721291, 'sts-b_test_eval_spearmanr': -0.010041927563666722, 'sts-b_test_eval_corr': -0.007624258528694006, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16--42-roberta-large-16026', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_12-48-12_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--42-roberta-large-16026', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias_eval_loss': 2.1181771755218506, 'sts-b_dev_bias_eval_pearson': 0.7921442707358253, 'sts-b_dev_bias_eval_spearmanr': 0.7636379219236833, 'sts-b_dev_bias_eval_corr': 0.7778910963297543, 'sts-b_test_bias_eval_loss': 2.1758928298950195, 'sts-b_test_bias_eval_pearson': 0.7106773264487267, 'sts-b_test_bias_eval_spearmanr': 0.7083501436442647, 'sts-b_test_bias_eval_corr': 0.7095137350464957, 'sts-b_dev_eval_loss': 2.1181771755218506, 'sts-b_dev_eval_pearson': 0.7921442707358253, 'sts-b_dev_eval_spearmanr': 0.7636379219236833, 'sts-b_dev_eval_corr': 0.7778910963297543, 'sts-b_test_eval_loss': 2.1758928298950195, 'sts-b_test_eval_pearson': 0.7106773264487267, 'sts-b_test_eval_spearmanr': 0.7083501436442647, 'sts-b_test_eval_corr': 0.7095137350464957, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16--42-roberta-large-13313', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_13-01-20_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--42-roberta-large-13313', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias,adapter_eval_loss': 2.8355252742767334, 'mnli_dev_prompt,bias,adapter_eval_mnli/acc': 0.6666666666666666, 'mnli_test_prompt,bias,adapter_eval_loss': 3.1670916080474854, 'mnli_test_prompt,bias,adapter_eval_mnli/acc': 0.6259806418746816, 'mnli-mm_test_prompt,bias,adapter_eval_loss': 2.9377198219299316, 'mnli-mm_test_prompt,bias,adapter_eval_mnli-mm/acc': 0.6472742066720911, 'mnli_dev_eval_loss': 2.8355252742767334, 'mnli_dev_eval_mnli/acc': 0.6666666666666666, 'mnli_test_eval_loss': 3.1670916080474854, 'mnli_test_eval_mnli/acc': 0.6259806418746816, 'mnli-mm_test_eval_loss': 2.9377198219299316, 'mnli-mm_test_eval_mnli-mm/acc': 0.6472742066720911, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-1036', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_12-41-12_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-1036', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias_eval_loss': 2.1205625534057617, 'sts-b_dev_bias_eval_pearson': 0.7564286488973258, 'sts-b_dev_bias_eval_spearmanr': 0.7460070319514194, 'sts-b_dev_bias_eval_corr': 0.7512178404243726, 'sts-b_test_bias_eval_loss': 2.180586338043213, 'sts-b_test_bias_eval_pearson': 0.6499116245228188, 'sts-b_test_bias_eval_spearmanr': 0.6372592611970201, 'sts-b_test_bias_eval_corr': 0.6435854428599195, 'sts-b_dev_eval_loss': 2.1205625534057617, 'sts-b_dev_eval_pearson': 0.7564286488973258, 'sts-b_dev_eval_spearmanr': 0.7460070319514194, 'sts-b_dev_eval_corr': 0.7512178404243726, 'sts-b_test_eval_loss': 2.180586338043213, 'sts-b_test_eval_pearson': 0.6499116245228188, 'sts-b_test_eval_spearmanr': 0.6372592611970201, 'sts-b_test_eval_corr': 0.6435854428599195, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16--42-roberta-large-12034', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_13-15-26_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--42-roberta-large-12034', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias_eval_loss': 2.1237294673919678, 'sts-b_dev_bias_eval_pearson': 0.710483103936802, 'sts-b_dev_bias_eval_spearmanr': 0.6817277455942069, 'sts-b_dev_bias_eval_corr': 0.6961054247655045, 'sts-b_test_bias_eval_loss': 2.1871469020843506, 'sts-b_test_bias_eval_pearson': 0.585454815564655, 'sts-b_test_bias_eval_spearmanr': 0.5769445316075362, 'sts-b_test_bias_eval_corr': 0.5811996735860956, 'sts-b_dev_eval_loss': 2.1237294673919678, 'sts-b_dev_eval_pearson': 0.710483103936802, 'sts-b_dev_eval_spearmanr': 0.6817277455942069, 'sts-b_dev_eval_corr': 0.6961054247655045, 'sts-b_test_eval_loss': 2.1871469020843506, 'sts-b_test_eval_pearson': 0.585454815564655, 'sts-b_test_eval_spearmanr': 0.5769445316075362, 'sts-b_test_eval_corr': 0.5811996735860956, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16--42-roberta-large-28226', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_13-28-54_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--42-roberta-large-28226', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias_eval_loss': 2.111450433731079, 'sts-b_dev_bias_eval_pearson': 0.478969037515364, 'sts-b_dev_bias_eval_spearmanr': 0.4647812083989616, 'sts-b_dev_bias_eval_corr': 0.47187512295716283, 'sts-b_test_bias_eval_loss': 2.211081027984619, 'sts-b_test_bias_eval_pearson': 0.05947455826833192, 'sts-b_test_bias_eval_spearmanr': 0.044318346370689675, 'sts-b_test_bias_eval_corr': 0.0518964523195108, 'sts-b_dev_eval_loss': 2.111450433731079, 'sts-b_dev_eval_pearson': 0.478969037515364, 'sts-b_dev_eval_spearmanr': 0.4647812083989616, 'sts-b_dev_eval_corr': 0.47187512295716283, 'sts-b_test_eval_loss': 2.211081027984619, 'sts-b_test_eval_pearson': 0.05947455826833192, 'sts-b_test_eval_spearmanr': 0.044318346370689675, 'sts-b_test_eval_corr': 0.0518964523195108, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16--100-roberta-large-10518', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_13-47-04_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--100-roberta-large-10518', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias,adapter_eval_loss': 3.0605967044830322, 'mnli_dev_prompt,bias,adapter_eval_mnli/acc': 0.6458333333333334, 'mnli_test_prompt,bias,adapter_eval_loss': 2.8611767292022705, 'mnli_test_prompt,bias,adapter_eval_mnli/acc': 0.6220071319409067, 'mnli-mm_test_prompt,bias,adapter_eval_loss': 2.6453850269317627, 'mnli-mm_test_prompt,bias,adapter_eval_mnli-mm/acc': 0.6379170056956875, 'mnli_dev_eval_loss': 3.0605967044830322, 'mnli_dev_eval_mnli/acc': 0.6458333333333334, 'mnli_test_eval_loss': 2.8611767292022705, 'mnli_test_eval_mnli/acc': 0.6220071319409067, 'mnli-mm_test_eval_loss': 2.6453850269317627, 'mnli-mm_test_eval_mnli-mm/acc': 0.6379170056956875, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-23089', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_13-18-24_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-23089', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias_eval_loss': 2.101759195327759, 'sts-b_dev_bias_eval_pearson': 0.6759800930540112, 'sts-b_dev_bias_eval_spearmanr': 0.6163362997011953, 'sts-b_dev_bias_eval_corr': 0.6461581963776033, 'sts-b_test_bias_eval_loss': 2.1936888694763184, 'sts-b_test_bias_eval_pearson': 0.5642567394421758, 'sts-b_test_bias_eval_spearmanr': 0.5492451472349944, 'sts-b_test_bias_eval_corr': 0.5567509433385851, 'sts-b_dev_eval_loss': 2.101759195327759, 'sts-b_dev_eval_pearson': 0.6759800930540112, 'sts-b_dev_eval_spearmanr': 0.6163362997011953, 'sts-b_dev_eval_corr': 0.6461581963776033, 'sts-b_test_eval_loss': 2.1936888694763184, 'sts-b_test_eval_pearson': 0.5642567394421758, 'sts-b_test_eval_spearmanr': 0.5492451472349944, 'sts-b_test_eval_corr': 0.5567509433385851, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16--100-roberta-large-684', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_14-08-22_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--100-roberta-large-684', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias_eval_loss': 2.1100430488586426, 'sts-b_dev_bias_eval_pearson': 0.5787122385784043, 'sts-b_dev_bias_eval_spearmanr': 0.5091073940832314, 'sts-b_dev_bias_eval_corr': 0.5439098163308178, 'sts-b_test_bias_eval_loss': 2.188901901245117, 'sts-b_test_bias_eval_pearson': 0.6099745733780128, 'sts-b_test_bias_eval_spearmanr': 0.6084141908765726, 'sts-b_test_bias_eval_corr': 0.6091943821272927, 'sts-b_dev_eval_loss': 2.1100430488586426, 'sts-b_dev_eval_pearson': 0.5787122385784043, 'sts-b_dev_eval_spearmanr': 0.5091073940832314, 'sts-b_dev_eval_corr': 0.5439098163308178, 'sts-b_test_eval_loss': 2.188901901245117, 'sts-b_test_eval_pearson': 0.6099745733780128, 'sts-b_test_eval_spearmanr': 0.6084141908765726, 'sts-b_test_eval_corr': 0.6091943821272927, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16--100-roberta-large-1288', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_14-28-07_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--100-roberta-large-1288', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias,adapter_eval_loss': 2.469191312789917, 'mnli_dev_prompt,bias,adapter_eval_mnli/acc': 0.75, 'mnli_test_prompt,bias,adapter_eval_loss': 3.3065943717956543, 'mnli_test_prompt,bias,adapter_eval_mnli/acc': 0.6713194090677534, 'mnli-mm_test_prompt,bias,adapter_eval_loss': 3.0682754516601562, 'mnli-mm_test_prompt,bias,adapter_eval_mnli-mm/acc': 0.697213181448332, 'mnli_dev_eval_loss': 2.469191312789917, 'mnli_dev_eval_mnli/acc': 0.75, 'mnli_test_eval_loss': 3.3065943717956543, 'mnli_test_eval_mnli/acc': 0.6713194090677534, 'mnli-mm_test_eval_loss': 3.0682754516601562, 'mnli-mm_test_eval_mnli-mm/acc': 0.697213181448332, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-31856', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_14-08-27_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-31856', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias_eval_loss': 2.1452114582061768, 'sts-b_dev_bias_eval_pearson': 0.5112838488066109, 'sts-b_dev_bias_eval_spearmanr': 0.4655169127256715, 'sts-b_dev_bias_eval_corr': 0.48840038076614123, 'sts-b_test_bias_eval_loss': 2.208782196044922, 'sts-b_test_bias_eval_pearson': 0.5487630411380231, 'sts-b_test_bias_eval_spearmanr': 0.536489600728325, 'sts-b_test_bias_eval_corr': 0.5426263209331741, 'sts-b_dev_eval_loss': 2.1452114582061768, 'sts-b_dev_eval_pearson': 0.5112838488066109, 'sts-b_dev_eval_spearmanr': 0.4655169127256715, 'sts-b_dev_eval_corr': 0.48840038076614123, 'sts-b_test_eval_loss': 2.208782196044922, 'sts-b_test_eval_pearson': 0.5487630411380231, 'sts-b_test_eval_spearmanr': 0.536489600728325, 'sts-b_test_eval_corr': 0.5426263209331741, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16--100-roberta-large-21346', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_14-48-31_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--100-roberta-large-21346', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_adapter_eval_loss': 2.166234016418457, 'sts-b_dev_adapter_eval_pearson': 0.3824170080607392, 'sts-b_dev_adapter_eval_spearmanr': 0.39314978062349376, 'sts-b_dev_adapter_eval_corr': 0.3877833943421165, 'sts-b_test_adapter_eval_loss': 2.2179811000823975, 'sts-b_test_adapter_eval_pearson': -0.05621735193465811, 'sts-b_test_adapter_eval_spearmanr': -0.054218939370020855, 'sts-b_test_adapter_eval_corr': -0.055218145652339484, 'sts-b_dev_eval_loss': 2.166234016418457, 'sts-b_dev_eval_pearson': 0.3824170080607392, 'sts-b_dev_eval_spearmanr': 0.39314978062349376, 'sts-b_dev_eval_corr': 0.3877833943421165, 'sts-b_test_eval_loss': 2.2179811000823975, 'sts-b_test_eval_pearson': -0.05621735193465811, 'sts-b_test_eval_spearmanr': -0.054218939370020855, 'sts-b_test_eval_corr': -0.055218145652339484, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--42-roberta-large-18373', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_15-09-38_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--42-roberta-large-18373', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_adapter_eval_loss': 2.1142053604125977, 'sts-b_dev_adapter_eval_pearson': 0.8413312503246417, 'sts-b_dev_adapter_eval_spearmanr': 0.8560164391741915, 'sts-b_dev_adapter_eval_corr': 0.8486738447494167, 'sts-b_test_adapter_eval_loss': 2.1753547191619873, 'sts-b_test_adapter_eval_pearson': 0.7002542243630279, 'sts-b_test_adapter_eval_spearmanr': 0.691068596533272, 'sts-b_test_adapter_eval_corr': 0.69566141044815, 'sts-b_dev_eval_loss': 2.1142053604125977, 'sts-b_dev_eval_pearson': 0.8413312503246417, 'sts-b_dev_eval_spearmanr': 0.8560164391741915, 'sts-b_dev_eval_corr': 0.8486738447494167, 'sts-b_test_eval_loss': 2.1753547191619873, 'sts-b_test_eval_pearson': 0.7002542243630279, 'sts-b_test_eval_spearmanr': 0.691068596533272, 'sts-b_test_eval_corr': 0.69566141044815, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--42-roberta-large-31417', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_15-32-01_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--42-roberta-large-31417', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias,adapter_eval_loss': 2.4014861583709717, 'mnli_dev_prompt,bias,adapter_eval_mnli/acc': 0.6875, 'mnli_test_prompt,bias,adapter_eval_loss': 2.5754714012145996, 'mnli_test_prompt,bias,adapter_eval_mnli/acc': 0.6784513499745288, 'mnli-mm_test_prompt,bias,adapter_eval_loss': 2.4267804622650146, 'mnli-mm_test_prompt,bias,adapter_eval_mnli-mm/acc': 0.6979251423921887, 'mnli_dev_eval_loss': 2.4014861583709717, 'mnli_dev_eval_mnli/acc': 0.6875, 'mnli_test_eval_loss': 2.5754714012145996, 'mnli_test_eval_mnli/acc': 0.6784513499745288, 'mnli-mm_test_eval_loss': 2.4267804622650146, 'mnli-mm_test_eval_mnli-mm/acc': 0.6979251423921887, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-15864', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_15-06-53_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-15864', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_adapter_eval_loss': 2.113267660140991, 'sts-b_dev_adapter_eval_pearson': 0.8595819095628949, 'sts-b_dev_adapter_eval_spearmanr': 0.8433442370066268, 'sts-b_dev_adapter_eval_corr': 0.8514630732847608, 'sts-b_test_adapter_eval_loss': 2.177065849304199, 'sts-b_test_adapter_eval_pearson': 0.678751911088297, 'sts-b_test_adapter_eval_spearmanr': 0.6774808213417974, 'sts-b_test_adapter_eval_corr': 0.6781163662150472, 'sts-b_dev_eval_loss': 2.113267660140991, 'sts-b_dev_eval_pearson': 0.8595819095628949, 'sts-b_dev_eval_spearmanr': 0.8433442370066268, 'sts-b_dev_eval_corr': 0.8514630732847608, 'sts-b_test_eval_loss': 2.177065849304199, 'sts-b_test_eval_pearson': 0.678751911088297, 'sts-b_test_eval_spearmanr': 0.6774808213417974, 'sts-b_test_eval_corr': 0.6781163662150472, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--42-roberta-large-19703', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_15-55-07_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--42-roberta-large-19703', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_adapter_eval_loss': 2.122122287750244, 'sts-b_dev_adapter_eval_pearson': 0.7521421435527093, 'sts-b_dev_adapter_eval_spearmanr': 0.69862401515096, 'sts-b_dev_adapter_eval_corr': 0.7253830793518345, 'sts-b_test_adapter_eval_loss': 2.1886093616485596, 'sts-b_test_adapter_eval_pearson': 0.5630107849300932, 'sts-b_test_adapter_eval_spearmanr': 0.5486112532432703, 'sts-b_test_adapter_eval_corr': 0.5558110190866817, 'sts-b_dev_eval_loss': 2.122122287750244, 'sts-b_dev_eval_pearson': 0.7521421435527093, 'sts-b_dev_eval_spearmanr': 0.69862401515096, 'sts-b_dev_eval_corr': 0.7253830793518345, 'sts-b_test_eval_loss': 2.1886093616485596, 'sts-b_test_eval_pearson': 0.5630107849300932, 'sts-b_test_eval_spearmanr': 0.5486112532432703, 'sts-b_test_eval_corr': 0.5558110190866817, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--42-roberta-large-22866', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_16-18-14_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--42-roberta-large-22866', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias,adapter_eval_loss': 1.9752222299575806, 'mnli_dev_prompt,bias,adapter_eval_mnli/acc': 0.7083333333333334, 'mnli_test_prompt,bias,adapter_eval_loss': 2.257063627243042, 'mnli_test_prompt,bias,adapter_eval_mnli/acc': 0.6915944982170148, 'mnli-mm_test_prompt,bias,adapter_eval_loss': 2.3423869609832764, 'mnli-mm_test_prompt,bias,adapter_eval_mnli-mm/acc': 0.6921277461350691, 'mnli_dev_eval_loss': 1.9752222299575806, 'mnli_dev_eval_mnli/acc': 0.7083333333333334, 'mnli_test_eval_loss': 2.257063627243042, 'mnli_test_eval_mnli/acc': 0.6915944982170148, 'mnli-mm_test_eval_loss': 2.3423869609832764, 'mnli-mm_test_eval_mnli-mm/acc': 0.6921277461350691, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-8498', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_16-04-52_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-8498', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_adapter_eval_loss': 2.118379831314087, 'sts-b_dev_adapter_eval_pearson': 0.3010693682950293, 'sts-b_dev_adapter_eval_spearmanr': 0.3289804501570816, 'sts-b_dev_adapter_eval_corr': 0.3150249092260554, 'sts-b_test_adapter_eval_loss': 2.215754508972168, 'sts-b_test_adapter_eval_pearson': -0.012021995374256089, 'sts-b_test_adapter_eval_spearmanr': -0.016090958803470015, 'sts-b_test_adapter_eval_corr': -0.014056477088863052, 'sts-b_dev_eval_loss': 2.118379831314087, 'sts-b_dev_eval_pearson': 0.3010693682950293, 'sts-b_dev_eval_spearmanr': 0.3289804501570816, 'sts-b_dev_eval_corr': 0.3150249092260554, 'sts-b_test_eval_loss': 2.215754508972168, 'sts-b_test_eval_pearson': -0.012021995374256089, 'sts-b_test_eval_spearmanr': -0.016090958803470015, 'sts-b_test_eval_corr': -0.014056477088863052, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--100-roberta-large-20015', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_16-41-44_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--100-roberta-large-20015', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt_eval_loss': 0.714008092880249, 'qnli_dev_prompt_eval_acc': 0.59375, 'qnli_test_prompt_eval_loss': 0.7790549993515015, 'qnli_test_prompt_eval_acc': 0.5165659893831228, 'qnli_dev_eval_loss': 0.714008092880249, 'qnli_dev_eval_acc': 0.59375, 'qnli_test_eval_loss': 0.7790549993515015, 'qnli_test_eval_acc': 0.5165659893831228, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-42-roberta-large-32006', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_17-11-34_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-42-roberta-large-32006', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_adapter_eval_loss': 2.09226393699646, 'sts-b_dev_adapter_eval_pearson': 0.7105140025211776, 'sts-b_dev_adapter_eval_spearmanr': 0.6698587894693384, 'sts-b_dev_adapter_eval_corr': 0.690186395995258, 'sts-b_test_adapter_eval_loss': 2.190216541290283, 'sts-b_test_adapter_eval_pearson': 0.5649610192949451, 'sts-b_test_adapter_eval_spearmanr': 0.5637257573605639, 'sts-b_test_adapter_eval_corr': 0.5643433883277544, 'sts-b_dev_eval_loss': 2.09226393699646, 'sts-b_dev_eval_pearson': 0.7105140025211776, 'sts-b_dev_eval_spearmanr': 0.6698587894693384, 'sts-b_dev_eval_corr': 0.690186395995258, 'sts-b_test_eval_loss': 2.190216541290283, 'sts-b_test_eval_pearson': 0.5649610192949451, 'sts-b_test_eval_spearmanr': 0.5637257573605639, 'sts-b_test_eval_corr': 0.5643433883277544, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--100-roberta-large-18210', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_17-06-32_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--100-roberta-large-18210', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt_eval_loss': 0.7266675233840942, 'qqp_dev_prompt_eval_acc': 0.65625, 'qqp_dev_prompt_eval_f1': 0.7027027027027026, 'qqp_dev_prompt_eval_acc_and_f1': 0.6794763513513513, 'qqp_test_prompt_eval_loss': 0.8063749074935913, 'qqp_test_prompt_eval_acc': 0.4927034380410586, 'qqp_test_prompt_eval_f1': 0.51333523158694, 'qqp_test_prompt_eval_acc_and_f1': 0.5030193348139993, 'qqp_dev_eval_loss': 0.7266675233840942, 'qqp_dev_eval_acc': 0.65625, 'qqp_dev_eval_f1': 0.7027027027027026, 'qqp_dev_eval_acc_and_f1': 0.6794763513513513, 'qqp_test_eval_loss': 0.8063749074935913, 'qqp_test_eval_acc': 0.4927034380410586, 'qqp_test_eval_f1': 0.51333523158694, 'qqp_test_eval_acc_and_f1': 0.5030193348139993, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-42-roberta-large-28682', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_17-17-02_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-42-roberta-large-28682', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt_eval_loss': 3.0497193336486816, 'qnli_dev_prompt_eval_acc': 0.59375, 'qnli_test_prompt_eval_loss': 3.423197031021118, 'qnli_test_prompt_eval_acc': 0.4836170602233205, 'qnli_dev_eval_loss': 3.0497193336486816, 'qnli_dev_eval_acc': 0.59375, 'qnli_test_eval_loss': 3.423197031021118, 'qnli_test_eval_acc': 0.4836170602233205, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-42-roberta-large-19868', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_17-29-12_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-42-roberta-large-19868', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias,adapter_eval_loss': 2.010162591934204, 'mnli_dev_prompt,bias,adapter_eval_mnli/acc': 0.7083333333333334, 'mnli_test_prompt,bias,adapter_eval_loss': 1.7491158246994019, 'mnli_test_prompt,bias,adapter_eval_mnli/acc': 0.6812022414671421, 'mnli-mm_test_prompt,bias,adapter_eval_loss': 1.8428900241851807, 'mnli-mm_test_prompt,bias,adapter_eval_mnli-mm/acc': 0.6891781936533767, 'mnli_dev_eval_loss': 2.010162591934204, 'mnli_dev_eval_mnli/acc': 0.7083333333333334, 'mnli_test_eval_loss': 1.7491158246994019, 'mnli_test_eval_mnli/acc': 0.6812022414671421, 'mnli-mm_test_eval_loss': 1.8428900241851807, 'mnli-mm_test_eval_mnli-mm/acc': 0.6891781936533767, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-9884', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_17-01-33_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-9884', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_adapter_eval_loss': 2.097285270690918, 'sts-b_dev_adapter_eval_pearson': 0.6678714453833583, 'sts-b_dev_adapter_eval_spearmanr': 0.6185434126813248, 'sts-b_dev_adapter_eval_corr': 0.6432074290323415, 'sts-b_test_adapter_eval_loss': 2.181913137435913, 'sts-b_test_adapter_eval_pearson': 0.636284298591135, 'sts-b_test_adapter_eval_spearmanr': 0.6315223040523841, 'sts-b_test_adapter_eval_corr': 0.6339033013217595, 'sts-b_dev_eval_loss': 2.097285270690918, 'sts-b_dev_eval_pearson': 0.6678714453833583, 'sts-b_dev_eval_spearmanr': 0.6185434126813248, 'sts-b_dev_eval_corr': 0.6432074290323415, 'sts-b_test_eval_loss': 2.181913137435913, 'sts-b_test_eval_pearson': 0.636284298591135, 'sts-b_test_eval_spearmanr': 0.6315223040523841, 'sts-b_test_eval_corr': 0.6339033013217595, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--100-roberta-large-19001', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_17-31-54_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--100-roberta-large-19001', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt_eval_loss': 0.6771430969238281, 'qqp_dev_prompt_eval_acc': 0.6875, 'qqp_dev_prompt_eval_f1': 0.75, 'qqp_dev_prompt_eval_acc_and_f1': 0.71875, 'qqp_test_prompt_eval_loss': 1.1799453496932983, 'qqp_test_prompt_eval_acc': 0.4577046747464754, 'qqp_test_prompt_eval_f1': 0.5486361296963458, 'qqp_test_prompt_eval_acc_and_f1': 0.5031704022214106, 'qqp_dev_eval_loss': 0.6771430969238281, 'qqp_dev_eval_acc': 0.6875, 'qqp_dev_eval_f1': 0.75, 'qqp_dev_eval_acc_and_f1': 0.71875, 'qqp_test_eval_loss': 1.1799453496932983, 'qqp_test_eval_acc': 0.4577046747464754, 'qqp_test_eval_f1': 0.5486361296963458, 'qqp_test_eval_acc_and_f1': 0.5031704022214106, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-42-roberta-large-26004', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_17-39-30_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-42-roberta-large-26004', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt_eval_loss': 0.7464724779129028, 'qnli_dev_prompt_eval_acc': 0.59375, 'qnli_test_prompt_eval_loss': 0.7418191432952881, 'qnli_test_prompt_eval_acc': 0.5096101043382757, 'qnli_dev_eval_loss': 0.7464724779129028, 'qnli_dev_eval_acc': 0.59375, 'qnli_test_eval_loss': 0.7418191432952881, 'qnli_test_eval_acc': 0.5096101043382757, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-42-roberta-large-9466', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_17-51-28_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-42-roberta-large-9466', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_adapter_eval_loss': 2.1094586849212646, 'sts-b_dev_adapter_eval_pearson': 0.6000036719209723, 'sts-b_dev_adapter_eval_spearmanr': 0.5571121014010505, 'sts-b_dev_adapter_eval_corr': 0.5785578866610114, 'sts-b_test_adapter_eval_loss': 2.1934618949890137, 'sts-b_test_adapter_eval_pearson': 0.5478471567447174, 'sts-b_test_adapter_eval_spearmanr': 0.5353664370777504, 'sts-b_test_adapter_eval_corr': 0.5416067969112339, 'sts-b_dev_eval_loss': 2.1094586849212646, 'sts-b_dev_eval_pearson': 0.6000036719209723, 'sts-b_dev_eval_spearmanr': 0.5571121014010505, 'sts-b_dev_eval_corr': 0.5785578866610114, 'sts-b_test_eval_loss': 2.1934618949890137, 'sts-b_test_eval_pearson': 0.5478471567447174, 'sts-b_test_eval_spearmanr': 0.5353664370777504, 'sts-b_test_eval_corr': 0.5416067969112339, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--100-roberta-large-13239', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_17-57-10_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--100-roberta-large-13239', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt_eval_loss': 0.7323927879333496, 'qqp_dev_prompt_eval_acc': 0.6875, 'qqp_dev_prompt_eval_f1': 0.7368421052631579, 'qqp_dev_prompt_eval_acc_and_f1': 0.712171052631579, 'qqp_test_prompt_eval_loss': 1.0164201259613037, 'qqp_test_prompt_eval_acc': 0.479248083106604, 'qqp_test_prompt_eval_f1': 0.5218043063505042, 'qqp_test_prompt_eval_acc_and_f1': 0.5005261947285541, 'qqp_dev_eval_loss': 0.7323927879333496, 'qqp_dev_eval_acc': 0.6875, 'qqp_dev_eval_f1': 0.7368421052631579, 'qqp_dev_eval_acc_and_f1': 0.712171052631579, 'qqp_test_eval_loss': 1.0164201259613037, 'qqp_test_eval_acc': 0.479248083106604, 'qqp_test_eval_f1': 0.5218043063505042, 'qqp_test_eval_acc_and_f1': 0.5005261947285541, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-42-roberta-large-24816', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_18-01-39_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-42-roberta-large-24816', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt_eval_loss': 1.3418292999267578, 'mnli_dev_prompt_eval_mnli/acc': 0.4166666666666667, 'mnli_test_prompt_eval_loss': 1.520777702331543, 'mnli_test_prompt_eval_mnli/acc': 0.32012226184411613, 'mnli-mm_test_prompt_eval_loss': 1.4982991218566895, 'mnli-mm_test_prompt_eval_mnli-mm/acc': 0.322620016273393, 'mnli_dev_eval_loss': 1.3418292999267578, 'mnli_dev_eval_mnli/acc': 0.4166666666666667, 'mnli_test_eval_loss': 1.520777702331543, 'mnli_test_eval_mnli/acc': 0.32012226184411613, 'mnli-mm_test_eval_loss': 1.4982991218566895, 'mnli-mm_test_eval_mnli-mm/acc': 0.322620016273393, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-31594', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_17-57-11_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-31594', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt_eval_loss': 0.6932764053344727, 'qnli_dev_prompt_eval_acc': 0.5625, 'qnli_test_prompt_eval_loss': 0.7237076163291931, 'qnli_test_prompt_eval_acc': 0.5141863444993593, 'qnli_dev_eval_loss': 0.6932764053344727, 'qnli_dev_eval_acc': 0.5625, 'qnli_test_eval_loss': 0.7237076163291931, 'qnli_test_eval_acc': 0.5141863444993593, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-42-roberta-large-30785', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_18-14-00_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-42-roberta-large-30785', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,adapter_eval_loss': 2.1203725337982178, 'sts-b_dev_prompt,adapter_eval_pearson': 0.7804089640622409, 'sts-b_dev_prompt,adapter_eval_spearmanr': 0.7764937791951259, 'sts-b_dev_prompt,adapter_eval_corr': 0.7784513716286834, 'sts-b_test_prompt,adapter_eval_loss': 2.178593158721924, 'sts-b_test_prompt,adapter_eval_pearson': 0.6703117923878148, 'sts-b_test_prompt,adapter_eval_spearmanr': 0.6593294973901924, 'sts-b_test_prompt,adapter_eval_corr': 0.6648206448890036, 'sts-b_dev_eval_loss': 2.1203725337982178, 'sts-b_dev_eval_pearson': 0.7804089640622409, 'sts-b_dev_eval_spearmanr': 0.7764937791951259, 'sts-b_dev_eval_corr': 0.7784513716286834, 'sts-b_test_eval_loss': 2.178593158721924, 'sts-b_test_eval_pearson': 0.6703117923878148, 'sts-b_test_eval_spearmanr': 0.6593294973901924, 'sts-b_test_eval_corr': 0.6648206448890036, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-42-roberta-large-12185', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_18-22-23_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-42-roberta-large-12185', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt_eval_loss': 0.8653236627578735, 'qqp_dev_prompt_eval_acc': 0.53125, 'qqp_dev_prompt_eval_f1': 0.6341463414634146, 'qqp_dev_prompt_eval_acc_and_f1': 0.5826981707317074, 'qqp_test_prompt_eval_loss': 0.8988714218139648, 'qqp_test_prompt_eval_acc': 0.4256740044521395, 'qqp_test_prompt_eval_f1': 0.5061045645977794, 'qqp_test_prompt_eval_acc_and_f1': 0.4658892845249595, 'qqp_dev_eval_loss': 0.8653236627578735, 'qqp_dev_eval_acc': 0.53125, 'qqp_dev_eval_f1': 0.6341463414634146, 'qqp_dev_eval_acc_and_f1': 0.5826981707317074, 'qqp_test_eval_loss': 0.8988714218139648, 'qqp_test_eval_acc': 0.4256740044521395, 'qqp_test_eval_f1': 0.5061045645977794, 'qqp_test_eval_acc_and_f1': 0.4658892845249595, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-42-roberta-large-3963', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_18-23-25_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-42-roberta-large-3963', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt_eval_loss': 0.6059290766716003, 'qnli_dev_prompt_eval_acc': 0.6875, 'qnli_test_prompt_eval_loss': 0.7758882641792297, 'qnli_test_prompt_eval_acc': 0.5253523704924035, 'qnli_dev_eval_loss': 0.6059290766716003, 'qnli_dev_eval_acc': 0.6875, 'qnli_test_eval_loss': 0.7758882641792297, 'qnli_test_eval_acc': 0.5253523704924035, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-100-roberta-large-25801', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_18-40-33_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-100-roberta-large-25801', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,adapter_eval_loss': 2.1174278259277344, 'sts-b_dev_prompt,adapter_eval_pearson': 0.8291685998035003, 'sts-b_dev_prompt,adapter_eval_spearmanr': 0.801287218218622, 'sts-b_dev_prompt,adapter_eval_corr': 0.8152279090110612, 'sts-b_test_prompt,adapter_eval_loss': 2.183475971221924, 'sts-b_test_prompt,adapter_eval_pearson': 0.6163636088689584, 'sts-b_test_prompt,adapter_eval_spearmanr': 0.6073366912117303, 'sts-b_test_prompt,adapter_eval_corr': 0.6118501500403444, 'sts-b_dev_eval_loss': 2.1174278259277344, 'sts-b_dev_eval_pearson': 0.8291685998035003, 'sts-b_dev_eval_spearmanr': 0.801287218218622, 'sts-b_dev_eval_corr': 0.8152279090110612, 'sts-b_test_eval_loss': 2.183475971221924, 'sts-b_test_eval_pearson': 0.6163636088689584, 'sts-b_test_eval_spearmanr': 0.6073366912117303, 'sts-b_test_eval_corr': 0.6118501500403444, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-42-roberta-large-30740', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_18-49-51_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-42-roberta-large-30740', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt_eval_loss': 0.7240594029426575, 'qqp_dev_prompt_eval_acc': 0.625, 'qqp_dev_prompt_eval_f1': 0.625, 'qqp_dev_prompt_eval_acc_and_f1': 0.625, 'qqp_test_prompt_eval_loss': 0.7940051555633545, 'qqp_test_prompt_eval_acc': 0.5549344546129112, 'qqp_test_prompt_eval_f1': 0.4283626659889446, 'qqp_test_prompt_eval_acc_and_f1': 0.49164856030092796, 'qqp_dev_eval_loss': 0.7240594029426575, 'qqp_dev_eval_acc': 0.625, 'qqp_dev_eval_f1': 0.625, 'qqp_dev_eval_acc_and_f1': 0.625, 'qqp_test_eval_loss': 0.7940051555633545, 'qqp_test_eval_acc': 0.5549344546129112, 'qqp_test_eval_f1': 0.4283626659889446, 'qqp_test_eval_acc_and_f1': 0.49164856030092796, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-100-roberta-large-21121', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_18-54-17_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-100-roberta-large-21121', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt_eval_loss': 1.1947616338729858, 'mnli_dev_prompt_eval_mnli/acc': 0.4375, 'mnli_test_prompt_eval_loss': 1.1796753406524658, 'mnli_test_prompt_eval_mnli/acc': 0.3611818644931228, 'mnli-mm_test_prompt_eval_loss': 1.1706632375717163, 'mnli-mm_test_prompt_eval_mnli-mm/acc': 0.3619812855980472, 'mnli_dev_eval_loss': 1.1947616338729858, 'mnli_dev_eval_mnli/acc': 0.4375, 'mnli_test_eval_loss': 1.1796753406524658, 'mnli_test_eval_mnli/acc': 0.3611818644931228, 'mnli-mm_test_eval_loss': 1.1706632375717163, 'mnli-mm_test_eval_mnli-mm/acc': 0.3619812855980472, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-11924', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_18-40-06_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-11924', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt_eval_loss': 2.3386893272399902, 'qnli_dev_prompt_eval_acc': 0.6875, 'qnli_test_prompt_eval_loss': 4.121875286102295, 'qnli_test_prompt_eval_acc': 0.5026542192934286, 'qnli_dev_eval_loss': 2.3386893272399902, 'qnli_dev_eval_acc': 0.6875, 'qnli_test_eval_loss': 4.121875286102295, 'qnli_test_eval_acc': 0.5026542192934286, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-100-roberta-large-16759', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_19-11-18_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-100-roberta-large-16759', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt_eval_loss': 0.6692712903022766, 'qqp_dev_prompt_eval_acc': 0.625, 'qqp_dev_prompt_eval_f1': 0.7142857142857143, 'qqp_dev_prompt_eval_acc_and_f1': 0.6696428571428572, 'qqp_test_prompt_eval_loss': 0.8024404644966125, 'qqp_test_prompt_eval_acc': 0.47996537224833047, 'qqp_test_prompt_eval_f1': 0.5252557183823695, 'qqp_test_prompt_eval_acc_and_f1': 0.50261054531535, 'qqp_dev_eval_loss': 0.6692712903022766, 'qqp_dev_eval_acc': 0.625, 'qqp_dev_eval_f1': 0.7142857142857143, 'qqp_dev_eval_acc_and_f1': 0.6696428571428572, 'qqp_test_eval_loss': 0.8024404644966125, 'qqp_test_eval_acc': 0.47996537224833047, 'qqp_test_eval_f1': 0.5252557183823695, 'qqp_test_eval_acc_and_f1': 0.50261054531535, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-100-roberta-large-26443', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_19-19-11_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-100-roberta-large-26443', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,adapter_eval_loss': 2.1149396896362305, 'sts-b_dev_prompt,adapter_eval_pearson': 0.8646157781146735, 'sts-b_dev_prompt,adapter_eval_spearmanr': 0.8479356146035705, 'sts-b_dev_prompt,adapter_eval_corr': 0.856275696359122, 'sts-b_test_prompt,adapter_eval_loss': 2.1813926696777344, 'sts-b_test_prompt,adapter_eval_pearson': 0.6513941581637278, 'sts-b_test_prompt,adapter_eval_spearmanr': 0.6490158743134914, 'sts-b_test_prompt,adapter_eval_corr': 0.6502050162386096, 'sts-b_dev_eval_loss': 2.1149396896362305, 'sts-b_dev_eval_pearson': 0.8646157781146735, 'sts-b_dev_eval_spearmanr': 0.8479356146035705, 'sts-b_dev_eval_corr': 0.856275696359122, 'sts-b_test_eval_loss': 2.1813926696777344, 'sts-b_test_eval_pearson': 0.6513941581637278, 'sts-b_test_eval_spearmanr': 0.6490158743134914, 'sts-b_test_eval_corr': 0.6502050162386096, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-42-roberta-large-165', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_19-17-40_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-42-roberta-large-165', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt_eval_loss': 1.2580058574676514, 'qnli_dev_prompt_eval_acc': 0.65625, 'qnli_test_prompt_eval_loss': 1.5202748775482178, 'qnli_test_prompt_eval_acc': 0.48325096101043385, 'qnli_dev_eval_loss': 1.2580058574676514, 'qnli_dev_eval_acc': 0.65625, 'qnli_test_eval_loss': 1.5202748775482178, 'qnli_test_eval_acc': 0.48325096101043385, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-100-roberta-large-27511', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_19-33-35_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-100-roberta-large-27511', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt_eval_loss': 0.7521593570709229, 'qqp_dev_prompt_eval_acc': 0.625, 'qqp_dev_prompt_eval_f1': 0.7142857142857143, 'qqp_dev_prompt_eval_acc_and_f1': 0.6696428571428572, 'qqp_test_prompt_eval_loss': 0.9565391540527344, 'qqp_test_prompt_eval_acc': 0.46059856542171657, 'qqp_test_prompt_eval_f1': 0.5312526867853151, 'qqp_test_prompt_eval_acc_and_f1': 0.49592562610351587, 'qqp_dev_eval_loss': 0.7521593570709229, 'qqp_dev_eval_acc': 0.625, 'qqp_dev_eval_f1': 0.7142857142857143, 'qqp_dev_eval_acc_and_f1': 0.6696428571428572, 'qqp_test_eval_loss': 0.9565391540527344, 'qqp_test_eval_acc': 0.46059856542171657, 'qqp_test_eval_f1': 0.5312526867853151, 'qqp_test_eval_acc_and_f1': 0.49592562610351587, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-100-roberta-large-32098', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_19-41-27_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-100-roberta-large-32098', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt_eval_loss': 1.111966609954834, 'mnli_dev_prompt_eval_mnli/acc': 0.4583333333333333, 'mnli_test_prompt_eval_loss': 1.1951746940612793, 'mnli_test_prompt_eval_mnli/acc': 0.34905756495160467, 'mnli-mm_test_prompt_eval_loss': 1.1669013500213623, 'mnli-mm_test_prompt_eval_mnli-mm/acc': 0.366659886086249, 'mnli_dev_eval_loss': 1.111966609954834, 'mnli_dev_eval_mnli/acc': 0.4583333333333333, 'mnli_test_eval_loss': 1.1951746940612793, 'mnli_test_eval_mnli/acc': 0.34905756495160467, 'mnli-mm_test_eval_loss': 1.1669013500213623, 'mnli-mm_test_eval_mnli-mm/acc': 0.366659886086249, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-23095', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_19-21-24_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-23095', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,adapter_eval_loss': 2.11792254447937, 'sts-b_dev_prompt,adapter_eval_pearson': 0.8106572420949167, 'sts-b_dev_prompt,adapter_eval_spearmanr': 0.7618013708849058, 'sts-b_dev_prompt,adapter_eval_corr': 0.7862293064899113, 'sts-b_test_prompt,adapter_eval_loss': 2.1868529319763184, 'sts-b_test_prompt,adapter_eval_pearson': 0.5804180415638053, 'sts-b_test_prompt,adapter_eval_spearmanr': 0.5758315299497623, 'sts-b_test_prompt,adapter_eval_corr': 0.5781247857567837, 'sts-b_dev_eval_loss': 2.11792254447937, 'sts-b_dev_eval_pearson': 0.8106572420949167, 'sts-b_dev_eval_spearmanr': 0.7618013708849058, 'sts-b_dev_eval_corr': 0.7862293064899113, 'sts-b_test_eval_loss': 2.1868529319763184, 'sts-b_test_eval_pearson': 0.5804180415638053, 'sts-b_test_eval_spearmanr': 0.5758315299497623, 'sts-b_test_eval_corr': 0.5781247857567837, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-42-roberta-large-9840', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_19-45-24_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-42-roberta-large-9840', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt_eval_loss': 1.2973096370697021, 'qnli_dev_prompt_eval_acc': 0.65625, 'qnli_test_prompt_eval_loss': 1.8734755516052246, 'qnli_test_prompt_eval_acc': 0.5083287570931723, 'qnli_dev_eval_loss': 1.2973096370697021, 'qnli_dev_eval_acc': 0.65625, 'qnli_test_eval_loss': 1.8734755516052246, 'qnli_test_eval_acc': 0.5083287570931723, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-100-roberta-large-13604', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_19-56-15_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-100-roberta-large-13604', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt_eval_loss': 0.8021315336227417, 'qqp_dev_prompt_eval_acc': 0.625, 'qqp_dev_prompt_eval_f1': 0.7142857142857143, 'qqp_dev_prompt_eval_acc_and_f1': 0.6696428571428572, 'qqp_test_prompt_eval_loss': 0.9929343461990356, 'qqp_test_prompt_eval_acc': 0.38572841949047737, 'qqp_test_prompt_eval_f1': 0.4691220794767106, 'qqp_test_prompt_eval_acc_and_f1': 0.42742524948359395, 'qqp_dev_eval_loss': 0.8021315336227417, 'qqp_dev_eval_acc': 0.625, 'qqp_dev_eval_f1': 0.7142857142857143, 'qqp_dev_eval_acc_and_f1': 0.6696428571428572, 'qqp_test_eval_loss': 0.9929343461990356, 'qqp_test_eval_acc': 0.38572841949047737, 'qqp_test_eval_f1': 0.4691220794767106, 'qqp_test_eval_acc_and_f1': 0.42742524948359395, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-100-roberta-large-12372', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_20-03-13_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-100-roberta-large-12372', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,adapter_eval_loss': 2.1116340160369873, 'sts-b_dev_prompt,adapter_eval_pearson': 0.3646383195357773, 'sts-b_dev_prompt,adapter_eval_spearmanr': 0.34551125113555253, 'sts-b_dev_prompt,adapter_eval_corr': 0.35507478533566494, 'sts-b_test_prompt,adapter_eval_loss': 2.211714506149292, 'sts-b_test_prompt,adapter_eval_pearson': 0.033773808369925294, 'sts-b_test_prompt,adapter_eval_spearmanr': 0.040527864387168766, 'sts-b_test_prompt,adapter_eval_corr': 0.037150836378547034, 'sts-b_dev_eval_loss': 2.1116340160369873, 'sts-b_dev_eval_pearson': 0.3646383195357773, 'sts-b_dev_eval_spearmanr': 0.34551125113555253, 'sts-b_dev_eval_corr': 0.35507478533566494, 'sts-b_test_eval_loss': 2.211714506149292, 'sts-b_test_eval_pearson': 0.033773808369925294, 'sts-b_test_eval_spearmanr': 0.040527864387168766, 'sts-b_test_eval_corr': 0.037150836378547034, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-100-roberta-large-6797', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_20-13-42_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-100-roberta-large-6797', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias_eval_loss': 4.161930084228516, 'qnli_dev_bias_eval_acc': 0.53125, 'qnli_test_bias_eval_loss': 3.8544046878814697, 'qnli_test_bias_eval_acc': 0.5028372688998719, 'qnli_dev_eval_loss': 4.161930084228516, 'qnli_dev_eval_acc': 0.53125, 'qnli_test_eval_loss': 3.8544046878814697, 'qnli_test_eval_acc': 0.5028372688998719, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16--42-roberta-large-24480', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_20-18-57_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--42-roberta-large-24480', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt_eval_loss': 1.1984611749649048, 'mnli_dev_prompt_eval_mnli/acc': 0.4791666666666667, 'mnli_test_prompt_eval_loss': 1.4173259735107422, 'mnli_test_prompt_eval_mnli/acc': 0.34620478858889453, 'mnli-mm_test_prompt_eval_loss': 1.3876628875732422, 'mnli-mm_test_prompt_eval_mnli-mm/acc': 0.3515052888527258, 'mnli_dev_eval_loss': 1.1984611749649048, 'mnli_dev_eval_mnli/acc': 0.4791666666666667, 'mnli_test_eval_loss': 1.4173259735107422, 'mnli_test_eval_mnli/acc': 0.34620478858889453, 'mnli-mm_test_eval_loss': 1.3876628875732422, 'mnli-mm_test_eval_mnli-mm/acc': 0.3515052888527258, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-26256', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_20-03-42_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-26256', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias_eval_loss': 5.231905937194824, 'qqp_dev_bias_eval_acc': 0.625, 'qqp_dev_bias_eval_f1': 0.6666666666666665, 'qqp_dev_bias_eval_acc_and_f1': 0.6458333333333333, 'qqp_test_bias_eval_loss': 6.8138837814331055, 'qqp_test_bias_eval_acc': 0.4963888201830324, 'qqp_test_bias_eval_f1': 0.5301271548242679, 'qqp_test_bias_eval_acc_and_f1': 0.5132579875036501, 'qqp_dev_eval_loss': 5.231905937194824, 'qqp_dev_eval_acc': 0.625, 'qqp_dev_eval_f1': 0.6666666666666665, 'qqp_dev_eval_acc_and_f1': 0.6458333333333333, 'qqp_test_eval_loss': 6.8138837814331055, 'qqp_test_eval_acc': 0.4963888201830324, 'qqp_test_eval_f1': 0.5301271548242679, 'qqp_test_eval_acc_and_f1': 0.5132579875036501, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16--42-roberta-large-13236', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_20-25-32_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--42-roberta-large-13236', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,adapter_eval_loss': 2.0954389572143555, 'sts-b_dev_prompt,adapter_eval_pearson': 0.6358664241873477, 'sts-b_dev_prompt,adapter_eval_spearmanr': 0.6087953303524191, 'sts-b_dev_prompt,adapter_eval_corr': 0.6223308772698835, 'sts-b_test_prompt,adapter_eval_loss': 2.181544780731201, 'sts-b_test_prompt,adapter_eval_pearson': 0.6303979027205101, 'sts-b_test_prompt,adapter_eval_spearmanr': 0.6319810701505997, 'sts-b_test_prompt,adapter_eval_corr': 0.631189486435555, 'sts-b_dev_eval_loss': 2.0954389572143555, 'sts-b_dev_eval_pearson': 0.6358664241873477, 'sts-b_dev_eval_spearmanr': 0.6087953303524191, 'sts-b_dev_eval_corr': 0.6223308772698835, 'sts-b_test_eval_loss': 2.181544780731201, 'sts-b_test_eval_pearson': 0.6303979027205101, 'sts-b_test_eval_spearmanr': 0.6319810701505997, 'sts-b_test_eval_corr': 0.631189486435555, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-100-roberta-large-26844', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_20-41-25_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-100-roberta-large-26844', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias_eval_loss': 3.641019821166992, 'qnli_dev_bias_eval_acc': 0.625, 'qnli_test_bias_eval_loss': 3.82725191116333, 'qnli_test_bias_eval_acc': 0.5756910122643236, 'qnli_dev_eval_loss': 3.641019821166992, 'qnli_dev_eval_acc': 0.625, 'qnli_test_eval_loss': 3.82725191116333, 'qnli_test_eval_acc': 0.5756910122643236, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16--42-roberta-large-18853', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_20-43-51_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--42-roberta-large-18853', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias_eval_loss': 1.6723284721374512, 'qqp_dev_bias_eval_acc': 0.8125, 'qqp_dev_bias_eval_f1': 0.8333333333333334, 'qqp_dev_bias_eval_acc_and_f1': 0.8229166666666667, 'qqp_test_bias_eval_loss': 2.97151255607605, 'qqp_test_bias_eval_acc': 0.6627999010635667, 'qqp_test_bias_eval_f1': 0.6603383411814534, 'qqp_test_bias_eval_acc_and_f1': 0.6615691211225101, 'qqp_dev_eval_loss': 1.6723284721374512, 'qqp_dev_eval_acc': 0.8125, 'qqp_dev_eval_f1': 0.8333333333333334, 'qqp_dev_eval_acc_and_f1': 0.8229166666666667, 'qqp_test_eval_loss': 2.97151255607605, 'qqp_test_eval_acc': 0.6627999010635667, 'qqp_test_eval_f1': 0.6603383411814534, 'qqp_test_eval_acc_and_f1': 0.6615691211225101, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16--42-roberta-large-19399', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_20-49-47_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--42-roberta-large-19399', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt_eval_loss': 1.2273420095443726, 'mnli_dev_prompt_eval_mnli/acc': 0.4375, 'mnli_test_prompt_eval_loss': 1.386350154876709, 'mnli_test_prompt_eval_mnli/acc': 0.332348446255731, 'mnli-mm_test_prompt_eval_loss': 1.3804423809051514, 'mnli-mm_test_prompt_eval_mnli-mm/acc': 0.3378763222131814, 'mnli_dev_eval_loss': 1.2273420095443726, 'mnli_dev_eval_mnli/acc': 0.4375, 'mnli_test_eval_loss': 1.386350154876709, 'mnli_test_eval_mnli/acc': 0.332348446255731, 'mnli-mm_test_eval_loss': 1.3804423809051514, 'mnli-mm_test_eval_mnli-mm/acc': 0.3378763222131814, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-16754', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_20-45-44_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-16754', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias_eval_loss': 1.8988707065582275, 'qnli_dev_bias_eval_acc': 0.65625, 'qnli_test_bias_eval_loss': 2.0482711791992188, 'qnli_test_bias_eval_acc': 0.5698334248581366, 'qnli_dev_eval_loss': 1.8988707065582275, 'qnli_dev_eval_acc': 0.65625, 'qnli_test_eval_loss': 2.0482711791992188, 'qnli_test_eval_acc': 0.5698334248581366, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16--42-roberta-large-29824', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_21-08-45_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--42-roberta-large-29824', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,adapter_eval_loss': 2.098031997680664, 'sts-b_dev_prompt,adapter_eval_pearson': 0.6959456745155905, 'sts-b_dev_prompt,adapter_eval_spearmanr': 0.6415341728910083, 'sts-b_dev_prompt,adapter_eval_corr': 0.6687399237032994, 'sts-b_test_prompt,adapter_eval_loss': 2.1861133575439453, 'sts-b_test_prompt,adapter_eval_pearson': 0.6338153673149849, 'sts-b_test_prompt,adapter_eval_spearmanr': 0.6326458544177946, 'sts-b_test_prompt,adapter_eval_corr': 0.6332306108663898, 'sts-b_dev_eval_loss': 2.098031997680664, 'sts-b_dev_eval_pearson': 0.6959456745155905, 'sts-b_dev_eval_spearmanr': 0.6415341728910083, 'sts-b_dev_eval_corr': 0.6687399237032994, 'sts-b_test_eval_loss': 2.1861133575439453, 'sts-b_test_eval_pearson': 0.6338153673149849, 'sts-b_test_eval_spearmanr': 0.6326458544177946, 'sts-b_test_eval_corr': 0.6332306108663898, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-100-roberta-large-5457', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_21-08-11_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-100-roberta-large-5457', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias_eval_loss': 1.865861415863037, 'qqp_dev_bias_eval_acc': 0.8125, 'qqp_dev_bias_eval_f1': 0.8421052631578948, 'qqp_dev_bias_eval_acc_and_f1': 0.8273026315789473, 'qqp_test_bias_eval_loss': 2.9316325187683105, 'qqp_test_bias_eval_acc': 0.6633193173386099, 'qqp_test_bias_eval_f1': 0.6628857298528903, 'qqp_test_bias_eval_acc_and_f1': 0.6631025235957502, 'qqp_dev_eval_loss': 1.865861415863037, 'qqp_dev_eval_acc': 0.8125, 'qqp_dev_eval_f1': 0.8421052631578948, 'qqp_dev_eval_acc_and_f1': 0.8273026315789473, 'qqp_test_eval_loss': 2.9316325187683105, 'qqp_test_eval_acc': 0.6633193173386099, 'qqp_test_eval_f1': 0.6628857298528903, 'qqp_test_eval_acc_and_f1': 0.6631025235957502, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16--42-roberta-large-10658', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_21-14-24_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--42-roberta-large-10658', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias_eval_loss': 2.0577306747436523, 'qnli_dev_bias_eval_acc': 0.59375, 'qnli_test_bias_eval_loss': 2.010023832321167, 'qnli_test_bias_eval_acc': 0.5907010799926781, 'qnli_dev_eval_loss': 2.0577306747436523, 'qnli_dev_eval_acc': 0.59375, 'qnli_test_eval_loss': 2.010023832321167, 'qnli_test_eval_acc': 0.5907010799926781, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16--42-roberta-large-26338', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_21-33-36_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--42-roberta-large-26338', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,adapter_eval_loss': 2.1195623874664307, 'sts-b_dev_prompt,adapter_eval_pearson': 0.6706488739524079, 'sts-b_dev_prompt,adapter_eval_spearmanr': 0.7106903796017363, 'sts-b_dev_prompt,adapter_eval_corr': 0.6906696267770721, 'sts-b_test_prompt,adapter_eval_loss': 2.238764762878418, 'sts-b_test_prompt,adapter_eval_pearson': 0.4534609316766104, 'sts-b_test_prompt,adapter_eval_spearmanr': 0.44486514508447644, 'sts-b_test_prompt,adapter_eval_corr': 0.4491630383805434, 'sts-b_dev_eval_loss': 2.1195623874664307, 'sts-b_dev_eval_pearson': 0.6706488739524079, 'sts-b_dev_eval_spearmanr': 0.7106903796017363, 'sts-b_dev_eval_corr': 0.6906696267770721, 'sts-b_test_eval_loss': 2.238764762878418, 'sts-b_test_eval_pearson': 0.4534609316766104, 'sts-b_test_eval_spearmanr': 0.44486514508447644, 'sts-b_test_eval_corr': 0.4491630383805434, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-100-roberta-large-22805', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_21-34-37_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-100-roberta-large-22805', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias_eval_loss': 2.006254196166992, 'qqp_dev_bias_eval_acc': 0.78125, 'qqp_dev_bias_eval_f1': 0.7999999999999999, 'qqp_dev_bias_eval_acc_and_f1': 0.7906249999999999, 'qqp_test_bias_eval_loss': 2.0564260482788086, 'qqp_test_bias_eval_acc': 0.7135295572594608, 'qqp_test_bias_eval_f1': 0.6772377661353248, 'qqp_test_bias_eval_acc_and_f1': 0.6953836616973927, 'qqp_dev_eval_loss': 2.006254196166992, 'qqp_dev_eval_acc': 0.78125, 'qqp_dev_eval_f1': 0.7999999999999999, 'qqp_dev_eval_acc_and_f1': 0.7906249999999999, 'qqp_test_eval_loss': 2.0564260482788086, 'qqp_test_eval_acc': 0.7135295572594608, 'qqp_test_eval_f1': 0.6772377661353248, 'qqp_test_eval_acc_and_f1': 0.6953836616973927, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16--42-roberta-large-20599', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_21-38-45_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--42-roberta-large-20599', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt_eval_loss': 1.0848978757858276, 'mnli_dev_prompt_eval_mnli/acc': 0.5208333333333334, 'mnli_test_prompt_eval_loss': 1.244402527809143, 'mnli_test_prompt_eval_mnli/acc': 0.34589913397860417, 'mnli-mm_test_prompt_eval_loss': 1.224440336227417, 'mnli-mm_test_prompt_eval_mnli-mm/acc': 0.3426566314076485, 'mnli_dev_eval_loss': 1.0848978757858276, 'mnli_dev_eval_mnli/acc': 0.5208333333333334, 'mnli_test_eval_loss': 1.244402527809143, 'mnli_test_eval_mnli/acc': 0.34589913397860417, 'mnli-mm_test_eval_loss': 1.224440336227417, 'mnli-mm_test_eval_mnli-mm/acc': 0.3426566314076485, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-25179', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_21-28-12_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-25179', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias_eval_loss': 2.1162006855010986, 'sts-b_dev_prompt,bias_eval_pearson': 0.854797498049368, 'sts-b_dev_prompt,bias_eval_spearmanr': 0.8334268613972282, 'sts-b_dev_prompt,bias_eval_corr': 0.8441121797232981, 'sts-b_test_prompt,bias_eval_loss': 2.178318738937378, 'sts-b_test_prompt,bias_eval_pearson': 0.7244690132435339, 'sts-b_test_prompt,bias_eval_spearmanr': 0.7301948017173129, 'sts-b_test_prompt,bias_eval_corr': 0.7273319074804234, 'sts-b_dev_eval_loss': 2.1162006855010986, 'sts-b_dev_eval_pearson': 0.854797498049368, 'sts-b_dev_eval_spearmanr': 0.8334268613972282, 'sts-b_dev_eval_corr': 0.8441121797232981, 'sts-b_test_eval_loss': 2.178318738937378, 'sts-b_test_eval_pearson': 0.7244690132435339, 'sts-b_test_eval_spearmanr': 0.7301948017173129, 'sts-b_test_eval_corr': 0.7273319074804234, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-42-roberta-large-13507', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_22-00-19_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-42-roberta-large-13507', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias_eval_loss': 0.7542219758033752, 'qnli_dev_bias_eval_acc': 0.5, 'qnli_test_bias_eval_loss': 0.7504256963729858, 'qnli_test_bias_eval_acc': 0.5053999633900788, 'qnli_dev_eval_loss': 0.7542219758033752, 'qnli_dev_eval_acc': 0.5, 'qnli_test_eval_loss': 0.7504256963729858, 'qnli_test_eval_acc': 0.5053999633900788, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16--100-roberta-large-27318', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_21-58-22_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--100-roberta-large-27318', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias_eval_loss': 0.7886562943458557, 'qqp_dev_bias_eval_acc': 0.5, 'qqp_dev_bias_eval_f1': 0.6666666666666666, 'qqp_dev_bias_eval_acc_and_f1': 0.5833333333333333, 'qqp_test_bias_eval_loss': 0.9058237075805664, 'qqp_test_bias_eval_acc': 0.36816720257234725, 'qqp_test_bias_eval_f1': 0.5381903642773208, 'qqp_test_bias_eval_acc_and_f1': 0.45317878342483403, 'qqp_dev_eval_loss': 0.7886562943458557, 'qqp_dev_eval_acc': 0.5, 'qqp_dev_eval_f1': 0.6666666666666666, 'qqp_dev_eval_acc_and_f1': 0.5833333333333333, 'qqp_test_eval_loss': 0.9058237075805664, 'qqp_test_eval_acc': 0.36816720257234725, 'qqp_test_eval_f1': 0.5381903642773208, 'qqp_test_eval_acc_and_f1': 0.45317878342483403, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16--100-roberta-large-13328', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_22-03-22_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--100-roberta-large-13328', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias_eval_loss': 2.124277114868164, 'sts-b_dev_prompt,bias_eval_pearson': 0.7162666241383207, 'sts-b_dev_prompt,bias_eval_spearmanr': 0.6934816722423829, 'sts-b_dev_prompt,bias_eval_corr': 0.7048741481903518, 'sts-b_test_prompt,bias_eval_loss': 2.182246685028076, 'sts-b_test_prompt,bias_eval_pearson': 0.6638590271196783, 'sts-b_test_prompt,bias_eval_spearmanr': 0.6609685359104632, 'sts-b_test_prompt,bias_eval_corr': 0.6624137815150708, 'sts-b_dev_eval_loss': 2.124277114868164, 'sts-b_dev_eval_pearson': 0.7162666241383207, 'sts-b_dev_eval_spearmanr': 0.6934816722423829, 'sts-b_dev_eval_corr': 0.7048741481903518, 'sts-b_test_eval_loss': 2.182246685028076, 'sts-b_test_eval_pearson': 0.6638590271196783, 'sts-b_test_eval_spearmanr': 0.6609685359104632, 'sts-b_test_eval_corr': 0.6624137815150708, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-42-roberta-large-4308', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_22-15-47_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-42-roberta-large-4308', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt_eval_loss': 1.2578363418579102, 'mnli_dev_prompt_eval_mnli/acc': 0.5208333333333334, 'mnli_test_prompt_eval_loss': 1.3953485488891602, 'mnli_test_prompt_eval_mnli/acc': 0.346001018848701, 'mnli-mm_test_prompt_eval_loss': 1.3978499174118042, 'mnli-mm_test_prompt_eval_mnli-mm/acc': 0.3415378356387307, 'mnli_dev_eval_loss': 1.2578363418579102, 'mnli_dev_eval_mnli/acc': 0.5208333333333334, 'mnli_test_eval_loss': 1.3953485488891602, 'mnli_test_eval_mnli/acc': 0.346001018848701, 'mnli-mm_test_eval_loss': 1.3978499174118042, 'mnli-mm_test_eval_mnli-mm/acc': 0.3415378356387307, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-10145', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_22-05-22_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-10145', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias_eval_loss': 1.2876081466674805, 'qnli_dev_bias_eval_acc': 0.71875, 'qnli_test_bias_eval_loss': 1.8579272031784058, 'qnli_test_bias_eval_acc': 0.5583012996522058, 'qnli_dev_eval_loss': 1.2876081466674805, 'qnli_dev_eval_acc': 0.71875, 'qnli_test_eval_loss': 1.8579272031784058, 'qnli_test_eval_acc': 0.5583012996522058, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16--100-roberta-large-25176', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_22-23-25_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--100-roberta-large-25176', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias_eval_loss': 2.116124153137207, 'sts-b_dev_prompt,bias_eval_pearson': 0.8102600697542128, 'sts-b_dev_prompt,bias_eval_spearmanr': 0.8031237692573996, 'sts-b_dev_prompt,bias_eval_corr': 0.8066919195058062, 'sts-b_test_prompt,bias_eval_loss': 2.1858668327331543, 'sts-b_test_prompt,bias_eval_pearson': 0.5961947187698972, 'sts-b_test_prompt,bias_eval_spearmanr': 0.5905133257846003, 'sts-b_test_prompt,bias_eval_corr': 0.5933540222772486, 'sts-b_dev_eval_loss': 2.116124153137207, 'sts-b_dev_eval_pearson': 0.8102600697542128, 'sts-b_dev_eval_spearmanr': 0.8031237692573996, 'sts-b_dev_eval_corr': 0.8066919195058062, 'sts-b_test_eval_loss': 2.1858668327331543, 'sts-b_test_eval_pearson': 0.5961947187698972, 'sts-b_test_eval_spearmanr': 0.5905133257846003, 'sts-b_test_eval_corr': 0.5933540222772486, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-42-roberta-large-4356', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_22-32-34_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-42-roberta-large-4356', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias_eval_loss': 2.523808479309082, 'qqp_dev_bias_eval_acc': 0.75, 'qqp_dev_bias_eval_f1': 0.7894736842105263, 'qqp_dev_bias_eval_acc_and_f1': 0.7697368421052632, 'qqp_test_bias_eval_loss': 3.1441538333892822, 'qqp_test_bias_eval_acc': 0.672347266881029, 'qqp_test_bias_eval_f1': 0.6758985149120446, 'qqp_test_bias_eval_acc_and_f1': 0.6741228908965368, 'qqp_dev_eval_loss': 2.523808479309082, 'qqp_dev_eval_acc': 0.75, 'qqp_dev_eval_f1': 0.7894736842105263, 'qqp_dev_eval_acc_and_f1': 0.7697368421052632, 'qqp_test_eval_loss': 3.1441538333892822, 'qqp_test_eval_acc': 0.672347266881029, 'qqp_test_eval_f1': 0.6758985149120446, 'qqp_test_eval_acc_and_f1': 0.6741228908965368, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16--100-roberta-large-7114', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_22-27-34_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--100-roberta-large-7114', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt_eval_loss': 1.334465503692627, 'mnli_dev_prompt_eval_mnli/acc': 0.5, 'mnli_test_prompt_eval_loss': 1.4690390825271606, 'mnli_test_prompt_eval_mnli/acc': 0.346001018848701, 'mnli-mm_test_prompt_eval_loss': 1.4864951372146606, 'mnli-mm_test_prompt_eval_mnli-mm/acc': 0.3440805532953621, 'mnli_dev_eval_loss': 1.334465503692627, 'mnli_dev_eval_mnli/acc': 0.5, 'mnli_test_eval_loss': 1.4690390825271606, 'mnli_test_eval_mnli/acc': 0.346001018848701, 'mnli-mm_test_eval_loss': 1.4864951372146606, 'mnli-mm_test_eval_mnli-mm/acc': 0.3440805532953621, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-9800', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_22-32-50_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-9800', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias_eval_loss': 2.125030040740967, 'sts-b_dev_prompt,bias_eval_pearson': 0.7193649728625611, 'sts-b_dev_prompt,bias_eval_spearmanr': 0.6789729190360407, 'sts-b_dev_prompt,bias_eval_corr': 0.6991689459493009, 'sts-b_test_prompt,bias_eval_loss': 2.1981937885284424, 'sts-b_test_prompt,bias_eval_pearson': 0.5139829799813967, 'sts-b_test_prompt,bias_eval_spearmanr': 0.5090344536032766, 'sts-b_test_prompt,bias_eval_corr': 0.5115087167923367, 'sts-b_dev_eval_loss': 2.125030040740967, 'sts-b_dev_eval_pearson': 0.7193649728625611, 'sts-b_dev_eval_spearmanr': 0.6789729190360407, 'sts-b_dev_eval_corr': 0.6991689459493009, 'sts-b_test_eval_loss': 2.1981937885284424, 'sts-b_test_eval_pearson': 0.5139829799813967, 'sts-b_test_eval_spearmanr': 0.5090344536032766, 'sts-b_test_eval_corr': 0.5115087167923367, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-42-roberta-large-17633', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_22-48-32_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-42-roberta-large-17633', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias_eval_loss': 1.6541531085968018, 'qnli_dev_bias_eval_acc': 0.71875, 'qnli_test_bias_eval_loss': 2.6342740058898926, 'qnli_test_bias_eval_acc': 0.6108365367014461, 'qnli_dev_eval_loss': 1.6541531085968018, 'qnli_dev_eval_acc': 0.71875, 'qnli_test_eval_loss': 2.6342740058898926, 'qnli_test_eval_acc': 0.6108365367014461, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16--100-roberta-large-28010', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_22-48-25_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--100-roberta-large-28010', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias_eval_loss': 3.268721342086792, 'qqp_dev_bias_eval_acc': 0.78125, 'qqp_dev_bias_eval_f1': 0.8108108108108109, 'qqp_dev_bias_eval_acc_and_f1': 0.7960304054054055, 'qqp_test_bias_eval_loss': 3.5836410522460938, 'qqp_test_bias_eval_acc': 0.6980212713331685, 'qqp_test_bias_eval_f1': 0.6787020711071345, 'qqp_test_bias_eval_acc_and_f1': 0.6883616712201515, 'qqp_dev_eval_loss': 3.268721342086792, 'qqp_dev_eval_acc': 0.78125, 'qqp_dev_eval_f1': 0.8108108108108109, 'qqp_dev_eval_acc_and_f1': 0.7960304054054055, 'qqp_test_eval_loss': 3.5836410522460938, 'qqp_test_eval_acc': 0.6980212713331685, 'qqp_test_eval_f1': 0.6787020711071345, 'qqp_test_eval_acc_and_f1': 0.6883616712201515, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16--100-roberta-large-28494', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_22-51-50_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--100-roberta-large-28494', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias_eval_loss': 2.1066761016845703, 'sts-b_dev_prompt,bias_eval_pearson': 0.6543892434998944, 'sts-b_dev_prompt,bias_eval_spearmanr': 0.6148648910477754, 'sts-b_dev_prompt,bias_eval_corr': 0.6346270672738349, 'sts-b_test_prompt,bias_eval_loss': 2.1946163177490234, 'sts-b_test_prompt,bias_eval_pearson': 0.5922233728811518, 'sts-b_test_prompt,bias_eval_spearmanr': 0.5823321194730897, 'sts-b_test_prompt,bias_eval_corr': 0.5872777461771208, 'sts-b_dev_eval_loss': 2.1066761016845703, 'sts-b_dev_eval_pearson': 0.6543892434998944, 'sts-b_dev_eval_spearmanr': 0.6148648910477754, 'sts-b_dev_eval_corr': 0.6346270672738349, 'sts-b_test_eval_loss': 2.1946163177490234, 'sts-b_test_eval_pearson': 0.5922233728811518, 'sts-b_test_eval_spearmanr': 0.5823321194730897, 'sts-b_test_eval_corr': 0.5872777461771208, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-100-roberta-large-30717', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_23-05-22_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-100-roberta-large-30717', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias_eval_loss': 6.301799774169922, 'mnli_dev_bias_eval_mnli/acc': 0.5208333333333334, 'mnli_test_bias_eval_loss': 6.307685375213623, 'mnli_test_bias_eval_mnli/acc': 0.4579724910850739, 'mnli-mm_test_bias_eval_loss': 6.183985710144043, 'mnli-mm_test_bias_eval_mnli-mm/acc': 0.47681041497152155, 'mnli_dev_eval_loss': 6.301799774169922, 'mnli_dev_eval_mnli/acc': 0.5208333333333334, 'mnli_test_eval_loss': 6.307685375213623, 'mnli_test_eval_mnli/acc': 0.4579724910850739, 'mnli-mm_test_eval_loss': 6.183985710144043, 'mnli-mm_test_eval_mnli-mm/acc': 0.47681041497152155, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--42-roberta-large-24105', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_22-59-52_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--42-roberta-large-24105', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias_eval_loss': 2.11067271232605, 'sts-b_dev_prompt,bias_eval_pearson': 0.6709815063803286, 'sts-b_dev_prompt,bias_eval_spearmanr': 0.6194630430897121, 'sts-b_dev_prompt,bias_eval_corr': 0.6452222747350204, 'sts-b_test_prompt,bias_eval_loss': 2.2064919471740723, 'sts-b_test_prompt,bias_eval_pearson': 0.5774750145240263, 'sts-b_test_prompt,bias_eval_spearmanr': 0.5764076927814488, 'sts-b_test_prompt,bias_eval_corr': 0.5769413536527375, 'sts-b_dev_eval_loss': 2.11067271232605, 'sts-b_dev_eval_pearson': 0.6709815063803286, 'sts-b_dev_eval_spearmanr': 0.6194630430897121, 'sts-b_dev_eval_corr': 0.6452222747350204, 'sts-b_test_eval_loss': 2.2064919471740723, 'sts-b_test_eval_pearson': 0.5774750145240263, 'sts-b_test_eval_spearmanr': 0.5764076927814488, 'sts-b_test_eval_corr': 0.5769413536527375, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-100-roberta-large-29703', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_23-21-03_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-100-roberta-large-29703', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias_eval_loss': 1.4521937370300293, 'qnli_dev_bias_eval_acc': 0.65625, 'qnli_test_bias_eval_loss': 1.6836309432983398, 'qnli_test_bias_eval_acc': 0.5841112941607176, 'qnli_dev_eval_loss': 1.4521937370300293, 'qnli_dev_eval_acc': 0.65625, 'qnli_test_eval_loss': 1.6836309432983398, 'qnli_test_eval_acc': 0.5841112941607176, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16--100-roberta-large-24616', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_23-13-04_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--100-roberta-large-24616', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias_eval_loss': 2.3793506622314453, 'qqp_dev_bias_eval_acc': 0.78125, 'qqp_dev_bias_eval_f1': 0.7999999999999999, 'qqp_dev_bias_eval_acc_and_f1': 0.7906249999999999, 'qqp_test_bias_eval_loss': 2.634521722793579, 'qqp_test_bias_eval_acc': 0.7227059114518921, 'qqp_test_bias_eval_f1': 0.6845614923609352, 'qqp_test_bias_eval_acc_and_f1': 0.7036337019064136, 'qqp_dev_eval_loss': 2.3793506622314453, 'qqp_dev_eval_acc': 0.78125, 'qqp_dev_eval_f1': 0.7999999999999999, 'qqp_dev_eval_acc_and_f1': 0.7906249999999999, 'qqp_test_eval_loss': 2.634521722793579, 'qqp_test_eval_acc': 0.7227059114518921, 'qqp_test_eval_f1': 0.6845614923609352, 'qqp_test_eval_acc_and_f1': 0.7036337019064136, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16--100-roberta-large-31577', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_23-16-17_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--100-roberta-large-31577', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias_eval_loss': 2.112265110015869, 'sts-b_dev_prompt,bias_eval_pearson': 0.5981443905589858, 'sts-b_dev_prompt,bias_eval_spearmanr': 0.540006975805046, 'sts-b_dev_prompt,bias_eval_corr': 0.5690756831820158, 'sts-b_test_prompt,bias_eval_loss': 2.1918389797210693, 'sts-b_test_prompt,bias_eval_pearson': 0.594346186198842, 'sts-b_test_prompt,bias_eval_spearmanr': 0.5908647823172527, 'sts-b_test_prompt,bias_eval_corr': 0.5926054842580474, 'sts-b_dev_eval_loss': 2.112265110015869, 'sts-b_dev_eval_pearson': 0.5981443905589858, 'sts-b_dev_eval_spearmanr': 0.540006975805046, 'sts-b_dev_eval_corr': 0.5690756831820158, 'sts-b_test_eval_loss': 2.1918389797210693, 'sts-b_test_eval_pearson': 0.594346186198842, 'sts-b_test_eval_spearmanr': 0.5908647823172527, 'sts-b_test_eval_corr': 0.5926054842580474, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-100-roberta-large-22859', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_23-36-54_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-100-roberta-large-22859', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias_eval_loss': 3.0733463764190674, 'mnli_dev_bias_eval_mnli/acc': 0.5833333333333334, 'mnli_test_bias_eval_loss': 2.744982957839966, 'mnli_test_bias_eval_mnli/acc': 0.5922567498726439, 'mnli-mm_test_bias_eval_loss': 2.5391273498535156, 'mnli-mm_test_bias_eval_mnli-mm/acc': 0.6123881204231082, 'mnli_dev_eval_loss': 3.0733463764190674, 'mnli_dev_eval_mnli/acc': 0.5833333333333334, 'mnli_test_eval_loss': 2.744982957839966, 'mnli_test_eval_mnli/acc': 0.5922567498726439, 'mnli-mm_test_eval_loss': 2.5391273498535156, 'mnli-mm_test_eval_mnli-mm/acc': 0.6123881204231082, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--42-roberta-large-16175', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_23-29-19_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--42-roberta-large-16175', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_adapter_eval_loss': 0.6237376928329468, 'qnli_dev_adapter_eval_acc': 0.53125, 'qnli_test_adapter_eval_loss': 0.7427153587341309, 'qnli_test_adapter_eval_acc': 0.4834340106168772, 'qnli_dev_eval_loss': 0.6237376928329468, 'qnli_dev_eval_acc': 0.53125, 'qnli_test_eval_loss': 0.7427153587341309, 'qnli_test_eval_acc': 0.4834340106168772, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--42-roberta-large-6749', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_23-37-51_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--42-roberta-large-6749', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_adapter_eval_loss': 0.7096879482269287, 'qqp_dev_adapter_eval_acc': 0.5, 'qqp_dev_adapter_eval_f1': 0.6666666666666666, 'qqp_dev_adapter_eval_acc_and_f1': 0.5833333333333333, 'qqp_test_adapter_eval_loss': 0.7577976584434509, 'qqp_test_adapter_eval_acc': 0.36816720257234725, 'qqp_test_adapter_eval_f1': 0.5381903642773208, 'qqp_test_adapter_eval_acc_and_f1': 0.45317878342483403, 'qqp_dev_eval_loss': 0.7096879482269287, 'qqp_dev_eval_acc': 0.5, 'qqp_dev_eval_f1': 0.6666666666666666, 'qqp_dev_eval_acc_and_f1': 0.5833333333333333, 'qqp_test_eval_loss': 0.7577976584434509, 'qqp_test_eval_acc': 0.36816720257234725, 'qqp_test_eval_f1': 0.5381903642773208, 'qqp_test_eval_acc_and_f1': 0.45317878342483403, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16--42-roberta-large-7985', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_23-40-49_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--42-roberta-large-7985', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias_eval_loss': 2.1224565505981445, 'sts-b_dev_prompt,bias_eval_pearson': 0.5972687709404746, 'sts-b_dev_prompt,bias_eval_spearmanr': 0.5506746885423391, 'sts-b_dev_prompt,bias_eval_corr': 0.5739717297414069, 'sts-b_test_prompt,bias_eval_loss': 2.2185909748077393, 'sts-b_test_prompt,bias_eval_pearson': 0.47580874297882375, 'sts-b_test_prompt,bias_eval_spearmanr': 0.45785254865803593, 'sts-b_test_prompt,bias_eval_corr': 0.4668306458184298, 'sts-b_dev_eval_loss': 2.1224565505981445, 'sts-b_dev_eval_pearson': 0.5972687709404746, 'sts-b_dev_eval_spearmanr': 0.5506746885423391, 'sts-b_dev_eval_corr': 0.5739717297414069, 'sts-b_test_eval_loss': 2.2185909748077393, 'sts-b_test_eval_pearson': 0.47580874297882375, 'sts-b_test_eval_spearmanr': 0.45785254865803593, 'sts-b_test_eval_corr': 0.4668306458184298, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/STS-B-16-prompt-100-roberta-large-8116', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan10_23-54-23_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-100-roberta-large-8116', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_adapter_eval_loss': 3.1518468856811523, 'qnli_dev_adapter_eval_acc': 0.6875, 'qnli_test_adapter_eval_loss': 4.101814270019531, 'qnli_test_adapter_eval_acc': 0.5528098114589054, 'qnli_dev_eval_loss': 3.1518468856811523, 'qnli_dev_eval_acc': 0.6875, 'qnli_test_eval_loss': 4.101814270019531, 'qnli_test_eval_acc': 0.5528098114589054, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--42-roberta-large-9958', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_00-04-06_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--42-roberta-large-9958', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_adapter_eval_loss': 1.6567152738571167, 'qqp_dev_adapter_eval_acc': 0.8125, 'qqp_dev_adapter_eval_f1': 0.823529411764706, 'qqp_dev_adapter_eval_acc_and_f1': 0.818014705882353, 'qqp_test_adapter_eval_loss': 2.280773401260376, 'qqp_test_adapter_eval_acc': 0.7382389314865199, 'qqp_test_adapter_eval_f1': 0.6710595841233332, 'qqp_test_adapter_eval_acc_and_f1': 0.7046492578049266, 'qqp_dev_eval_loss': 1.6567152738571167, 'qqp_dev_eval_acc': 0.8125, 'qqp_dev_eval_f1': 0.823529411764706, 'qqp_dev_eval_acc_and_f1': 0.818014705882353, 'qqp_test_eval_loss': 2.280773401260376, 'qqp_test_eval_acc': 0.7382389314865199, 'qqp_test_eval_f1': 0.6710595841233332, 'qqp_test_eval_acc_and_f1': 0.7046492578049266, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16--42-roberta-large-14620', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_00-07-54_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--42-roberta-large-14620', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias,adapter_eval_loss': 2.1526036262512207, 'sts-b_dev_bias,adapter_eval_pearson': 0.40562388867238, 'sts-b_dev_bias,adapter_eval_spearmanr': 0.39145660970584306, 'sts-b_dev_bias,adapter_eval_corr': 0.3985402491891115, 'sts-b_test_bias,adapter_eval_loss': 2.211737632751465, 'sts-b_test_bias,adapter_eval_pearson': -0.004923819544974283, 'sts-b_test_bias,adapter_eval_spearmanr': -0.004569604436345706, 'sts-b_test_bias,adapter_eval_corr': -0.004746711990659994, 'sts-b_dev_eval_loss': 2.1526036262512207, 'sts-b_dev_eval_pearson': 0.40562388867238, 'sts-b_dev_eval_spearmanr': 0.39145660970584306, 'sts-b_dev_eval_corr': 0.3985402491891115, 'sts-b_test_eval_loss': 2.211737632751465, 'sts-b_test_eval_pearson': -0.004923819544974283, 'sts-b_test_eval_spearmanr': -0.004569604436345706, 'sts-b_test_eval_corr': -0.004746711990659994, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--42-roberta-large-28268', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_00-18-06_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--42-roberta-large-28268', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias_eval_loss': 3.016852617263794, 'mnli_dev_bias_eval_mnli/acc': 0.6458333333333334, 'mnli_test_bias_eval_loss': 3.2386903762817383, 'mnli_test_bias_eval_mnli/acc': 0.5600611309220581, 'mnli-mm_test_bias_eval_loss': 2.967935800552368, 'mnli-mm_test_bias_eval_mnli-mm/acc': 0.5820789259560618, 'mnli_dev_eval_loss': 3.016852617263794, 'mnli_dev_eval_mnli/acc': 0.6458333333333334, 'mnli_test_eval_loss': 3.2386903762817383, 'mnli_test_eval_mnli/acc': 0.5600611309220581, 'mnli-mm_test_eval_loss': 2.967935800552368, 'mnli-mm_test_eval_mnli-mm/acc': 0.5820789259560618, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--42-roberta-large-8814', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_00-03-20_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--42-roberta-large-8814', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_adapter_eval_loss': 2.651355266571045, 'qnli_dev_adapter_eval_acc': 0.6875, 'qnli_test_adapter_eval_loss': 3.1193740367889404, 'qnli_test_adapter_eval_acc': 0.5712978217096834, 'qnli_dev_eval_loss': 2.651355266571045, 'qnli_dev_eval_acc': 0.6875, 'qnli_test_eval_loss': 3.1193740367889404, 'qnli_test_eval_acc': 0.5712978217096834, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--42-roberta-large-13023', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_00-30-10_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--42-roberta-large-13023', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_adapter_eval_loss': 1.8197834491729736, 'qqp_dev_adapter_eval_acc': 0.78125, 'qqp_dev_adapter_eval_f1': 0.7999999999999999, 'qqp_dev_adapter_eval_acc_and_f1': 0.7906249999999999, 'qqp_test_adapter_eval_loss': 1.983015775680542, 'qqp_test_adapter_eval_acc': 0.7031164976502597, 'qqp_test_adapter_eval_f1': 0.6721477151675727, 'qqp_test_adapter_eval_acc_and_f1': 0.6876321064089161, 'qqp_dev_eval_loss': 1.8197834491729736, 'qqp_dev_eval_acc': 0.78125, 'qqp_dev_eval_f1': 0.7999999999999999, 'qqp_dev_eval_acc_and_f1': 0.7906249999999999, 'qqp_test_eval_loss': 1.983015775680542, 'qqp_test_eval_acc': 0.7031164976502597, 'qqp_test_eval_f1': 0.6721477151675727, 'qqp_test_eval_acc_and_f1': 0.6876321064089161, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16--42-roberta-large-26557', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_00-35-04_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--42-roberta-large-26557', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias,adapter_eval_loss': 2.1148734092712402, 'sts-b_dev_bias,adapter_eval_pearson': 0.8694356056781357, 'sts-b_dev_bias,adapter_eval_spearmanr': 0.8433442370066268, 'sts-b_dev_bias,adapter_eval_corr': 0.8563899213423812, 'sts-b_test_bias,adapter_eval_loss': 2.1743547916412354, 'sts-b_test_bias,adapter_eval_pearson': 0.7447091433466345, 'sts-b_test_bias,adapter_eval_spearmanr': 0.7399027830505146, 'sts-b_test_bias,adapter_eval_corr': 0.7423059631985746, 'sts-b_dev_eval_loss': 2.1148734092712402, 'sts-b_dev_eval_pearson': 0.8694356056781357, 'sts-b_dev_eval_spearmanr': 0.8433442370066268, 'sts-b_dev_eval_corr': 0.8563899213423812, 'sts-b_test_eval_loss': 2.1743547916412354, 'sts-b_test_eval_pearson': 0.7447091433466345, 'sts-b_test_eval_spearmanr': 0.7399027830505146, 'sts-b_test_eval_corr': 0.7423059631985746, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--42-roberta-large-27193', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_00-44-29_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--42-roberta-large-27193', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_adapter_eval_loss': 2.33229398727417, 'qnli_dev_adapter_eval_acc': 0.625, 'qnli_test_adapter_eval_loss': 2.3667213916778564, 'qnli_test_adapter_eval_acc': 0.5879553358960278, 'qnli_dev_eval_loss': 2.33229398727417, 'qnli_dev_eval_acc': 0.625, 'qnli_test_eval_loss': 2.3667213916778564, 'qnli_test_eval_acc': 0.5879553358960278, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--42-roberta-large-29168', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_00-56-23_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--42-roberta-large-29168', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_adapter_eval_loss': 2.460891008377075, 'qqp_dev_adapter_eval_acc': 0.78125, 'qqp_dev_adapter_eval_f1': 0.8108108108108109, 'qqp_dev_adapter_eval_acc_and_f1': 0.7960304054054055, 'qqp_test_adapter_eval_loss': 3.3699944019317627, 'qqp_test_adapter_eval_acc': 0.6352708384862725, 'qqp_test_adapter_eval_f1': 0.6478819427861884, 'qqp_test_adapter_eval_acc_and_f1': 0.6415763906362304, 'qqp_dev_eval_loss': 2.460891008377075, 'qqp_dev_eval_acc': 0.78125, 'qqp_dev_eval_f1': 0.8108108108108109, 'qqp_dev_eval_acc_and_f1': 0.7960304054054055, 'qqp_test_eval_loss': 3.3699944019317627, 'qqp_test_eval_acc': 0.6352708384862725, 'qqp_test_eval_f1': 0.6478819427861884, 'qqp_test_eval_acc_and_f1': 0.6415763906362304, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16--42-roberta-large-12127', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_01-02-15_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--42-roberta-large-12127', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias_eval_loss': 2.2794294357299805, 'mnli_dev_bias_eval_mnli/acc': 0.6041666666666666, 'mnli_test_bias_eval_loss': 2.264638900756836, 'mnli_test_bias_eval_mnli/acc': 0.5511971472236373, 'mnli-mm_test_bias_eval_loss': 2.0955750942230225, 'mnli-mm_test_bias_eval_mnli-mm/acc': 0.5727217249796582, 'mnli_dev_eval_loss': 2.2794294357299805, 'mnli_dev_eval_mnli/acc': 0.6041666666666666, 'mnli_test_eval_loss': 2.264638900756836, 'mnli_test_eval_mnli/acc': 0.5511971472236373, 'mnli-mm_test_eval_loss': 2.0955750942230225, 'mnli-mm_test_eval_mnli-mm/acc': 0.5727217249796582, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--42-roberta-large-23342', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_00-51-08_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--42-roberta-large-23342', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias,adapter_eval_loss': 2.120783805847168, 'sts-b_dev_bias,adapter_eval_pearson': 0.811008369313309, 'sts-b_dev_bias,adapter_eval_spearmanr': 0.7900842568820794, 'sts-b_dev_bias,adapter_eval_corr': 0.8005463130976942, 'sts-b_test_bias,adapter_eval_loss': 2.1832194328308105, 'sts-b_test_bias,adapter_eval_pearson': 0.6745890743057484, 'sts-b_test_bias,adapter_eval_spearmanr': 0.6677395714344603, 'sts-b_test_bias,adapter_eval_corr': 0.6711643228701043, 'sts-b_dev_eval_loss': 2.120783805847168, 'sts-b_dev_eval_pearson': 0.811008369313309, 'sts-b_dev_eval_spearmanr': 0.7900842568820794, 'sts-b_dev_eval_corr': 0.8005463130976942, 'sts-b_test_eval_loss': 2.1832194328308105, 'sts-b_test_eval_pearson': 0.6745890743057484, 'sts-b_test_eval_spearmanr': 0.6677395714344603, 'sts-b_test_eval_corr': 0.6711643228701043, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--42-roberta-large-27181', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_01-10-59_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--42-roberta-large-27181', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_adapter_eval_loss': 0.6931543350219727, 'qnli_dev_adapter_eval_acc': 0.5, 'qnli_test_adapter_eval_loss': 0.6931127905845642, 'qnli_test_adapter_eval_acc': 0.5053999633900788, 'qnli_dev_eval_loss': 0.6931543350219727, 'qnli_dev_eval_acc': 0.5, 'qnli_test_eval_loss': 0.6931127905845642, 'qnli_test_eval_acc': 0.5053999633900788, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--100-roberta-large-12986', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_01-22-35_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--100-roberta-large-12986', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_adapter_eval_loss': 0.6947274208068848, 'qqp_dev_adapter_eval_acc': 0.5, 'qqp_dev_adapter_eval_f1': 0.6666666666666666, 'qqp_dev_adapter_eval_acc_and_f1': 0.5833333333333333, 'qqp_test_adapter_eval_loss': 0.7095585465431213, 'qqp_test_adapter_eval_acc': 0.36816720257234725, 'qqp_test_adapter_eval_f1': 0.5381903642773208, 'qqp_test_adapter_eval_acc_and_f1': 0.45317878342483403, 'qqp_dev_eval_loss': 0.6947274208068848, 'qqp_dev_eval_acc': 0.5, 'qqp_dev_eval_f1': 0.6666666666666666, 'qqp_dev_eval_acc_and_f1': 0.5833333333333333, 'qqp_test_eval_loss': 0.7095585465431213, 'qqp_test_eval_acc': 0.36816720257234725, 'qqp_test_eval_f1': 0.5381903642773208, 'qqp_test_eval_acc_and_f1': 0.45317878342483403, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16--100-roberta-large-16666', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_01-29-30_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--100-roberta-large-16666', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias,adapter_eval_loss': 2.122612476348877, 'sts-b_dev_bias,adapter_eval_pearson': 0.7412763289228217, 'sts-b_dev_bias,adapter_eval_spearmanr': 0.7109289071107692, 'sts-b_dev_bias,adapter_eval_corr': 0.7261026180167954, 'sts-b_test_bias,adapter_eval_loss': 2.18733811378479, 'sts-b_test_bias,adapter_eval_pearson': 0.5811806880416664, 'sts-b_test_bias,adapter_eval_spearmanr': 0.5667803780318516, 'sts-b_test_bias,adapter_eval_corr': 0.573980533036759, 'sts-b_dev_eval_loss': 2.122612476348877, 'sts-b_dev_eval_pearson': 0.7412763289228217, 'sts-b_dev_eval_spearmanr': 0.7109289071107692, 'sts-b_dev_eval_corr': 0.7261026180167954, 'sts-b_test_eval_loss': 2.18733811378479, 'sts-b_test_eval_pearson': 0.5811806880416664, 'sts-b_test_eval_spearmanr': 0.5667803780318516, 'sts-b_test_eval_corr': 0.573980533036759, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--42-roberta-large-15734', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_01-38-28_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--42-roberta-large-15734', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_adapter_eval_loss': 1.8131039142608643, 'qnli_dev_adapter_eval_acc': 0.65625, 'qnli_test_adapter_eval_loss': 2.2921154499053955, 'qnli_test_adapter_eval_acc': 0.5482335712978217, 'qnli_dev_eval_loss': 1.8131039142608643, 'qnli_dev_eval_acc': 0.65625, 'qnli_test_eval_loss': 2.2921154499053955, 'qnli_test_eval_acc': 0.5482335712978217, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--100-roberta-large-31520', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_01-48-57_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--100-roberta-large-31520', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_adapter_eval_loss': 3.4531188011169434, 'qqp_dev_adapter_eval_acc': 0.78125, 'qqp_dev_adapter_eval_f1': 0.8205128205128205, 'qqp_dev_adapter_eval_acc_and_f1': 0.8008814102564102, 'qqp_test_adapter_eval_loss': 3.8060829639434814, 'qqp_test_adapter_eval_acc': 0.669651249072471, 'qqp_test_adapter_eval_f1': 0.6719717064544651, 'qqp_test_adapter_eval_acc_and_f1': 0.6708114777634681, 'qqp_dev_eval_loss': 3.4531188011169434, 'qqp_dev_eval_acc': 0.78125, 'qqp_dev_eval_f1': 0.8205128205128205, 'qqp_dev_eval_acc_and_f1': 0.8008814102564102, 'qqp_test_eval_loss': 3.8060829639434814, 'qqp_test_eval_acc': 0.669651249072471, 'qqp_test_eval_f1': 0.6719717064544651, 'qqp_test_eval_acc_and_f1': 0.6708114777634681, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16--100-roberta-large-22887', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_01-56-21_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--100-roberta-large-22887', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias_eval_loss': 1.2252051830291748, 'mnli_dev_bias_eval_mnli/acc': 0.375, 'mnli_test_bias_eval_loss': 1.2696149349212646, 'mnli_test_bias_eval_mnli/acc': 0.33285787060621497, 'mnli-mm_test_bias_eval_loss': 1.275956153869629, 'mnli-mm_test_bias_eval_mnli-mm/acc': 0.3373677786818552, 'mnli_dev_eval_loss': 1.2252051830291748, 'mnli_dev_eval_mnli/acc': 0.375, 'mnli_test_eval_loss': 1.2696149349212646, 'mnli_test_eval_mnli/acc': 0.33285787060621497, 'mnli-mm_test_eval_loss': 1.275956153869629, 'mnli-mm_test_eval_mnli-mm/acc': 0.3373677786818552, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--100-roberta-large-14610', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_01-38-27_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--100-roberta-large-14610', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias,adapter_eval_loss': 2.1128811836242676, 'sts-b_dev_bias,adapter_eval_pearson': 0.5237493413822698, 'sts-b_dev_bias,adapter_eval_spearmanr': 0.4835760911065003, 'sts-b_dev_bias,adapter_eval_corr': 0.5036627162443851, 'sts-b_test_bias,adapter_eval_loss': 2.213742733001709, 'sts-b_test_bias,adapter_eval_pearson': 0.038819451440134364, 'sts-b_test_bias,adapter_eval_spearmanr': 0.039950096937927636, 'sts-b_test_bias,adapter_eval_corr': 0.039384774189031, 'sts-b_dev_eval_loss': 2.1128811836242676, 'sts-b_dev_eval_pearson': 0.5237493413822698, 'sts-b_dev_eval_spearmanr': 0.4835760911065003, 'sts-b_dev_eval_corr': 0.5036627162443851, 'sts-b_test_eval_loss': 2.213742733001709, 'sts-b_test_eval_pearson': 0.038819451440134364, 'sts-b_test_eval_spearmanr': 0.039950096937927636, 'sts-b_test_eval_corr': 0.039384774189031, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--100-roberta-large-13432', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_02-06-14_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--100-roberta-large-13432', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_adapter_eval_loss': 2.002666473388672, 'qnli_dev_adapter_eval_acc': 0.6875, 'qnli_test_adapter_eval_loss': 2.2017552852630615, 'qnli_test_adapter_eval_acc': 0.5928976752699981, 'qnli_dev_eval_loss': 2.002666473388672, 'qnli_dev_eval_acc': 0.6875, 'qnli_test_eval_loss': 2.2017552852630615, 'qnli_test_eval_acc': 0.5928976752699981, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--100-roberta-large-12284', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_02-15-09_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--100-roberta-large-12284', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_adapter_eval_loss': 2.8456740379333496, 'qqp_dev_adapter_eval_acc': 0.75, 'qqp_dev_adapter_eval_f1': 0.7894736842105263, 'qqp_dev_adapter_eval_acc_and_f1': 0.7697368421052632, 'qqp_test_adapter_eval_loss': 3.1015751361846924, 'qqp_test_adapter_eval_acc': 0.6801385110066782, 'qqp_test_adapter_eval_f1': 0.6628076762619941, 'qqp_test_adapter_eval_acc_and_f1': 0.6714730936343362, 'qqp_dev_eval_loss': 2.8456740379333496, 'qqp_dev_eval_acc': 0.75, 'qqp_dev_eval_f1': 0.7894736842105263, 'qqp_dev_eval_acc_and_f1': 0.7697368421052632, 'qqp_test_eval_loss': 3.1015751361846924, 'qqp_test_eval_acc': 0.6801385110066782, 'qqp_test_eval_f1': 0.6628076762619941, 'qqp_test_eval_acc_and_f1': 0.6714730936343362, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16--100-roberta-large-22336', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_02-23-24_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--100-roberta-large-22336', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias,adapter_eval_loss': 2.09466290473938, 'sts-b_dev_bias,adapter_eval_pearson': 0.686976088598475, 'sts-b_dev_bias,adapter_eval_spearmanr': 0.6534893682000438, 'sts-b_dev_bias,adapter_eval_corr': 0.6702327283992594, 'sts-b_test_bias,adapter_eval_loss': 2.1757609844207764, 'sts-b_test_bias,adapter_eval_pearson': 0.6965036568391584, 'sts-b_test_bias,adapter_eval_spearmanr': 0.6958423874104146, 'sts-b_test_bias,adapter_eval_corr': 0.6961730221247865, 'sts-b_dev_eval_loss': 2.09466290473938, 'sts-b_dev_eval_pearson': 0.686976088598475, 'sts-b_dev_eval_spearmanr': 0.6534893682000438, 'sts-b_dev_eval_corr': 0.6702327283992594, 'sts-b_test_eval_loss': 2.1757609844207764, 'sts-b_test_eval_pearson': 0.6965036568391584, 'sts-b_test_eval_spearmanr': 0.6958423874104146, 'sts-b_test_eval_corr': 0.6961730221247865, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--100-roberta-large-2261', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_02-33-14_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--100-roberta-large-2261', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_adapter_eval_loss': 1.6451178789138794, 'qnli_dev_adapter_eval_acc': 0.6875, 'qnli_test_adapter_eval_loss': 2.168748378753662, 'qnli_test_adapter_eval_acc': 0.5623283909939594, 'qnli_dev_eval_loss': 1.6451178789138794, 'qnli_dev_eval_acc': 0.6875, 'qnli_test_eval_loss': 2.168748378753662, 'qnli_test_eval_acc': 0.5623283909939594, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--100-roberta-large-20576', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_02-40-59_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--100-roberta-large-20576', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias_eval_loss': 2.605224609375, 'mnli_dev_bias_eval_mnli/acc': 0.8125, 'mnli_test_bias_eval_loss': 3.4551022052764893, 'mnli_test_bias_eval_mnli/acc': 0.6861946001018848, 'mnli-mm_test_bias_eval_loss': 3.104194164276123, 'mnli-mm_test_bias_eval_mnli-mm/acc': 0.7131814483319772, 'mnli_dev_eval_loss': 2.605224609375, 'mnli_dev_eval_mnli/acc': 0.8125, 'mnli_test_eval_loss': 3.4551022052764893, 'mnli_test_eval_mnli/acc': 0.6861946001018848, 'mnli-mm_test_eval_loss': 3.104194164276123, 'mnli-mm_test_eval_mnli-mm/acc': 0.7131814483319772, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--100-roberta-large-21383', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_02-26-07_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--100-roberta-large-21383', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_adapter_eval_loss': 3.155689239501953, 'qqp_dev_adapter_eval_acc': 0.71875, 'qqp_dev_adapter_eval_f1': 0.7567567567567567, 'qqp_dev_adapter_eval_acc_and_f1': 0.7377533783783783, 'qqp_test_adapter_eval_loss': 2.857064962387085, 'qqp_test_adapter_eval_acc': 0.7219144199851595, 'qqp_test_adapter_eval_f1': 0.6798963642057911, 'qqp_test_adapter_eval_acc_and_f1': 0.7009053920954753, 'qqp_dev_eval_loss': 3.155689239501953, 'qqp_dev_eval_acc': 0.71875, 'qqp_dev_eval_f1': 0.7567567567567567, 'qqp_dev_eval_acc_and_f1': 0.7377533783783783, 'qqp_test_eval_loss': 2.857064962387085, 'qqp_test_eval_acc': 0.7219144199851595, 'qqp_test_eval_f1': 0.6798963642057911, 'qqp_test_eval_acc_and_f1': 0.7009053920954753, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16--100-roberta-large-14057', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_02-50-24_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--100-roberta-large-14057', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias,adapter_eval_loss': 2.095916271209717, 'sts-b_dev_bias,adapter_eval_pearson': 0.6727837837066106, 'sts-b_dev_bias,adapter_eval_spearmanr': 0.6185434126813248, 'sts-b_dev_bias,adapter_eval_corr': 0.6456635981939678, 'sts-b_test_bias,adapter_eval_loss': 2.181333541870117, 'sts-b_test_bias,adapter_eval_pearson': 0.6432832197940012, 'sts-b_test_bias,adapter_eval_spearmanr': 0.6429944929878758, 'sts-b_test_bias,adapter_eval_corr': 0.6431388563909385, 'sts-b_dev_eval_loss': 2.095916271209717, 'sts-b_dev_eval_pearson': 0.6727837837066106, 'sts-b_dev_eval_spearmanr': 0.6185434126813248, 'sts-b_dev_eval_corr': 0.6456635981939678, 'sts-b_test_eval_loss': 2.181333541870117, 'sts-b_test_eval_pearson': 0.6432832197940012, 'sts-b_test_eval_spearmanr': 0.6429944929878758, 'sts-b_test_eval_corr': 0.6431388563909385, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--100-roberta-large-27126', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_02-59-52_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--100-roberta-large-27126', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,adapter_eval_loss': 2.8324661254882812, 'qnli_dev_prompt,adapter_eval_acc': 0.5625, 'qnli_test_prompt,adapter_eval_loss': 2.9540960788726807, 'qnli_test_prompt,adapter_eval_acc': 0.52242357678931, 'qnli_dev_eval_loss': 2.8324661254882812, 'qnli_dev_eval_acc': 0.5625, 'qnli_test_eval_loss': 2.9540960788726807, 'qnli_test_eval_acc': 0.52242357678931, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-42-roberta-large-32214', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_03-06-55_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-42-roberta-large-32214', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,adapter_eval_loss': 1.8655877113342285, 'qqp_dev_prompt,adapter_eval_acc': 0.71875, 'qqp_dev_prompt,adapter_eval_f1': 0.7272727272727272, 'qqp_dev_prompt,adapter_eval_acc_and_f1': 0.7230113636363635, 'qqp_test_prompt,adapter_eval_loss': 2.7483248710632324, 'qqp_test_prompt,adapter_eval_acc': 0.5968093000247341, 'qqp_test_prompt,adapter_eval_f1': 0.5547999453775775, 'qqp_test_prompt,adapter_eval_acc_and_f1': 0.5758046227011557, 'qqp_dev_eval_loss': 1.8655877113342285, 'qqp_dev_eval_acc': 0.71875, 'qqp_dev_eval_f1': 0.7272727272727272, 'qqp_dev_eval_acc_and_f1': 0.7230113636363635, 'qqp_test_eval_loss': 2.7483248710632324, 'qqp_test_eval_acc': 0.5968093000247341, 'qqp_test_eval_f1': 0.5547999453775775, 'qqp_test_eval_acc_and_f1': 0.5758046227011557, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16-prompt-42-roberta-large-28565', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_03-16-59_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-42-roberta-large-28565', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_bias,adapter_eval_loss': 2.1057639122009277, 'sts-b_dev_bias,adapter_eval_pearson': 0.6149997478925842, 'sts-b_dev_bias,adapter_eval_spearmanr': 0.5543532101758885, 'sts-b_dev_bias,adapter_eval_corr': 0.5846764790342363, 'sts-b_test_bias,adapter_eval_loss': 2.1910648345947266, 'sts-b_test_bias,adapter_eval_pearson': 0.5688339896488425, 'sts-b_test_bias,adapter_eval_spearmanr': 0.5585006670625061, 'sts-b_test_bias,adapter_eval_corr': 0.5636673283556743, 'sts-b_dev_eval_loss': 2.1057639122009277, 'sts-b_dev_eval_pearson': 0.6149997478925842, 'sts-b_dev_eval_spearmanr': 0.5543532101758885, 'sts-b_dev_eval_corr': 0.5846764790342363, 'sts-b_test_eval_loss': 2.1910648345947266, 'sts-b_test_eval_pearson': 0.5688339896488425, 'sts-b_test_eval_spearmanr': 0.5585006670625061, 'sts-b_test_eval_corr': 0.5636673283556743, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16--100-roberta-large-6631', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_03-28-06_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16--100-roberta-large-6631', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias_eval_loss': 1.6439803838729858, 'mnli_dev_bias_eval_mnli/acc': 0.6875, 'mnli_test_bias_eval_loss': 2.1167945861816406, 'mnli_test_bias_eval_mnli/acc': 0.6254712175241977, 'mnli-mm_test_bias_eval_loss': 1.9430862665176392, 'mnli-mm_test_bias_eval_mnli-mm/acc': 0.6505288852725793, 'mnli_dev_eval_loss': 1.6439803838729858, 'mnli_dev_eval_mnli/acc': 0.6875, 'mnli_test_eval_loss': 2.1167945861816406, 'mnli_test_eval_mnli/acc': 0.6254712175241977, 'mnli-mm_test_eval_loss': 1.9430862665176392, 'mnli-mm_test_eval_mnli-mm/acc': 0.6505288852725793, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--100-roberta-large-8742', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_03-13-42_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--100-roberta-large-8742', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,adapter_eval_loss': 5.448956489562988, 'qnli_dev_prompt,adapter_eval_acc': 0.65625, 'qnli_test_prompt,adapter_eval_loss': 6.458499431610107, 'qnli_test_prompt,adapter_eval_acc': 0.5255354200988468, 'qnli_dev_eval_loss': 5.448956489562988, 'qnli_dev_eval_acc': 0.65625, 'qnli_test_eval_loss': 6.458499431610107, 'qnli_test_eval_acc': 0.5255354200988468, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-42-roberta-large-18048', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_03-33-56_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-42-roberta-large-18048', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,adapter_eval_loss': 1.875855565071106, 'qqp_dev_prompt,adapter_eval_acc': 0.875, 'qqp_dev_prompt,adapter_eval_f1': 0.875, 'qqp_dev_prompt,adapter_eval_acc_and_f1': 0.875, 'qqp_test_prompt,adapter_eval_loss': 4.469786167144775, 'qqp_test_prompt,adapter_eval_acc': 0.728394756369033, 'qqp_test_prompt,adapter_eval_f1': 0.6712177011287763, 'qqp_test_prompt,adapter_eval_acc_and_f1': 0.6998062287489046, 'qqp_dev_eval_loss': 1.875855565071106, 'qqp_dev_eval_acc': 0.875, 'qqp_dev_eval_f1': 0.875, 'qqp_dev_eval_acc_and_f1': 0.875, 'qqp_test_eval_loss': 4.469786167144775, 'qqp_test_eval_acc': 0.728394756369033, 'qqp_test_eval_f1': 0.6712177011287763, 'qqp_test_eval_acc_and_f1': 0.6998062287489046, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16-prompt-42-roberta-large-20842', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_03-45-08_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-42-roberta-large-20842', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias,adapter_eval_loss': 2.1526050567626953, 'sts-b_dev_prompt,bias,adapter_eval_pearson': 0.24746613355541097, 'sts-b_dev_prompt,bias,adapter_eval_spearmanr': 0.2564060237095993, 'sts-b_dev_prompt,bias,adapter_eval_corr': 0.2519360786325051, 'sts-b_test_prompt,bias,adapter_eval_loss': 2.2126755714416504, 'sts-b_test_prompt,bias,adapter_eval_pearson': 0.01940083996258247, 'sts-b_test_prompt,bias,adapter_eval_spearmanr': 0.01914295392883402, 'sts-b_test_prompt,bias,adapter_eval_corr': 0.019271896945708245, 'sts-b_dev_eval_loss': 2.1526050567626953, 'sts-b_dev_eval_pearson': 0.24746613355541097, 'sts-b_dev_eval_spearmanr': 0.2564060237095993, 'sts-b_dev_eval_corr': 0.2519360786325051, 'sts-b_test_eval_loss': 2.2126755714416504, 'sts-b_test_eval_pearson': 0.01940083996258247, 'sts-b_test_eval_spearmanr': 0.01914295392883402, 'sts-b_test_eval_corr': 0.019271896945708245, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-42-roberta-large-31183', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_03-55-28_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-42-roberta-large-31183', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,adapter_eval_loss': 1.8641812801361084, 'qnli_dev_prompt,adapter_eval_acc': 0.65625, 'qnli_test_prompt,adapter_eval_loss': 2.5831298828125, 'qnli_test_prompt,adapter_eval_acc': 0.6071755445725792, 'qnli_dev_eval_loss': 1.8641812801361084, 'qnli_dev_eval_acc': 0.65625, 'qnli_test_eval_loss': 2.5831298828125, 'qnli_test_eval_acc': 0.6071755445725792, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-42-roberta-large-7982', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_04-01-24_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-42-roberta-large-7982', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,adapter_eval_loss': 2.487353801727295, 'qqp_dev_prompt,adapter_eval_acc': 0.75, 'qqp_dev_prompt,adapter_eval_f1': 0.7777777777777777, 'qqp_dev_prompt,adapter_eval_acc_and_f1': 0.7638888888888888, 'qqp_test_prompt,adapter_eval_loss': 3.79166841506958, 'qqp_test_prompt,adapter_eval_acc': 0.6975265891664606, 'qqp_test_prompt,adapter_eval_f1': 0.6779893093187982, 'qqp_test_prompt,adapter_eval_acc_and_f1': 0.6877579492426293, 'qqp_dev_eval_loss': 2.487353801727295, 'qqp_dev_eval_acc': 0.75, 'qqp_dev_eval_f1': 0.7777777777777777, 'qqp_dev_eval_acc_and_f1': 0.7638888888888888, 'qqp_test_eval_loss': 3.79166841506958, 'qqp_test_eval_acc': 0.6975265891664606, 'qqp_test_eval_f1': 0.6779893093187982, 'qqp_test_eval_acc_and_f1': 0.6877579492426293, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16-prompt-42-roberta-large-22713', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_04-12-52_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-42-roberta-large-22713', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias_eval_loss': 1.3571580648422241, 'mnli_dev_bias_eval_mnli/acc': 0.75, 'mnli_test_bias_eval_loss': 2.146218776702881, 'mnli_test_bias_eval_mnli/acc': 0.6172185430463576, 'mnli-mm_test_bias_eval_loss': 2.102808952331543, 'mnli-mm_test_bias_eval_mnli-mm/acc': 0.6235760781122864, 'mnli_dev_eval_loss': 1.3571580648422241, 'mnli_dev_eval_mnli/acc': 0.75, 'mnli_test_eval_loss': 2.146218776702881, 'mnli_test_eval_mnli/acc': 0.6172185430463576, 'mnli-mm_test_eval_loss': 2.102808952331543, 'mnli-mm_test_eval_mnli-mm/acc': 0.6235760781122864, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16--100-roberta-large-23448', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_04-01-10_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--100-roberta-large-23448', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias,adapter_eval_loss': 2.1127142906188965, 'sts-b_dev_prompt,bias,adapter_eval_pearson': 0.842405703385305, 'sts-b_dev_prompt,bias,adapter_eval_spearmanr': 0.843160581902749, 'sts-b_dev_prompt,bias,adapter_eval_corr': 0.842783142644027, 'sts-b_test_prompt,bias,adapter_eval_loss': 2.163184881210327, 'sts-b_test_prompt,bias,adapter_eval_pearson': 0.8040699595492178, 'sts-b_test_prompt,bias,adapter_eval_spearmanr': 0.8038035173468382, 'sts-b_test_prompt,bias,adapter_eval_corr': 0.803936738448028, 'sts-b_dev_eval_loss': 2.1127142906188965, 'sts-b_dev_eval_pearson': 0.842405703385305, 'sts-b_dev_eval_spearmanr': 0.843160581902749, 'sts-b_dev_eval_corr': 0.842783142644027, 'sts-b_test_eval_loss': 2.163184881210327, 'sts-b_test_eval_pearson': 0.8040699595492178, 'sts-b_test_eval_spearmanr': 0.8038035173468382, 'sts-b_test_eval_corr': 0.803936738448028, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-42-roberta-large-18209', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_04-25-18_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-42-roberta-large-18209', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,adapter_eval_loss': 3.0936663150787354, 'qnli_dev_prompt,adapter_eval_acc': 0.625, 'qnli_test_prompt,adapter_eval_loss': 3.1481332778930664, 'qnli_test_prompt,adapter_eval_acc': 0.5817316492769541, 'qnli_dev_eval_loss': 3.0936663150787354, 'qnli_dev_eval_acc': 0.625, 'qnli_test_eval_loss': 3.1481332778930664, 'qnli_test_eval_acc': 0.5817316492769541, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-42-roberta-large-15261', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_04-28-30_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-42-roberta-large-15261', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,adapter_eval_loss': 0.7635514736175537, 'qqp_dev_prompt,adapter_eval_acc': 0.75, 'qqp_dev_prompt,adapter_eval_f1': 0.7647058823529411, 'qqp_dev_prompt,adapter_eval_acc_and_f1': 0.7573529411764706, 'qqp_test_prompt,adapter_eval_loss': 0.7669916749000549, 'qqp_test_prompt,adapter_eval_acc': 0.68276032649023, 'qqp_test_prompt,adapter_eval_f1': 0.6526566646807128, 'qqp_test_prompt,adapter_eval_acc_and_f1': 0.6677084955854714, 'qqp_dev_eval_loss': 0.7635514736175537, 'qqp_dev_eval_acc': 0.75, 'qqp_dev_eval_f1': 0.7647058823529411, 'qqp_dev_eval_acc_and_f1': 0.7573529411764706, 'qqp_test_eval_loss': 0.7669916749000549, 'qqp_test_eval_acc': 0.68276032649023, 'qqp_test_eval_f1': 0.6526566646807128, 'qqp_test_eval_acc_and_f1': 0.6677084955854714, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16-prompt-42-roberta-large-21136', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_04-40-41_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-42-roberta-large-21136', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,adapter_eval_loss': 0.7229676246643066, 'qnli_dev_prompt,adapter_eval_acc': 0.5, 'qnli_test_prompt,adapter_eval_loss': 0.7203251123428345, 'qnli_test_prompt,adapter_eval_acc': 0.5053999633900788, 'qnli_dev_eval_loss': 0.7229676246643066, 'qnli_dev_eval_acc': 0.5, 'qnli_test_eval_loss': 0.7203251123428345, 'qnli_test_eval_acc': 0.5053999633900788, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-100-roberta-large-20606', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_04-56-11_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-100-roberta-large-20606', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias,adapter_eval_loss': 2.1129393577575684, 'sts-b_dev_prompt,bias,adapter_eval_pearson': 0.8576050423279067, 'sts-b_dev_prompt,bias,adapter_eval_spearmanr': 0.8591385759401132, 'sts-b_dev_prompt,bias,adapter_eval_corr': 0.85837180913401, 'sts-b_test_prompt,bias,adapter_eval_loss': 2.177948236465454, 'sts-b_test_prompt,bias,adapter_eval_pearson': 0.6701165547179824, 'sts-b_test_prompt,bias,adapter_eval_spearmanr': 0.6659970281136275, 'sts-b_test_prompt,bias,adapter_eval_corr': 0.6680567914158049, 'sts-b_dev_eval_loss': 2.1129393577575684, 'sts-b_dev_eval_pearson': 0.8576050423279067, 'sts-b_dev_eval_spearmanr': 0.8591385759401132, 'sts-b_dev_eval_corr': 0.85837180913401, 'sts-b_test_eval_loss': 2.177948236465454, 'sts-b_test_eval_pearson': 0.6701165547179824, 'sts-b_test_eval_spearmanr': 0.6659970281136275, 'sts-b_test_eval_corr': 0.6680567914158049, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-42-roberta-large-9989', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_04-55-25_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-42-roberta-large-9989', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,adapter_eval_loss': 0.7339523434638977, 'qqp_dev_prompt,adapter_eval_acc': 0.5, 'qqp_dev_prompt,adapter_eval_f1': 0.6666666666666666, 'qqp_dev_prompt,adapter_eval_acc_and_f1': 0.5833333333333333, 'qqp_test_prompt,adapter_eval_loss': 0.8098343014717102, 'qqp_test_prompt,adapter_eval_acc': 0.36816720257234725, 'qqp_test_prompt,adapter_eval_f1': 0.5381903642773208, 'qqp_test_prompt,adapter_eval_acc_and_f1': 0.45317878342483403, 'qqp_dev_eval_loss': 0.7339523434638977, 'qqp_dev_eval_acc': 0.5, 'qqp_dev_eval_f1': 0.6666666666666666, 'qqp_dev_eval_acc_and_f1': 0.5833333333333333, 'qqp_test_eval_loss': 0.8098343014717102, 'qqp_test_eval_acc': 0.36816720257234725, 'qqp_test_eval_f1': 0.5381903642773208, 'qqp_test_eval_acc_and_f1': 0.45317878342483403, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16-prompt-100-roberta-large-15787', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_05-08-27_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-100-roberta-large-15787', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_adapter_eval_loss': 1.2038817405700684, 'mnli_dev_adapter_eval_mnli/acc': 0.3333333333333333, 'mnli_test_adapter_eval_loss': 1.2120486497879028, 'mnli_test_adapter_eval_mnli/acc': 0.31818644931227713, 'mnli-mm_test_adapter_eval_loss': 1.2128840684890747, 'mnli-mm_test_adapter_eval_mnli-mm/acc': 0.318246541903987, 'mnli_dev_eval_loss': 1.2038817405700684, 'mnli_dev_eval_mnli/acc': 0.3333333333333333, 'mnli_test_eval_loss': 1.2120486497879028, 'mnli_test_eval_mnli/acc': 0.31818644931227713, 'mnli-mm_test_eval_loss': 1.2128840684890747, 'mnli-mm_test_eval_mnli-mm/acc': 0.318246541903987, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--42-roberta-large-439', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_04-48-24_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--42-roberta-large-439', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,adapter_eval_loss': 2.063051223754883, 'qnli_dev_prompt,adapter_eval_acc': 0.65625, 'qnli_test_prompt,adapter_eval_loss': 2.7101378440856934, 'qnli_test_prompt,adapter_eval_acc': 0.5667215815485996, 'qnli_dev_eval_loss': 2.063051223754883, 'qnli_dev_eval_acc': 0.65625, 'qnli_test_eval_loss': 2.7101378440856934, 'qnli_test_eval_acc': 0.5667215815485996, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-100-roberta-large-25003', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_05-23-30_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-100-roberta-large-25003', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias,adapter_eval_loss': 2.1195149421691895, 'sts-b_dev_prompt,bias,adapter_eval_pearson': 0.7828629788782003, 'sts-b_dev_prompt,bias,adapter_eval_spearmanr': 0.7427012400816199, 'sts-b_dev_prompt,bias,adapter_eval_corr': 0.7627821094799101, 'sts-b_test_prompt,bias,adapter_eval_loss': 2.1879615783691406, 'sts-b_test_prompt,bias,adapter_eval_pearson': 0.5609370538107048, 'sts-b_test_prompt,bias,adapter_eval_spearmanr': 0.5512839953964133, 'sts-b_test_prompt,bias,adapter_eval_corr': 0.556110524603559, 'sts-b_dev_eval_loss': 2.1195149421691895, 'sts-b_dev_eval_pearson': 0.7828629788782003, 'sts-b_dev_eval_spearmanr': 0.7427012400816199, 'sts-b_dev_eval_corr': 0.7627821094799101, 'sts-b_test_eval_loss': 2.1879615783691406, 'sts-b_test_eval_pearson': 0.5609370538107048, 'sts-b_test_eval_spearmanr': 0.5512839953964133, 'sts-b_test_eval_corr': 0.556110524603559, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-42-roberta-large-3955', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_05-25-43_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-42-roberta-large-3955', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,adapter_eval_loss': 3.675895929336548, 'qqp_dev_prompt,adapter_eval_acc': 0.78125, 'qqp_dev_prompt,adapter_eval_f1': 0.8205128205128205, 'qqp_dev_prompt,adapter_eval_acc_and_f1': 0.8008814102564102, 'qqp_test_prompt,adapter_eval_loss': 4.331294059753418, 'qqp_test_prompt,adapter_eval_acc': 0.7020529309918377, 'qqp_test_prompt,adapter_eval_f1': 0.695269415633696, 'qqp_test_prompt,adapter_eval_acc_and_f1': 0.6986611733127669, 'qqp_dev_eval_loss': 3.675895929336548, 'qqp_dev_eval_acc': 0.78125, 'qqp_dev_eval_f1': 0.8205128205128205, 'qqp_dev_eval_acc_and_f1': 0.8008814102564102, 'qqp_test_eval_loss': 4.331294059753418, 'qqp_test_eval_acc': 0.7020529309918377, 'qqp_test_eval_f1': 0.695269415633696, 'qqp_test_eval_acc_and_f1': 0.6986611733127669, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16-prompt-100-roberta-large-13284', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_05-36-07_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-100-roberta-large-13284', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,adapter_eval_loss': 2.9446144104003906, 'qnli_dev_prompt,adapter_eval_acc': 0.65625, 'qnli_test_prompt,adapter_eval_loss': 3.3005335330963135, 'qnli_test_prompt,adapter_eval_acc': 0.5403624382207578, 'qnli_dev_eval_loss': 2.9446144104003906, 'qnli_dev_eval_acc': 0.65625, 'qnli_test_eval_loss': 3.3005335330963135, 'qnli_test_eval_acc': 0.5403624382207578, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-100-roberta-large-5326', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_05-51-01_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-100-roberta-large-5326', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_adapter_eval_loss': 4.079019069671631, 'mnli_dev_adapter_eval_mnli/acc': 0.5833333333333334, 'mnli_test_adapter_eval_loss': 3.800872325897217, 'mnli_test_adapter_eval_mnli/acc': 0.5502801833927662, 'mnli-mm_test_adapter_eval_loss': 3.110193967819214, 'mnli-mm_test_adapter_eval_mnli-mm/acc': 0.584926769731489, 'mnli_dev_eval_loss': 4.079019069671631, 'mnli_dev_eval_mnli/acc': 0.5833333333333334, 'mnli_test_eval_loss': 3.800872325897217, 'mnli_test_eval_mnli/acc': 0.5502801833927662, 'mnli-mm_test_eval_loss': 3.110193967819214, 'mnli-mm_test_eval_mnli-mm/acc': 0.584926769731489, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--42-roberta-large-22110', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_05-37-19_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--42-roberta-large-22110', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias,adapter_eval_loss': 2.111530065536499, 'sts-b_dev_prompt,bias,adapter_eval_pearson': 0.17806712403514952, 'sts-b_dev_prompt,bias,adapter_eval_spearmanr': 0.11461746461764614, 'sts-b_dev_prompt,bias,adapter_eval_corr': 0.14634229432639784, 'sts-b_test_prompt,bias,adapter_eval_loss': 2.2110934257507324, 'sts-b_test_prompt,bias,adapter_eval_pearson': 0.00021672795300800031, 'sts-b_test_prompt,bias,adapter_eval_spearmanr': -0.0068703413229458206, 'sts-b_test_prompt,bias,adapter_eval_corr': -0.00332680668496891, 'sts-b_dev_eval_loss': 2.111530065536499, 'sts-b_dev_eval_pearson': 0.17806712403514952, 'sts-b_dev_eval_spearmanr': 0.11461746461764614, 'sts-b_dev_eval_corr': 0.14634229432639784, 'sts-b_test_eval_loss': 2.2110934257507324, 'sts-b_test_eval_pearson': 0.00021672795300800031, 'sts-b_test_eval_spearmanr': -0.0068703413229458206, 'sts-b_test_eval_corr': -0.00332680668496891, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-100-roberta-large-20477', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_05-56-37_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-100-roberta-large-20477', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,adapter_eval_loss': 2.1989736557006836, 'qqp_dev_prompt,adapter_eval_acc': 0.8125, 'qqp_dev_prompt,adapter_eval_f1': 0.823529411764706, 'qqp_dev_prompt,adapter_eval_acc_and_f1': 0.818014705882353, 'qqp_test_prompt,adapter_eval_loss': 2.6944408416748047, 'qqp_test_prompt,adapter_eval_acc': 0.7337867919861489, 'qqp_test_prompt,adapter_eval_f1': 0.6861641638722846, 'qqp_test_prompt,adapter_eval_acc_and_f1': 0.7099754779292168, 'qqp_dev_eval_loss': 2.1989736557006836, 'qqp_dev_eval_acc': 0.8125, 'qqp_dev_eval_f1': 0.823529411764706, 'qqp_dev_eval_acc_and_f1': 0.818014705882353, 'qqp_test_eval_loss': 2.6944408416748047, 'qqp_test_eval_acc': 0.7337867919861489, 'qqp_test_eval_f1': 0.6861641638722846, 'qqp_test_eval_acc_and_f1': 0.7099754779292168, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16-prompt-100-roberta-large-2851', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_06-04-07_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-100-roberta-large-2851', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,adapter_eval_loss': 3.8602752685546875, 'qnli_dev_prompt,adapter_eval_acc': 0.6875, 'qnli_test_prompt,adapter_eval_loss': 3.851425886154175, 'qnli_test_prompt,adapter_eval_acc': 0.5409115870400879, 'qnli_dev_eval_loss': 3.8602752685546875, 'qnli_dev_eval_acc': 0.6875, 'qnli_test_eval_loss': 3.851425886154175, 'qnli_test_eval_acc': 0.5409115870400879, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-100-roberta-large-9815', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_06-18-18_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-100-roberta-large-9815', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias,adapter_eval_loss': 2.0896096229553223, 'sts-b_dev_prompt,bias,adapter_eval_pearson': 0.705533502807266, 'sts-b_dev_prompt,bias,adapter_eval_spearmanr': 0.6658124156724341, 'sts-b_dev_prompt,bias,adapter_eval_corr': 0.68567295923985, 'sts-b_test_prompt,bias,adapter_eval_loss': 2.185255289077759, 'sts-b_test_prompt,bias,adapter_eval_pearson': 0.5945120808058884, 'sts-b_test_prompt,bias,adapter_eval_spearmanr': 0.5863883065924025, 'sts-b_test_prompt,bias,adapter_eval_corr': 0.5904501936991454, 'sts-b_dev_eval_loss': 2.0896096229553223, 'sts-b_dev_eval_pearson': 0.705533502807266, 'sts-b_dev_eval_spearmanr': 0.6658124156724341, 'sts-b_dev_eval_corr': 0.68567295923985, 'sts-b_test_eval_loss': 2.185255289077759, 'sts-b_test_eval_pearson': 0.5945120808058884, 'sts-b_test_eval_spearmanr': 0.5863883065924025, 'sts-b_test_eval_corr': 0.5904501936991454, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-100-roberta-large-32699', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_06-27-22_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-100-roberta-large-32699', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,adapter_eval_loss': 2.669224500656128, 'qqp_dev_prompt,adapter_eval_acc': 0.75, 'qqp_dev_prompt,adapter_eval_f1': 0.8, 'qqp_dev_prompt,adapter_eval_acc_and_f1': 0.775, 'qqp_test_prompt,adapter_eval_loss': 3.1110119819641113, 'qqp_test_prompt,adapter_eval_acc': 0.7042790007420232, 'qqp_test_prompt,adapter_eval_f1': 0.6771615272452342, 'qqp_test_prompt,adapter_eval_acc_and_f1': 0.6907202639936287, 'qqp_dev_eval_loss': 2.669224500656128, 'qqp_dev_eval_acc': 0.75, 'qqp_dev_eval_f1': 0.8, 'qqp_dev_eval_acc_and_f1': 0.775, 'qqp_test_eval_loss': 3.1110119819641113, 'qqp_test_eval_acc': 0.7042790007420232, 'qqp_test_eval_f1': 0.6771615272452342, 'qqp_test_eval_acc_and_f1': 0.6907202639936287, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16-prompt-100-roberta-large-28389', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_06-32-09_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-100-roberta-large-28389', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias_eval_loss': 3.0392796993255615, 'qnli_dev_prompt,bias_eval_acc': 0.53125, 'qnli_test_prompt,bias_eval_loss': 2.5276455879211426, 'qnli_test_prompt,bias_eval_acc': 0.509793153944719, 'qnli_dev_eval_loss': 3.0392796993255615, 'qnli_dev_eval_acc': 0.53125, 'qnli_test_eval_loss': 2.5276455879211426, 'qnli_test_eval_acc': 0.509793153944719, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-42-roberta-large-29528', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_06-45-34_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-42-roberta-large-29528', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_adapter_eval_loss': 3.0429065227508545, 'mnli_dev_adapter_eval_mnli/acc': 0.5416666666666666, 'mnli_test_adapter_eval_loss': 3.1525015830993652, 'mnli_test_adapter_eval_mnli/acc': 0.5127865511971472, 'mnli-mm_test_adapter_eval_loss': 2.7968590259552, 'mnli-mm_test_adapter_eval_mnli-mm/acc': 0.5407851912123678, 'mnli_dev_eval_loss': 3.0429065227508545, 'mnli_dev_eval_mnli/acc': 0.5416666666666666, 'mnli_test_eval_loss': 3.1525015830993652, 'mnli_test_eval_mnli/acc': 0.5127865511971472, 'mnli-mm_test_eval_loss': 2.7968590259552, 'mnli-mm_test_eval_mnli-mm/acc': 0.5407851912123678, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--42-roberta-large-13721', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_06-26-42_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--42-roberta-large-13721', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,bias_eval_loss': 1.4556641578674316, 'qqp_dev_prompt,bias_eval_acc': 0.8125, 'qqp_dev_prompt,bias_eval_f1': 0.8333333333333334, 'qqp_dev_prompt,bias_eval_acc_and_f1': 0.8229166666666667, 'qqp_test_prompt,bias_eval_loss': 2.696542739868164, 'qqp_test_prompt,bias_eval_acc': 0.7391293593865941, 'qqp_test_prompt,bias_eval_f1': 0.7014633870191626, 'qqp_test_prompt,bias_eval_acc_and_f1': 0.7202963732028783, 'qqp_dev_eval_loss': 1.4556641578674316, 'qqp_dev_eval_acc': 0.8125, 'qqp_dev_eval_f1': 0.8333333333333334, 'qqp_dev_eval_acc_and_f1': 0.8229166666666667, 'qqp_test_eval_loss': 2.696542739868164, 'qqp_test_eval_acc': 0.7391293593865941, 'qqp_test_eval_f1': 0.7014633870191626, 'qqp_test_eval_acc_and_f1': 0.7202963732028783, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-42-roberta-large-2554', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_07-00-42_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-42-roberta-large-2554', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias,adapter_eval_loss': 2.100632667541504, 'sts-b_dev_prompt,bias,adapter_eval_pearson': 0.6023784488227975, 'sts-b_dev_prompt,bias,adapter_eval_spearmanr': 0.5440533496019503, 'sts-b_dev_prompt,bias,adapter_eval_corr': 0.5732158992123739, 'sts-b_test_prompt,bias,adapter_eval_loss': 2.1867856979370117, 'sts-b_test_prompt,bias,adapter_eval_pearson': 0.5808850351804209, 'sts-b_test_prompt,bias,adapter_eval_spearmanr': 0.5728380787243922, 'sts-b_test_prompt,bias,adapter_eval_corr': 0.5768615569524065, 'sts-b_dev_eval_loss': 2.100632667541504, 'sts-b_dev_eval_pearson': 0.6023784488227975, 'sts-b_dev_eval_spearmanr': 0.5440533496019503, 'sts-b_dev_eval_corr': 0.5732158992123739, 'sts-b_test_eval_loss': 2.1867856979370117, 'sts-b_test_eval_pearson': 0.5808850351804209, 'sts-b_test_eval_spearmanr': 0.5728380787243922, 'sts-b_test_eval_corr': 0.5768615569524065, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-100-roberta-large-31855', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_06-56-23_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-100-roberta-large-31855', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias_eval_loss': 1.8673779964447021, 'qnli_dev_prompt,bias_eval_acc': 0.6875, 'qnli_test_prompt,bias_eval_loss': 2.0335564613342285, 'qnli_test_prompt,bias_eval_acc': 0.5714808713161267, 'qnli_dev_eval_loss': 1.8673779964447021, 'qnli_dev_eval_acc': 0.6875, 'qnli_test_eval_loss': 2.0335564613342285, 'qnli_test_eval_acc': 0.5714808713161267, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-42-roberta-large-18225', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_07-11-37_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-42-roberta-large-18225', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,bias_eval_loss': 2.795991897583008, 'qqp_dev_prompt,bias_eval_acc': 0.75, 'qqp_dev_prompt,bias_eval_f1': 0.7894736842105263, 'qqp_dev_prompt,bias_eval_acc_and_f1': 0.7697368421052632, 'qqp_test_prompt,bias_eval_loss': 3.649472951889038, 'qqp_test_prompt,bias_eval_acc': 0.6895374721741281, 'qqp_test_prompt,bias_eval_f1': 0.6740417575568712, 'qqp_test_prompt,bias_eval_acc_and_f1': 0.6817896148654996, 'qqp_dev_eval_loss': 2.795991897583008, 'qqp_dev_eval_acc': 0.75, 'qqp_dev_eval_f1': 0.7894736842105263, 'qqp_dev_eval_acc_and_f1': 0.7697368421052632, 'qqp_test_eval_loss': 3.649472951889038, 'qqp_test_eval_acc': 0.6895374721741281, 'qqp_test_eval_f1': 0.6740417575568712, 'qqp_test_eval_acc_and_f1': 0.6817896148654996, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-42-roberta-large-17569', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_07-25-33_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-42-roberta-large-17569', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sts-b_dev_prompt,bias,adapter_eval_loss': 2.1010711193084717, 'sts-b_dev_prompt,bias,adapter_eval_pearson': 0.6483640597412197, 'sts-b_dev_prompt,bias,adapter_eval_spearmanr': 0.5948169481449315, 'sts-b_dev_prompt,bias,adapter_eval_corr': 0.6215905039430756, 'sts-b_test_prompt,bias,adapter_eval_loss': 2.188190221786499, 'sts-b_test_prompt,bias,adapter_eval_pearson': 0.5871769608832847, 'sts-b_test_prompt,bias,adapter_eval_spearmanr': 0.5774364489672709, 'sts-b_test_prompt,bias,adapter_eval_corr': 0.5823067049252778, 'sts-b_dev_eval_loss': 2.1010711193084717, 'sts-b_dev_eval_pearson': 0.6483640597412197, 'sts-b_dev_eval_spearmanr': 0.5948169481449315, 'sts-b_dev_eval_corr': 0.6215905039430756, 'sts-b_test_eval_loss': 2.188190221786499, 'sts-b_test_eval_pearson': 0.5871769608832847, 'sts-b_test_eval_spearmanr': 0.5774364489672709, 'sts-b_test_eval_corr': 0.5823067049252778, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/STS-B-16-prompt-100-roberta-large-5250', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_07-27-50_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/STS-B-16-prompt-100-roberta-large-5250', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'sts-b', 'data_dir': 'data/k-shot/STS-B/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias_eval_loss': 2.64438796043396, 'qnli_dev_prompt,bias_eval_acc': 0.65625, 'qnli_test_prompt,bias_eval_loss': 2.6937828063964844, 'qnli_test_prompt,bias_eval_acc': 0.5809994508511807, 'qnli_dev_eval_loss': 2.64438796043396, 'qnli_dev_eval_acc': 0.65625, 'qnli_test_eval_loss': 2.6937828063964844, 'qnli_test_eval_acc': 0.5809994508511807, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-42-roberta-large-12866', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_07-37-34_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-42-roberta-large-12866', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_adapter_eval_loss': 3.3636608123779297, 'mnli_dev_adapter_eval_mnli/acc': 0.5625, 'mnli_test_adapter_eval_loss': 3.2409374713897705, 'mnli_test_adapter_eval_mnli/acc': 0.49424350483953133, 'mnli-mm_test_adapter_eval_loss': 2.7436840534210205, 'mnli-mm_test_adapter_eval_mnli-mm/acc': 0.5333604556550041, 'mnli_dev_eval_loss': 3.3636608123779297, 'mnli_dev_eval_mnli/acc': 0.5625, 'mnli_test_eval_loss': 3.2409374713897705, 'mnli_test_eval_mnli/acc': 0.49424350483953133, 'mnli-mm_test_eval_loss': 2.7436840534210205, 'mnli-mm_test_eval_mnli-mm/acc': 0.5333604556550041, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--42-roberta-large-27845', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_07-16-08_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--42-roberta-large-27845', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,bias_eval_loss': 2.154370069503784, 'qqp_dev_prompt,bias_eval_acc': 0.6875, 'qqp_dev_prompt,bias_eval_f1': 0.7222222222222223, 'qqp_dev_prompt,bias_eval_acc_and_f1': 0.7048611111111112, 'qqp_test_prompt,bias_eval_loss': 1.9569458961486816, 'qqp_test_prompt,bias_eval_acc': 0.6832055404402672, 'qqp_test_prompt,bias_eval_f1': 0.668169335198715, 'qqp_test_prompt,bias_eval_acc_and_f1': 0.675687437819491, 'qqp_dev_eval_loss': 2.154370069503784, 'qqp_dev_eval_acc': 0.6875, 'qqp_dev_eval_f1': 0.7222222222222223, 'qqp_dev_eval_acc_and_f1': 0.7048611111111112, 'qqp_test_eval_loss': 1.9569458961486816, 'qqp_test_eval_acc': 0.6832055404402672, 'qqp_test_eval_f1': 0.668169335198715, 'qqp_test_eval_acc_and_f1': 0.675687437819491, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-42-roberta-large-28203', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_07-50-36_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-42-roberta-large-28203', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_adapter_eval_loss': 1.273180365562439, 'mnli_dev_adapter_eval_mnli/acc': 0.3333333333333333, 'mnli_test_adapter_eval_loss': 1.2647449970245361, 'mnli_test_adapter_eval_mnli/acc': 0.3273560876209883, 'mnli-mm_test_adapter_eval_loss': 1.2633304595947266, 'mnli-mm_test_adapter_eval_mnli-mm/acc': 0.3295362082994304, 'mnli_dev_eval_loss': 1.273180365562439, 'mnli_dev_eval_mnli/acc': 0.3333333333333333, 'mnli_test_eval_loss': 1.2647449970245361, 'mnli_test_eval_mnli/acc': 0.3273560876209883, 'mnli-mm_test_eval_loss': 1.2633304595947266, 'mnli-mm_test_eval_mnli-mm/acc': 0.3295362082994304, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--100-roberta-large-12701', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_08-03-45_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--100-roberta-large-12701', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias_eval_loss': 1.585181713104248, 'qnli_dev_prompt,bias_eval_acc': 0.625, 'qnli_test_prompt,bias_eval_loss': 2.0255331993103027, 'qnli_test_prompt,bias_eval_acc': 0.5718469705290133, 'qnli_dev_eval_loss': 1.585181713104248, 'qnli_dev_eval_acc': 0.625, 'qnli_test_eval_loss': 2.0255331993103027, 'qnli_test_eval_acc': 0.5718469705290133, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-42-roberta-large-25077', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_08-03-16_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-42-roberta-large-25077', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,bias_eval_loss': 1.1534411907196045, 'qqp_dev_prompt,bias_eval_acc': 0.6875, 'qqp_dev_prompt,bias_eval_f1': 0.7222222222222223, 'qqp_dev_prompt,bias_eval_acc_and_f1': 0.7048611111111112, 'qqp_test_prompt,bias_eval_loss': 0.9254342913627625, 'qqp_test_prompt,bias_eval_acc': 0.6822656443235221, 'qqp_test_prompt,bias_eval_f1': 0.6590221372830068, 'qqp_test_prompt,bias_eval_acc_and_f1': 0.6706438908032645, 'qqp_dev_eval_loss': 1.1534411907196045, 'qqp_dev_eval_acc': 0.6875, 'qqp_dev_eval_f1': 0.7222222222222223, 'qqp_dev_eval_acc_and_f1': 0.7048611111111112, 'qqp_test_eval_loss': 0.9254342913627625, 'qqp_test_eval_acc': 0.6822656443235221, 'qqp_test_eval_f1': 0.6590221372830068, 'qqp_test_eval_acc_and_f1': 0.6706438908032645, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-42-roberta-large-15448', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_08-16-03_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-42-roberta-large-15448', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_adapter_eval_loss': 1.4474902153015137, 'mnli_dev_adapter_eval_mnli/acc': 0.7083333333333334, 'mnli_test_adapter_eval_loss': 2.497070074081421, 'mnli_test_adapter_eval_mnli/acc': 0.6443199184921039, 'mnli-mm_test_adapter_eval_loss': 2.217503786087036, 'mnli-mm_test_adapter_eval_mnli-mm/acc': 0.6634458909682669, 'mnli_dev_eval_loss': 1.4474902153015137, 'mnli_dev_eval_mnli/acc': 0.7083333333333334, 'mnli_test_eval_loss': 2.497070074081421, 'mnli_test_eval_mnli/acc': 0.6443199184921039, 'mnli-mm_test_eval_loss': 2.217503786087036, 'mnli-mm_test_eval_mnli-mm/acc': 0.6634458909682669, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--100-roberta-large-29899', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_08-24-38_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--100-roberta-large-29899', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias_eval_loss': 1.2646396160125732, 'qnli_dev_prompt,bias_eval_acc': 0.84375, 'qnli_test_prompt,bias_eval_loss': 2.4510483741760254, 'qnli_test_prompt,bias_eval_acc': 0.6093721398498994, 'qnli_dev_eval_loss': 1.2646396160125732, 'qnli_dev_eval_acc': 0.84375, 'qnli_test_eval_loss': 2.4510483741760254, 'qnli_test_eval_acc': 0.6093721398498994, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-100-roberta-large-12974', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_08-28-57_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-100-roberta-large-12974', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_adapter_eval_loss': 1.5681716203689575, 'mnli_dev_adapter_eval_mnli/acc': 0.7083333333333334, 'mnli_test_adapter_eval_loss': 2.522280216217041, 'mnli_test_adapter_eval_mnli/acc': 0.5732042791645441, 'mnli-mm_test_adapter_eval_loss': 2.3034307956695557, 'mnli-mm_test_adapter_eval_mnli-mm/acc': 0.5971318144833198, 'mnli_dev_eval_loss': 1.5681716203689575, 'mnli_dev_eval_mnli/acc': 0.7083333333333334, 'mnli_test_eval_loss': 2.522280216217041, 'mnli_test_eval_mnli/acc': 0.5732042791645441, 'mnli-mm_test_eval_loss': 2.3034307956695557, 'mnli-mm_test_eval_mnli-mm/acc': 0.5971318144833198, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--100-roberta-large-1165', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_08-44-57_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--100-roberta-large-1165', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,bias_eval_loss': 2.6764957904815674, 'qqp_dev_prompt,bias_eval_acc': 0.75, 'qqp_dev_prompt,bias_eval_f1': 0.7894736842105263, 'qqp_dev_prompt,bias_eval_acc_and_f1': 0.7697368421052632, 'qqp_test_prompt,bias_eval_loss': 3.081364870071411, 'qqp_test_prompt,bias_eval_acc': 0.6972792480831066, 'qqp_test_prompt,bias_eval_f1': 0.6738788670095126, 'qqp_test_prompt,bias_eval_acc_and_f1': 0.6855790575463097, 'qqp_dev_eval_loss': 2.6764957904815674, 'qqp_dev_eval_acc': 0.75, 'qqp_dev_eval_f1': 0.7894736842105263, 'qqp_dev_eval_acc_and_f1': 0.7697368421052632, 'qqp_test_eval_loss': 3.081364870071411, 'qqp_test_eval_acc': 0.6972792480831066, 'qqp_test_eval_f1': 0.6738788670095126, 'qqp_test_eval_acc_and_f1': 0.6855790575463097, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-100-roberta-large-26794', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_08-41-08_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-100-roberta-large-26794', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias_eval_loss': 2.3166396617889404, 'qnli_dev_prompt,bias_eval_acc': 0.75, 'qnli_test_prompt,bias_eval_loss': 3.6135387420654297, 'qnli_test_prompt,bias_eval_acc': 0.5923485264506682, 'qnli_dev_eval_loss': 2.3166396617889404, 'qnli_dev_eval_acc': 0.75, 'qnli_test_eval_loss': 3.6135387420654297, 'qnli_test_eval_acc': 0.5923485264506682, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-100-roberta-large-8959', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_08-54-45_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-100-roberta-large-8959', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_adapter_eval_loss': 1.6098612546920776, 'mnli_dev_adapter_eval_mnli/acc': 0.6875, 'mnli_test_adapter_eval_loss': 2.2532289028167725, 'mnli_test_adapter_eval_mnli/acc': 0.5475292919001529, 'mnli-mm_test_adapter_eval_loss': 2.1362547874450684, 'mnli-mm_test_adapter_eval_mnli-mm/acc': 0.5609235150528885, 'mnli_dev_eval_loss': 1.6098612546920776, 'mnli_dev_eval_mnli/acc': 0.6875, 'mnli_test_eval_loss': 2.2532289028167725, 'mnli_test_eval_mnli/acc': 0.5475292919001529, 'mnli-mm_test_eval_loss': 2.1362547874450684, 'mnli-mm_test_eval_mnli-mm/acc': 0.5609235150528885, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--100-roberta-large-15512', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_09-05-13_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--100-roberta-large-15512', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,bias_eval_loss': 2.3504416942596436, 'qqp_dev_prompt,bias_eval_acc': 0.78125, 'qqp_dev_prompt,bias_eval_f1': 0.8108108108108109, 'qqp_dev_prompt,bias_eval_acc_and_f1': 0.7960304054054055, 'qqp_test_prompt,bias_eval_loss': 2.6804120540618896, 'qqp_test_prompt,bias_eval_acc': 0.7224585703685382, 'qqp_test_prompt,bias_eval_f1': 0.6869227979130047, 'qqp_test_prompt,bias_eval_acc_and_f1': 0.7046906841407714, 'qqp_dev_eval_loss': 2.3504416942596436, 'qqp_dev_eval_acc': 0.78125, 'qqp_dev_eval_f1': 0.8108108108108109, 'qqp_dev_eval_acc_and_f1': 0.7960304054054055, 'qqp_test_eval_loss': 2.6804120540618896, 'qqp_test_eval_acc': 0.7224585703685382, 'qqp_test_eval_f1': 0.6869227979130047, 'qqp_test_eval_acc_and_f1': 0.7046906841407714, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-100-roberta-large-16392', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_09-06-20_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-100-roberta-large-16392', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias_eval_loss': 3.0290307998657227, 'qnli_dev_prompt,bias_eval_acc': 0.6875, 'qnli_test_prompt,bias_eval_loss': 3.797590732574463, 'qnli_test_prompt,bias_eval_acc': 0.5390810909756544, 'qnli_dev_eval_loss': 3.0290307998657227, 'qnli_dev_eval_acc': 0.6875, 'qnli_test_eval_loss': 3.797590732574463, 'qnli_test_eval_acc': 0.5390810909756544, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-100-roberta-large-19619', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_09-20-30_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-100-roberta-large-19619', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,adapter_eval_loss': 1.252127766609192, 'mnli_dev_prompt,adapter_eval_mnli/acc': 0.3333333333333333, 'mnli_test_prompt,adapter_eval_loss': 1.266746163368225, 'mnli_test_prompt,adapter_eval_mnli/acc': 0.31818644931227713, 'mnli-mm_test_prompt,adapter_eval_loss': 1.2670830488204956, 'mnli-mm_test_prompt,adapter_eval_mnli-mm/acc': 0.318246541903987, 'mnli_dev_eval_loss': 1.252127766609192, 'mnli_dev_eval_mnli/acc': 0.3333333333333333, 'mnli_test_eval_loss': 1.266746163368225, 'mnli_test_eval_mnli/acc': 0.31818644931227713, 'mnli-mm_test_eval_loss': 1.2670830488204956, 'mnli-mm_test_eval_mnli-mm/acc': 0.318246541903987, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-24715', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_09-25-34_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-24715', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,bias_eval_loss': 1.2625925540924072, 'qqp_dev_prompt,bias_eval_acc': 0.8125, 'qqp_dev_prompt,bias_eval_f1': 0.823529411764706, 'qqp_dev_prompt,bias_eval_acc_and_f1': 0.818014705882353, 'qqp_test_prompt,bias_eval_loss': 1.4162238836288452, 'qqp_test_prompt,bias_eval_acc': 0.7510511996042543, 'qqp_test_prompt,bias_eval_f1': 0.6844728674880091, 'qqp_test_prompt,bias_eval_acc_and_f1': 0.7177620335461317, 'qqp_dev_eval_loss': 1.2625925540924072, 'qqp_dev_eval_acc': 0.8125, 'qqp_dev_eval_f1': 0.823529411764706, 'qqp_dev_eval_acc_and_f1': 0.818014705882353, 'qqp_test_eval_loss': 1.4162238836288452, 'qqp_test_eval_acc': 0.7510511996042543, 'qqp_test_eval_f1': 0.6844728674880091, 'qqp_test_eval_acc_and_f1': 0.7177620335461317, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-100-roberta-large-31807', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_09-31-08_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-100-roberta-large-31807', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias_eval_loss': 2.776113510131836, 'qnli_dev_prompt,bias_eval_acc': 0.625, 'qnli_test_prompt,bias_eval_loss': 3.0690486431121826, 'qnli_test_prompt,bias_eval_acc': 0.5350539996339008, 'qnli_dev_eval_loss': 2.776113510131836, 'qnli_dev_eval_acc': 0.625, 'qnli_test_eval_loss': 3.0690486431121826, 'qnli_test_eval_acc': 0.5350539996339008, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QNLI-16-prompt-100-roberta-large-6767', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_09-46-15_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-100-roberta-large-6767', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,adapter_eval_loss': 4.000194072723389, 'mnli_dev_prompt,adapter_eval_mnli/acc': 0.5833333333333334, 'mnli_test_prompt,adapter_eval_loss': 3.3898186683654785, 'mnli_test_prompt,adapter_eval_mnli/acc': 0.6049923586347428, 'mnli-mm_test_prompt,adapter_eval_loss': 3.2637438774108887, 'mnli-mm_test_prompt,adapter_eval_mnli-mm/acc': 0.6268307567127747, 'mnli_dev_eval_loss': 4.000194072723389, 'mnli_dev_eval_mnli/acc': 0.5833333333333334, 'mnli_test_eval_loss': 3.3898186683654785, 'mnli_test_eval_mnli/acc': 0.6049923586347428, 'mnli-mm_test_eval_loss': 3.2637438774108887, 'mnli-mm_test_eval_mnli-mm/acc': 0.6268307567127747, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-4210', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_09-47-21_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-4210', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,bias_eval_loss': 1.0998302698135376, 'qqp_dev_prompt,bias_eval_acc': 0.78125, 'qqp_dev_prompt,bias_eval_f1': 0.8108108108108109, 'qqp_dev_prompt,bias_eval_acc_and_f1': 0.7960304054054055, 'qqp_test_prompt,bias_eval_loss': 1.3896095752716064, 'qqp_test_prompt,bias_eval_acc': 0.7292604501607717, 'qqp_test_prompt,bias_eval_f1': 0.6805952728333818, 'qqp_test_prompt,bias_eval_acc_and_f1': 0.7049278614970768, 'qqp_dev_eval_loss': 1.0998302698135376, 'qqp_dev_eval_acc': 0.78125, 'qqp_dev_eval_f1': 0.8108108108108109, 'qqp_dev_eval_acc_and_f1': 0.7960304054054055, 'qqp_test_eval_loss': 1.3896095752716064, 'qqp_test_eval_acc': 0.7292604501607717, 'qqp_test_eval_f1': 0.6805952728333818, 'qqp_test_eval_acc_and_f1': 0.7049278614970768, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-100-roberta-large-12221', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_09-55-57_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-100-roberta-large-12221', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias,adapter_eval_loss': 0.6943245530128479, 'qnli_dev_bias,adapter_eval_acc': 0.5, 'qnli_test_bias,adapter_eval_loss': 0.6948670148849487, 'qnli_test_bias,adapter_eval_acc': 0.4946000366099213, 'qnli_dev_eval_loss': 0.6943245530128479, 'qnli_dev_eval_acc': 0.5, 'qnli_test_eval_loss': 0.6948670148849487, 'qnli_test_eval_acc': 0.4946000366099213, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--42-roberta-large-5784', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_10-12-28_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--42-roberta-large-5784', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias,adapter_eval_loss': 0.6942287683486938, 'qqp_dev_bias,adapter_eval_acc': 0.5, 'qqp_dev_bias,adapter_eval_f1': 0.6666666666666666, 'qqp_dev_bias,adapter_eval_acc_and_f1': 0.5833333333333333, 'qqp_test_bias,adapter_eval_loss': 0.7065408229827881, 'qqp_test_bias,adapter_eval_acc': 0.36816720257234725, 'qqp_test_bias,adapter_eval_f1': 0.5381903642773208, 'qqp_test_bias,adapter_eval_acc_and_f1': 0.45317878342483403, 'qqp_dev_eval_loss': 0.6942287683486938, 'qqp_dev_eval_acc': 0.5, 'qqp_dev_eval_f1': 0.6666666666666666, 'qqp_dev_eval_acc_and_f1': 0.5833333333333333, 'qqp_test_eval_loss': 0.7065408229827881, 'qqp_test_eval_acc': 0.36816720257234725, 'qqp_test_eval_f1': 0.5381903642773208, 'qqp_test_eval_acc_and_f1': 0.45317878342483403, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16--42-roberta-large-2131', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_10-21-09_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--42-roberta-large-2131', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,adapter_eval_loss': 3.0506293773651123, 'mnli_dev_prompt,adapter_eval_mnli/acc': 0.6666666666666666, 'mnli_test_prompt,adapter_eval_loss': 3.3388333320617676, 'mnli_test_prompt,adapter_eval_mnli/acc': 0.5092205807437595, 'mnli-mm_test_prompt,adapter_eval_loss': 3.092433452606201, 'mnli-mm_test_prompt,adapter_eval_mnli-mm/acc': 0.5326484947111473, 'mnli_dev_eval_loss': 3.0506293773651123, 'mnli_dev_eval_mnli/acc': 0.6666666666666666, 'mnli_test_eval_loss': 3.3388333320617676, 'mnli_test_eval_mnli/acc': 0.5092205807437595, 'mnli-mm_test_eval_loss': 3.092433452606201, 'mnli-mm_test_eval_mnli-mm/acc': 0.5326484947111473, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-28602', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_10-15-49_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-28602', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias,adapter_eval_loss': 2.3993542194366455, 'qnli_dev_bias,adapter_eval_acc': 0.59375, 'qnli_test_bias,adapter_eval_loss': 2.63161039352417, 'qnli_test_bias,adapter_eval_acc': 0.5427420831045213, 'qnli_dev_eval_loss': 2.3993542194366455, 'qnli_dev_eval_acc': 0.59375, 'qnli_test_eval_loss': 2.63161039352417, 'qnli_test_eval_acc': 0.5427420831045213, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--42-roberta-large-31768', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_10-41-38_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--42-roberta-large-31768', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias,adapter_eval_loss': 1.128723382949829, 'qqp_dev_bias,adapter_eval_acc': 0.8125, 'qqp_dev_bias,adapter_eval_f1': 0.8125, 'qqp_dev_bias,adapter_eval_acc_and_f1': 0.8125, 'qqp_test_bias,adapter_eval_loss': 2.158630609512329, 'qqp_test_bias,adapter_eval_acc': 0.7162503091763542, 'qqp_test_bias,adapter_eval_f1': 0.614749143663107, 'qqp_test_bias,adapter_eval_acc_and_f1': 0.6654997264197307, 'qqp_dev_eval_loss': 1.128723382949829, 'qqp_dev_eval_acc': 0.8125, 'qqp_dev_eval_f1': 0.8125, 'qqp_dev_eval_acc_and_f1': 0.8125, 'qqp_test_eval_loss': 2.158630609512329, 'qqp_test_eval_acc': 0.7162503091763542, 'qqp_test_eval_f1': 0.614749143663107, 'qqp_test_eval_acc_and_f1': 0.6654997264197307, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16--42-roberta-large-11828', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_10-51-05_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--42-roberta-large-11828', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,adapter_eval_loss': 3.161029577255249, 'mnli_dev_prompt,adapter_eval_mnli/acc': 0.6458333333333334, 'mnli_test_prompt,adapter_eval_loss': 3.1978700160980225, 'mnli_test_prompt,adapter_eval_mnli/acc': 0.530922058074376, 'mnli-mm_test_prompt,adapter_eval_loss': 2.9030327796936035, 'mnli-mm_test_prompt,adapter_eval_mnli-mm/acc': 0.5528885272579332, 'mnli_dev_eval_loss': 3.161029577255249, 'mnli_dev_eval_mnli/acc': 0.6458333333333334, 'mnli_test_eval_loss': 3.1978700160980225, 'mnli_test_eval_mnli/acc': 0.530922058074376, 'mnli-mm_test_eval_loss': 2.9030327796936035, 'mnli-mm_test_eval_mnli-mm/acc': 0.5528885272579332, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-13661', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_10-56-49_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-13661', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias,adapter_eval_loss': 2.7633392810821533, 'qnli_dev_bias,adapter_eval_acc': 0.71875, 'qnli_test_bias,adapter_eval_loss': 2.850425958633423, 'qnli_test_bias,adapter_eval_acc': 0.5939959729086582, 'qnli_dev_eval_loss': 2.7633392810821533, 'qnli_dev_eval_acc': 0.71875, 'qnli_test_eval_loss': 2.850425958633423, 'qnli_test_eval_acc': 0.5939959729086582, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--42-roberta-large-23897', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_11-10-16_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--42-roberta-large-23897', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias,adapter_eval_loss': 2.207545280456543, 'qqp_dev_bias,adapter_eval_acc': 0.8125, 'qqp_dev_bias,adapter_eval_f1': 0.8333333333333334, 'qqp_dev_bias,adapter_eval_acc_and_f1': 0.8229166666666667, 'qqp_test_bias,adapter_eval_loss': 3.43389892578125, 'qqp_test_bias,adapter_eval_acc': 0.6789265396982439, 'qqp_test_bias,adapter_eval_f1': 0.6572854238720067, 'qqp_test_bias,adapter_eval_acc_and_f1': 0.6681059817851254, 'qqp_dev_eval_loss': 2.207545280456543, 'qqp_dev_eval_acc': 0.8125, 'qqp_dev_eval_f1': 0.8333333333333334, 'qqp_dev_eval_acc_and_f1': 0.8229166666666667, 'qqp_test_eval_loss': 3.43389892578125, 'qqp_test_eval_acc': 0.6789265396982439, 'qqp_test_eval_f1': 0.6572854238720067, 'qqp_test_eval_acc_and_f1': 0.6681059817851254, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16--42-roberta-large-1846', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_11-21-34_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--42-roberta-large-1846', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias,adapter_eval_loss': 1.992173433303833, 'qnli_dev_bias,adapter_eval_acc': 0.625, 'qnli_test_bias,adapter_eval_loss': 1.9267240762710571, 'qnli_test_bias,adapter_eval_acc': 0.5916163280248947, 'qnli_dev_eval_loss': 1.992173433303833, 'qnli_dev_eval_acc': 0.625, 'qnli_test_eval_loss': 1.9267240762710571, 'qnli_test_eval_acc': 0.5916163280248947, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--42-roberta-large-31251', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_11-39-29_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--42-roberta-large-31251', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,adapter_eval_loss': 1.2729960680007935, 'mnli_dev_prompt,adapter_eval_mnli/acc': 0.3333333333333333, 'mnli_test_prompt,adapter_eval_loss': 1.2613476514816284, 'mnli_test_prompt,adapter_eval_mnli/acc': 0.3273560876209883, 'mnli-mm_test_prompt,adapter_eval_loss': 1.2602483034133911, 'mnli-mm_test_prompt,adapter_eval_mnli-mm/acc': 0.3295362082994304, 'mnli_dev_eval_loss': 1.2729960680007935, 'mnli_dev_eval_mnli/acc': 0.3333333333333333, 'mnli_test_eval_loss': 1.2613476514816284, 'mnli_test_eval_mnli/acc': 0.3273560876209883, 'mnli-mm_test_eval_loss': 1.2602483034133911, 'mnli-mm_test_eval_mnli-mm/acc': 0.3295362082994304, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-433', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_11-38-03_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-433', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias,adapter_eval_loss': 2.6832494735717773, 'qqp_dev_bias,adapter_eval_acc': 0.78125, 'qqp_dev_bias,adapter_eval_f1': 0.7999999999999999, 'qqp_dev_bias,adapter_eval_acc_and_f1': 0.7906249999999999, 'qqp_test_bias,adapter_eval_loss': 3.1758999824523926, 'qqp_test_bias,adapter_eval_acc': 0.6545139747712095, 'qqp_test_bias,adapter_eval_f1': 0.6532101891851632, 'qqp_test_bias,adapter_eval_acc_and_f1': 0.6538620819781864, 'qqp_dev_eval_loss': 2.6832494735717773, 'qqp_dev_eval_acc': 0.78125, 'qqp_dev_eval_f1': 0.7999999999999999, 'qqp_dev_eval_acc_and_f1': 0.7906249999999999, 'qqp_test_eval_loss': 3.1758999824523926, 'qqp_test_eval_acc': 0.6545139747712095, 'qqp_test_eval_f1': 0.6532101891851632, 'qqp_test_eval_acc_and_f1': 0.6538620819781864, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16--42-roberta-large-14748', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_11-51-34_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--42-roberta-large-14748', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias,adapter_eval_loss': 3.015638828277588, 'qnli_dev_bias,adapter_eval_acc': 0.75, 'qnli_test_bias,adapter_eval_loss': 4.338083267211914, 'qnli_test_bias,adapter_eval_acc': 0.5063152114222954, 'qnli_dev_eval_loss': 3.015638828277588, 'qnli_dev_eval_acc': 0.75, 'qnli_test_eval_loss': 4.338083267211914, 'qnli_test_eval_acc': 0.5063152114222954, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--100-roberta-large-1115', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_12-09-14_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--100-roberta-large-1115', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias,adapter_eval_loss': 2.279545783996582, 'qqp_dev_bias,adapter_eval_acc': 0.75, 'qqp_dev_bias,adapter_eval_f1': 0.75, 'qqp_dev_bias,adapter_eval_acc_and_f1': 0.75, 'qqp_test_bias,adapter_eval_loss': 2.1203231811523438, 'qqp_test_bias,adapter_eval_acc': 0.7544892406628741, 'qqp_test_bias,adapter_eval_f1': 0.6910290730249642, 'qqp_test_bias,adapter_eval_acc_and_f1': 0.7227591568439191, 'qqp_dev_eval_loss': 2.279545783996582, 'qqp_dev_eval_acc': 0.75, 'qqp_dev_eval_f1': 0.75, 'qqp_dev_eval_acc_and_f1': 0.75, 'qqp_test_eval_loss': 2.1203231811523438, 'qqp_test_eval_acc': 0.7544892406628741, 'qqp_test_eval_f1': 0.6910290730249642, 'qqp_test_eval_acc_and_f1': 0.7227591568439191, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16--100-roberta-large-13366', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_12-22-46_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--100-roberta-large-13366', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,adapter_eval_loss': 2.2404627799987793, 'mnli_dev_prompt,adapter_eval_mnli/acc': 0.7291666666666666, 'mnli_test_prompt,adapter_eval_loss': 2.623929500579834, 'mnli_test_prompt,adapter_eval_mnli/acc': 0.6658176260825267, 'mnli-mm_test_prompt,adapter_eval_loss': 2.557530164718628, 'mnli-mm_test_prompt,adapter_eval_mnli-mm/acc': 0.6831773799837266, 'mnli_dev_eval_loss': 2.2404627799987793, 'mnli_dev_eval_mnli/acc': 0.7291666666666666, 'mnli_test_eval_loss': 2.623929500579834, 'mnli_test_eval_mnli/acc': 0.6658176260825267, 'mnli-mm_test_eval_loss': 2.557530164718628, 'mnli-mm_test_eval_mnli-mm/acc': 0.6831773799837266, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-16884', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_12-20-02_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-16884', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias,adapter_eval_loss': 2.019375801086426, 'qnli_dev_bias,adapter_eval_acc': 0.65625, 'qnli_test_bias,adapter_eval_loss': 2.7038955688476562, 'qnli_test_bias,adapter_eval_acc': 0.5584843492586491, 'qnli_dev_eval_loss': 2.019375801086426, 'qnli_dev_eval_acc': 0.65625, 'qnli_test_eval_loss': 2.7038955688476562, 'qnli_test_eval_acc': 0.5584843492586491, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--100-roberta-large-22960', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_12-38-34_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--100-roberta-large-22960', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias,adapter_eval_loss': 2.1638107299804688, 'qqp_dev_bias,adapter_eval_acc': 0.8125, 'qqp_dev_bias,adapter_eval_f1': 0.8421052631578948, 'qqp_dev_bias,adapter_eval_acc_and_f1': 0.8273026315789473, 'qqp_test_bias,adapter_eval_loss': 2.569108724594116, 'qqp_test_bias,adapter_eval_acc': 0.7527578530793965, 'qqp_test_bias,adapter_eval_f1': 0.715780494739835, 'qqp_test_bias,adapter_eval_acc_and_f1': 0.7342691739096157, 'qqp_dev_eval_loss': 2.1638107299804688, 'qqp_dev_eval_acc': 0.8125, 'qqp_dev_eval_f1': 0.8421052631578948, 'qqp_dev_eval_acc_and_f1': 0.8273026315789473, 'qqp_test_eval_loss': 2.569108724594116, 'qqp_test_eval_acc': 0.7527578530793965, 'qqp_test_eval_f1': 0.715780494739835, 'qqp_test_eval_acc_and_f1': 0.7342691739096157, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16--100-roberta-large-8224', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_12-53-42_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--100-roberta-large-8224', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias,adapter_eval_loss': 1.9018722772598267, 'qnli_dev_bias,adapter_eval_acc': 0.65625, 'qnli_test_bias,adapter_eval_loss': 2.2967605590820312, 'qnli_test_bias,adapter_eval_acc': 0.5802672524254073, 'qnli_dev_eval_loss': 1.9018722772598267, 'qnli_dev_eval_acc': 0.65625, 'qnli_test_eval_loss': 2.2967605590820312, 'qnli_test_eval_acc': 0.5802672524254073, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--100-roberta-large-8688', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_13-08-29_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--100-roberta-large-8688', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,adapter_eval_loss': 2.0129923820495605, 'mnli_dev_prompt,adapter_eval_mnli/acc': 0.625, 'mnli_test_prompt,adapter_eval_loss': 2.665043830871582, 'mnli_test_prompt,adapter_eval_mnli/acc': 0.5918492103922568, 'mnli-mm_test_prompt,adapter_eval_loss': 2.5389175415039062, 'mnli-mm_test_prompt,adapter_eval_mnli-mm/acc': 0.6060821806346623, 'mnli_dev_eval_loss': 2.0129923820495605, 'mnli_dev_eval_mnli/acc': 0.625, 'mnli_test_eval_loss': 2.665043830871582, 'mnli_test_eval_mnli/acc': 0.5918492103922568, 'mnli-mm_test_eval_loss': 2.5389175415039062, 'mnli-mm_test_eval_mnli-mm/acc': 0.6060821806346623, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-11940', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_13-00-45_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-11940', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias,adapter_eval_loss': 2.25113582611084, 'qqp_dev_bias,adapter_eval_acc': 0.75, 'qqp_dev_bias,adapter_eval_f1': 0.7894736842105263, 'qqp_dev_bias,adapter_eval_acc_and_f1': 0.7697368421052632, 'qqp_test_bias,adapter_eval_loss': 2.2515366077423096, 'qqp_test_bias,adapter_eval_acc': 0.7077170418006431, 'qqp_test_bias,adapter_eval_f1': 0.6768220976343498, 'qqp_test_bias,adapter_eval_acc_and_f1': 0.6922695697174964, 'qqp_dev_eval_loss': 2.25113582611084, 'qqp_dev_eval_acc': 0.75, 'qqp_dev_eval_f1': 0.7894736842105263, 'qqp_dev_eval_acc_and_f1': 0.7697368421052632, 'qqp_test_eval_loss': 2.2515366077423096, 'qqp_test_eval_acc': 0.7077170418006431, 'qqp_test_eval_f1': 0.6768220976343498, 'qqp_test_eval_acc_and_f1': 0.6922695697174964, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16--100-roberta-large-1123', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_13-24-16_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--100-roberta-large-1123', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_bias,adapter_eval_loss': 2.2653493881225586, 'qnli_dev_bias,adapter_eval_acc': 0.6875, 'qnli_test_bias,adapter_eval_loss': 3.0425355434417725, 'qnli_test_bias,adapter_eval_acc': 0.5701995240710233, 'qnli_dev_eval_loss': 2.2653493881225586, 'qnli_dev_eval_acc': 0.6875, 'qnli_test_eval_loss': 3.0425355434417725, 'qnli_test_eval_acc': 0.5701995240710233, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16--100-roberta-large-6213', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_13-38-01_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16--100-roberta-large-6213', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,adapter_eval_loss': 2.093773126602173, 'mnli_dev_prompt,adapter_eval_mnli/acc': 0.6041666666666666, 'mnli_test_prompt,adapter_eval_loss': 2.4295237064361572, 'mnli_test_prompt,adapter_eval_mnli/acc': 0.5879775853285787, 'mnli-mm_test_prompt,adapter_eval_loss': 2.355083465576172, 'mnli-mm_test_prompt,adapter_eval_mnli-mm/acc': 0.5993694060211554, 'mnli_dev_eval_loss': 2.093773126602173, 'mnli_dev_eval_mnli/acc': 0.6041666666666666, 'mnli_test_eval_loss': 2.4295237064361572, 'mnli_test_eval_mnli/acc': 0.5879775853285787, 'mnli-mm_test_eval_loss': 2.355083465576172, 'mnli-mm_test_eval_mnli-mm/acc': 0.5993694060211554, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-10781', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_13-41-14_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-10781', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias,adapter_eval_loss': 1.3265702724456787, 'qqp_dev_bias,adapter_eval_acc': 0.71875, 'qqp_dev_bias,adapter_eval_f1': 0.742857142857143, 'qqp_dev_bias,adapter_eval_acc_and_f1': 0.7308035714285714, 'qqp_test_bias,adapter_eval_loss': 1.3801069259643555, 'qqp_test_bias,adapter_eval_acc': 0.7129854068760821, 'qqp_test_bias,adapter_eval_f1': 0.6674309297260116, 'qqp_test_bias,adapter_eval_acc_and_f1': 0.6902081683010468, 'qqp_dev_eval_loss': 1.3265702724456787, 'qqp_dev_eval_acc': 0.71875, 'qqp_dev_eval_f1': 0.742857142857143, 'qqp_dev_eval_acc_and_f1': 0.7308035714285714, 'qqp_test_eval_loss': 1.3801069259643555, 'qqp_test_eval_acc': 0.7129854068760821, 'qqp_test_eval_f1': 0.6674309297260116, 'qqp_test_eval_acc_and_f1': 0.6902081683010468, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16--100-roberta-large-15011', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_13-54-43_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--100-roberta-large-15011', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias,adapter_eval_loss': 7.134557723999023, 'qnli_dev_prompt,bias,adapter_eval_acc': 0.53125, 'qnli_test_prompt,bias,adapter_eval_loss': 7.998316287994385, 'qnli_test_prompt,bias,adapter_eval_acc': 0.5059491122094087, 'qnli_dev_eval_loss': 7.134557723999023, 'qnli_dev_eval_acc': 0.53125, 'qnli_test_eval_loss': 7.998316287994385, 'qnli_test_eval_acc': 0.5059491122094087, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-42-roberta-large-27082', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_14-07-49_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-42-roberta-large-27082', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,bias,adapter_eval_loss': 0.7245093584060669, 'qqp_dev_prompt,bias,adapter_eval_acc': 0.5, 'qqp_dev_prompt,bias,adapter_eval_f1': 0.6666666666666666, 'qqp_dev_prompt,bias,adapter_eval_acc_and_f1': 0.5833333333333333, 'qqp_test_prompt,bias,adapter_eval_loss': 0.7908375859260559, 'qqp_test_prompt,bias,adapter_eval_acc': 0.36816720257234725, 'qqp_test_prompt,bias,adapter_eval_f1': 0.5381903642773208, 'qqp_test_prompt,bias,adapter_eval_acc_and_f1': 0.45317878342483403, 'qqp_dev_eval_loss': 0.7245093584060669, 'qqp_dev_eval_acc': 0.5, 'qqp_dev_eval_f1': 0.6666666666666666, 'qqp_dev_eval_acc_and_f1': 0.5833333333333333, 'qqp_test_eval_loss': 0.7908375859260559, 'qqp_test_eval_acc': 0.36816720257234725, 'qqp_test_eval_f1': 0.5381903642773208, 'qqp_test_eval_acc_and_f1': 0.45317878342483403, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16-prompt-42-roberta-large-20562', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_14-24-40_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-42-roberta-large-20562', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias_eval_loss': 4.3324174880981445, 'mnli_dev_prompt,bias_eval_mnli/acc': 0.625, 'mnli_test_prompt,bias_eval_loss': 4.225822925567627, 'mnli_test_prompt,bias_eval_mnli/acc': 0.5674987264391238, 'mnli-mm_test_prompt,bias_eval_loss': 3.9231820106506348, 'mnli-mm_test_prompt,bias_eval_mnli-mm/acc': 0.5912327095199349, 'mnli_dev_eval_loss': 4.3324174880981445, 'mnli_dev_eval_mnli/acc': 0.625, 'mnli_test_eval_loss': 4.225822925567627, 'mnli_test_eval_mnli/acc': 0.5674987264391238, 'mnli-mm_test_eval_loss': 3.9231820106506348, 'mnli-mm_test_eval_mnli-mm/acc': 0.5912327095199349, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-20199', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_14-24-14_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-20199', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias,adapter_eval_loss': 3.0601885318756104, 'qnli_dev_prompt,bias,adapter_eval_acc': 0.53125, 'qnli_test_prompt,bias,adapter_eval_loss': 3.7430057525634766, 'qnli_test_prompt,bias,adapter_eval_acc': 0.5053999633900788, 'qnli_dev_eval_loss': 3.0601885318756104, 'qnli_dev_eval_acc': 0.53125, 'qnli_test_eval_loss': 3.7430057525634766, 'qnli_test_eval_acc': 0.5053999633900788, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-42-roberta-large-30958', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_14-39-05_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-42-roberta-large-30958', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,bias,adapter_eval_loss': 2.322498321533203, 'qqp_dev_prompt,bias,adapter_eval_acc': 0.8125, 'qqp_dev_prompt,bias,adapter_eval_f1': 0.8333333333333334, 'qqp_dev_prompt,bias,adapter_eval_acc_and_f1': 0.8229166666666667, 'qqp_test_prompt,bias,adapter_eval_loss': 3.5651657581329346, 'qqp_test_prompt,bias,adapter_eval_acc': 0.7104872619342073, 'qqp_test_prompt,bias,adapter_eval_f1': 0.6718438980627435, 'qqp_test_prompt,bias,adapter_eval_acc_and_f1': 0.6911655799984754, 'qqp_dev_eval_loss': 2.322498321533203, 'qqp_dev_eval_acc': 0.8125, 'qqp_dev_eval_f1': 0.8333333333333334, 'qqp_dev_eval_acc_and_f1': 0.8229166666666667, 'qqp_test_eval_loss': 3.5651657581329346, 'qqp_test_eval_acc': 0.7104872619342073, 'qqp_test_eval_f1': 0.6718438980627435, 'qqp_test_eval_acc_and_f1': 0.6911655799984754, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16-prompt-42-roberta-large-15193', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_14-56-06_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-42-roberta-large-15193', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias_eval_loss': 3.4898569583892822, 'mnli_dev_prompt,bias_eval_mnli/acc': 0.6666666666666666, 'mnli_test_prompt,bias_eval_loss': 3.5004405975341797, 'mnli_test_prompt,bias_eval_mnli/acc': 0.546510443199185, 'mnli-mm_test_prompt,bias_eval_loss': 3.3639895915985107, 'mnli-mm_test_prompt,bias_eval_mnli-mm/acc': 0.5639747762408462, 'mnli_dev_eval_loss': 3.4898569583892822, 'mnli_dev_eval_mnli/acc': 0.6666666666666666, 'mnli_test_eval_loss': 3.5004405975341797, 'mnli_test_eval_mnli/acc': 0.546510443199185, 'mnli-mm_test_eval_loss': 3.3639895915985107, 'mnli-mm_test_eval_mnli-mm/acc': 0.5639747762408462, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-17367', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_15-02-24_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-17367', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias,adapter_eval_loss': 2.040200710296631, 'qnli_dev_prompt,bias,adapter_eval_acc': 0.625, 'qnli_test_prompt,bias,adapter_eval_loss': 2.207874298095703, 'qnli_test_prompt,bias,adapter_eval_acc': 0.5751418634449936, 'qnli_dev_eval_loss': 2.040200710296631, 'qnli_dev_eval_acc': 0.625, 'qnli_test_eval_loss': 2.207874298095703, 'qnli_test_eval_acc': 0.5751418634449936, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-42-roberta-large-19450', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_15-09-52_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-42-roberta-large-19450', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,bias,adapter_eval_loss': 1.9336330890655518, 'qqp_dev_prompt,bias,adapter_eval_acc': 0.8125, 'qqp_dev_prompt,bias,adapter_eval_f1': 0.8333333333333334, 'qqp_dev_prompt,bias,adapter_eval_acc_and_f1': 0.8229166666666667, 'qqp_test_prompt,bias,adapter_eval_loss': 3.140634775161743, 'qqp_test_prompt,bias,adapter_eval_acc': 0.6864951768488746, 'qqp_test_prompt,bias,adapter_eval_f1': 0.6675758608932832, 'qqp_test_prompt,bias,adapter_eval_acc_and_f1': 0.6770355188710789, 'qqp_dev_eval_loss': 1.9336330890655518, 'qqp_dev_eval_acc': 0.8125, 'qqp_dev_eval_f1': 0.8333333333333334, 'qqp_dev_eval_acc_and_f1': 0.8229166666666667, 'qqp_test_eval_loss': 3.140634775161743, 'qqp_test_eval_acc': 0.6864951768488746, 'qqp_test_eval_f1': 0.6675758608932832, 'qqp_test_eval_acc_and_f1': 0.6770355188710789, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16-prompt-42-roberta-large-17557', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_15-27-26_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-42-roberta-large-17557', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias,adapter_eval_loss': 2.5191667079925537, 'qnli_dev_prompt,bias,adapter_eval_acc': 0.65625, 'qnli_test_prompt,bias,adapter_eval_loss': 2.968590259552002, 'qnli_test_prompt,bias,adapter_eval_acc': 0.5914332784184514, 'qnli_dev_eval_loss': 2.5191667079925537, 'qnli_dev_eval_acc': 0.65625, 'qnli_test_eval_loss': 2.968590259552002, 'qnli_test_eval_acc': 0.5914332784184514, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-42-roberta-large-6946', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_15-40-59_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-42-roberta-large-6946', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias_eval_loss': 2.5562095642089844, 'mnli_dev_prompt,bias_eval_mnli/acc': 0.6666666666666666, 'mnli_test_prompt,bias_eval_loss': 2.383133888244629, 'mnli_test_prompt,bias_eval_mnli/acc': 0.555680081507896, 'mnli-mm_test_prompt,bias_eval_loss': 2.3155133724212646, 'mnli-mm_test_prompt,bias_eval_mnli-mm/acc': 0.5669243287225386, 'mnli_dev_eval_loss': 2.5562095642089844, 'mnli_dev_eval_mnli/acc': 0.6666666666666666, 'mnli_test_eval_loss': 2.383133888244629, 'mnli_test_eval_mnli/acc': 0.555680081507896, 'mnli-mm_test_eval_loss': 2.3155133724212646, 'mnli-mm_test_eval_mnli-mm/acc': 0.5669243287225386, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-2617', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_15-40-15_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-2617', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,bias,adapter_eval_loss': 1.0412874221801758, 'qqp_dev_prompt,bias,adapter_eval_acc': 0.71875, 'qqp_dev_prompt,bias,adapter_eval_f1': 0.742857142857143, 'qqp_dev_prompt,bias,adapter_eval_acc_and_f1': 0.7308035714285714, 'qqp_test_prompt,bias,adapter_eval_loss': 1.026078224182129, 'qqp_test_prompt,bias,adapter_eval_acc': 0.678802869156567, 'qqp_test_prompt,bias,adapter_eval_f1': 0.6566367001586462, 'qqp_test_prompt,bias,adapter_eval_acc_and_f1': 0.6677197846576066, 'qqp_dev_eval_loss': 1.0412874221801758, 'qqp_dev_eval_acc': 0.71875, 'qqp_dev_eval_f1': 0.742857142857143, 'qqp_dev_eval_acc_and_f1': 0.7308035714285714, 'qqp_test_eval_loss': 1.026078224182129, 'qqp_test_eval_acc': 0.678802869156567, 'qqp_test_eval_f1': 0.6566367001586462, 'qqp_test_eval_acc_and_f1': 0.6677197846576066, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16-prompt-42-roberta-large-8994', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_15-58-59_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-42-roberta-large-8994', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias_eval_loss': 2.214538812637329, 'mnli_dev_prompt,bias_eval_mnli/acc': 0.625, 'mnli_test_prompt,bias_eval_loss': 2.076543092727661, 'mnli_test_prompt,bias_eval_mnli/acc': 0.5370351502801833, 'mnli-mm_test_prompt,bias_eval_loss': 2.0132405757904053, 'mnli-mm_test_prompt,bias_eval_mnli-mm/acc': 0.552786818551668, 'mnli_dev_eval_loss': 2.214538812637329, 'mnli_dev_eval_mnli/acc': 0.625, 'mnli_test_eval_loss': 2.076543092727661, 'mnli_test_eval_mnli/acc': 0.5370351502801833, 'mnli-mm_test_eval_loss': 2.0132405757904053, 'mnli-mm_test_eval_mnli-mm/acc': 0.552786818551668, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-42-roberta-large-10763', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_16-16-43_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-42-roberta-large-10763', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias,adapter_eval_loss': 0.7211003303527832, 'qnli_dev_prompt,bias,adapter_eval_acc': 0.5, 'qnli_test_prompt,bias,adapter_eval_loss': 0.7185184359550476, 'qnli_test_prompt,bias,adapter_eval_acc': 0.5053999633900788, 'qnli_dev_eval_loss': 0.7211003303527832, 'qnli_dev_eval_acc': 0.5, 'qnli_test_eval_loss': 0.7185184359550476, 'qnli_test_eval_acc': 0.5053999633900788, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-100-roberta-large-20465', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_16-12-23_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-100-roberta-large-20465', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_eval_loss': 0.3679763078689575, 'sst-2_dev_eval_acc': 0.8360091743119266, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-full--13-roberta-large-13428', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_16-53-11_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-full--13-roberta-large-13428', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': None, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/original/SST-2', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-fulldata-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_eval_loss': 0.9839726686477661, 'mrpc_dev_eval_acc': 0.5049019607843137, 'mrpc_dev_eval_f1': 0.6188679245283017, 'mrpc_dev_eval_acc_and_f1': 0.5618849426563077, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-full--13-roberta-large-2981', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_16-55-50_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-full--13-roberta-large-2981', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': None, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mrpc', 'data_dir': 'data/original/MRPC', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-fulldata-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias_eval_loss': 1.9633163213729858, 'mnli_dev_prompt,bias_eval_mnli/acc': 0.6875, 'mnli_test_prompt,bias_eval_loss': 2.717170000076294, 'mnli_test_prompt,bias_eval_mnli/acc': 0.6114111054508405, 'mnli-mm_test_prompt,bias_eval_loss': 2.592017889022827, 'mnli-mm_test_prompt,bias_eval_mnli-mm/acc': 0.6193043124491456, 'mnli_dev_eval_loss': 1.9633163213729858, 'mnli_dev_eval_mnli/acc': 0.6875, 'mnli_test_eval_loss': 2.717170000076294, 'mnli_test_eval_mnli/acc': 0.6114111054508405, 'mnli-mm_test_eval_loss': 2.592017889022827, 'mnli-mm_test_eval_mnli-mm/acc': 0.6193043124491456, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-17366', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_16-37-41_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-17366', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,bias,adapter_eval_loss': 0.7031800150871277, 'qqp_dev_prompt,bias,adapter_eval_acc': 0.5, 'qqp_dev_prompt,bias,adapter_eval_f1': 0.6666666666666666, 'qqp_dev_prompt,bias,adapter_eval_acc_and_f1': 0.5833333333333333, 'qqp_test_prompt,bias,adapter_eval_loss': 0.7407114505767822, 'qqp_test_prompt,bias,adapter_eval_acc': 0.36816720257234725, 'qqp_test_prompt,bias,adapter_eval_f1': 0.538173666226746, 'qqp_test_prompt,bias,adapter_eval_acc_and_f1': 0.45317043439954663, 'qqp_dev_eval_loss': 0.7031800150871277, 'qqp_dev_eval_acc': 0.5, 'qqp_dev_eval_f1': 0.6666666666666666, 'qqp_dev_eval_acc_and_f1': 0.5833333333333333, 'qqp_test_eval_loss': 0.7407114505767822, 'qqp_test_eval_acc': 0.36816720257234725, 'qqp_test_eval_f1': 0.538173666226746, 'qqp_test_eval_acc_and_f1': 0.45317043439954663, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16-prompt-100-roberta-large-27986', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_16-30-47_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-100-roberta-large-27986', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_eval_loss': 1.3036892414093018, 'rte_dev_eval_acc': 0.5126353790613718, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-full--13-roberta-large-6483', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_17-13-55_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-full--13-roberta-large-6483', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': None, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'rte', 'data_dir': 'data/original/RTE', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-fulldata-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias,adapter_eval_loss': 1.3671016693115234, 'qnli_dev_prompt,bias,adapter_eval_acc': 0.6875, 'qnli_test_prompt,bias,adapter_eval_loss': 1.9248894453048706, 'qnli_test_prompt,bias,adapter_eval_acc': 0.6117517847336629, 'qnli_dev_eval_loss': 1.3671016693115234, 'qnli_dev_eval_acc': 0.6875, 'qnli_test_eval_loss': 1.9248894453048706, 'qnli_test_eval_acc': 0.6117517847336629, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-100-roberta-large-4300', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_16-43-52_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-100-roberta-large-4300', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias_eval_loss': 2.353886842727661, 'mnli_dev_prompt,bias_eval_mnli/acc': 0.6458333333333334, 'mnli_test_prompt,bias_eval_loss': 2.7311108112335205, 'mnli_test_prompt,bias_eval_mnli/acc': 0.6260825267447784, 'mnli-mm_test_prompt,bias_eval_loss': 2.7007601261138916, 'mnli-mm_test_prompt,bias_eval_mnli-mm/acc': 0.6302888527257934, 'mnli_dev_eval_loss': 2.353886842727661, 'mnli_dev_eval_mnli/acc': 0.6458333333333334, 'mnli_test_eval_loss': 2.7311108112335205, 'mnli_test_eval_mnli/acc': 0.6260825267447784, 'mnli-mm_test_eval_loss': 2.7007601261138916, 'mnli-mm_test_eval_mnli-mm/acc': 0.6302888527257934, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-25320', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_16-58-39_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-25320', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,bias,adapter_eval_loss': 2.4477391242980957, 'qqp_dev_prompt,bias,adapter_eval_acc': 0.75, 'qqp_dev_prompt,bias,adapter_eval_f1': 0.7777777777777777, 'qqp_dev_prompt,bias,adapter_eval_acc_and_f1': 0.7638888888888888, 'qqp_test_prompt,bias,adapter_eval_loss': 2.8216323852539062, 'qqp_test_prompt,bias,adapter_eval_acc': 0.7069502844422458, 'qqp_test_prompt,bias,adapter_eval_f1': 0.6824443848834092, 'qqp_test_prompt,bias,adapter_eval_acc_and_f1': 0.6946973346628276, 'qqp_dev_eval_loss': 2.4477391242980957, 'qqp_dev_eval_acc': 0.75, 'qqp_dev_eval_f1': 0.7777777777777777, 'qqp_dev_eval_acc_and_f1': 0.7638888888888888, 'qqp_test_eval_loss': 2.8216323852539062, 'qqp_test_eval_acc': 0.7069502844422458, 'qqp_test_eval_f1': 0.6824443848834092, 'qqp_test_eval_acc_and_f1': 0.6946973346628276, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16-prompt-100-roberta-large-28054', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_17-02-25_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-100-roberta-large-28054', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias_eval_loss': 1.897685170173645, 'mnli_dev_prompt,bias_eval_mnli/acc': 0.5833333333333334, 'mnli_test_prompt,bias_eval_loss': 1.9361289739608765, 'mnli_test_prompt,bias_eval_mnli/acc': 0.5708609271523178, 'mnli-mm_test_prompt,bias_eval_loss': 1.9443778991699219, 'mnli-mm_test_prompt,bias_eval_mnli-mm/acc': 0.5795362082994304, 'mnli_dev_eval_loss': 1.897685170173645, 'mnli_dev_eval_mnli/acc': 0.5833333333333334, 'mnli_test_eval_loss': 1.9361289739608765, 'mnli_test_eval_mnli/acc': 0.5708609271523178, 'mnli-mm_test_eval_loss': 1.9443778991699219, 'mnli-mm_test_eval_mnli-mm/acc': 0.5795362082994304, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-19375', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_17-19-25_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-19375', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias,adapter_eval_loss': 2.860903263092041, 'qnli_dev_prompt,bias,adapter_eval_acc': 0.6875, 'qnli_test_prompt,bias,adapter_eval_loss': 3.218906879425049, 'qnli_test_prompt,bias,adapter_eval_acc': 0.5579352004393191, 'qnli_dev_eval_loss': 2.860903263092041, 'qnli_dev_eval_acc': 0.6875, 'qnli_test_eval_loss': 3.218906879425049, 'qnli_test_eval_acc': 0.5579352004393191, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-100-roberta-large-29407', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_17-14-42_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-100-roberta-large-29407', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt_eval_loss': 0.7418691515922546, 'mrpc_dev_prompt_eval_acc': 0.6838235294117647, 'mrpc_dev_prompt_eval_f1': 0.8122270742358079, 'mrpc_dev_prompt_eval_acc_and_f1': 0.7480253018237863, 'mrpc_dev_eval_loss': 0.7418691515922546, 'mrpc_dev_eval_acc': 0.6838235294117647, 'mrpc_dev_eval_f1': 0.8122270742358079, 'mrpc_dev_eval_acc_and_f1': 0.7480253018237863, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-full-prompt-13-roberta-large-6164', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_16-56-40_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-full-prompt-13-roberta-large-6164', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mrpc', 'data_dir': 'data/original/MRPC', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-fulldata-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt_eval_loss': 0.14390039443969727, 'sst-2_dev_prompt_eval_acc': 0.9587155963302753, 'sst-2_dev_eval_loss': 0.14390039443969727, 'sst-2_dev_eval_acc': 0.9587155963302753, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-full-prompt-13-roberta-large-20784', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_16-54-00_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-full-prompt-13-roberta-large-20784', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/original/SST-2', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-fulldata-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_prompt,bias_eval_loss': 1.7378171682357788, 'mnli_dev_prompt,bias_eval_mnli/acc': 0.6041666666666666, 'mnli_test_prompt,bias_eval_loss': 1.8490301370620728, 'mnli_test_prompt,bias_eval_mnli/acc': 0.5658685685175752, 'mnli-mm_test_prompt,bias_eval_loss': 1.868882179260254, 'mnli-mm_test_prompt,bias_eval_mnli-mm/acc': 0.5735353946297803, 'mnli_dev_eval_loss': 1.7378171682357788, 'mnli_dev_eval_mnli/acc': 0.6041666666666666, 'mnli_test_eval_loss': 1.8490301370620728, 'mnli_test_eval_mnli/acc': 0.5658685685175752, 'mnli-mm_test_eval_loss': 1.868882179260254, 'mnli-mm_test_eval_mnli-mm/acc': 0.5735353946297803, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MNLI-16-prompt-100-roberta-large-8173', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_17-40-34_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16-prompt-100-roberta-large-8173', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,bias,adapter_eval_loss': 3.375040054321289, 'qqp_dev_prompt,bias,adapter_eval_acc': 0.8125, 'qqp_dev_prompt,bias,adapter_eval_f1': 0.8333333333333334, 'qqp_dev_prompt,bias,adapter_eval_acc_and_f1': 0.8229166666666667, 'qqp_test_prompt,bias,adapter_eval_loss': 4.16687536239624, 'qqp_test_prompt,bias,adapter_eval_acc': 0.7317091268859758, 'qqp_test_prompt,bias,adapter_eval_f1': 0.7070832545704949, 'qqp_test_prompt,bias,adapter_eval_acc_and_f1': 0.7193961907282354, 'qqp_dev_eval_loss': 3.375040054321289, 'qqp_dev_eval_acc': 0.8125, 'qqp_dev_eval_f1': 0.8333333333333334, 'qqp_dev_eval_acc_and_f1': 0.8229166666666667, 'qqp_test_eval_loss': 4.16687536239624, 'qqp_test_eval_acc': 0.7317091268859758, 'qqp_test_eval_f1': 0.7070832545704949, 'qqp_test_eval_acc_and_f1': 0.7193961907282354, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16-prompt-100-roberta-large-25134', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_17-33-36_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-100-roberta-large-25134', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qnli_dev_prompt,bias,adapter_eval_loss': 3.8470828533172607, 'qnli_dev_prompt,bias,adapter_eval_acc': 0.6875, 'qnli_test_prompt,bias,adapter_eval_loss': 3.5633723735809326, 'qnli_test_prompt,bias,adapter_eval_acc': 0.5524437122460186, 'qnli_dev_eval_loss': 3.8470828533172607, 'qnli_dev_eval_acc': 0.6875, 'qnli_test_eval_loss': 3.5633723735809326, 'qnli_test_eval_acc': 0.5524437122460186, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QNLI-16-prompt-100-roberta-large-10111', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_17-45-32_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QNLI-16-prompt-100-roberta-large-10111', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qnli', 'data_dir': 'data/k-shot/QNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias,adapter_eval_loss': 1.2903696298599243, 'mnli_dev_bias,adapter_eval_mnli/acc': 0.3333333333333333, 'mnli_test_bias,adapter_eval_loss': 1.3060094118118286, 'mnli_test_bias,adapter_eval_mnli/acc': 0.31818644931227713, 'mnli-mm_test_bias,adapter_eval_loss': 1.3064836263656616, 'mnli-mm_test_bias,adapter_eval_mnli-mm/acc': 0.318246541903987, 'mnli_dev_eval_loss': 1.2903696298599243, 'mnli_dev_eval_mnli/acc': 0.3333333333333333, 'mnli_test_eval_loss': 1.3060094118118286, 'mnli_test_eval_mnli/acc': 0.31818644931227713, 'mnli-mm_test_eval_loss': 1.3064836263656616, 'mnli-mm_test_eval_mnli-mm/acc': 0.318246541903987, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--42-roberta-large-32243', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_18-01-09_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--42-roberta-large-32243', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt,bias,adapter_eval_loss': 2.4050216674804688, 'qqp_dev_prompt,bias,adapter_eval_acc': 0.8125, 'qqp_dev_prompt,bias,adapter_eval_f1': 0.823529411764706, 'qqp_dev_prompt,bias,adapter_eval_acc_and_f1': 0.818014705882353, 'qqp_test_prompt,bias,adapter_eval_loss': 3.03749680519104, 'qqp_test_prompt,bias,adapter_eval_acc': 0.7350234974029186, 'qqp_test_prompt,bias,adapter_eval_f1': 0.691063240764772, 'qqp_test_prompt,bias,adapter_eval_acc_and_f1': 0.7130433690838454, 'qqp_dev_eval_loss': 2.4050216674804688, 'qqp_dev_eval_acc': 0.8125, 'qqp_dev_eval_f1': 0.823529411764706, 'qqp_dev_eval_acc_and_f1': 0.818014705882353, 'qqp_test_eval_loss': 3.03749680519104, 'qqp_test_eval_acc': 0.7350234974029186, 'qqp_test_eval_f1': 0.691063240764772, 'qqp_test_eval_acc_and_f1': 0.7130433690838454, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/QQP-16-prompt-100-roberta-large-2663', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_18-06-32_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-100-roberta-large-2663', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt,bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt_eval_loss': 0.5384612083435059, 'mrpc_dev_prompt_eval_acc': 0.7426470588235294, 'mrpc_dev_prompt_eval_f1': 0.8341232227488151, 'mrpc_dev_prompt_eval_acc_and_f1': 0.7883851407861723, 'mrpc_dev_eval_loss': 0.5384612083435059, 'mrpc_dev_eval_acc': 0.7426470588235294, 'mrpc_dev_eval_f1': 0.8341232227488151, 'mrpc_dev_eval_acc_and_f1': 0.7883851407861723, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-full-prompt-13-roberta-large-2664', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_17-49-55_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-full-prompt-13-roberta-large-2664', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mrpc', 'data_dir': 'data/original/MRPC', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-fulldata-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt_eval_loss': 0.7321170568466187, 'qqp_dev_prompt_eval_acc': 0.625, 'qqp_dev_prompt_eval_f1': 0.7000000000000001, 'qqp_dev_prompt_eval_acc_and_f1': 0.6625000000000001, 'qqp_test_prompt_eval_loss': 0.8627510070800781, 'qqp_test_prompt_eval_acc': 0.46599060103883255, 'qqp_test_prompt_eval_f1': 0.5331286220915146, 'qqp_test_prompt_eval_acc_and_f1': 0.4995596115651736, 'qqp_dev_eval_loss': 0.7321170568466187, 'qqp_dev_eval_acc': 0.625, 'qqp_dev_eval_f1': 0.7000000000000001, 'qqp_dev_eval_acc_and_f1': 0.6625000000000001, 'qqp_test_eval_loss': 0.8627510070800781, 'qqp_test_eval_acc': 0.46599060103883255, 'qqp_test_eval_f1': 0.5331286220915146, 'qqp_test_eval_acc_and_f1': 0.4995596115651736, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-42-roberta-large-25761', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_18-31-05_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-42-roberta-large-25761', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt_eval_loss': 0.14543496072292328, 'sst-2_dev_prompt_eval_acc': 0.9575688073394495, 'sst-2_dev_eval_loss': 0.14543496072292328, 'sst-2_dev_eval_acc': 0.9575688073394495, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-full-prompt-13-roberta-large-19849', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_17-51-44_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-full-prompt-13-roberta-large-19849', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/original/SST-2', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-fulldata-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt_eval_loss': 0.7443609237670898, 'qqp_dev_prompt_eval_acc': 0.625, 'qqp_dev_prompt_eval_f1': 0.6842105263157896, 'qqp_dev_prompt_eval_acc_and_f1': 0.6546052631578948, 'qqp_test_prompt_eval_loss': 0.8031127452850342, 'qqp_test_prompt_eval_acc': 0.5009893643334158, 'qqp_test_prompt_eval_f1': 0.55371955670582, 'qqp_test_prompt_eval_acc_and_f1': 0.5273544605196179, 'qqp_dev_eval_loss': 0.7443609237670898, 'qqp_dev_eval_acc': 0.625, 'qqp_dev_eval_f1': 0.6842105263157896, 'qqp_dev_eval_acc_and_f1': 0.6546052631578948, 'qqp_test_eval_loss': 0.8031127452850342, 'qqp_test_eval_acc': 0.5009893643334158, 'qqp_test_eval_f1': 0.55371955670582, 'qqp_test_eval_acc_and_f1': 0.5273544605196179, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-42-roberta-large-8357', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_18-44-45_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-42-roberta-large-8357', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt_eval_loss': 0.7097751498222351, 'rte_dev_prompt_eval_acc': 0.5776173285198556, 'rte_dev_eval_loss': 0.7097751498222351, 'rte_dev_eval_acc': 0.5776173285198556, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-full-prompt-13-roberta-large-1061', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 2, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_17-14-37_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-full-prompt-13-roberta-large-1061', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'rte', 'data_dir': 'data/original/RTE', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-fulldata-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias,adapter_eval_loss': 3.638766288757324, 'mnli_dev_bias,adapter_eval_mnli/acc': 0.5833333333333334, 'mnli_test_bias,adapter_eval_loss': 3.5176806449890137, 'mnli_test_bias,adapter_eval_mnli/acc': 0.584411614875191, 'mnli-mm_test_bias,adapter_eval_loss': 3.3262267112731934, 'mnli-mm_test_bias,adapter_eval_mnli-mm/acc': 0.5975386493083807, 'mnli_dev_eval_loss': 3.638766288757324, 'mnli_dev_eval_mnli/acc': 0.5833333333333334, 'mnli_test_eval_loss': 3.5176806449890137, 'mnli_test_eval_mnli/acc': 0.584411614875191, 'mnli-mm_test_eval_loss': 3.3262267112731934, 'mnli-mm_test_eval_mnli-mm/acc': 0.5975386493083807, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--42-roberta-large-12830', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_18-26-18_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--42-roberta-large-12830', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt_eval_loss': 0.7155321836471558, 'qqp_dev_prompt_eval_acc': 0.65625, 'qqp_dev_prompt_eval_f1': 0.7317073170731707, 'qqp_dev_prompt_eval_acc_and_f1': 0.6939786585365854, 'qqp_test_prompt_eval_loss': 0.9277049899101257, 'qqp_test_prompt_eval_acc': 0.4640366064803364, 'qqp_test_prompt_eval_f1': 0.5397701930633138, 'qqp_test_prompt_eval_acc_and_f1': 0.5019033997718251, 'qqp_dev_eval_loss': 0.7155321836471558, 'qqp_dev_eval_acc': 0.65625, 'qqp_dev_eval_f1': 0.7317073170731707, 'qqp_dev_eval_acc_and_f1': 0.6939786585365854, 'qqp_test_eval_loss': 0.9277049899101257, 'qqp_test_eval_acc': 0.4640366064803364, 'qqp_test_eval_f1': 0.5397701930633138, 'qqp_test_eval_acc_and_f1': 0.5019033997718251, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-42-roberta-large-21441', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_18-57-28_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-42-roberta-large-21441', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt_eval_loss': 0.6986018419265747, 'qqp_dev_prompt_eval_acc': 0.6875, 'qqp_dev_prompt_eval_f1': 0.75, 'qqp_dev_prompt_eval_acc_and_f1': 0.71875, 'qqp_test_prompt_eval_loss': 0.8485317826271057, 'qqp_test_prompt_eval_acc': 0.4187979223348998, 'qqp_test_prompt_eval_f1': 0.5356493557821517, 'qqp_test_prompt_eval_acc_and_f1': 0.4772236390585257, 'qqp_dev_eval_loss': 0.6986018419265747, 'qqp_dev_eval_acc': 0.6875, 'qqp_dev_eval_f1': 0.75, 'qqp_dev_eval_acc_and_f1': 0.71875, 'qqp_test_eval_loss': 0.8485317826271057, 'qqp_test_eval_acc': 0.4187979223348998, 'qqp_test_eval_f1': 0.5356493557821517, 'qqp_test_eval_acc_and_f1': 0.4772236390585257, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-42-roberta-large-30921', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_19-10-23_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-42-roberta-large-30921', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt_eval_loss': 0.8604977130889893, 'qqp_dev_prompt_eval_acc': 0.75, 'qqp_dev_prompt_eval_f1': 0.7647058823529411, 'qqp_dev_prompt_eval_acc_and_f1': 0.7573529411764706, 'qqp_test_prompt_eval_loss': 1.1238510608673096, 'qqp_test_prompt_eval_acc': 0.4896611427158051, 'qqp_test_prompt_eval_f1': 0.5023035916733, 'qqp_test_prompt_eval_acc_and_f1': 0.4959823671945525, 'qqp_dev_eval_loss': 0.8604977130889893, 'qqp_dev_eval_acc': 0.75, 'qqp_dev_eval_f1': 0.7647058823529411, 'qqp_dev_eval_acc_and_f1': 0.7573529411764706, 'qqp_test_eval_loss': 1.1238510608673096, 'qqp_test_eval_acc': 0.4896611427158051, 'qqp_test_eval_f1': 0.5023035916733, 'qqp_test_eval_acc_and_f1': 0.4959823671945525, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-100-roberta-large-18041', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_19-24-25_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-100-roberta-large-18041', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt_eval_loss': 0.7377265691757202, 'mrpc_dev_prompt_eval_acc': 0.6936274509803921, 'mrpc_dev_prompt_eval_f1': 0.8091603053435115, 'mrpc_dev_prompt_eval_acc_and_f1': 0.7513938781619518, 'mrpc_dev_eval_loss': 0.7377265691757202, 'mrpc_dev_eval_acc': 0.6936274509803921, 'mrpc_dev_eval_f1': 0.8091603053435115, 'mrpc_dev_eval_acc_and_f1': 0.7513938781619518, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-full-prompt-13-roberta-large-2695', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_18-42-06_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-full-prompt-13-roberta-large-2695', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mrpc', 'data_dir': 'data/original/MRPC', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-fulldata-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias,adapter_eval_loss': 3.6188552379608154, 'mnli_dev_bias,adapter_eval_mnli/acc': 0.6041666666666666, 'mnli_test_bias,adapter_eval_loss': 3.564178705215454, 'mnli_test_bias,adapter_eval_mnli/acc': 0.5427407030056036, 'mnli-mm_test_bias,adapter_eval_loss': 3.15028977394104, 'mnli-mm_test_bias,adapter_eval_mnli-mm/acc': 0.5718063466232709, 'mnli_dev_eval_loss': 3.6188552379608154, 'mnli_dev_eval_mnli/acc': 0.6041666666666666, 'mnli_test_eval_loss': 3.564178705215454, 'mnli_test_eval_mnli/acc': 0.5427407030056036, 'mnli-mm_test_eval_loss': 3.15028977394104, 'mnli-mm_test_eval_mnli-mm/acc': 0.5718063466232709, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--42-roberta-large-3030', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_19-09-12_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--42-roberta-large-3030', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt_eval_loss': 0.756227433681488, 'qqp_dev_prompt_eval_acc': 0.625, 'qqp_dev_prompt_eval_f1': 0.6666666666666665, 'qqp_dev_prompt_eval_acc_and_f1': 0.6458333333333333, 'qqp_test_prompt_eval_loss': 0.9414107203483582, 'qqp_test_prompt_eval_acc': 0.5037101162503091, 'qqp_test_prompt_eval_f1': 0.530698163957432, 'qqp_test_prompt_eval_acc_and_f1': 0.5172041401038705, 'qqp_dev_eval_loss': 0.756227433681488, 'qqp_dev_eval_acc': 0.625, 'qqp_dev_eval_f1': 0.6666666666666665, 'qqp_dev_eval_acc_and_f1': 0.6458333333333333, 'qqp_test_eval_loss': 0.9414107203483582, 'qqp_test_eval_acc': 0.5037101162503091, 'qqp_test_eval_f1': 0.530698163957432, 'qqp_test_eval_acc_and_f1': 0.5172041401038705, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-100-roberta-large-32381', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_19-38-25_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-100-roberta-large-32381', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt_eval_loss': 0.15363191068172455, 'sst-2_dev_prompt_eval_acc': 0.9472477064220184, 'sst-2_dev_eval_loss': 0.15363191068172455, 'sst-2_dev_eval_acc': 0.9472477064220184, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-full-prompt-13-roberta-large-31819', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_18-50-50_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-full-prompt-13-roberta-large-31819', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/original/SST-2', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-fulldata-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt_eval_loss': 0.8991175889968872, 'qqp_dev_prompt_eval_acc': 0.625, 'qqp_dev_prompt_eval_f1': 0.6470588235294118, 'qqp_dev_prompt_eval_acc_and_f1': 0.6360294117647058, 'qqp_test_prompt_eval_loss': 1.1942161321640015, 'qqp_test_prompt_eval_acc': 0.49799653722483306, 'qqp_test_prompt_eval_f1': 0.5063722151960307, 'qqp_test_prompt_eval_acc_and_f1': 0.5021843762104319, 'qqp_dev_eval_loss': 0.8991175889968872, 'qqp_dev_eval_acc': 0.625, 'qqp_dev_eval_f1': 0.6470588235294118, 'qqp_dev_eval_acc_and_f1': 0.6360294117647058, 'qqp_test_eval_loss': 1.1942161321640015, 'qqp_test_eval_acc': 0.49799653722483306, 'qqp_test_eval_f1': 0.5063722151960307, 'qqp_test_eval_acc_and_f1': 0.5021843762104319, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-100-roberta-large-20088', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_19-52-00_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-100-roberta-large-20088', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_prompt_eval_loss': 0.6776689887046814, 'qqp_dev_prompt_eval_acc': 0.65625, 'qqp_dev_prompt_eval_f1': 0.6206896551724138, 'qqp_dev_prompt_eval_acc_and_f1': 0.6384698275862069, 'qqp_test_prompt_eval_loss': 0.7218976020812988, 'qqp_test_prompt_eval_acc': 0.5027207519168934, 'qqp_test_prompt_eval_f1': 0.44231782752212145, 'qqp_test_prompt_eval_acc_and_f1': 0.4725192897195074, 'qqp_dev_eval_loss': 0.6776689887046814, 'qqp_dev_eval_acc': 0.65625, 'qqp_dev_eval_f1': 0.6206896551724138, 'qqp_dev_eval_acc_and_f1': 0.6384698275862069, 'qqp_test_eval_loss': 0.7218976020812988, 'qqp_test_eval_acc': 0.5027207519168934, 'qqp_test_eval_f1': 0.44231782752212145, 'qqp_test_eval_acc_and_f1': 0.4725192897195074, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16-prompt-100-roberta-large-16866', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_20-06-18_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16-prompt-100-roberta-large-16866', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias,adapter_eval_loss': 3.6062564849853516, 'mnli_dev_bias,adapter_eval_mnli/acc': 0.6041666666666666, 'mnli_test_bias,adapter_eval_loss': 3.4262163639068604, 'mnli_test_bias,adapter_eval_mnli/acc': 0.5226693835965359, 'mnli-mm_test_bias,adapter_eval_loss': 2.9652931690216064, 'mnli-mm_test_bias,adapter_eval_mnli-mm/acc': 0.5579739625711961, 'mnli_dev_eval_loss': 3.6062564849853516, 'mnli_dev_eval_mnli/acc': 0.6041666666666666, 'mnli_test_eval_loss': 3.4262163639068604, 'mnli_test_eval_mnli/acc': 0.5226693835965359, 'mnli-mm_test_eval_loss': 2.9652931690216064, 'mnli-mm_test_eval_mnli-mm/acc': 0.5579739625711961, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--42-roberta-large-17503', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 3e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_19-50-54_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--42-roberta-large-17503', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-42', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias_eval_loss': 2.2525720596313477, 'qqp_dev_bias_eval_acc': 0.71875, 'qqp_dev_bias_eval_f1': 0.6666666666666666, 'qqp_dev_bias_eval_acc_and_f1': 0.6927083333333333, 'qqp_test_bias_eval_loss': 3.617633819580078, 'qqp_test_bias_eval_acc': 0.5925797674993817, 'qqp_test_bias_eval_f1': 0.5077401231247385, 'qqp_test_bias_eval_acc_and_f1': 0.55015994531206, 'qqp_dev_eval_loss': 2.2525720596313477, 'qqp_dev_eval_acc': 0.71875, 'qqp_dev_eval_f1': 0.6666666666666666, 'qqp_dev_eval_acc_and_f1': 0.6927083333333333, 'qqp_test_eval_loss': 3.617633819580078, 'qqp_test_eval_acc': 0.5925797674993817, 'qqp_test_eval_f1': 0.5077401231247385, 'qqp_test_eval_acc_and_f1': 0.55015994531206, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16--42-roberta-large-8745', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_20-20-00_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--42-roberta-large-8745', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_prompt_eval_loss': 0.9625099301338196, 'mrpc_dev_prompt_eval_acc': 0.49019607843137253, 'mrpc_dev_prompt_eval_f1': 0.584, 'mrpc_dev_prompt_eval_acc_and_f1': 0.5370980392156862, 'mrpc_dev_eval_loss': 0.9625099301338196, 'mrpc_dev_eval_acc': 0.49019607843137253, 'mrpc_dev_eval_f1': 0.584, 'mrpc_dev_eval_acc_and_f1': 0.5370980392156862, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-full-prompt-13-roberta-large-4506', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_19-39-38_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-full-prompt-13-roberta-large-4506', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mrpc', 'data_dir': 'data/original/MRPC', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-fulldata-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt_eval_loss': 0.5192900896072388, 'rte_dev_prompt_eval_acc': 0.7653429602888087, 'rte_dev_eval_loss': 0.5192900896072388, 'rte_dev_eval_acc': 0.7653429602888087, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-full-prompt-13-roberta-large-28559', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 2, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_19-03-55_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-full-prompt-13-roberta-large-28559', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'rte', 'data_dir': 'data/original/RTE', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-fulldata-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias_eval_loss': 2.5038063526153564, 'qqp_dev_bias_eval_acc': 0.71875, 'qqp_dev_bias_eval_f1': 0.6666666666666666, 'qqp_dev_bias_eval_acc_and_f1': 0.6927083333333333, 'qqp_test_bias_eval_loss': 2.114741325378418, 'qqp_test_bias_eval_acc': 0.590155824882513, 'qqp_test_bias_eval_f1': 0.43038844963905126, 'qqp_test_bias_eval_acc_and_f1': 0.5102721372607821, 'qqp_dev_eval_loss': 2.5038063526153564, 'qqp_dev_eval_acc': 0.71875, 'qqp_dev_eval_f1': 0.6666666666666666, 'qqp_dev_eval_acc_and_f1': 0.6927083333333333, 'qqp_test_eval_loss': 2.114741325378418, 'qqp_test_eval_acc': 0.590155824882513, 'qqp_test_eval_f1': 0.43038844963905126, 'qqp_test_eval_acc_and_f1': 0.5102721372607821, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16--42-roberta-large-14234', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_20-36-18_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--42-roberta-large-14234', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_prompt_eval_loss': 0.3766925632953644, 'sst-2_dev_prompt_eval_acc': 0.8279816513761468, 'sst-2_dev_eval_loss': 0.3766925632953644, 'sst-2_dev_eval_acc': 0.8279816513761468, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-full-prompt-13-roberta-large-22165', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_19-56-16_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-full-prompt-13-roberta-large-22165', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/original/SST-2', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-fulldata-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias_eval_loss': 1.6371864080429077, 'qqp_dev_bias_eval_acc': 0.6875, 'qqp_dev_bias_eval_f1': 0.6666666666666666, 'qqp_dev_bias_eval_acc_and_f1': 0.6770833333333333, 'qqp_test_bias_eval_loss': 2.332536458969116, 'qqp_test_bias_eval_acc': 0.5525847143210487, 'qqp_test_bias_eval_f1': 0.4568683380873742, 'qqp_test_bias_eval_acc_and_f1': 0.5047265262042114, 'qqp_dev_eval_loss': 1.6371864080429077, 'qqp_dev_eval_acc': 0.6875, 'qqp_dev_eval_f1': 0.6666666666666666, 'qqp_dev_eval_acc_and_f1': 0.6770833333333333, 'qqp_test_eval_loss': 2.332536458969116, 'qqp_test_eval_acc': 0.5525847143210487, 'qqp_test_eval_f1': 0.4568683380873742, 'qqp_test_eval_acc_and_f1': 0.5047265262042114, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16--42-roberta-large-15256', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_20-53-16_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--42-roberta-large-15256', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias,adapter_eval_loss': 1.1864380836486816, 'mnli_dev_bias,adapter_eval_mnli/acc': 0.3333333333333333, 'mnli_test_bias,adapter_eval_loss': 1.1923162937164307, 'mnli_test_bias,adapter_eval_mnli/acc': 0.3273560876209883, 'mnli-mm_test_bias,adapter_eval_loss': 1.1948227882385254, 'mnli-mm_test_bias,adapter_eval_mnli-mm/acc': 0.3295362082994304, 'mnli_dev_eval_loss': 1.1864380836486816, 'mnli_dev_eval_mnli/acc': 0.3333333333333333, 'mnli_test_eval_loss': 1.1923162937164307, 'mnli_test_eval_mnli/acc': 0.3273560876209883, 'mnli-mm_test_eval_loss': 1.1948227882385254, 'mnli-mm_test_eval_mnli-mm/acc': 0.3295362082994304, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--100-roberta-large-622', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_20-33-06_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--100-roberta-large-622', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias_eval_loss': 0.8674933910369873, 'qqp_dev_bias_eval_acc': 0.75, 'qqp_dev_bias_eval_f1': 0.7333333333333334, 'qqp_dev_bias_eval_acc_and_f1': 0.7416666666666667, 'qqp_test_bias_eval_loss': 1.372469425201416, 'qqp_test_bias_eval_acc': 0.5521889685876824, 'qqp_test_bias_eval_f1': 0.46723361680840425, 'qqp_test_bias_eval_acc_and_f1': 0.5097112926980434, 'qqp_dev_eval_loss': 0.8674933910369873, 'qqp_dev_eval_acc': 0.75, 'qqp_dev_eval_f1': 0.7333333333333334, 'qqp_dev_eval_acc_and_f1': 0.7416666666666667, 'qqp_test_eval_loss': 1.372469425201416, 'qqp_test_eval_acc': 0.5521889685876824, 'qqp_test_eval_f1': 0.46723361680840425, 'qqp_test_eval_acc_and_f1': 0.5097112926980434, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16--42-roberta-large-12654', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_21-09-49_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--42-roberta-large-12654', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-42', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias_eval_loss': 0.6300148367881775, 'mrpc_dev_bias_eval_acc': 0.6838235294117647, 'mrpc_dev_bias_eval_f1': 0.8122270742358079, 'mrpc_dev_bias_eval_acc_and_f1': 0.7480253018237863, 'mrpc_dev_eval_loss': 0.6300148367881775, 'mrpc_dev_eval_acc': 0.6838235294117647, 'mrpc_dev_eval_f1': 0.8122270742358079, 'mrpc_dev_eval_acc_and_f1': 0.7480253018237863, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-full--13-roberta-large-16250', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_20-38-20_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-full--13-roberta-large-16250', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mrpc', 'data_dir': 'data/original/MRPC', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-fulldata-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias_eval_loss': 0.7578644752502441, 'qqp_dev_bias_eval_acc': 0.5, 'qqp_dev_bias_eval_f1': 0.6666666666666666, 'qqp_dev_bias_eval_acc_and_f1': 0.5833333333333333, 'qqp_test_bias_eval_loss': 0.8538713455200195, 'qqp_test_bias_eval_acc': 0.36816720257234725, 'qqp_test_bias_eval_f1': 0.5381903642773208, 'qqp_test_bias_eval_acc_and_f1': 0.45317878342483403, 'qqp_dev_eval_loss': 0.7578644752502441, 'qqp_dev_eval_acc': 0.5, 'qqp_dev_eval_f1': 0.6666666666666666, 'qqp_dev_eval_acc_and_f1': 0.5833333333333333, 'qqp_test_eval_loss': 0.8538713455200195, 'qqp_test_eval_acc': 0.36816720257234725, 'qqp_test_eval_f1': 0.5381903642773208, 'qqp_test_eval_acc_and_f1': 0.45317878342483403, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16--100-roberta-large-19676', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_21-26-04_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--100-roberta-large-19676', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias_eval_loss': 0.7803203463554382, 'qqp_dev_bias_eval_acc': 0.5, 'qqp_dev_bias_eval_f1': 0.6666666666666666, 'qqp_dev_bias_eval_acc_and_f1': 0.5833333333333333, 'qqp_test_bias_eval_loss': 0.8921329975128174, 'qqp_test_bias_eval_acc': 0.36816720257234725, 'qqp_test_bias_eval_f1': 0.5381903642773208, 'qqp_test_bias_eval_acc_and_f1': 0.45317878342483403, 'qqp_dev_eval_loss': 0.7803203463554382, 'qqp_dev_eval_acc': 0.5, 'qqp_dev_eval_f1': 0.6666666666666666, 'qqp_dev_eval_acc_and_f1': 0.5833333333333333, 'qqp_test_eval_loss': 0.8921329975128174, 'qqp_test_eval_acc': 0.36816720257234725, 'qqp_test_eval_f1': 0.5381903642773208, 'qqp_test_eval_acc_and_f1': 0.45317878342483403, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16--100-roberta-large-26758', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_21-42-21_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--100-roberta-large-26758', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias,adapter_eval_loss': 4.076100826263428, 'mnli_dev_bias,adapter_eval_mnli/acc': 0.6875, 'mnli_test_bias,adapter_eval_loss': 4.683804035186768, 'mnli_test_bias,adapter_eval_mnli/acc': 0.6828323993886908, 'mnli-mm_test_bias,adapter_eval_loss': 4.433382511138916, 'mnli-mm_test_bias,adapter_eval_mnli-mm/acc': 0.6983319772172498, 'mnli_dev_eval_loss': 4.076100826263428, 'mnli_dev_eval_mnli/acc': 0.6875, 'mnli_test_eval_loss': 4.683804035186768, 'mnli_test_eval_mnli/acc': 0.6828323993886908, 'mnli-mm_test_eval_loss': 4.433382511138916, 'mnli-mm_test_eval_mnli-mm/acc': 0.6983319772172498, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--100-roberta-large-8885', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_21-17-56_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--100-roberta-large-8885', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'sst-2_dev_bias_eval_loss': 0.6930884718894958, 'sst-2_dev_bias_eval_acc': 0.5091743119266054, 'sst-2_dev_eval_loss': 0.6930884718894958, 'sst-2_dev_eval_acc': 0.5091743119266054, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/SST-2-full--13-roberta-large-1391', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.01, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_20-59-25_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/SST-2-full--13-roberta-large-1391', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'sst-2', 'data_dir': 'data/original/SST-2', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*_It_was*mask*.*sep+*', 'mapping': "{'0':'terrible','1':'great'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-fulldata-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias_eval_loss': 5.042375087738037, 'qqp_dev_bias_eval_acc': 0.625, 'qqp_dev_bias_eval_f1': 0.7142857142857143, 'qqp_dev_bias_eval_acc_and_f1': 0.6696428571428572, 'qqp_test_bias_eval_loss': 4.870768070220947, 'qqp_test_bias_eval_acc': 0.5356913183279742, 'qqp_test_bias_eval_f1': 0.5851491712707182, 'qqp_test_bias_eval_acc_and_f1': 0.5604202447993463, 'qqp_dev_eval_loss': 5.042375087738037, 'qqp_dev_eval_acc': 0.625, 'qqp_dev_eval_f1': 0.7142857142857143, 'qqp_dev_eval_acc_and_f1': 0.6696428571428572, 'qqp_test_eval_loss': 4.870768070220947, 'qqp_test_eval_acc': 0.5356913183279742, 'qqp_test_eval_f1': 0.5851491712707182, 'qqp_test_eval_acc_and_f1': 0.5604202447993463, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16--100-roberta-large-25395', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_21-59-26_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--100-roberta-large-25395', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'rte_dev_prompt_eval_loss': 0.5789088606834412, 'rte_dev_prompt_eval_acc': 0.7364620938628159, 'rte_dev_eval_loss': 0.5789088606834412, 'rte_dev_eval_acc': 0.7364620938628159, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/RTE-full-prompt-13-roberta-large-31590', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 2, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_20-48-28_node1', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/RTE-full-prompt-13-roberta-large-31590', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['prompt'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'rte', 'data_dir': 'data/original/RTE', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*prompt*sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-fulldata-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'qqp_dev_bias_eval_loss': 1.5681861639022827, 'qqp_dev_bias_eval_acc': 0.6875, 'qqp_dev_bias_eval_f1': 0.7368421052631579, 'qqp_dev_bias_eval_acc_and_f1': 0.712171052631579, 'qqp_test_bias_eval_loss': 1.362994909286499, 'qqp_test_bias_eval_acc': 0.6247588424437299, 'qqp_test_bias_eval_f1': 0.6175795921453959, 'qqp_test_bias_eval_acc_and_f1': 0.6211692172945629, 'qqp_dev_eval_loss': 1.5681861639022827, 'qqp_dev_eval_acc': 0.6875, 'qqp_dev_eval_f1': 0.7368421052631579, 'qqp_dev_eval_acc_and_f1': 0.712171052631579, 'qqp_test_eval_loss': 1.362994909286499, 'qqp_test_eval_acc': 0.6247588424437299, 'qqp_test_eval_f1': 0.6175795921453959, 'qqp_test_eval_acc_and_f1': 0.6211692172945629, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/QQP-16--100-roberta-large-22791', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_22-16-09_node3', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/QQP-16--100-roberta-large-22791', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'qqp', 'data_dir': 'data/k-shot/QQP/16-100', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mrpc_dev_bias_eval_loss': 0.37260815501213074, 'mrpc_dev_bias_eval_acc': 0.9044117647058824, 'mrpc_dev_bias_eval_f1': 0.9273743016759777, 'mrpc_dev_bias_eval_acc_and_f1': 0.9158930331909301, 'mrpc_dev_eval_loss': 0.37260815501213074, 'mrpc_dev_eval_acc': 0.9044117647058824, 'mrpc_dev_eval_f1': 0.9273743016759777, 'mrpc_dev_eval_acc_and_f1': 0.9158930331909301, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': False, 'output_dir': 'result/MRPC-full--13-roberta-large-11190', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_21-37-14_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MRPC-full--13-roberta-large-11190', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 4), 'task_name': 'mrpc', 'data_dir': 'data/original/MRPC', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**mask*,*+sentl_1**sep+*', 'mapping': "{'0':'No','1':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-fulldata-Y', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'mnli_dev_bias,adapter_eval_loss': 2.140249252319336, 'mnli_dev_bias,adapter_eval_mnli/acc': 0.75, 'mnli_test_bias,adapter_eval_loss': 2.9374921321868896, 'mnli_test_bias,adapter_eval_mnli/acc': 0.6190524707080999, 'mnli-mm_test_bias,adapter_eval_loss': 2.692767381668091, 'mnli-mm_test_bias,adapter_eval_mnli-mm/acc': 0.6349674532139952, 'mnli_dev_eval_loss': 2.140249252319336, 'mnli_dev_eval_mnli/acc': 0.75, 'mnli_test_eval_loss': 2.9374921321868896, 'mnli_test_eval_mnli/acc': 0.6190524707080999, 'mnli-mm_test_eval_loss': 2.692767381668091, 'mnli-mm_test_eval_mnli-mm/acc': 0.6349674532139952, 'model_name_or_path': 'roberta-large', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'random_segment': False, 'prompt_num': 10, 'use_adapter': True, 'output_dir': 'result/MNLI-16--100-roberta-large-30583', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 6000, 'warmup_steps': 0, 'logging_dir': 'runs/Jan11_22-01-11_node2', 'logging_first_step': False, 'logging_steps': 200, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 100, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/MNLI-16--100-roberta-large-30583', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'training_params': ['bias,adapter'], 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'mnli', 'data_dir': 'data/k-shot/MNLI/16-100', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 4, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0**sep+**sent_1**sep+**mask**sep+*', 'mapping': "{'contradiction':'No','entailment':'Yes','neutral':'Maybe'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-N', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
